<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 3.9.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <link rel="alternate" href="/atom.xml" title="退思园" type="application/atom+xml">
  <meta name="google-site-verification" content="EDvvZZUFkxy_QUzZTaqwsG_9VHqFthY-NhQE4j6WL-s">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.5.0',
    exturl: false,
    sidebar: {"position":"right","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":true,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: 'LHD9LWONQ3',
      apiKey: '23a113c49e36d8cc93f61239cb530b43',
      indexName: 'gowa.club',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    sidebarPadding: 40
  };
</script>

  <meta name="description" content="LSTM（长短期记忆）是最常用的 RNN （递归神经网络了）。经常用于序列数据。关于它的详细介绍可以看这个 权威博客。本文章原文位于：这里">
<meta name="keywords" content="TensorFlow">
<meta property="og:type" content="article">
<meta property="og:title" content="TensorFlow中的LSTM了解">
<meta property="og:url" content="https://gowa.club/Python/TensorFlow中的LSTM了解.html">
<meta property="og:site_name" content="退思园">
<meta property="og:description" content="LSTM（长短期记忆）是最常用的 RNN （递归神经网络了）。经常用于序列数据。关于它的详细介绍可以看这个 权威博客。本文章原文位于：这里">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://gowa.club/res/Unrolled_RNN.png">
<meta property="og:image" content="https://gowa.club/res/num_units.png">
<meta property="og:image" content="https://gowa.club/res/lstm_unit.png">
<meta property="og:image" content="https://gowa.club/res/inputs.png">
<meta property="og:updated_time" content="2018-11-26T15:59:20.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="TensorFlow中的LSTM了解">
<meta name="twitter:description" content="LSTM（长短期记忆）是最常用的 RNN （递归神经网络了）。经常用于序列数据。关于它的详细介绍可以看这个 权威博客。本文章原文位于：这里">
<meta name="twitter:image" content="https://gowa.club/res/Unrolled_RNN.png">

<link rel="canonical" href="https://gowa.club/Python/TensorFlow中的LSTM了解.html">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>TensorFlow中的LSTM了解 | 退思园</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-137245514-1"></script>
    <script>
      var host = window.location.hostname;
      if (host !== "localhost" || !true) {
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'UA-137245514-1');
      }
    </script>






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">退思园</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">烦恼一般都是想太多了。</p>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>Home</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>About</a>

  </li>
        <li class="menu-item menu-item-soft">

    <a href="/soft/" rel="section"><i class="fa fa-fw fa-rocket"></i>soft</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input" id="search-input"></div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="algolia-results">
  <div id="algolia-stats"></div>
  <div id="algolia-hits"></div>
  <div id="algolia-pagination" class="algolia-pagination"></div>
</div>

  
</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://gowa.club/Python/TensorFlow中的LSTM了解.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Gowa2017 Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="退思园">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          TensorFlow中的LSTM了解
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-11-26 23:59:20" itemprop="dateCreated datePublished" datetime="2018-11-26T23:59:20+08:00">2018-11-26</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Python/" itemprop="url" rel="index">
                    <span itemprop="name">Python</span>
                  </a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Disqus: </span>
    
    <a title="disqus" href="/Python/TensorFlow中的LSTM了解.html#comments" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="Python/TensorFlow中的LSTM了解.html" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>LSTM（长短期记忆）是最常用的 RNN （递归神经网络了）。经常用于序列数据。关于它的详细介绍可以看这个 <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="noopener">权威博客</a>。本文章原文位于：<a href="https://jasdeep06.github.io/posts/Understanding-LSTM-in-Tensorflow-MNIST/" target="_blank" rel="noopener">这里</a></p>
<a id="more"></a>
<h1 id="MNIST-数据集"><a href="#MNIST-数据集" class="headerlink" title="MNIST 数据集"></a>MNIST 数据集</h1><p>MNIST 是一个手写数字识别的数据集。可以用代码来下载使用：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">"/tmp/data/"</span>, one_hot=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>数据分割为三个部分：</p>
<ol>
<li><em>mnist.train</em>  55000 个图片数据</li>
<li><em>mnist.test</em> 10000 的测试图片数据。</li>
<li><em>mnist.validation</em>  5000 个有效的图片数据。</li>
</ol>
<h2 id="数据形状"><a href="#数据形状" class="headerlink" title="数据形状"></a>数据形状</h2><p>让我们讨论关于MNIST数据集的训练数据的形状。所有三个部分数据的形状是相同的。</p>
<p>训练数据，55000 张图片，每张图片 28 X 28 pixels。这 784 个像素点放在一个维度是 784 的向量中。所以呢，训练数据的形状就是 <em>(55000,784)</em>，可通过 <em>mnist.train.images</em> 进行引用。</p>
<p> 55000 个训练图片中，每个都有一个对应的标签，表示了图片所数的类（是哪个数字）。这里有 10 个（ 0,1,2….）。类标签以一种热编码形式表示。</p>
<p> 标签在 numpy 数组中的形式为 <em>(55000,10)</em>，通过 <em>mnist.train.lables</em>。</p>
<h1 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h1><p>写代码前先画出一个概要，这有助于我们的代码更直观。</p>
<h2 id="vanilla-RNN"><a href="#vanilla-RNN" class="headerlink" title="vanilla RNN"></a>vanilla RNN</h2><p>把一个 RNN 进行展开的话，就是如下这样：</p>
<p><img src="../res/Unrolled_RNN.png" alt></p>
<p>在这里：</p>
<ol>
<li><script type="math/tex">X_t</script> 引用在 t 时刻的输入。</li>
<li><script type="math/tex">S_t</script> 引用在 t 时刻的隐藏状态。可以把它想象成我们网络的 <strong>记忆</strong>。</li>
<li><script type="math/tex">O_t</script> 引用 t 时刻的输出。</li>
<li><em>U, V, W</em> 表示在所有的时刻中共享的参数。使用同样参数的意义在于，我们的模型在每个时刻做的任务是一样的，只是输入不同。</li>
</ol>
<p>通过把 RNN 展开，我们达到了一个目的：在任何时刻，我们都会考虑前一时刻的输入，所以可以想象它是一个 <strong>前馈网络</strong>（由时刻之间的联系表示）</p>
<h2 id="两个要点"><a href="#两个要点" class="headerlink" title="两个要点"></a>两个要点</h2><p>我们的实施将取决于两个主要概念，这些概念将使我们对实施感到满意：</p>
<ol>
<li>TensorFlow 中对于 LSTM 神经元的解释。</li>
<li>传递数据给 TensorFlow RNN 前把数据格式化。</li>
</ol>
<h2 id="TensorFlow-中的-LSTM-神经元"><a href="#TensorFlow-中的-LSTM-神经元" class="headerlink" title="TensorFlow 中的 LSTM 神经元"></a>TensorFlow 中的 LSTM 神经元</h2><p>我们可以很简单的在 TensorFlow 中声明一个 LSTM 神经元：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">tf.contrib.rnn.BasicLSTMCell(num_units)</span><br></pre></td></tr></table></figure>
<p><em>num_units</em> 代表了 LSTM 神经元中的单元数。<br><em>num_units</em> 可以类比于前馈神经网络的隐藏层。在一个前馈神经网络中隐藏层的节点数<strong>等于</strong>这个网络中每个时刻 LSTM 神经元内 LSTM 中的单元数。下面的图片可能会减少我们的疑惑。</p>
<p><img src="../res/num_units.png" alt></p>
<p>num_units 的任何一个 LSTM 单元可以被看作是一个标准的 LSTM 单元：</p>
<p><img src="../res/lstm_unit.png" alt></p>
<h2 id="格式化输入"><a href="#格式化输入" class="headerlink" title="格式化输入"></a>格式化输入</h2><p>TensorFlow 中最简单的 RNN 就是 <em>static_rnn</em> 了。</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">tf.static_rnn(cell,inputs)</span><br></pre></td></tr></table></figure>
<p>其拥有很多参数，但现在我们只关注这两个。</p>
<p><em>inputs</em> 参数接受一个<strong>张量列表</strong>，形状为 <em>(batch_size, input_size)</em> 。列表的长度，就是这个网络展开的时刻数。就是说，在我们的网络中，一个输入就对应了一个时刻。</p>
<p>就我们的 MNIST 图片数据而言，我们的图片大小是 28 X 28。可以把图片看成是 28 行，每行有 28 pixels。我们会把我们的网络展开成 28 个时刻，这样，每个时刻我们就可以输入一行数据了（28 pixels, input_size，输入张量的维度），一个图片就会走完 28 个时刻。 如果我们提供了 <em>batch_size</em> 个图片数据，每个时刻都会提供 <em>batch_size</em> 条数据。下面的图片看得更清楚：</p>
<p><img src="../res/inputs.png" alt></p>
<p><em>static_rnn</em> 的输入是一个张量列表，形状 <em>(batch_size, num_units)</em>。列表的长度，就是网络展开的长度。在此实现中，我们将仅关注最终时间步的输出，因为当将图像的所有行提供给RNN时将生成预测结果，也就是最后一个时刻。</p>
<p>现在我们已经完成了所有繁重的工作，我们已经准备好编写代码。一旦上述概念清楚，编码部分就非常直接了。</p>
<h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><p>开始，让我们导入必要的依赖项，数据集并声明一些常量。我们将使用batch_size = 128 和 num_units = 128。</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.contrib <span class="keyword">import</span> rnn</span><br><span class="line"></span><br><span class="line"><span class="comment">#import mnist dataset</span></span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line">mnist=input_data.read_data_sets(<span class="string">"/tmp/data/"</span>,one_hot=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#define constants</span></span><br><span class="line"><span class="comment">#unrolled through 28 time steps</span></span><br><span class="line">time_steps=<span class="number">28</span></span><br><span class="line"><span class="comment">#hidden LSTM units</span></span><br><span class="line">num_units=<span class="number">128</span></span><br><span class="line"><span class="comment">#rows of 28 pixels</span></span><br><span class="line">n_input=<span class="number">28</span></span><br><span class="line"><span class="comment">#learning rate for adam</span></span><br><span class="line">learning_rate=<span class="number">0.001</span></span><br><span class="line"><span class="comment">#mnist is meant to be classified in 10 classes(0-9).</span></span><br><span class="line">n_classes=<span class="number">10</span></span><br><span class="line"><span class="comment">#size of batch</span></span><br><span class="line">batch_size=<span class="number">128</span></span><br></pre></td></tr></table></figure>
<p>现在让我们声明占位符和权重以及偏差变量，这些变量将用于将shape [batch_size，num_units]的输出转换为[batch_size，n_classes]，以便可以预测正确的类。</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">#weights and biases of appropriate shape to accomplish above task</span></span><br><span class="line">out_weights=tf.Variable(tf.random_normal([num_units,n_classes]))</span><br><span class="line">out_bias=tf.Variable(tf.random_normal([n_classes]))</span><br><span class="line"></span><br><span class="line"><span class="comment">#defining placeholders</span></span><br><span class="line"><span class="comment">#input image placeholder</span></span><br><span class="line"><span class="comment"># [None, time_steps, n_input] 代表了 批量数，网络展开时刻数，每个时刻输入数据的大小</span></span><br><span class="line">x=tf.placeholder(<span class="string">"float"</span>,[<span class="literal">None</span>,time_steps,n_input])</span><br><span class="line"><span class="comment">#input label placeholder</span></span><br><span class="line">y=tf.placeholder(<span class="string">"float"</span>,[<span class="literal">None</span>,n_classes])</span><br></pre></td></tr></table></figure>
<p>现在我们正在接收 shape [batch_size，time_steps，n_input] 的输入，我们需要将其转换为长度为 time_steps 的shape [batch_size，n_inputs]的张量列表，以便可以将其输入static_rnn。</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">#processing the input tensor from [batch_size,n_steps,n_input] to "time_steps" number of [batch_size,n_input] tensors</span></span><br><span class="line"><span class="comment"># 将 [batch_size,n_steps,n_input] 沿 time_steps 展开后，结果就是 [batch_size,n_input] 列表，大小是 time_steps。列表中每个元素都会被每个时刻当做输入。</span></span><br><span class="line">input=tf.unstack(x ,time_steps,<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>现在我们已经准备好定义我们的网络。我们将使用一层BasicLSTMCell并使用我们的static_rnn网络。</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">#defining the network</span></span><br><span class="line">lstm_layer=rnn.BasicLSTMCell(num_units,forget_bias=<span class="number">1</span>)</span><br><span class="line">outputs,_=rnn.static_rnn(lstm_layer,input,dtype=<span class="string">"float32"</span>)</span><br></pre></td></tr></table></figure>
<p>由于我们只考虑上一次时间步的输入，我们将从中生成我们的预测:</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">#converting last output of dimension [batch_size,num_units] to [batch_size,n_classes] by out_weight multiplication</span></span><br><span class="line">prediction=tf.matmul(outputs[<span class="number">-1</span>],out_weights)+out_bias</span><br></pre></td></tr></table></figure>
<p>定义损失，优化器和准确性。</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">#loss_function</span></span><br><span class="line">loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction,labels=y))</span><br><span class="line"><span class="comment">#optimization</span></span><br><span class="line">opt=tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)</span><br><span class="line"></span><br><span class="line"><span class="comment">#model evaluation</span></span><br><span class="line">correct_prediction=tf.equal(tf.argmax(prediction,<span class="number">1</span>),tf.argmax(y,<span class="number">1</span>))</span><br><span class="line">accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))</span><br></pre></td></tr></table></figure>
<p>现在我们已经定义了图表，我们可以运行它。</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">#initialize variables</span></span><br><span class="line">init=tf.global_variables_initializer()</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    iter=<span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> iter&lt;<span class="number">800</span>:</span><br><span class="line">        batch_x,batch_y=mnist.train.next_batch(batch_size=batch_size)</span><br><span class="line"></span><br><span class="line">        batch_x=batch_x.reshape((batch_size,time_steps,n_input))</span><br><span class="line"></span><br><span class="line">        sess.run(opt, feed_dict=&#123;x: batch_x, y: batch_y&#125;)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> iter %<span class="number">10</span>==<span class="number">0</span>:</span><br><span class="line">            acc=sess.run(accuracy,feed_dict=&#123;x:batch_x,y:batch_y&#125;)</span><br><span class="line">            los=sess.run(loss,feed_dict=&#123;x:batch_x,y:batch_y&#125;)</span><br><span class="line">            print(<span class="string">"For iter "</span>,iter)</span><br><span class="line">            print(<span class="string">"Accuracy "</span>,acc)</span><br><span class="line">            print(<span class="string">"Loss "</span>,los)</span><br><span class="line">            print(<span class="string">"__________________"</span>)</span><br><span class="line"></span><br><span class="line">        iter=iter+<span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>这里需要注意的一件重要事情是，我们的图像基本上被展平为一个维度784的矢量。函数next_batch（batch_size）必然返回这些784维向量的batch_size批量。因此，它们被重新整形为[batch_size，time_steps，n_input]，以便我们的占位符可以接受它们。</p>
<p>我们还可以计算出我们模型的测试精度 - </p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">#calculating test accuracy</span></span><br><span class="line">test_data = mnist.test.images[:<span class="number">128</span>].reshape((<span class="number">-1</span>, time_steps, n_input))</span><br><span class="line">test_label = mnist.test.labels[:<span class="number">128</span>]</span><br><span class="line">print(<span class="string">"Testing Accuracy:"</span>, sess.run(accuracy, feed_dict=&#123;x: test_data, y: test_label&#125;))</span><br></pre></td></tr></table></figure>
<p>在运行时，模型运行的测试精度为99.21％。<script src="https://unpkg.com/viz.js@2.1.2/viz.js"></script><script src="https://unpkg.com/viz.js@2.1.2/full.render.js"></script><script>let graphviz_engines = ["circo",    "dot",    "fdp",    "neato",    "osage",    "twopi"];function doGraphviz(engine) {    let domAllDot = document.querySelectorAll('.language-' + engine);    for (let i = 0; i < domAllDot.length; i++) {        let dom = domAllDot[i];        let graphSource = dom.innerText || dom.textContent;        try {           let viz = new Viz();             viz.renderSVGElement(graphSource, {engine: engine})                 .then(r => {            dom.innerHTML ='';dom.append(r); });        } catch (e) {            console.error("Error when parsing node:", dom, e);        }    }}let init = function () {    for (let i = 0; i < graphviz_engines.length; i++) {        doGraphviz(graphviz_engines[i]);    }};if (typeof window.addEventListener != "undefined") {    window.addEventListener("load", init, false);} else {    window.attachEvent("onload", init);}</script></p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/TensorFlow/" rel="tag"># TensorFlow</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
                <a href="/Java/Dagger与安卓.html" rel="next" title="Dagger与安卓">
                  <i class="fa fa-chevron-left"></i> Dagger与安卓
                </a>
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
                <a href="/Java/Poi中添加Anchor图片到Docx文档.html" rel="prev" title="Poi中添加Anchor图片到Docx文档">
                  Poi中添加Anchor图片到Docx文档 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          
    
  <div class="comments" id="comments">
    <div id="disqus_thread">
      <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
    </div>
  </div>
  

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#MNIST-数据集"><span class="nav-number">1.</span> <span class="nav-text">MNIST 数据集</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#数据形状"><span class="nav-number">1.1.</span> <span class="nav-text">数据形状</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#实现"><span class="nav-number">2.</span> <span class="nav-text">实现</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#vanilla-RNN"><span class="nav-number">2.1.</span> <span class="nav-text">vanilla RNN</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#两个要点"><span class="nav-number">2.2.</span> <span class="nav-text">两个要点</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#TensorFlow-中的-LSTM-神经元"><span class="nav-number">2.3.</span> <span class="nav-text">TensorFlow 中的 LSTM 神经元</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#格式化输入"><span class="nav-number">2.4.</span> <span class="nav-text">格式化输入</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#代码"><span class="nav-number">3.</span> <span class="nav-text">代码</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Gowa2017 Zhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">309</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">26</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">131</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="feed-link motion-element">
    <a href="/atom.xml" rel="alternate">
      <i class="fa fa-rss"></i>RSS
    </a>
  </div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/gowa2017" title="GitHub → https://github.com/gowa2017" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:shouzheng.zhang@gmail.com" title="E-Mail → mailto:shouzheng.zhang@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-json"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 2016 – 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Gowa2017 Zhang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> v3.9.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">Theme – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.5.0
  </div>

        












        
      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script>
<script src="/js/schemes/pisces.js"></script>
<script src="/js/next-boot.js"></script>



  




  
<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/instantsearch.js@2/dist/instantsearch.min.css">
<script src="//cdn.jsdelivr.net/npm/instantsearch.js@2/dist/instantsearch.min.js"></script><script src="/js/algolia-search.js"></script>














  

  
      
<script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    

  

<script>
  function loadCount() {
    var d = document, s = d.createElement('script');
    s.src = 'https://gowa-1.disqus.com/count.js';
    s.id = 'dsq-count-scr';
    (d.head || d.body).appendChild(s);
  }
  // defer loading until the whole page loading is completed
  window.addEventListener('load', loadCount, false);
</script>
<script>
  function loadComments() {
    if (window.DISQUS) {
      DISQUS.reset({
        reload: true,
        config: {page: {
            url: "https://gowa.club/Python/TensorFlow中的LSTM了解.html",
            identifier: "Python/TensorFlow中的LSTM了解.html",
            title: "TensorFlow中的LSTM了解"
          }
        }
      });
    } else {
      var d = document, s = d.createElement('script');
      s.src = 'https://gowa-1.disqus.com/embed.js';
      s.setAttribute('data-timestamp', '' + +new Date());
      (d.head || d.body).appendChild(s);
    }
  }
    window.addEventListener('load', loadComments, false);
</script>

</body>
</html>
