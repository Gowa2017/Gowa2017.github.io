<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 3.9.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <link rel="alternate" href="/atom.xml" title="退思园" type="application/atom+xml">
  <meta name="google-site-verification" content="EDvvZZUFkxy_QUzZTaqwsG_9VHqFthY-NhQE4j6WL-s">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.5.0',
    exturl: false,
    sidebar: {"position":"right","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":true,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: 'LHD9LWONQ3',
      apiKey: '23a113c49e36d8cc93f61239cb530b43',
      indexName: 'gowa.club',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    sidebarPadding: 40
  };
</script>

  <meta name="description" content="学习一个简单的例子，关于神经网络的，总是会看到关于 stack unstack 函数的使用。但这涉及到的东西实在是多，比如最基本的一个前提概念就是，Tensor 张量，非常难以理解这个东西。">
<meta name="keywords" content="TensorFlow,Python">
<meta property="og:type" content="article">
<meta property="og:title" content="TensorFlow中的张量的stack与unstack">
<meta property="og:url" content="https://gowa.club/Python/TensorFlow中张量的stack与unstack.html">
<meta property="og:site_name" content="退思园">
<meta property="og:description" content="学习一个简单的例子，关于神经网络的，总是会看到关于 stack unstack 函数的使用。但这涉及到的东西实在是多，比如最基本的一个前提概念就是，Tensor 张量，非常难以理解这个东西。">
<meta property="og:locale" content="zh-Hans">
<meta property="og:updated_time" content="2018-11-02T14:12:25.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="TensorFlow中的张量的stack与unstack">
<meta name="twitter:description" content="学习一个简单的例子，关于神经网络的，总是会看到关于 stack unstack 函数的使用。但这涉及到的东西实在是多，比如最基本的一个前提概念就是，Tensor 张量，非常难以理解这个东西。">

<link rel="canonical" href="https://gowa.club/Python/TensorFlow中张量的stack与unstack.html">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>TensorFlow中的张量的stack与unstack | 退思园</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-137245514-1"></script>
    <script>
      var host = window.location.hostname;
      if (host !== "localhost" || !true) {
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'UA-137245514-1');
      }
    </script>






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">退思园</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">烦恼一般都是想太多了。</p>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>Home</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>About</a>

  </li>
        <li class="menu-item menu-item-soft">

    <a href="/soft/" rel="section"><i class="fa fa-fw fa-rocket"></i>soft</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input" id="search-input"></div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="algolia-results">
  <div id="algolia-stats"></div>
  <div id="algolia-hits"></div>
  <div id="algolia-pagination" class="algolia-pagination"></div>
</div>

  
</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://gowa.club/Python/TensorFlow中张量的stack与unstack.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Gowa2017 Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="退思园">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          TensorFlow中的张量的stack与unstack
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-11-02 22:12:25" itemprop="dateCreated datePublished" datetime="2018-11-02T22:12:25+08:00">2018-11-02</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Python/" itemprop="url" rel="index">
                    <span itemprop="name">Python</span>
                  </a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Disqus: </span>
    
    <a title="disqus" href="/Python/TensorFlow中张量的stack与unstack.html#comments" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="Python/TensorFlow中张量的stack与unstack.html" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>学习一个简单的例子，关于神经网络的，总是会看到关于 stack unstack 函数的使用。但这涉及到的东西实在是多，比如最基本的一个前提概念就是，Tensor 张量，非常难以理解这个东西。</p>
<a id="more"></a>
<h1 id="张量"><a href="#张量" class="headerlink" title="张量"></a>张量</h1><p><a href="https://www.tensorflow.org/programmers_guide/tensors?hl=zh-cn" target="_blank" rel="noopener">张量 TensorFlow 定义</a></p>
<p>TensorFlow 框架涉及到两个重要的元素：<strong>张量</strong> 和 <strong>操作</strong> 。</p>
<p>按照定义，<strong>张量</strong> 是对矢量和矩阵向潜在更高维度的泛化。</p>
<p>我们在使用 TensorFlow 的时候，我们操作和传递的主要对象都是 <strong>张量，tf.Tensor</strong>。<strong>tf.Tensor</strong> 对象表示一个部分定义的计算，最终会产生一个值。TensorFlow 程序首先会构建一个 tf.Tensor 对象图，详细说明如何基于其他可用张量计算每个张量，然后运行该图的某些部分以获得期望的结果。</p>
<p>张量具有以下两个属性：</p>
<ul>
<li>数据类型</li>
<li>形状 shape</li>
</ul>
<p>张量中的每个元素具有相同的数据类型，且该数据类型一定是已知的。形状，即是张量的维数和每个维度的大小，可能只是部分已知。如果其输入的形状也完全已知，则大多数指令会生成形状完全已知的张量，但在某些情况下，只能在图的执行时间找到张量的形状。</p>
<p>以下是一些特殊的张量：</p>
<ul>
<li>tf.Variable</li>
<li>tf.constant</li>
<li>tf.placeholder</li>
<li>tf.SparseTensor</li>
</ul>
<p>除了 tf.Variable ，张量的值不变。因此，执行一个任务的时候，张量只有一个值。但重复评估同一张量可能会有不同的值。</p>
<h2 id="阶"><a href="#阶" class="headerlink" title="阶"></a>阶</h2><p><strong>张量</strong> 对象的 <strong>阶</strong> 是其本身的维数。其同义词包括：<strong>秩、等级或 n 维</strong>。 TensorFlow 中的阶与数学矩阵中的阶并不是同一概念。 TensorFlow中的每个阶都对应一个不同的数学实例。</p>
<p>张量的 <strong>形状</strong> 中元素数量与阶（维数）相等。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>阶</th>
<th>数学实例</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>标量（只有大小）</td>
</tr>
<tr>
<td>1</td>
<td>矢量（大小和方向）</td>
</tr>
<tr>
<td>2</td>
<td>矩阵（数据表）</td>
</tr>
<tr>
<td>3</td>
<td>3阶张量（数据立体）</td>
</tr>
<tr>
<td>n</td>
<td>n阶张量（自行想象）</td>
</tr>
</tbody>
</table>
</div>
<h3 id="0-阶"><a href="#0-阶" class="headerlink" title="0 阶"></a>0 阶</h3><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">mammal = tf.Variable(<span class="string">"Elephant"</span>, tf.string)</span><br><span class="line">ignition = tf.Variable(<span class="number">451</span>, tf.int16)</span><br><span class="line">floating = tf.Variable(<span class="number">3.14159265359</span>, tf.float64)</span><br><span class="line">its_complicated = tf.Variable(<span class="number">12.3</span> - <span class="number">4.85j</span>, tf.complex64)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意：字符串在 TensorFlow 中被视为单一项，而不是一连串字符串。TensorFlow 可以有标量字符串，字符串矢量，等等。</p>
</blockquote>
<h3 id="1-阶"><a href="#1-阶" class="headerlink" title="1 阶"></a>1 阶</h3><p>要建立 1 阶的 tf.Tensor 对象，可传递一个项目列表作为初值：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">mystr = tf.Variable([<span class="string">"Hello"</span>], tf.string)</span><br><span class="line">cool_numbers  = tf.Variable([<span class="number">3.14159</span>, <span class="number">2.71828</span>], tf.float32)</span><br><span class="line">first_primes = tf.Variable([<span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">11</span>], tf.int32)</span><br><span class="line">its_very_complicated = tf.Variable([<span class="number">12.3</span> - <span class="number">4.85j</span>, <span class="number">7.5</span> - <span class="number">6.23j</span>], tf.complex64)</span><br></pre></td></tr></table></figure>
<h3 id="更高阶"><a href="#更高阶" class="headerlink" title="更高阶"></a>更高阶</h3><p>2 阶 tf.Tensor 对象至少包含一行和一列：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">mymat = tf.Variable([[<span class="number">7</span>],[<span class="number">11</span>]], tf.int16)</span><br><span class="line">myxor = tf.Variable([[<span class="literal">False</span>, <span class="literal">True</span>],[<span class="literal">True</span>, <span class="literal">False</span>]], tf.bool)</span><br><span class="line">linear_squares = tf.Variable([[<span class="number">4</span>], [<span class="number">9</span>], [<span class="number">16</span>], [<span class="number">25</span>]], tf.int32)</span><br><span class="line">squarish_squares = tf.Variable([ [<span class="number">4</span>, <span class="number">9</span>], [<span class="number">16</span>, <span class="number">25</span>] ], tf.int32)</span><br><span class="line">rank_of_squares = tf.rank(squarish_squares)</span><br><span class="line">mymatC = tf.Variable([[<span class="number">7</span>],[<span class="number">11</span>]], tf.int32)</span><br></pre></td></tr></table></figure>
<p>同样，更高阶的张量由一个 n 维数组组成。例如，在图像处理过程中，会使用许多 4 阶张量，维度对应批次大小、图像宽度、图像高度和颜色通道。</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">my_image = tf.zeros([<span class="number">10</span>, <span class="number">299</span>, <span class="number">299</span>, <span class="number">3</span>])  <span class="comment"># batch x height x width x color</span></span><br></pre></td></tr></table></figure>
<h2 id="获取-tf-Tensor-对象的阶"><a href="#获取-tf-Tensor-对象的阶" class="headerlink" title="获取 tf.Tensor 对象的阶"></a>获取 tf.Tensor 对象的阶</h2><p>要确定 tf.Tensor 对象的阶，需调用 tf.rank 方法。例如，以下方法以编程方式确定上一章节中所定义的 tf.Tensor 的阶：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">r = tf.rank(my_image)</span><br><span class="line"><span class="comment"># After the graph runs, r will hold the value 4.</span></span><br></pre></td></tr></table></figure>
<h2 id="引用-tf-Tensor-切片"><a href="#引用-tf-Tensor-切片" class="headerlink" title="引用 tf.Tensor 切片"></a>引用 tf.Tensor 切片</h2><p>由于 tf.Tensor 是 n 维单元数组，要访问 tf.Tensor 中的某一单元，需要指定 n 个索引。</p>
<p>0 阶张量（标量）不需要索引，因为其本身便是单一数字。</p>
<p>对于 1 阶张量（矢量）来说，通过传递单一索引可以访问某个数字：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">my_scalar = my_vector[<span class="number">2</span>]</span><br></pre></td></tr></table></figure>
<p>请注意，如果想从矢量中动态地选择元素，那么在 [] 内传递的索引本身可以是一个标量 tf.Tensor。</p>
<p>对于 2 阶及以上的张量来说，情况更为有趣。对于 2 阶 tf.Tensor 来说，传递两个数字会如预期般返回一个标量：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">my_scalar = my_matrix[<span class="number">1</span>, <span class="number">2</span>]</span><br></pre></td></tr></table></figure>
<p>而传递一个数字则会返回一个矩阵子矢量，如下所示：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">my_row_vector = my_matrix[<span class="number">2</span>]</span><br><span class="line">my_column_vector = my_matrix[:, <span class="number">3</span>]</span><br></pre></td></tr></table></figure>
<p>符号 <strong>:</strong> 是 Python 切片语法，意味“不要触碰该维度”。这对更高阶的张量来说很有用，可以帮助访问其子矢量，子矩阵，甚至其他子张量。</p>
<h2 id="形状"><a href="#形状" class="headerlink" title="形状"></a>形状</h2><p>张量的<strong>形状</strong>是每个维度中元素的数量。TensorFlow 在图的构建过程中自动推理形状。这些推理的形状可能具有已知或未知的阶。如果阶已知，则每个维度的大小可能已知或未知。</p>
<p>TensorFlow 文件编制中通过三种符号约定来描述张量维度：阶，形状和维数。下表阐述了三者如何相互关联：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>阶</th>
<th>形状</th>
<th>维度</th>
<th>示例</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>[]</td>
<td>0-D</td>
<td>0维张量。标量</td>
</tr>
<tr>
<td>1</td>
<td>[D0]</td>
<td>1-D</td>
<td>形状为[5]的1维张量</td>
</tr>
<tr>
<td>2</td>
<td>[D0,D1]</td>
<td>2-D</td>
<td>形状为[3,4]的2维张量</td>
</tr>
<tr>
<td>3</td>
<td>[D0, D1, D2]</td>
<td>3-D</td>
<td>形状为[1,4,3]的3维张量</td>
</tr>
<tr>
<td>n</td>
<td>[D0, D1,  …. Dn-1]</td>
<td>n维</td>
<td>形状为 [D0,D1,…Dn-1]的张量</td>
</tr>
</tbody>
</table>
</div>
<p>形状包含了两个属性，<em>dims, ndim</em></p>
<h3 id="tf-TensorShape"><a href="#tf-TensorShape" class="headerlink" title="tf.TensorShape"></a>tf.TensorShape</h3><p>此是形状在内部的实现。<a href="https://www.tensorflow.org/api_docs/python/tf/TensorShape" target="_blank" rel="noopener">https://www.tensorflow.org/api_docs/python/tf/TensorShape</a></p>
<h3 id="tf-shape"><a href="#tf-shape" class="headerlink" title="tf.shape()"></a>tf.shape()</h3><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">tf.shape(</span><br><span class="line">    input,</span><br><span class="line">    name=<span class="literal">None</span>,</span><br><span class="line">    out_type=tf.int32</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>返回张量的形状。</p>
<p>这个操作会返回一个 1-D 整数张量，代表了 <em>input</em> 的形状。</p>
<p>例如：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">t = tf.constant([[[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], [<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>]], [[<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>]]])</span><br><span class="line">tf.shape(t)  <span class="comment"># [2, 2, 3]</span></span><br></pre></td></tr></table></figure>
<h1 id="tf-concat"><a href="#tf-concat" class="headerlink" title="tf.concat()"></a>tf.concat()</h1><p>要了解 <code>tf.stack()</code> 就必须要了解 <code>tf.concat()</code>。这函数会沿某一维度拼接张量。</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">tf.concat(</span><br><span class="line">    values,</span><br><span class="line">    axis,</span><br><span class="line">    name=<span class="string">'concat'</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>沿 <em>axis</em> 维度连接 <em>values</em> 中的张量列表。如果 <em>values[i].shape=[D0, D1, … Daxis(i), … Dn]</em> 那么结果就是：<br>[D0, D1, … Raxis, …Dn]<br>其中<br>Raxis = sum(Daxis(i))</p>
</blockquote>
<p>这也就是说，输入张量内的数据沿 <em>axis</em> 维度连接了。</p>
<p>输入张量的维数必匹配，除了 <em>axis</em> 外的维度必须相等。</p>
<p>例如：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">t1 = [[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]]</span><br><span class="line">t2 = [[<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>], [<span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>]]</span><br><span class="line">tf.concat([t1, t2], <span class="number">0</span>)  <span class="comment"># [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]]</span></span><br><span class="line">tf.concat([t1, t2], <span class="number">1</span>)  <span class="comment"># [[1, 2, 3, 7, 8, 9], [4, 5, 6, 10, 11, 12]]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># tensor t3 with shape [2, 3]</span></span><br><span class="line"><span class="comment"># tensor t4 with shape [2, 3]</span></span><br><span class="line">tf.shape(tf.concat([t3, t4], <span class="number">0</span>))  <span class="comment"># [4, 3]</span></span><br><span class="line">tf.shape(tf.concat([t3, t4], <span class="number">1</span>))  <span class="comment"># [2, 6]</span></span><br></pre></td></tr></table></figure>
<p>而：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">tf.concat([tf.expand_dims(t, axis) <span class="keyword">for</span> t <span class="keyword">in</span> tensors], axis)</span><br><span class="line">tf.stack(tensors, axis=axis)</span><br></pre></td></tr></table></figure>
<p>这两者是相等的。</p>
<h1 id="tf-stack"><a href="#tf-stack" class="headerlink" title="tf.stack()"></a>tf.stack()</h1><p><a href="https://www.tensorflow.org/api_docs/python/tf/stack" target="_blank" rel="noopener">官方定义</a></p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">tf.stack(</span><br><span class="line">    values,</span><br><span class="line">    axis=<span class="number">0</span>,</span><br><span class="line">    name=<span class="string">'stack'</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>把一个 R 阶的张量列表堆成一个 R+1 阶的张量。</p>
<p>通过沿 <em>axis</em> 方向，将 <em>values</em> 中的张量列表打包到一个比 <em>values</em> 中的任何一个张量高一阶的张量中。现在给定一个长度为 <em>N</em> 的列表，其中的张量形状为 <em>(A, B, C)</em>。</p>
<ul>
<li>如果 <em>axis == 0</em> ，输出张量的形状是 <em>(N, A, B, C)</em></li>
<li>如果 <em>axis == 1</em> ，输出张量的形状是 <em>(A, N, B, C)</em><br>…….<br>…….</li>
</ul>
<p>例如：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">x = tf.constant([<span class="number">1</span>, <span class="number">4</span>])</span><br><span class="line">y = tf.constant([<span class="number">2</span>, <span class="number">5</span>])</span><br><span class="line">z = tf.constant([<span class="number">3</span>, <span class="number">6</span>])</span><br><span class="line">tf.stack([x, y, z])  <span class="comment"># [[1, 4], [2, 5], [3, 6]] (Pack along first dim.)</span></span><br><span class="line">tf.stack([x, y, z], axis=<span class="number">1</span>)  <span class="comment"># [[1, 2, 3], [4, 5, 6]]</span></span><br></pre></td></tr></table></figure>
<p>理解的时候，我把 <em>[x, y, z]</em> 理解为一个张量了，而其实上，我不应该混淆，<strong>张量</strong> 与其在 Python 中的阵列实现混为一谈。这个时候，其只是作为一个 张量列表 传递给 stack() 函数的。</p>
<p>列表中的张量其形状都是 <em>[2]</em>， 列表长度为 <em>3</em>，那么，stack() 后的张量形状应该为 <em>[3,2]</em>。而当 <em>axis = 1</em>，的时候，就应该是 <em>[2,3]</em></p>
<p>这与 unstack 是相反的操作。这与 ：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">tf.stack([x, y, z]) = np.stack([x, y, z])</span><br></pre></td></tr></table></figure>
<p>一致。</p>
<p>参数：</p>
<ul>
<li><strong>values</strong> 具有相同形状和类型的<strong>张量</strong>对象列表</li>
<li><strong>axis</strong> <em>int</em> 值。要压缩的轴方向。默认就是第一个。负值回绕，所以有效值就是 <em>[-(R+1), R+1)</em>。</li>
<li><strong>name</strong> 操作名称</li>
</ul>
<p>返回值：</p>
<ul>
<li><strong>output</strong> 与 <em>values</em> 类型相同的压缩后的 <strong>张量</strong> 。</li>
</ul>
<p>抛出：</p>
<ul>
<li><strong>ValueError</strong> 如果 <em>axis</em> 超过了范围 <em>[-(R+1), R+1)</em></li>
</ul>
<h1 id="tf-unstack"><a href="#tf-unstack" class="headerlink" title="tf.unstack()"></a>tf.unstack()</h1><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">tf.unstack(</span><br><span class="line">    value,</span><br><span class="line">    num=<span class="literal">None</span>,</span><br><span class="line">    axis=<span class="number">0</span>,</span><br><span class="line">    name=<span class="string">'unstack'</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>把 R 阶的张量解压为 R-1 阶。</p>
<p>通过沿 <em>axis</em> 方向解开，从 <em>value</em> 张量内解压出 <em>num</em> 个张量。如果没有指定 <em>num（默认情况）</em>，这会从 <em>value</em> 的形状去推测出来。但如果 <em>value.shape[axis]</em> 是未知的，就会抛出 <em>ValueError</em> 错误。</p>
<p>比如给出一个形状为 <strong>(A, B, C, D)</strong>的张量：</p>
<p>如果 <strong>axis==0</strong>，那么 <strong>输出</strong> 的第 <em>i</em> 个张量就是切片 <strong>value[i, :, :, :]</strong>，且输出中的每个张量形状都是 <strong>(B, C, D)</strong>。<strong>注意，解压的轴消失了。这和 <code>split</code> 不一样</strong>。</p>
<p>如果 <strong>axis==1</strong>，那么 <strong>输出</strong> 的第 <em>i</em> 个张量就是切片 <strong>value[:, i, :, :]</strong>，且输出中的每个张量形状都是 <strong>(A, C, D)</strong>。<strong>注意，解压的轴消失了。这和 <code>split</code> 不一样</strong>。</p>
<p>参数：</p>
<ul>
<li><strong>value</strong>: 一个 R &gt; 0 阶张量</li>
<li><strong>num</strong>: 轴的长度。</li>
<li><strong>axis</strong>: 解压的轴方向。</li>
<li><strong>name</strong>: 操作名称（可选）</li>
</ul>
<p>返回值：</p>
<p>一个从 <strong>value</strong> 解压出来的 张量列表。</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/TensorFlow/" rel="tag"># TensorFlow</a>
              <a href="/tags/Python/" rel="tag"># Python</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
                <a href="/Android/Android截图后相册没有立马到相册中.html" rel="next" title="Android截图后相册没有立马到相册中">
                  <i class="fa fa-chevron-left"></i> Android截图后相册没有立马到相册中
                </a>
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
                <a href="/macOS/macOS的networksetup命令来管理网络.html" rel="prev" title="macOS的networksetup命令来管理网络">
                  macOS的networksetup命令来管理网络 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          
    
  <div class="comments" id="comments">
    <div id="disqus_thread">
      <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
    </div>
  </div>
  

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#张量"><span class="nav-number">1.</span> <span class="nav-text">张量</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#阶"><span class="nav-number">1.1.</span> <span class="nav-text">阶</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#0-阶"><span class="nav-number">1.1.1.</span> <span class="nav-text">0 阶</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-阶"><span class="nav-number">1.1.2.</span> <span class="nav-text">1 阶</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#更高阶"><span class="nav-number">1.1.3.</span> <span class="nav-text">更高阶</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#获取-tf-Tensor-对象的阶"><span class="nav-number">1.2.</span> <span class="nav-text">获取 tf.Tensor 对象的阶</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#引用-tf-Tensor-切片"><span class="nav-number">1.3.</span> <span class="nav-text">引用 tf.Tensor 切片</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#形状"><span class="nav-number">1.4.</span> <span class="nav-text">形状</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-TensorShape"><span class="nav-number">1.4.1.</span> <span class="nav-text">tf.TensorShape</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-shape"><span class="nav-number">1.4.2.</span> <span class="nav-text">tf.shape()</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#tf-concat"><span class="nav-number">2.</span> <span class="nav-text">tf.concat()</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#tf-stack"><span class="nav-number">3.</span> <span class="nav-text">tf.stack()</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#tf-unstack"><span class="nav-number">4.</span> <span class="nav-text">tf.unstack()</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Gowa2017 Zhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">320</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">26</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">134</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="feed-link motion-element">
    <a href="/atom.xml" rel="alternate">
      <i class="fa fa-rss"></i>RSS
    </a>
  </div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/gowa2017" title="GitHub → https://github.com/gowa2017" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:shouzheng.zhang@gmail.com" title="E-Mail → mailto:shouzheng.zhang@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-json"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 2016 – 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Gowa2017 Zhang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> v3.9.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">Theme – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.5.0
  </div>

        












        
      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script>
<script src="/js/schemes/pisces.js"></script>
<script src="/js/next-boot.js"></script>



  




  
<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/instantsearch.js@2/dist/instantsearch.min.css">
<script src="//cdn.jsdelivr.net/npm/instantsearch.js@2/dist/instantsearch.min.js"></script><script src="/js/algolia-search.js"></script>














  

  

  

<script>
  function loadCount() {
    var d = document, s = d.createElement('script');
    s.src = 'https://gowa-1.disqus.com/count.js';
    s.id = 'dsq-count-scr';
    (d.head || d.body).appendChild(s);
  }
  // defer loading until the whole page loading is completed
  window.addEventListener('load', loadCount, false);
</script>
<script>
  function loadComments() {
    if (window.DISQUS) {
      DISQUS.reset({
        reload: true,
        config: {page: {
            url: "https://gowa.club/Python/TensorFlow中张量的stack与unstack.html",
            identifier: "Python/TensorFlow中张量的stack与unstack.html",
            title: "TensorFlow中的张量的stack与unstack"
          }
        }
      });
    } else {
      var d = document, s = d.createElement('script');
      s.src = 'https://gowa-1.disqus.com/embed.js';
      s.setAttribute('data-timestamp', '' + +new Date());
      (d.head || d.body).appendChild(s);
    }
  }
    window.addEventListener('load', loadComments, false);
</script>

</body>
</html>
