{"meta":{"title":"退思园","subtitle":"烦恼一般都是想太多了。","description":null,"author":"Gowa2017 Zhang","url":"https://gowa2017.github.io"},"pages":[{"title":"","date":"2019-01-17T06:24:19.033Z","updated":"2018-11-29T04:27:09.000Z","comments":true,"path":"googlef3b21893c4358bb6.html","permalink":"https://gowa2017.github.io/googlef3b21893c4358bb6.html","excerpt":"","text":"google-site-verification: googlef3b21893c4358bb6.html"},{"title":"Manual References","date":"2016-12-13T01:48:09.000Z","updated":"2017-12-22T05:46:14.000Z","comments":true,"path":"Manual-References/index.html","permalink":"https://gowa2017.github.io/Manual-References/index.html","excerpt":"","text":"数据交换设备华为防火墙E1000E华为BRAS ME60 LinuxBash文档-enBash文档-zh_CNAPUE 3rd edition-enAPUE 2nd edition-zh_CN 其他参考工具VIM参考手册-zh_CNgit版本管理工具-zh_CN TCP/IP 协议[TCP/IP详解 卷一：协议 第二版][41]"},{"title":"about","date":"2017-12-24T08:56:53.000Z","updated":"2019-03-05T02:13:54.748Z","comments":true,"path":"about/index.html","permalink":"https://gowa2017.github.io/about/index.html","excerpt":"","text":"工作这么多年，很多技能和知识其实都是在不断补充的。但要说我最开始也最有用学习到的知识，还应该感谢 W. Richard Stevens，他的大作 APUE/UNP/TCP/IP 都完整的了解过。对于更接近于系统层面的东西奠定了我的基础。 个人自评电子专业毕业，游戏狂魔出身。传奇世界，天龙八部，倩女幽魂始终不忘。由此而来的对于计算机的莫大兴趣，工作兴趣集于一身，岂不更好。系统层面的东西基础比较牢固，开发方面的知识有点软。崇尚定量工作，讨厌为了加班而加班。任务完成即可收工是最棒的企业理念。现而今勉勉强强算个小公司中型项目经理。 工作经历 2011-9 —— 2013-6 深圳华强北，国内一级手机渠道商，后面负责粤西几个地市运营商相关业务。始终不是我的梦想，转投IT行业了。 2013-11 —— 2016-6 东莞一家计算机企业干活。主攻 MySQL/Linux 环境相关。外加 Lua 做脚本逻辑开发。运维活，实在没有什么太大的成绩。嗯，我存在的价值其实就是解决总是会出现的各种莫名其妙的数据，性能问题。 2016-9 —— 2017-11 回老家，还是干运维活。国内一大型互联网企业，主攻电信业务。负责的是 AAA，DNS系统的维护，主导了一个DHCP项目的建立完成。提升技能：DNS协议，DHCP协议，组网知识，负载均衡，服务高可用。 2018-3 —— Now 终于转行开发。主要负责业务上的需求管理，进度管理。公司现在做市内几个区的业务执法系统，文书处理，数据分析比较多。后台 SpringMVC。人少，逃脱不了写代码的工作啊，虽然我非常喜欢代码，但是，每个程序员最终不往项目经理走，往哪里去？基本技能有了这些基础，大多数时候，绝大部分问题，即使不懂，谷歌大法也能助我解决。Unix 这个是一直以来的基础。对于 APUE/UNP/TLPI 看了很多遍，多数要点均能记住。从编程的角度来对系统进行了解。所以之前别人看我觉得运维工作干得非常不错，其实代码写得很少的了。 进程模型 fork-exec-COW。每个进程都是 initd 进程 fork 出来的子进程，替换执行代码而来。 线程模型（同步） 线程的出现，是为了解决 fork 的代价太过昂贵而生。事实就是在不重新开辟内存区域的情况下，将一些代码段的执行交给内核进行调度。内存的共享势必会涉及到竞争的问题，所以才有了锁，信号等的同步机制。 阻塞IO/非阻塞IO。通常情况下阻塞的IO，我们必须等待内核把我们想要的数据准备好了，我们才会返回。经典的例子就是对于两个进程分别打开管道两端进行读写的时候，有可能是永远不返回哦。非阻塞IO在数据不可用的时候，会返回一个错误，接着我们的进程来回测试能操作不就行了。 epoll/select 非阻塞IO下，如果我总是要循环测试是否可读可写，这比较低效，如果我们能同时关注多个 fd，某个能用了就开始操作多好。这两个就是为了我们在关注多个IO事件时而来的系统调用。select 比较通用，问题再于 select 面对多个 fd（文件描述符）组成的集合时，有任何一个事件发生，都必须遍历整个列表来看是哪个发生了事件。epoll 呢，只会返回有事件发生的集合。 信号机制。异步通信了。 TCP/IPTCP/IP 详解第二 三版都看过很多遍了。对于常用的的各层，各种协议均了解。IP/TCP/UDP/ 这些自不用说。路由如何汇聚，隧道，NAT 等也有了解。事实上，我觉得当前应该了解的还是 IP/TCP 就差不多了。 对于IP层的了解，需要首先意识到， 1. 每个网络接口设备都有一个 MAC 地址； 2. 但并不是所有的设备都是直接物理相连的。IP 层要解决的问题，就是可能不物理相连，且链路类型不一致上的逻辑链路通信问题。路由器，是IP层的核心设备。有了全局路由表，才让互联网得以互联。 对于 TCP 的了解，首先要看一下一个简单的通信模型是什么样的。以C/S 为例， C 发送数据，S接收数据，S返回确认，C接收。这其中就会有一系列的问题：C 发送的数据 S 有没有收到？如果收不到等待多久后重新发送？ C 发送数据的速率多少才合适？快了 S 处理不过来，慢了浪费资源？ C 发送的数据在网络中传输有没有被修改？所以才有了 TCP 的速率协商，拥塞控制，校验和，超时重传，滑动窗口。了解问题产生的背景，才能明白 TCP 为什么会有那么多机制的意义。 从编程角度看，其实一个服务器只需要： socket(), bind(), listen(), accept() 就可以完成了。而客户端只需要：socket(),bind(),connect() 就可以同服务端通信了。 MySQL对于 MySQL 的开始，来源于第二份工作，需要对数据库进行安装，备份，数据恢复等了解。然后才涉及到了解索引的意义，事务的使用及锁的相关知识。关于这点，了解一下 MySQL 执行一个查询的过程非常有用。 数据的存储，两个重要的指标就是：安全与效率。为了数据安全，所以备份很重要。为了数据的一致性，事务很重要。一个系统的瓶颈，大多产生在 IO 层面，所以索引的建立，会加快查询到想要记录的速度。 索引 事务 MySQL dump Binlog Explain Join 主从复制。 工作中。。。虽然其实我很讨厌Java那冗长的包类名，但不能不说，其用起来确实很省心呢。只是我实在讨厌做UI啊，为什么一定要让我写安卓呢。 Java（当前） SpringMVC 启动过程，绑定模式 MyBatis 动态 SQL Poi Docx 文书处理 iText PDF处理 FreeMarker 模板转 PDF （利用 flyingsaucer） JVM（我是与 UNIX 系统类比来理解的其中的线程模型的） 安卓（当前）当前的机器上，性能什么的早就不是瓶颈了。注意不要在处理 bitmap 的时候 OOM，不要傻傻的在 Activity/Fragment 里面写太多代码，不要动不动返回 Null 又不检查就传消息过去就好了。用户体验？做项目这个压根顾不上，等进度跟上了再考虑吧。重复：UI是弱项。 Dagger 依赖注入 ButterKnife 视图注入。解决 findViewById 到处写的问题。 Retrofit 网络请求。 Glide 图片加载 ObjectBox 本地数据库 MVP 架构。为了方便维护，修改，新模块都这样干吧。 虚拟机语言无论是 Python, Lua, JS 都是解释性语言。我们编写的脚本，除了逻辑，大部分的事务都是由底层代码完成，我们在脚本中调用这些底层代码API，把注意力集中在逻辑上。性能的瓶颈应该都在于 解析-编译 这个过程会比编译型语言花上更多的时间和资源。 但其实当前这个环境，性能已经不是第一位的了。如何快速的出产品，才是比较OK的做法。 Python主要是利用了轮子多，解决任务而用。为了处理异构数据，用 pandas 来进行处理后导入。 因为自己对于 TensorFlow 有兴趣，所以也会用 numpy。 另外，为了模拟请求接口，还研究了用 requests。 Lua这个算是研究得比较深了。知识来源于 PIL。大爱这个语言的原因，来源于第一份有关的工作就是用 Lua 来执行很多很多的脚本，游戏逻辑，任务系统，怪物AI等等。当前工作压根用不上。似乎现在小游戏，前端后台都被 JS 一统了。我的游戏梦，怎么实现？ JavaScript还未深入研究，不过在写页面的时候，又怎么会不遇到呢。不过，据说能用 JS 写的东西，最终都会用 JS 来写。所以，有有必要学一学呢。再说，node 的存在，也让我们用 js 写服务端程序了。 vue"},{"title":"","date":"2019-01-17T06:24:19.034Z","updated":"2017-12-28T14:27:03.000Z","comments":true,"path":"diary/2017-12-20-爱人间信息及时传达的重要性.html","permalink":"https://gowa2017.github.io/diary/2017-12-20-爱人间信息及时传达的重要性.html","excerpt":"","text":"2017-12-20 周三 晴 关于爱人间对信息传达的及时性今天媳妇儿生气了，我其实是莫名其妙的。因为昨天，家里停电，我的手机因为前一天晚上没有好好充电，所以没有了电，在只有1%电的时候，我就微信告诉她，没有电了，然后一会就关机了。下午，我和父亲前往镇政府办事，在一家照相馆的时候，由于父亲要用手机把手机上的图片给传到相馆的微信上去，但是却连接不上相馆的WIFI，于是我就在那里充电我的手机，并且开了热点给父亲用。这样手机就开机了。确实，我没有去看媳妇是否有往我的手机上发信息，后面媳妇电话过来，质问我什么情况，怎么半天没有了消息，非常的生气与愤怒，之后就再没有理我了。今天中午前往县城，等待媳妇下班，想知道具体是什么原因，因为在我看来，这并不是什么很大的问题，但事实是我错的非常的离谱。一起吃了火锅，然后就谈起了这个情况，媳妇一直不爱搭理我，对我爱理不理的，最终开口说出了原因。她感觉很累，她不想像十个月前那样，手机一关机，就没有了音讯，十个月见不到我的人，听不到我的声音，不知道我的情况,况且我现在的特殊情况，属于被监管人员。我真的错了啊，错的非常厉害，原来我不以为然的一个没有告知，对她竟然是有这么大的影响。这能说明，我的媳妇，是多么的爱着我，担心关心着我呢。我怎么能让我的媳妇，如此为我担心，让我深爱着我的人，因此而悲伤，或者再次经受那样残酷的打击呢。更有一个问题，由于我自身的原因，我想得太多，加上我现在的情况，家庭经济状况的拮据和想要达成的目标之间，差距太大。对于结婚的事情，一直没有提上日程，其实我也很急切的，但是我总是感觉现在的情况，我却无颜去提这个事情，甚至不知道如何着手，从哪里开始。也许是因为我现在，连沟通的底气和自信都失去了吧，可是，媳妇的父母、家庭会怎么样看待我的。我甚至不知道我的打算，能不能得到媳妇的谅解，又或者，我在现在这样的情况下还想将家庭的经济投资在一个并不确定的将来上面是否靠谱。所以一直这样犹豫着，拖拉着。媳妇都已经把想要结婚的意图表达得这么明显了，可我却视而不见，这是非常不应该的。我想，“知行合一”，想要做到这一点的，真的好难，但是做到这一点，可能真正的能无往而不利了。希望今天，能给我一个深刻的教训，不要让担心我、爱着我的人为我而担心受怕，不要把别人对我的爱视而不见，当作理所当然。谢谢媳妇儿，遇到你是我今生最大的幸运和幸福。"},{"title":"","date":"2019-01-17T06:24:19.034Z","updated":"2017-12-28T14:27:03.000Z","comments":true,"path":"diary/2017-12-24-爱人间需要坦白沟通.html","permalink":"https://gowa2017.github.io/diary/2017-12-24-爱人间需要坦白沟通.html","excerpt":"","text":"关于爱人间沟通的坦白今天，蔡友锋在家里请大家吃饭，缘由是谢老、卢鹏、蔡友锋他们三个人是一天生日，就趁这个由头聚在一起吃个饭。其实，我知道的，现在所谓的活动已经变了味，吃饭过后，总是免不了要打麻将的，而且打得还不小。 但今天媳妇因为是要去考研究生，所以周五的时候就已经回到了贵阳，所以周六今天的活动就没有参加，在我去的时候，她还跟我说她想下来，不和我在一起很不安逸，只是因为阿姨不想跑下来，所以才推迟到周日下来。 晚上吃完饭，大概是21点左右吧，就开始打麻将了，我不想打，所以就跑在一边去玩电脑了，但是蔡晨曦好恼火，老动我，所以也只能不玩了。最后就是跟媳妇在微信上说话，说着说着，媳妇儿却不理我了，没有音讯。我还说发生了什么事情又热恼了她呢，打电话过去一问，原来她困了，都已经睡着了，我也就挂了电话。 我本意是吃完饭，他们打麻将我就撤退的。只是，还能说什么呢。曾经答应过媳妇儿以后都不再打麻将这样的事情的，可我还是参与了。不想去找什么借口说是凑角也好，睡觉起来打也罢来表明什么东西，其实事实就是我自己没有控制住自己的想法，趁媳妇儿没有关注到我的时候，就开始打麻将了。 自然，第二天媳妇儿知道了是非常生气的。好多时候，原来媳妇儿很在意我说话做事的态度的，答应的事情没有做到，非常的愤怒，一度又想到了，会不会因此而又离开我。当媳妇儿质问我的时候，我是沉默的，但出于一个本能的反应，就找了非常蹩脚的理由想去说服媳妇儿，结果很明显，媳妇儿更加的愤怒。问我输了多少，找谁借的，然后，还把前些天他没空取钱我给她的一千块钱还给了我，还把欠别人的钱给还了，然后，就没有然后了。 对于这样的情况，我好无力，我从来就好不会处理在两个人出现矛盾的时候采取合适的方式去缓和气氛，很多时候，我都只是沉默。却不知，这样沉默，对媳妇来说，就是无言的抗拒和绝不认错的默认。心里一直在犹豫不定，媳妇不接我电话怎么办？这样的情况下了个人说不了话怎么办？不听的解释怎么办？一定要离开我怎么办？ 沉默，沉默，犹豫，犹豫…… 回头想一下这个过程，为什么我会去打麻将呢？是因为无聊么？不是的，因为我喜欢看书，有电脑可以玩，还可以睡大觉。 那是因为别人的劝阻么？也不是的，没有任何人可以决定自己做什么事情，是自己的思想被别人的行为和语言所改变，而没有仔细想想可能会产生的后果和影响。 那有没有想到可能会引起媳妇儿的愤怒？说实话，当媳妇儿已经睡觉之后，我就已经放松了的，没有去多想。但我知道，如果媳妇儿醒来如果找不到我，一定会发现点什么，会生气的。我手机开始还放在另外一个房间充电，但是在临天亮的时候我还专门把手机拿了放在身上，可是打着麻将，去忘记了时间，没有听到信息响的声音。 有否记得曾经对媳妇说过不再打麻将的话？在当时的时候，真的忘记了。可能有那么一瞬记起过，但是会想到媳妇应该会允许接受的吧，不是什么大不了的事情。现在想来，这个事情，媳妇儿应该是能接受并且谅解的，但是我打着麻烦却把媳妇丢在脑后，不看信息不回信息。在她质问我的时候，还没有脑袋的找些根本说不过去的理由和借口来狡辩，这才是她生气的根本吧。 归根结底，从自身来说，到底是什么原因使我居然还是去打麻将了呢？以前，我从不在乎打麻将到底是输还是赢的，多少对我来说，都无所谓，因为并不知道缺钱是什么感觉，现在还有着这样并不正视生活现实的心态，所以就改变了自己的坚持和初衷。更深一层，普遍一点来说，这也是一种赌博，赌博是一种会刺激快感的活动，每个人都会渴望下一秒和牌的就是自己，然后获得收益。而在麻将桌上，并不需要付出很大的努力就有可能有很大的回报。在现而今打麻将的层面来说，其数额是已经超出了一个正常娱乐的限度的。就我自己而言，也不无怀着利用打麻将，能够赢钱这样的心态走上了桌子，即使，自己过往的战绩，输多赢少，一败涂地，也总会想着，这一次不会这么坑了吧，事实证明，这是非常荒谬的想法。我应该更清晰的认清一下自身，知道什么事情是自己擅长的，什么事情是自己一定会失败的，而不要把希望寄托于运气和偶然之上。 媳妇儿，对不起，我又给你增加了那么大的压力，只是，你会原谅我这一次么。 最终媳妇还是理解了我，说下次不能这样了，有什么事情要老实说，不要遮遮掩掩的，说些不着天不着地的谎话，我这人一说假话就说不下去，一下子就被看出来了。后面媳妇去贵阳一个同事家玩，还在那吃了烙锅，下午大概是18点左右接着阿姨才到来息烽，那里 也没有去，就直接去我家把我接下来了。 因为周一是外婆生日，阿姨们下来就是为了给外婆过生日的，出乎意料的阿姨下车去取了钱后，居然包了一个红包，然后递给我说，明天给外婆，自己不要加钱在里面，都统一了的。哎哟喂我的娘啊，虽然我这个时候确实比较潦倒，但是阿姨能这样想让我非常的感动啊，这得什么样的心思才能想到这个东西啊。 虽然媳妇觉得这样有点丢人，我可不觉得这样有什么丢人的，我不能辜负了别人的好意啊，所以后面我领了这份好意，再把这个红包悄悄的藏在了媳妇儿的包里，自己再去准备一个红包去。 晚上还有一个事情，就是媳妇的干咳已经好久了，只是咳嗽，不发烧，也没有不舒服。上周四去了医院检查，医生说先吃点药，然后就开了氨咖黄、阿莫西林、琵琶露、利林巴韦来吃，结果吃了两天还是没有什么效果。在圣诞的时候，别人都去狂欢，而我们却跑去医院，这是一个什么样的体验啊。 下面来说说，一个小病在医院里面是什么样处理的。首先，医生询问了一下基本的情况，看了一下喉咙，反馈说喉咙有点肿。然后就开始开单：1、血常规；2、CT。我顿时感觉心里一万支草泥马在奔腾，换个医生咋就这么坑爹呢。 不过CT体检前几天才做，没有问题，然后不做了，就去做了一下血常规。最后医生看了后说，没有任何问题，那么还是打个点滴吧，媳妇不想，想打一下屁股针，医生说打屁股针无效，现在你这个没有哪个地方有炎症、没有发烧，用抗生素的药也没有什么作用。意思就是你这个就是干咳，他也没有什么好办法好药，其治疗方式就一个：打个点滴。然后再做个雾化，唉，感觉这是什么东西啊。 后面我不禁有点挨不住段子精神，就把这个过程总结了一下，在医院里看病的几大步骤： 挂号。 排队等叫号。 简单问诊。（预判支气管炎） 医生开检测单。（血常规、CT（体检时刚做，无异常）） 交钱。前往各科室进行检查。 反馈结果到接诊医生。结果是没有异常。 还是来打两针。开始开输液单。（费用包括，药品费用，器械费用，场地费用） 交钱，输液去。"},{"title":"","date":"2019-01-17T06:24:19.034Z","updated":"2017-12-28T14:27:03.000Z","comments":true,"path":"diary/2017-12-26-结婚那些事的无奈与痛苦.html","permalink":"https://gowa2017.github.io/diary/2017-12-26-结婚那些事的无奈与痛苦.html","excerpt":"","text":"关于结婚这个事情的无奈媳妇今天说我这人实在是做什么事情都不上心，对于结婚这个事情，以为是今天想结明天就能结这么简单，从来没有认真仔细的研究考虑一下这个过程中所可能需要提前预定、处理的问题。事实上，确实是这样的，但是就我个人感觉而言，这些可能都是钱的问题。我已经不再是过去的我，现在的我身受诸多限制，而且处于没有经济收入的这个状态。虽然看起来我现在非常的不在意是用父母的钱、还是媳妇儿的钱、还是接受其父母的帮助，但其实我内心是非常在意我是否有能力能做出贡献来的。 对于结婚这个事情，一直以来，我都认真是自己的事情，而不因为把这个事情的很多压力压在父母身上，在我现在这个情况下，我实在是很希望能和媳妇儿结婚，然后开始我们两个一起的生活的。但是我好担心我的后面会让媳妇造成很大的不便和苦恼跟压力，以后的日子，说不定会过得非常的困苦，矛盾的。但我也知道，在我身陷囹圄的时候，媳妇都依然坚持的等待着我、相信我能出来，当年那一句”即使是最长的刑期，我也能等你的啊？“言犹在耳，可我却为何依然会担心媳妇会放不下一些我认为不必要的东西呢，为何我却鼓不起勇气和媳妇好好的沟通呢。 我想要的，是我所爱的人，以后跟我能过上幸福美满轻松无忧的生活，而不是为了这样那样的各种费用而感觉非常的拮据难熬的日子，现在的情况，是有点恼火的。而我曾经对媳妇儿的承诺，还有媳妇儿对一个婚礼的渴望，让我感觉是有压力的。看着媳妇那充满了希望跟快乐的眼神和表情，我实在是兴不起泼冷水的念头。一个粗略的预算，可能结这个婚，30－40万可能是要花下来的，但我现在肯定无法付出这么多的金钱呢。 我相信，媳妇儿在我身陷囹圄的时候都爱着我，等着我，是肯定不会介意我现在是什么情况的，也愿意相信我将来会重新站起来，和她一起，走上幸福的道路。但很多话我却说不出口，难道我能跟媳妇儿说，”媳妇儿，我现在比较恼火。彩礼能不能少给点？婚纱照随便拍拍？婚礼的话就免了乡下办吧？“，真的，我说不出口。所以，一拖再拖，媳妇就认为我没有一点想要和她结婚的迹象，一点都不积极主动的去干各种了解流程、提前预定酒席、婚礼的工作，可是，我心里也有很多无奈啊。 还有，跟她家里怎么交代呢？和父母怎么开口呢？她的朋友们会怎么看？虽然说，可能我们的幸福，只是我们自己知道，办得怎么样，给谁看呢？但，谁不会有那么一点记忆和虚荣的心理会某时间就跳出来作祟一下呢？ 抱歉媳妇儿，我会努力的。"},{"title":"","date":"2019-01-17T06:24:19.034Z","updated":"2017-12-28T14:27:03.000Z","comments":true,"path":"diary/2017-12-28-从细节上为爱的人考虑并体现出爱.html","permalink":"https://gowa2017.github.io/diary/2017-12-28-从细节上为爱的人考虑并体现出爱.html","excerpt":"","text":"关于如何爱人在生活中细节的体现今天很麻烦，因为昨天晚上吃宵夜的时候，把媳妇一个袋子里面的文件给遗失在了夜市一条街上，临走的时候，也不是很清楚的记得到底是拿起走了，坐上出租车到县委的时候下车掉车上了，还是压根就没有从吃宵夜的地方拿起走。 介于是一个非常麻烦的事情，我就前往了镇派出所希望能通过监控进行一下检验。幸好，给行了这个方便，通过在里面花了几个小时的观察，先是确定出租车公司，是宏运的；但是晚上的光线太强反光的看不清楚车牌号，沿着时间线追踪了这个车也还是无法看清楚。最终想了想还是观察一下我们上车的时候有没有拿着文件。 时间回到我们上车的时候，从摄像头里面可以看到，我和媳妇儿两个人挽着手走着将要上车的时候，手里只提了几个苹果的塑料袋子和一个水瓶并没有文件，由此断定我们没有拿着文件上车，文件遗落在吃宵夜的地方了。 幸好，开宵夜摊子的那家是霞霞家亲戚，于是顺理的就让媳妇打个电话去，下午的时候回了电话，确实是捡到了一个文件袋，已经帮忙收起来了。下午去拿就行了。 媳妇下班后，前往李永莎家吃了晚饭，20点准时离开，去夜市一条街拿了文件就送我回家了。其实我是非常不愿意媳妇送我回家的，因为在乡下，媳妇一个人出来还要花点时间，而如果停车的地方不好的话还要一个人走好一截路才能回家，这凉风吹吹的感觉我自己体会得到，所以十分不想媳妇儿去体会。 只是，媳妇在我家坐了一会我就让媳妇先回去了，结果媳妇儿停好车以后告诉我她手机即将没有电，马上去捡点药，顺便输最后一次夜。我内心当时的感觉说不出来，只是觉得媳妇儿好苦，我好蠢。 我不知道我到底一天在关注些什么？是一直因为缺钱结婚的事情让我心头一直有话有事压抑着所以不去想其他的地方么？那为什么我有的时候还要想着去看书呢？是在逃避吧。？ 还是我压根就不知道怎么去爱人的，媳妇生病了，虽然是干咳。我却没有用心的想想好的办法来看看怎么解决这个问题，只是去输了两天液，都没有好，是继续输液还是怎么办我却没有和媳妇儿去沟通下去，最终却让媳妇儿一个人去输液，大晚上的？ 我到底该怎么样表达我对她的爱啊，对她的爱不是放在嘴上的吧，应该是从生活细节上进行关心处理，而不是让她有感觉到不适和无奈的心情才对吧。 多想想吧，少年，为媳妇解决一些生活中可能提前会遇到的事情，了解她的对于各种事情的想法，一起沟通来找出解决的办法吧。而不是要么只关注自己的事情，要么只关注一下自己习惯了做的事情，人都是有情绪跟变化的，怎么可能会一成不变呢，媳妇儿，我看来跟我待久了，最终女人都会离开我看来是有原因的？ 所以 请关心媳妇的身体、请关注媳妇儿的情绪、请体会媳妇儿的难处。"},{"title":"","date":"2019-01-17T06:24:19.034Z","updated":"2018-01-06T11:48:13.000Z","comments":true,"path":"diary/2018-01-04-戒烟.html","permalink":"https://gowa2017.github.io/diary/2018-01-04-戒烟.html","excerpt":"","text":"戒烟 \\n"},{"title":"","date":"2019-01-17T06:24:19.034Z","updated":"2018-02-23T04:18:39.000Z","comments":true,"path":"diary/2018-02-23-终于要结婚.html","permalink":"https://gowa2017.github.io/diary/2018-02-23-终于要结婚.html","excerpt":"","text":"终于要结婚 \\n终于要结婚了，昨天两家父母有了会面。气氛还有点融洽，在于媳妇父母的宽松理解和大度。不在意我家是否给了多少东西，彩礼，只要媳妇和我乐意，就很高兴了。但从事实而言，在这个事情上，我家是做得不太妥当的。 其一，关于彩礼，曾经我是想给予媳妇20万这样的。为什么会想在我并不富裕的家庭给予这么多，因为媳妇值得，再来，也不想让媳妇觉得委屈。但由于我自己的事情，把自己的积蓄基本花光，而父母则把所有的钱都用在了给我和哥哥修建房子上面，所以他们也没有了多余的钱。最终，只给了88888 这么个数字，有点寒酸，但谢谢媳妇，媳妇家人的理解。 其二，关于婚礼。当年，是想要给予媳妇一个像样的婚礼的，同样的原因，一直没有敢提这个事情。而其家里是一定要给予唯一的女儿一个像样的嫁礼的。所以，最终是她的父母一直在努力积极爽快的置办这些事情，而我的父母并没有考虑这个事情。开始的时候是预估在媳妇家那边，在酒店里举行婚礼的，但是媳妇的叔叔伯伯认为，婚礼应该在男方而不是女方办，避免因为外人的不明白而看作是嫁儿子一样，引起我家人的不适。所以就征询了一下我父母的意见，而基于农村人一种比较节约的思想，是不想花这个钱的。及时媳妇父母愿意说这个费用他们承担，因为考虑到我现在的情况，她的父母对我，果然实在不要太好。父亲开始是不想接受的，但最终还是接受了我的意见，在男方家办。但这个费用，却不方便让女方出，所以前些天在讨论这个事情的时候，我就把父亲的态度草率的透露给了媳妇，导致了大家的不适。虽然昨天的沟通，已经敲定。但依然有些不妥的过程。 生活中，总是无法避免一些不能不面对的问题，其实归根结底大多是钱的问题，都是穷害的。 其三，即使是这样从简，媳妇那边暂时承担了一些本来不属于他们的事务，但这计算下来的花费也不低于20万这个数字。还有些缺口。 其四，可能是由于是身份、生活观念和环境上的不同。父母有些事情是实在无法向媳妇父母启齿的，因为本来就觉得有些委屈了媳妇儿。再者，由于我匆忙的想结婚，很多多事情父母，特别是父亲，其实是没有考虑好很么要继续这个过程的。所以在有的事情的处理上，有欠妥当，失了关注，我猜想这已经是引起了媳妇家的不适的。但他们真的，从未表达过，表现出来过。 得妻如此，还有何求？得如此岳父岳母，也还有什么不满意。不能忘记今日，昔日之好，以后一定要知道感恩。这只是一个务虚的话，最重要的事情是当前要把婚礼的事情办得漂亮妥当；更远一点，就是要把自己的生活问题解决，不要问他们增加负担，更远一些，就是要让他们过得更加自在和自由。 父母都不容易，特别是媳妇爱上了一个我这样的的人，更是不容易。 关于沟通上的问题，有些欠考虑了。虽然，媳妇一直要强调，想要知道最真实的想法和态度，但是其实有的时候第一反应，并不一定就是最真实的反应。在信息不名，了解不对称的情况下的反应，肯定会有偏差。而我和媳妇的沟通，唉，已经到了无所顾忌的地步，无论什么都相互给对方说。而我们各自在父母面前又是不设防的，很容易就把一些不好的信息传达到自己的父母耳中，造成了很多不必要的麻烦。 事实就是，无论谁跟你说他想知道你最真实的想法是什么，一定不要盲目的去表达。一定要确定这个事情，是不是真的没有什么副作用再去小心表达。 感谢各方父母，感谢媳妇儿。"},{"title":"","date":"2019-01-17T06:24:19.034Z","updated":"2018-03-20T15:56:33.000Z","comments":true,"path":"diary/2018-03-16-无法工作心里的痛苦.html","permalink":"https://gowa2017.github.io/diary/2018-03-16-无法工作心里的痛苦.html","excerpt":"","text":"无法工作心里的痛苦 \\n11月1号至现在，已经过去了4个多月了，社区矫正的生活确实不是很麻烦但是却也不自在。时不时的会让参加一些劳动，或者去劳动基地进行工作，也挺累的，但这都不是问题。 从严管变成普管，可以请假了。但我想要的其实不是这个，我想要的是一个正常的生活。前公司经理让我去上班，而且催得很急，但是和司法所内所长的沟通，得到的却是否定的结果，不能离开县外，只能在县内工作。 当时内心是非常的失望痛苦的，因为马上就成家立业了，如果没有事情做着，确实不像话，更何况媳妇已经怀孕了，孩子的奶粉钱还不知道从哪里来。但这有什么办法呢。 谁让自己会犯下事被判缓刑呢，相对于去监狱服刑这应该是很好的结果了，但在社会中，谁不想要有一个自然平淡的生活呢，但现在似乎都不能达到这个简单的目标。 路还需要一步一步走，其实我懂的技术并不少，但是怎么样变现这是一个非常头疼的问题。或许我这样的人只适合给别人打工吧，不适合自己创业去。"},{"title":"","date":"2019-01-17T06:24:19.034Z","updated":"2018-09-27T11:55:19.000Z","comments":true,"path":"diary/2018-09-24-结婚后真的需要自己的家.html","permalink":"https://gowa2017.github.io/diary/2018-09-24-结婚后真的需要自己的家.html","excerpt":"","text":"结婚后真的需要自己的家 \\n其实一直不是很理解为什么很多结婚了的男女，都想要自己出去住。大多可能都是觉得与父母在一起，会有很多的不变。生活方式上的不习惯，消费观念上的不一致，总会造成这样那样的冲突。 父母的唠叨和啰嗦也是造成不太和谐的主要原因之一。我的家庭和媳妇的家庭都还算和谐。父母其实不会太多的过问或者掺和我们的生活，但偶尔的唠叨是不可避免的。 因为很多客观无法改变的原因，其实我和媳妇倒是很多回我位于乡下的家。多数时候都是住在，应该是属于她曾经的家，当然，其实我这个人不是太在意这些东西，或者是说对这些东西并不敏感。无所谓居所是在哪里，甚至，在结婚之前，刚确定关系的时候，我因为工作没有去租房子的时候，就已经到她家去一直居住着了。 但最近的很多情况让我还是体会到一些问题。比如，在她家的时候，我看着她父母在忙碌一些事情的时候我就不可能坐在一旁玩我自己的东西，做自己的事情而不去帮一把忙；而在家里的时候，自己家的习惯可能有很多事情并不需要做的；她也一样，在乡下我家的时候，她不能对很多事情无动于衷，不能不在父母，哥嫂的目光下无所事事，所以就想找些事情来做。但这其实很多烦躁的呢 于是，我这个时候才明白，其实离开双方的父母，不仅仅是因为想要出去过自己的日子，而是确实有很多不便的。甚至，父母可能会因为偶尔前往去看一下他们而感到暖心，但对于天天在一起，则会感到厌烦。 生命和人就是这么的让人感到无奈啊。"},{"title":"","date":"2019-01-17T06:24:19.034Z","updated":"2018-11-12T16:01:21.000Z","comments":true,"path":"diary/2018-11-05-等待孩子出世的时刻.html","permalink":"https://gowa2017.github.io/diary/2018-11-05-等待孩子出世的时刻.html","excerpt":"","text":"等待孩子出世的时刻 \\n昨天中午就带着媳妇来到了医院，结果非常的痛苦啊。从下午到今天中午11点，进产房。一直处于平均5分钟即有一分钟除于阵痛状态，好不容易熬到了进产房的时刻，宫口却也只开了一公分左右。为了媳妇能早点进入产房，打一下无痛针，但不知道为什么看着媳妇进去那个地方，滑动门关上的时候有想哭的感觉啊。 想着媳妇一痛就会浑身发抖，用手撞击床头，我还可以安慰他扶着她，而一旦进了产房，就只有一个人，我不知道什么情况，她的痛苦也不知道到底是怎么样啊。 这个心情，很是奇怪，居然看到别人家的小孩有一种欣喜的感觉了我以前是非常不喜欢小孩子的总感觉很麻烦，当然，现在也是。但却不排斥自己有个小孩跟着自己飞了。 媳妇快点出来吧。"},{"title":"回忆录-同行","date":"2017-12-22T14:16:19.000Z","updated":"2017-12-22T14:16:19.000Z","comments":true,"path":"diary/story2.html","permalink":"https://gowa2017.github.io/diary/story2.html","excerpt":"话说相识是偶然，但是两个人的相爱必然就是需要很大的努力和运气才能到一起的了。两个从不相识的人，从见面到认识，最后到相爱到一起，感觉是非常奇妙也是非常困难的一个过程呢。要不是这样，为什么这么多的男女最终没有到一起呢。","text":"话说相识是偶然，但是两个人的相爱必然就是需要很大的努力和运气才能到一起的了。两个从不相识的人，从见面到认识，最后到相爱到一起，感觉是非常奇妙也是非常困难的一个过程呢。要不是这样，为什么这么多的男女最终没有到一起呢。春节是一个无法拒绝的节日，即使是流浪在外多年的我，每到春节还是乖乖的滚回家去，跟父母把年一起过了。1月24日回去东莞之后，毫无疑问的是准备回家过节的事情了。要说平时每年我都怎么过呢，不就是在家和父母一起吃饭，然后睡大觉，上坟山。其实是没有什么事情的，然后到初六的时候基本上就跑去东莞那边继续干活了。 自我回去以后，两人间联系依旧，但是呢，少了当时的那种冲动和激情，似乎没有经常在半夜三四点在睡觉了，都是准时的就睡觉了。或许是因为那时候我事情有些多了的缘故？对于怎么过春节，这个问题，进行了深入的讨论。 话说媳妇每年似乎都不是安心在家过年，都是在除夕过后，自己和朋友出去玩，或者和朋友出去玩。16年也不会例外，对于跑去哪里玩，我是十分支持的，主要是我活不怎么忙，有得玩自然也不落下，再说了，走遍中国的名山大川可是我一直以来的想法呢。所以在媳妇儿说她要在过年这段时间 出去玩的时候，我瞬间就表达了想要和她一起去的意思。但媳妇可不是这么随便的人，自然是要很客气的说，她还要跟父母一起去呢，到时候看父母一起去哪里呢；实在父母不去，她还要跟几个朋友一起去呢，是黄美惠和雍晚芸吧。 结果就是，天遂人愿，父母不去，朋友也放鸽子不去了。再也没有推托的理由了。对于去哪里，这可是一个技术活。春节嘛，冬天，要是去爬什么高山的，估计是没啥意思的；至于说三亚看海么，我刚去过，也不是很想去。哎呀最后媳妇儿就说到了要去彩云之南，顿时我也激动了起来。你说为什么呢，因为啊，曾经玩了好久的游戏里面，大理、洱海、苍山、石林等等地方可是我一直想要走一遭的，那可是承载了好几年记忆的东西呢。就这样一拍即和，确定了2月8日，大年初一，前往大理的行程。嗯，我订机票她订房，就这样开启了两个人的旅行了。 就为这事，我还跟老板说了，我过年不加班，可能要耽搁时间的问题，详细听了我的事情后，瞬间就贡献支援了一个单反，表示新年就没有红包了，这个就是奖金了。向来对老板的抠门有所了解的我就不跟他客气，收下了，反正也没指望过年发什么奖金的。 不过，媳妇其实是非常不想别人知道我们两个一起出去耍的，基于女性同志的害羞心态？还是并不想和我相处，而担心以后败坏了名声？不过我可没顾忌这么多，难以压抑的激动嘛，就把这个信息告诉我的同学们，当然，没有忘记叮嘱他们不要在媳妇儿面前说去。这不，我刚刚说完，媳妇儿就知会一声不要到处说，让别人知道。哦吼，还有我叮嘱得早，不然还真会给坑掉。反正我是不会承认我曾经给别人说过这事的。我那时已经好期待时间快点过去，春节早点到来了。 2月4日我回家，2月7日就是除夕，回去后两人并没有在一起相见的机会。这个时候，我琢磨着，都是要在家陪着父母的。再说了，我对约会其实一点经验都没有呢，压根就不知道怎么约呢。用我的话来说就是，没事干了两个人跑到路上走来走去的，这实在太蠢，完全就不能理解电视上的，或者那些约会的人到底是个什么心态，当时确实是这样想的哦。是不太懂”浪漫“这个词怎么去演绎，只关注一些必要的东西，后来我才晓得我这样是真心不会有女朋友的呢。 不知怎么滴，就把约会的日子定在了除夕的那天，2月7日，中午呢。我先一步到了团圆山脚下开始爬山的那个口子那，就在老高速路的旁边，从邮政那条街上去。哇哦，我在上面站着，就看着媳妇儿穿着那个格子的呢子衣服？黑色丝袜就来了？还好那天天气不错呢不怎么冷，吓我呢。 不知道别人约会是怎么样的，不过约会在去爬山，还是这么一个小的山，其实好有点无聊的哦。人家电视上演的都是一起去餐厅啊，一起去看电影啊，游乐场啊什么的，这些场所，县城里面，统统滴没有。至于可能会反对说还有那个玛费尔啊，抱歉去了一次我就不想再去那里了？你能想象，一群外国大汉，拿着烤箱和微波炉给你做宫爆鸡丁或者辣子鸡，最后得出来的是什么样的产品么？照这样看来，来一个假假的爬山约会活动也是一个没有选择的好办法了。 爬呀爬，爬呀爬，一会就快到了山顶，说了什么，我完全没有印象，反正时间过得是超级快的。这不，爬到快到山顶的时候，看着路有点烂，媳妇那纤细的身板我还真担心一不小心把叫给扭了。于是就在上山走烂路的时候，顺手就抄起媳妇的手拉着往上爬，我去，居然没反对，那我可不能客气了哦。当然，更进一步的事情我是没有想滴。 山顶景色不错，可以看到整个息烽县城的环境，不过我的心思可不在这。这不，就在我们准备下山回家的时候，毫不意外的走向了相反的方向。本来县城是在团圆山外面的，而我们却走上了往团圆山圈子里面进去的一条路，还以为这个路最终可以走到终点。却不知道，我们往下走了快四十分钟，才发现，这路，怎么越来越不对劲，越走越荒，一点城市的迹象都没有。找了个阿姨问了一下才发现，原来那边是没有路去息烽的，想要去息烽还得往回走，翻过我们先前在上面看风景的山顶，再下去才是县城。 这下麻烦有点大了，当然我是不在乎走多久的，年轻力壮嘛，还有美女陪着，有啥不乐呢。哥哥打电话给我说回家吃饭了都只能说没辙，走错方向了，还在往回走回家的路上。就这样啊，往回走了快一个小时才回到山顶。对于穿着一双鞋跟不矮的鞋走这么长时间的女孩来说，这略微有点残忍了。这不，下山到半山腰的时候，媳妇终于说她走不动了，脚累得很。唉，没有办法，只能临时客串了一下白龙马，我可从来没有背过女人的，好像唯一背过的雌性生物只有我大堂哥家的侄女。 第一次背女人，而且还是自己有意思的女人，很有点心情激动，背起就开跑，都不想放下来。最后还是媳妇一直闹着要下来我才放下来了。哎呀这小手牵了，人也背了，用媳妇后来的话说就是，那天都让你牵手了，又让你背了，难道你还不算好上了不成。不过，比较迟钝的我，完全没有这样的觉悟跟意识，只是觉得这样是一个非常的好现象。心头窃喜着，就忘记给嘴找个把门的，于是，这个消息又被泄漏到了朋友汇。童鞋们都在恭喜我着。"},{"title":"","date":"2019-01-17T06:24:19.034Z","updated":"2018-01-06T11:46:58.000Z","comments":true,"path":"diary/2018-01-02-男人的自尊，女人的真爱，父母的理解.html","permalink":"https://gowa2017.github.io/diary/2018-01-02-男人的自尊，女人的真爱，父母的理解.html","excerpt":"","text":"今天又是非常痛苦的一天。关于我和媳妇婚姻的问题，爱情的问题，两人之间出现过多次的矛盾和不愉快。我远不知道媳妇其实已经思考，知道了好多，今天前去其实是有很多事情，想了很久，拖了很久，才鼓起勇气想和媳妇沟通一下的。 约媳妇一起吃了饭，期间一直想开口某些事情却一直不知道如何启齿。随后在细雨中送媳妇回家，但最终还是鼓起勇气，提起了话头，慢吞吞的，总算说出了心里的顾忌和难处。 曾经关于结婚的事情，某一次，在车上，似乎是才蔡友锋的车上提起个这个问题，当时问我准备是给多少彩礼去订婚呢，我回答是 10万了。后面好像又说了是什么，媳妇吞吐了一下，我不知道媳妇是因为这个数字过小，还是其实她当时根本就不想回答关于我和她婚姻的问题毕竟当时我和她还不没有讨论过这个问题，我就说那就20万撒，我只是真实的说出了我自己的想法。后面好像还有时间媳妇说到要让家里陪嫁一辆车，我说这可不行，我们怎么能让爸妈这么操劳呢。还有，媳妇说家里办婚礼的钱，到时候说不定都会被她给收着拿走，我都很反对的说，如果我们没有什么需要的话，还是要父母自己留着的，毕竟以后我们俩有小有老，怕顾了不这么多，自己留点备用金，总是好的。 我今天主要目的就是想要讨论这个问题的，如果不是昨天晚上爸爸回来，和妈妈一起都问到，到底我和媳妇儿的事情，怎么搞，现在该做准备了，不能拖了。我想和媳妇儿结婚的，但是我现在的情况是有点困难，很多麻烦的事情不断，钱是一方面的问题。曾经说出了20万彩礼这样的话，现在如何启齿来给媳妇说打折，这样的事情感觉分外无耻，因为，遇到媳妇儿本来就是我最大的幸运，何况媳妇儿为我，守护坚持了这么久，等待了这么久，我怎么忍心让她受一点委屈。所以对于媳妇在物色婚纱照，研究婚礼怎么办的时候，我其实是很无助的，我无法开口给媳妇说，这可能要花不少钱哦，能不能不这样呢。但想到媳妇的付出，看到黄美惠婚礼的眼神（我一回来就给我看了她的结婚典礼视频），还有曾经在崔琬璐婚礼上的欢呼雀跃，她去参加几个朋友婚礼时的羡慕，我无法说出这样的话，只能用不反对（默认）来表示赞同，可心里在想的事，这钱暂时从哪里出呢？有点头疼。 我从未主动关心过怎么样办婚礼，结婚整个流程的问题（其实曾经和父母有过沟通，但没有表达出来）。因为，在没有解决最大的难题之前，我觉得那是没有意义的，我不敢去试探和沟通媳妇儿，或者媳妇儿父母家里到底是什么样想法，又可能其实我是不想他人，即使是我的父母，看到我现在的狼狈和疲惫。总想着，等着有钱了，等我能以力换钱了，就会什么都能轻松一点了，即使是婚礼花钱，也能慢慢的补上窟窿。这些事情，我从未跟父母说过，和媳妇说过，和身边的人说过，也没有想找别人来试探一下媳妇的想法。只和曾经在东莞的那个同事，说过一些关于婚姻，婚礼筹办上的一些难处。为什么会给他说，其实也和自身的内心的卑微的自尊作祟，毫不可以否认的剖析自身来说，我把她当成了姐姐，还记得她，和她曾经的男朋友都记得我曾经在2014？年说过一句话：就是和他们在一起共事的时候，我就像在外有了家的感觉一样。甚至也为她跟了她曾经的男朋友而在内心不值，也曾她嫁了一个二婚的男人而扼腕叹息。可是，我和她果然是没有任何关系的。 可媳妇儿不赞同我的说法，我可以和她沟通这些事情的。但是，可能是我感觉吧，她那样一个经历了婚姻的压力，且与我相识的人，应该能理解我内心的无奈，可以说是同病相怜？或者是，她能听到我的声音，却不会看到我的狼狈，让我可以没有这么多的顾忌吧。没有人会理解我是多么想要和媳妇儿在一起的那种想法，我在里面的时候的那种只要能出去和媳妇在一起，即使全世界都爆炸都可以的想法是有多坚定。诚然，出来一段时间有过动摇，但当面对必须要把天平进行衡量的时候，我毫不犹豫的会选择媳妇那一端。 可是为什么我不愿意也不主动和媳妇儿去沟通好这些事情然后继续我们的将来呢？仔细的把问题一一的写来就是。 我不愿意我把我的难处给媳妇儿说了以后？而且这远远不是结束，她怎么样去给她的父母开口商量这样的事情？ 那我知道她父母是怎么样想的？我不知道，她一家人对我的好，我心里非常的明白。却对他们没有信心，如此的矛盾。是因为看电视小说太多，自己变得太个敏感现实功利，所以会以这样的思考去揣度他人么。 如果她与她的父母并不接受我的想法呢？我害怕担心这点，所以无从开口，害怕失败和失去。 你就这样下去，会有结果么？答案是否定的，迟早有一天情况会变得更加恶劣。 那我到底在犹豫什么？自尊作祟。 天可怜见，媳妇跟我说了什么？她说，曾经我还没有出来的时候，她信誓旦旦的跟朋友们说，我一出来就和我立马结婚。我到底是该怎么样懵懂，愚蠢。让媳妇的心伤成了什么样而不自知啊？ 我又仔细的想了一想，这里面让我一直有这个潜意识的情况就是，我不想媳妇儿受到委屈，不想她被别人所看轻了。因为想起，曾经媳妇儿和她妈妈受过的委屈，虽然可能多一点金钱上的付出不能说明什么，但是对于外人来说，这确实是一个非常重要的表示。或许一直是抱着这么多的心理，才实在无法放弃内心的这个疙瘩。 但是这又有什么用呢，这只会造成事情的拖延和恶劣。当事情自己无法解决的时候，放弃自尊，像可以帮助自己、理解自己的人去求助吧，和不相干的人发再多的牢骚，也于事无助的。 上面说了为什么没有沟通和研究结婚这个事情，那现在就来研究一下结婚的事情吧？ 我想和媳妇儿结婚么？想的，愿意的，没有什么比这个事情能让我更加愿意了。不忘初心，我不会忘记自己在最无助最难过的时候，是谁一直站在我身边，最想要的事情是什么。如果到了那个地方，还不真正的明白自己想要的什么，那这生就白过了。 我准备怎么来操办这个事情？归根结底还是现在经济不足的问题，只能进行一个有限性规划。 媳妇儿最想要的是什么？当前最想要的是什么？当前最在乎的是什么？ 媳妇想要的是和一个男人组建一个幸福美满的家庭，从现实意义上讲这是一个衣食无忧，同时男人担当，爱护老婆，爱护家庭。当前最想要的，其实就是能有个像样的婚礼，彰显人生中最重要最美妙的时刻。当前最在乎的，就是我对她的态度，心里的态度和表现出来的态度。 对媳妇在生活中的态度，媳妇儿是满意的。唯一有问题的冲突就是在对于结婚这个过程的重视上，我的满不在乎，造成了最坏的结果。那么结婚到底要经历哪些过程啊？ 相识－相恋－相知－相守，都有了，却唯独没有婚姻。求婚－订婚－结婚….生子－一生。没有这重要的一环，什么都不能证明，也不会有结果。 而且自从与媳妇相识相知，我已不再以前那个事事自我人了，居然会在媳妇面前有类似撒娇的时候？沉默和装可怜以期待获得媳妇自己的理解，但她怎么又可能知道我到底在想什么呢，我还是应该更加主动一些，积极透露我的心思和想法这样。 而且在媳妇儿心情不好不乐意的时候，我就会手足无措，根本就不知道该怎么说话怎么做事了，而在媳妇儿情绪正常非常高兴的时候，我却能非常从容的沟通、逗乐，这到底是一个什么样的状态呢。 我的行事，在目的明确的时候，总会积极主动很多。总想要把所有的情况都考虑好，然后再去实现目的，而一旦有的环节可能有阻碍，就会拖拖拉拉。对比以前和你的相处。"},{"title":"回忆录-相识","date":"2017-12-22T07:16:19.000Z","updated":"2017-12-22T07:16:19.000Z","comments":true,"path":"diary/story1.html","permalink":"https://gowa2017.github.io/diary/story1.html","excerpt":"相识 我与媳妇的相识，其实是一定准备也没有的，也没有任何铺垫。当然，估计大多数人都是这样，在遇到自己要共度一生的人的时候，一点都没有想到过以后。就这样说吧，可能偶尔相见的某一个人就是以后和你过一生的人了。","text":"相识 我与媳妇的相识，其实是一定准备也没有的，也没有任何铺垫。当然，估计大多数人都是这样，在遇到自己要共度一生的人的时候，一点都没有想到过以后。就这样说吧，可能偶尔相见的某一个人就是以后和你过一生的人了。 2015年，一整年都是游荡着的，没有任何目标的在过活着。因为与前女友似乎是在元旦节的时候分手了，所以之后就一直没有什么目标，目的的过日子。那个时候的我，一点生活的目标都没有，压根不知道自己到底想要做什么，未来是什么样，跟什么样的人过，所以就日益的重复着咯。 期间，在6月的时候，就出去到处走了一遭，主要的还是想要去大山上转一转。从小就有的武侠情节，就推动我往华山、西安、武当、成都、九寨沟，最后去了重庆跟刘德才、金继业、聂海燕都一起吃饭了？然后回到了老家。历时一个月吧，一个人的游玩的日子倒也轻松自在。 8月的时候，大学同学邀约一起去海南玩一下，于是就去了那里。 然后，8月底的时候，就跟我一同事去了扬州玩，去瘦西湖溜了一圈，又去南京找郑禄枫和郑明超一起耍子。之后还去了我哥哥工作的地方，无锡周庄。 然后在某次回家的时候，还和刘伟一起，去了乐山，峨眉山。 由于我那时候和前女友分了手，然后呢其实我自己当时还没有一个成交的女朋友嘛，我这一群同学应该来说还是挂念着我的。于是在身边有了好产品的时候就就想起打电话给我了。 还记得蔡友锋打电话给我的时候说是给我介绍女朋友，就是那个谁谁谁的闺蜜啊。我一点印象都没有，谁？不知道啊。她闺蜜？我更不清楚了。当后来据媳妇说啊，其实我们是早就见面过了，只不过那时我压根就没有注意到。是蔡友锋有次去我家接我去县城里面吃饭，然后我就在我们村的招呼站那里，穿个短袖？一个绿色的短裤，还在那玩手机。上车后连头也没回头看一下，压根就没注意到，我将来的媳妇儿就在我后面坐着呢，哈哈。 还有，好像媳妇儿之间是和蔡友锋们一起去过我家的，还是之后去的，不是很清楚了。 我那个时候的状态，其实心里是完全没有想找一个女朋友这个意思的。主要是一个人的日子也是过得快乐惬意的，想玩哪里就去玩哪里，再说了，那时候工作的性质，也让我实在提不起来被什么东西所限制着的那着想法。当然，同学的好意不能辜负撒，于是呢就回家了一趟。 贵阳百花湖，是这个地方。大家约在一起去那里玩，嗯，也就是为媳妇她闺蜜和我创造见面的机会了嘛。记得有，蔡友锋一家、郑禄波一家、蔡涛一家、媳妇儿和我、她闺蜜，然后还有谁？记得不清楚了。 说实话， 我那一次就不是带着相亲的目的去的，什么目的，我也不知道，反正心里无可无不可的。用蔡友锋后面的话就说，不知道我到底在想什么，说介绍对象吧，也不问一下别人的微信，也不想要看一下别人的照片，说去就去了。嗷，或者那时候我也不想要看吧，就想去试试，说不定就能成了。毕竟那时候的观念可不是要找一个自己爱的人，或者爱自己的人去过日子咯，马马虎虎过得去就算了这样。 抱着这样的目的和心思去干这种事，结果是早就注定的，我无意，我想别人女孩肯定也不可能黏上来啊，我毕竟长相不是刘德华，要有自知，之后虽然说还是在蔡友锋的指导下加了她闺蜜的微信，但说不上几句话也就没有下文了。于是呢，这生命中的第一次“相亲”自然是胎死腹中了。 生活还要得过。时间不会因此而停止的，回到东莞，继续开始那没有意义的工作。那段时间似乎是没有什么活需要干的，记得9月27日到10月中我一直在打游戏，倩女幽魂，还花了几万块钱，但是完全没有什么卵用，等到最后卖号的时候才卖了1500块钱。缩水得厉害呢。 期间倒是有个清远的姑娘有过一段时间的交往，但是在生活观念、价值观念方面的差距还是太大，所以最终不欢而散。这不，终于在1月初吧又接到了蔡友锋的电话，他就问我有没有女朋友的，于是我就说没有呢。那么，我与媳妇的，就从那一天开始了。 在这里，不得不谈一下，我对媳妇儿在百花湖见到时候的印象，哦，那时候是带着寻常看一个女孩在眼光去观察的，就是瞥了一眼，没有仔细的研究观察。穿的似乎是一件黑色的大褂子，好长，头发是卷起来的，没戴眼镜，- -，胸好平，还不怎么高。还有个就是去我家的时候记得的样子，好瘦，脸上有点浮肿的样子，后面我问蔡友锋，他说那女孩那段时间工作有点忙，又有些个人的事情心情不好才是那个状况，但是人是极好的。 1月14日，这天晚上，扬州那同事，听说我要回去看妹子咯，于是一打量了我一下，说，你就这样去啊。我说就这样啊。她说你就这样去，要是人能看到上那真是瞎了眼。就拉着我去金月湾楼下，买了一套，牛仔裤加个西服外套，第二天我就穿着这身，坐上飞机，晚上就到了第一次见面的地方，小海螺。 哎呀，其实那点的东西一点都不好吃，环境还有点臭臭的，而且贵，吃得我点都不安逸。不过嘛，兄弟伙们决定的地方嘛，人才是最重要的。到场的都有谁呢，似乎是去百花湖的原班人马哟。蔡有锋、蔡涛、郑禄波还有我和媳妇儿咯。 毕竟是第一次见面，饭后自然是各回各家，各找各妈。兄弟们都不错，哇哦，就让我上了媳妇儿的车。那啥，本来媳妇儿跟二妹是想一起的，后面二妹被拉走了，我就跟上去了。其实好难为情的，我怎么能这样干呢，都是同学们给了的勇气吧。嗯，用蔡友锋的话说，就是我说她回家。贵阳我不熟撒，等到了媳妇儿家楼下的时候，她说到了。我就有的没的说了句，就是这里啊，在这下车么。媳妇儿不耐烦的说，是撒，不成你要跟着我上去啊。那天就结束了。 现在的人通讯这样的发达，沟通自然不需要面对面，所以能避免很多尴尬的场面出现，在手机的另一端，可以暂时说忙，可以想想怎么说话，完全不会出啥状况。自然，我是加了媳妇儿的微信滴。我这人其实脸皮好薄，见面的时候，如果不是抱着某一目的的话还好，可以肆无忌惮的打量观察别人，但是一旦是抱着相亲这样的目的去的话，就实在不好意思老是盯着别人看了，去观察别人了，那时候长相我都没有好好看一下呢，或者其实是因为我近视了？ 人的习惯是难以改变的，我想每个男的加了妹子之后的第一件事估计就是去翻别人的朋友圈，毕竟这是一个了解别人平常生活的好机会嘛。在网络这个可以无病呻吟的地方，可以暴露出最真实的一面。哟喝，没想到那时候媳妇儿可是相当给力的，拍了不少自拍在朋友圈呢。我认为其实我是被一张她和岳栩在办公室里面的一些照片给吸引上了。居然看起来这么靓，这么可爱，笑靥如花啊，阳光开朗啊。好姑娘。 第一印象是极好的，刚见面的疏冷可以理解，哪里就有见面就热情的姑娘呢，人家又不是卖保险的。于是微信上面就开始了无营养有目的的对话。你要问我都说了什么？抱歉，太多我记不清楚了，再说了，这个是可以拿出来说的么。反正好几个晚上都是大半夜才睡觉呢，有戏，不想理你的人，会跟你说话到大半夜？开什么玩笑呢，大家都很忙，时间宝贵得很，第二天还要上班呢。眼圈黑了怎么办，影响工作怎么办。 期间媳妇儿说其实她有一个好想去的地方，是成都，因为曾经去过，感觉那边生活节奏不快，各方面都还可以。我说那你要是去了，你爸妈不就会很闹心，媳妇儿说嘛，自己先过去撒，等有能力再把父母接过去就是了。唔，有追求，有理想的女孩肯定都是充满了力量的。当时我心里还无不恶意的想，该不是她前男友就是成都的吧。别打我哦。 目标有了，沟通也有了，问题是怎么样才将我对她的这种爱慕之情表达出来，其实这是一个技术活。拿捏不好时机的话很容易弄巧成拙啊，在这方面没有什么经验的我，有点蛋疼。后面是说到什么问题？好像也是找对象的问题吧。我说找你妹啊，回答是我可没有妹，我就顺杆往上撑，没妹那你就顶上了。自然是不肯的，怎么能做妹妹的备胎呢，我早知道你没妹妹了，说的就是你啊。嗯，是被拒绝了的。不过，第一次这样不是非常直接的表白，被拒绝也很正常。但拒绝之后，面对抱有目的的男人，却不拒绝沟通，还有戏。 某日，媳妇儿晚上不是睡觉前么，准备泡个脚么。 “哟喂，你这洗脚还自己倒水啊，要不我来帮你吧。” “别扯了，你那么远，倒也倒不了。” “那这意思，我要是能给你倒你就让倒啊。” “是这个意思。” 要不人们总是说世事无常呢，谁也不知道明天或者下一刻究竟会发生什么呢。不过我是知道会发生什么的。就这样，我在2016年1月18号从贵阳回到东莞后，在1月21日，又坐上了去找个人帮倒洗脚水的飞机。要不我这一直跟媳妇儿说我真来了哦，她还点都不信。 这里不能不感谢瑶姐啊，不过也超级想抱怨这老是堵车的G75高速。14.50下的飞机，然后直接就想打车下去息烽的，结果路上堵车，整得到了17点多还没到。我到的时候，瑶姐花已准备好，就等我抱着送上去了。叶老大家，没错，我推门进去的时候几个正在打麻将，这次有莫宇在了。蔡友锋夸张滴从凳子上“掉”了下来，媳妇儿一脸扑在桌子上。脸红不红，我不知道，反正远了我看不清楚，不过我可是紧张激动脸也红的。 吃饭的时候嘛，蔡友锋就不停的发挥了好队友精神，当然，这个效果如何，我不得而知，不过从后面的结果来看肯定是有益滴。按说，都这样了，总得有点话语吧，不过我忘记了都干了些啥说了些啥了。别看在微信上可以热火朝天，但放在面对面的时候，就有点怂，人之常情。今天是安排了什么活动，也记得不太清楚了，重点还看一下第二天。 当天说到，听说息烽有家假洋西餐厅玛费尔开业了，在这个时候，不坑我坑谁，就说想去看看咋样。我必须毫不犹豫的说没问题啊，于是就约好第二天大家一起去咯，中午去。嗯，原来同志们都是超级上道的，到了第二天的时候，我早就前往目的地坐好，等待客人们的光临，结果，一个人没来。就剩下我未来媳妇儿一个人要来，不过那时候我可没告诉她就她一个人呢，说瑶姐要来。 空手过去的，不过突然灵机一动，召来餐厅小弟问一句，小伙计帮我去弄点花撒，要玫瑰哈。这伙计也是超级机灵的，附近没有花，他就跑到了三角花园去买了黑大一抱玫瑰回来。反正媳妇儿那时候是十分勉强的收下了，两人随便吃了点牛排就撤退了，八分熟的牛排感觉不咋样，非常的有中餐的味道。送着媳妇儿抱着花下楼，我看她却不是往单位去，反而回去外婆那了，纳闷，你不去上班么，马上到时间了。 “我总不能抱着这个去上班吧。” 这一次来回到此结束了，感觉吧，虽然没有明显的结果，然距离成功，还是有点距离。不过我相信那时候应该不会太远了。介于在东莞的有些事情还没有解决好，于是在24号的时候我又去了东莞。这时候都快过年了，我其实是不想过去的，但是呢，陈老板说我还是过去一下好。 谁又知道，过年才是好日子的到来哦。"},{"title":"about","date":"2017-12-24T08:56:53.000Z","updated":"2019-06-03T14:10:44.307Z","comments":true,"path":"soft/index.html","permalink":"https://gowa2017.github.io/soft/index.html","excerpt":"","text":"Kindle 用来阅读。Android，iOS 可装上APP。 OmniFocus 个人事务，时间管理。 GTD 最好的一个实现。 OmniPlan 项目管理 Alfred macOS 全局索引搜索 MacDown markdown 编辑器 Paw HTTP API 测试 Sequel Pro MySQL 客户端 WPS from MAC 没办法， office 365 也不好用啊 OmniDiskSweeper 用来做磁盘清理的 calibre 电子书制作转换 iTerm+zsh 终端工具 mycli MySQL 命令行客户端 VNC-Viewer VNC 客户端 p7zip 命令行压缩解压工具"}],"posts":[{"title":"关于RxJava操作符flatMap与concatMap的探究","slug":"关于RxJava操作符flatMap与concatMap的探究","date":"2019-08-01T15:53:06.000Z","updated":"2019-08-01T15:53:06.000Z","comments":true,"path":"RxJava/关于RxJava操作符flatMap与concatMap的探究.html","link":"","permalink":"https://gowa2017.github.io/RxJava/关于RxJava操作符flatMap与concatMap的探究.html","excerpt":"迷惑的地方在于当 flatMap 和 concatMap 在运作的时候，在配合线程切换的话，其细节到底是怎么样的呢？","text":"迷惑的地方在于当 flatMap 和 concatMap 在运作的时候，在配合线程切换的话，其细节到底是怎么样的呢？ FlatMap根据 Reactivex.io 网站上的定义： The FlatMap operator transforms an Observable by applying a function that you specify to each item emitted by the source Observable, where that function returns an Observable that itself emits items. FlatMap then merges the emissions of these resulting Observables, emitting these merged results as its own sequence. This method is useful, for example, when you have an Observable that emits a series of items that themselves have Observable members or are in other ways transformable into Observables, so that you can create a new Observable that emits the complete collection of items emitted by the sub-Observables of these items. Note that FlatMap merges the emissions of these Observables, so that they may interleave. 这些说的是： 我们使用一个函数来将 Observable 发射的每个元素都变换为一个 Observable。这个函数，我们称之为 mapper 然后 FlatMap 将所有变换后的 Observable 发射的元素进行 merge(合并)，最终，得到一个发射所有这些合并后元素的 Observable。 merge(合并)后的元素，其顺序是不一定的。 基础首先，我们知道，RxJava 的运作其实分成三个阶段： 装配（Assembly Time） 订阅（Subscription Time） 运行（Runtime） 例子Observable.just(\"A\",\"B\",\"C\") .flatMap(new Function&lt;String, ObservableSource&lt;String&gt;&gt;() &#123; @Override public ObservableSource&lt;String&gt; apply(String it) throws Exception &#123; return Observable.create(emitter -&gt; &#123; for (int i = 0; i &lt; 3; i++) &#123; emitter.onNext(String.format(\"%s-%d\", it, i)); &#125; ; emitter.onComplete(); &#125;); &#125; &#125;) .subscribe(System.out::println); AssemblyObservable.just(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;) 会返回一个 ObservableFromArray，在此我称其为 source。 当我们调用 source.flatMap()的时候，其实是在装配阶段，这个时候，其结果，会返回一个 ObservableFlatMap，为了称呼，我们称之为 flatObservable，此 ObservableFlatMap 的上流（upstream） 就是 source： RxJavaPlugins.onAssembly(new ObservableFlatMap&lt;T, R&gt;(this, mapper, delayErrors, maxConcurrency, bufferSize)); 好了，这个时候， source 与 flatObservable 之间的联系，也就是 flatObservable 持有 source 而已。 Runtime当我们对 flatObservable 进行订阅的时候，实际上，我们是对其指定了一个 Observer。 // ObservableFlatMap@Overridepublic void subscribeActual(Observer&lt;? super U&gt; t) &#123; if (ObservableScalarXMap.tryScalarXMapSubscribe(source, t, mapper)) &#123; return; &#125; source.subscribe(new MergeObserver&lt;T, U&gt;(t, mapper, delayErrors, maxConcurrency, bufferSize));&#125; 是不是很惊喜，flatObservable 利用一个 MergeObserver 又订阅了 source。 我们来看看， 我们的 source ObservableFromArray 这个时候干了什么： //ObservableFromArray @Override public void subscribeActual(Observer&lt;? super T&gt; observer) &#123; FromArrayDisposable&lt;T&gt; d = new FromArrayDisposable&lt;T&gt;(observer, array); observer.onSubscribe(d); if (d.fusionMode) &#123; return; &#125; d.run(); &#125; FromArrayDisposable(Observer&lt;? super T&gt; actual, T[] array) &#123; this.downstream = actual; this.array = array;&#125;void run() &#123; T[] a = array; int n = a.length; for (int i = 0; i &lt; n &amp;&amp; !isDisposed(); i++) &#123; T value = a[i]; if (value == null) &#123; downstream.onError(new NullPointerException(\"The \" + i + \"th element is null\")); return; &#125; downstream.onNext(value); &#125; if (!isDisposed()) &#123; downstream.onComplete(); &#125;&#125; 很简单，ObservableFromArray 建立了一个 FromArrayDisposable，其利用了 for 循环，给 downstream 传递数据（这里是 MergeObserver ）传递数据。 //MergeObserver @Override public void onNext(T t) &#123; // safeguard against misbehaving sources if (done) &#123; return; &#125; ObservableSource&lt;? extends U&gt; p; try &#123; p = ObjectHelper.requireNonNull(mapper.apply(t), \"The mapper returned a null ObservableSource\"); &#125; catch (Throwable e) &#123; Exceptions.throwIfFatal(e); upstream.dispose(); onError(e); return; &#125; if (maxConcurrency != Integer.MAX_VALUE) &#123; synchronized (this) &#123; if (wip == maxConcurrency) &#123; sources.offer(p); return; &#125; wip++; &#125; &#125; subscribeInner(p); &#125; MergeObserver 首先调用我们提供的 mapper 函数来获得一个 Observable。 // MergeObserver @SuppressWarnings(\"unchecked\") void subscribeInner(ObservableSource&lt;? extends U&gt; p) &#123; for (;;) &#123; if (p instanceof Callable) &#123; if (tryEmitScalar(((Callable&lt;? extends U&gt;)p)) &amp;&amp; maxConcurrency != Integer.MAX_VALUE) &#123; boolean empty = false; synchronized (this) &#123; p = sources.poll(); if (p == null) &#123; wip--; empty = true; &#125; &#125; if (empty) &#123; drain(); break; &#125; &#125; else &#123; break; &#125; &#125; else &#123; InnerObserver&lt;T, U&gt; inner = new InnerObserver&lt;T, U&gt;(this, uniqueId++); if (addInner(inner)) &#123; p.subscribe(inner); &#125; break; &#125; &#125; &#125; 接着，用一个 InnerObserver 来订阅了我们 mapper 返回的 Observable。这里，如果是 Callable 来的 Observer ,就直接发射数据了。InnerObserver 有一个 parent 参数，这里是 MergeObserver。 //InnerObserver @Override public void onSubscribe(Disposable d) &#123; if (DisposableHelper.setOnce(this, d)) &#123; if (d instanceof QueueDisposable) &#123; @SuppressWarnings(\"unchecked\") QueueDisposable&lt;U&gt; qd = (QueueDisposable&lt;U&gt;) d; int m = qd.requestFusion(QueueDisposable.ANY | QueueDisposable.BOUNDARY); if (m == QueueDisposable.SYNC) &#123; fusionMode = m; queue = qd; done = true; parent.drain(); return; &#125; if (m == QueueDisposable.ASYNC) &#123; fusionMode = m; queue = qd; &#125; &#125; &#125; &#125; @Override public void onNext(U t) &#123; if (fusionMode == QueueDisposable.NONE) &#123; parent.tryEmit(t, this); &#125; else &#123; parent.drain(); &#125; &#125; 当我们 mapper 向 InnerObserver 发射数据的时候，其直接将数据发射给了 MergeObserver。 这里说明一下，如果 InnerObserver 订阅的是一个 QueueDisposable 的话，那么其就会协商一下，发送模式，如果是同步发射，就会要求 MergeObserver 将所有 mapper 返回的 Observable 数据全部发射到 最下游再继续。 当我们的 mapper 返回的 Observable 发射模式是 QueueDisposable.NONE 时，MergeObserver 采用的是 tryEmit 的形式来发射数据： void tryEmit(U value, InnerObserver&lt;T, U&gt; inner) &#123; if (get() == 0 &amp;&amp; compareAndSet(0, 1)) &#123; downstream.onNext(value); if (decrementAndGet() == 0) &#123; return; &#125; &#125; else &#123; SimpleQueue&lt;U&gt; q = inner.queue; if (q == null) &#123; q = new SpscLinkedArrayQueue&lt;U&gt;(bufferSize); inner.queue = q; &#125; q.offer(value); if (getAndIncrement() != 0) &#123; return; &#125; &#125; drainLoop();&#125; 如果数据无法立即发射，那么就把他放在队列中，在 for 循环内进行遍历发射。 看起来好像不会出乱序的情况？例子中的执行确实也没有出现乱序这是为什么？ 这是因为我们是在同一个线程内进行操作的，同时我们的数据也比较特殊。 可以从这里来看，对于每一个 mapper 返回的 Observable，我们都用 InnerObserver 来进行了订阅，但是其何时发射数据，这个是不一定的。所以说，在 InnerObserver 的 onNext 方法中，随后调用 MergeObserver.tryEmit(value, inner) 的方法时，会有需要发射的值，放到 inner 的队列中，然后再进行发射。 因此这个顺序是不一定的。 ConcatMapConcatMap 的实现其实和 flatMap 有相似的地方。不过其多做了一点事情： 用 SourceObserver 来连接上游的 source。 用 InnerObserver 来订阅每个变换后的 Observable。 SourceObserver 的下流是一个 SerializedObserver 由 SerializedObserver 将数据发射至最后。 其工作的过程是： SourceObserver由 onNext 收到数据，放到队列中。 对队列中的数据进行应用 mapper ，然后用一个 InnerObserver 进行订阅。 InnerObserver 会将数据发射给 SerializedObserver。 SerializedObserver 也在在队列中将数据逐个发射出去。 SubscribeOn指定 Observable 在哪个 Scheduler 上进行操作。 ObserverOn这个操作符的意义，是指定，我们的 Observer 会在哪个 Scheduler 上观察 Observable，也就是说，Observable 将通知发送到哪个 Scheduler。","categories":[{"name":"RxJava","slug":"RxJava","permalink":"https://gowa2017.github.io/categories/RxJava/"}],"tags":[{"name":"RxJava","slug":"RxJava","permalink":"https://gowa2017.github.io/tags/RxJava/"}],"keywords":[{"name":"RxJava","slug":"RxJava","permalink":"https://gowa2017.github.io/categories/RxJava/"}]},{"title":"使用Retrofit-Rxjava来上传下载文件","slug":"使用Retrofit-Rxjava来上传下载文件","date":"2019-07-31T03:43:28.000Z","updated":"2019-07-31T03:43:28.000Z","comments":true,"path":"HTTP/使用Retrofit-Rxjava来上传下载文件.html","link":"","permalink":"https://gowa2017.github.io/HTTP/使用Retrofit-Rxjava来上传下载文件.html","excerpt":"使用 Http 协议进行文件传输的时候，需要了解一些必要的知识，然后才能配合使用 Retrofit 和 RxJava 来进行操作。","text":"使用 Http 协议进行文件传输的时候，需要了解一些必要的知识，然后才能配合使用 Retrofit 和 RxJava 来进行操作。 HTTP首先，HTTP 是一个超文本传输协议，以就是说，这个协议，是用来交互文本的，而不是二进制流的。我们必须把我们的文件转换成文本形式，才能进行传输。 RFC7230 定义了此协议。 术语URIURI （uniform resource identifier） 是统一资源标识符的意思。可以用来唯一的标识一个资源。 一般由三部分组成： URI一般由三部组成： ①访问资源的命名机制 ②存放资源的主机名 ③资源自身的名称，由路径表示，着重强调于资源。URL URL 是（Uniform Resource locator） 是统一资源定位器的意思，其也是一种 URI 的实现，其不仅指定了资源的标识，还指明了如何定位资源。 一般也是由三部分组成： ①协议(或称为服务方式) ②存有该资源的主机IP地址(有时也包括端口号) ③主机资源的具体地址。如目录和文件名等 URNURN，uniform resource name，统一资源命名，是通过名字来标识资源，比如mailto:java-net@java.sun.com。 消息格式start-line(method SP request-target SP HTTP-version CRLF/HTTP-version SP status-code SP reason-phrase CRLF)*( header-field CRLF )CRLF[ message-body ](message-body = *OCTET) 什么时候允许出现 message-body 在请求和响应消息中是不同的。 在请求中，如果 Header 有一个 Content-Length 或 Transfer-Encoding 字段，就表示会有一个 Body。请求消息的结构和方法的语义是相互独立的，因此及时方法没有定义会使用 message-body 其也可能会出现。 响应消息中是否会出现 message-body 与 其对应的请求和响应的状态码有关。 multipart/form-dataRFC 7578 定义了 multipart/form-data 媒体类型。对于 message-body 中是一个 multipart/form-data 的数据时，其是由很多分隔符分开的部分组成的。 Boundary 类似 “CRLF — Boundary” Content-Disposition 每个部分都会有这个字段，其类型是 form-data，同时包含一个额外的参数 “name”，表示从表单中初始的字段名。Content-Disposition: form-data; name=&quot;user&quot; 对于文件的话，可以用 filename 来替代 name，但有的时候这个参数没有意义，可能不会识别它，看服务器来决定。 Content-Type 可能会有，默认是 text/plain。如果发送的是文件的时候，那么默认的会是 application/octet-stream。 例子： --AaB03xcontent-disposition: form-data; name=&quot;field1&quot;content-type: text/plain;charset=UTF-8content-transfer-encoding: quoted-printableJoe owes =E2=82=AC100.--AaB03x Retrofit 实现上传2.0 需要用 OkHttp 的 RequestBody 或者 MultipartBody.Part 来封装我们的文件进行传输。 RequestBody 包含数据流，contentType, contentLength MultipartBody.Part 对 RequestBody 进行封装。事实上就是加上 content-disposition: form-data; name=&quot;field1&quot;; filename=&quot;field&quot; /** Returns a new request body that transmits the content of &#123;@code file&#125;. */public static RequestBody create(final @Nullable MediaType contentType, final File file) &#123; if (file == null) throw new NullPointerException(\"file == null\"); return new RequestBody() &#123; @Override public @Nullable MediaType contentType() &#123; return contentType; &#125; @Override public long contentLength() &#123; return file.length(); &#125; @Override public void writeTo(BufferedSink sink) throws IOException &#123; Source source = null; try &#123; source = Okio.source(file); sink.writeAll(source); &#125; finally &#123; Util.closeQuietly(source); &#125; &#125; &#125;;&#125; public static Part createFormData(String name, @Nullable String filename, RequestBody body) &#123; if (name == null) &#123; throw new NullPointerException(\"name == null\"); &#125; StringBuilder disposition = new StringBuilder(\"form-data; name=\"); appendQuotedString(disposition, name); if (filename != null) &#123; disposition.append(\"; filename=\"); appendQuotedString(disposition, filename); &#125; return create(Headers.of(\"Content-Disposition\", disposition.toString()), body); &#125; public static Part createFormData(String name, @Nullable String filename, RequestBody body) &#123; if (name == null) &#123; throw new NullPointerException(\"name == null\"); &#125; StringBuilder disposition = new StringBuilder(\"form-data; name=\"); appendQuotedString(disposition, name); if (filename != null) &#123; disposition.append(\"; filename=\"); appendQuotedString(disposition, filename); &#125; return create(Headers.of(\"Content-Disposition\", disposition.toString()), body); &#125; 可以看到 formdata 实际上就是将多个 RequestBody 封装成 Part 然后进行传输了。 一般来说，2.0会以下面的形式进行上传文件： public interface FileUploadService &#123; @Multipart @POST(\"upload\") Call&lt;ResponseBody&gt; upload( @Part(\"description\") RequestBody description, @Part MultipartBody.Part file );&#125;## 服务端代码```jsmethod: 'POST', path: '/upload', config: &#123; payload: &#123; maxBytes: 209715200, output: 'stream', parse: false &#125;, handler: function(request, reply) &#123; var multiparty = require('multiparty'); var form = new multiparty.Form(); form.parse(request.payload, function(err, fields, files) &#123; console.log(err); console.log(fields); console.log(files); return reply(util.inspect(&#123;fields: fields, files: files&#125;)); &#125;); &#125;&#125; 其将会打印日志： null &#123; description: [ &apos;hello, this is description speaking&apos; ] &#125;&#123; picture: [ &#123; fieldName: &apos;picture&apos;, originalFilename: &apos;20160312_095248.jpg&apos;, path: &apos;/var/folders/rq/q_m4_21j3lqf1lw48fqttx_80000gn/T/X_sxX6LDUMBcuUcUGDMBKc2T.jpg&apos;, headers: [Object], size: 39369 &#125; ] &#125; 完整代码private void uploadFile(Uri fileUri) &#123; // create upload service client FileUploadService service = ServiceGenerator.createService(FileUploadService.class); // https://github.com/iPaulPro/aFileChooser/blob/master/aFileChooser/src/com/ipaulpro/afilechooser/utils/FileUtils.java // use the FileUtils to get the actual file by uri File file = FileUtils.getFile(this, fileUri); // create RequestBody instance from file RequestBody requestFile = RequestBody.create( MediaType.parse(getContentResolver().getType(fileUri)), file ); // MultipartBody.Part is used to send also the actual file name MultipartBody.Part body = MultipartBody.Part.createFormData(\"picture\", file.getName(), requestFile); // add another part within the multipart request String descriptionString = \"hello, this is description speaking\"; RequestBody description = RequestBody.create( okhttp3.MultipartBody.FORM, descriptionString); // finally, execute the request Call&lt;ResponseBody&gt; call = service.upload(description, body); call.enqueue(new Callback&lt;ResponseBody&gt;() &#123; @Override public void onResponse(Call&lt;ResponseBody&gt; call, Response&lt;ResponseBody&gt; response) &#123; Log.v(\"Upload\", \"success\"); &#125; @Override public void onFailure(Call&lt;ResponseBody&gt; call, Throwable t) &#123; Log.e(\"Upload error:\", t.getMessage()); &#125; &#125;);&#125; OkHttp 的 Source与Sink从 RequestBody 的建立代码中，我们看到，实际上是将我们的 File 构造了一个 Source ， 然后写到了一个 Sink 中。 // Okio public static Source source(File file) throws FileNotFoundException &#123; if (file == null) &#123; throw new IllegalArgumentException(\"file == null\"); &#125; else &#123; return source((InputStream)(new FileInputStream(file))); &#125; &#125; public static Sink sink(File file) throws FileNotFoundException &#123; if (file == null) &#123; throw new IllegalArgumentException(\"file == null\"); &#125; else &#123; return sink((OutputStream)(new FileOutputStream(file))); &#125; &#125; 我们可以简单的将 Source, Sink 看成是输入流或者输入流。虽然其提供了一些很有用很方便有效率的方法，但这不影响我们的讨论。 我们来看一下 OkHttp 是怎么样发送请求的，在 CallServerInterceptor 中，最终发生网络请求，发送数据： @Override public Response intercept(Chain chain) throws IOException &#123; RealInterceptorChain realChain = (RealInterceptorChain) chain; HttpCodec httpCodec = realChain.httpStream(); StreamAllocation streamAllocation = realChain.streamAllocation(); RealConnection connection = (RealConnection) realChain.connection(); Request request = realChain.request(); long sentRequestMillis = System.currentTimeMillis(); realChain.eventListener().requestHeadersStart(realChain.call()); httpCodec.writeRequestHeaders(request); realChain.eventListener().requestHeadersEnd(realChain.call(), request); Response.Builder responseBuilder = null; // 如果 Post 方法，且含有一个 Body if (HttpMethod.permitsRequestBody(request.method()) &amp;&amp; request.body() != null) &#123; // If there's a \"Expect: 100-continue\" header on the request, wait for a \"HTTP/1.1 100 // Continue\" response before transmitting the request body. If we don't get that, return // what we did get (such as a 4xx response) without ever transmitting the request body. if (\"100-continue\".equalsIgnoreCase(request.header(\"Expect\"))) &#123; httpCodec.flushRequest(); realChain.eventListener().responseHeadersStart(realChain.call()); responseBuilder = httpCodec.readResponseHeaders(true); &#125; if (responseBuilder == null) &#123; // Write the request body if the \"Expect: 100-continue\" expectation was met. realChain.eventListener().requestBodyStart(realChain.call()); long contentLength = request.body().contentLength(); CountingSink requestBodyOut = new CountingSink(httpCodec.createRequestBody(request, contentLength)); BufferedSink bufferedRequestBody = Okio.buffer(requestBodyOut); request.body().writeTo(bufferedRequestBody); bufferedRequestBody.close(); realChain.eventListener() .requestBodyEnd(realChain.call(), requestBodyOut.successfulCount); &#125; else if (!connection.isMultiplexed()) &#123; // If the \"Expect: 100-continue\" expectation wasn't met, prevent the HTTP/1 connection // from being reused. Otherwise we're still obligated to transmit the request body to // leave the connection in a consistent state. streamAllocation.noNewStreams(); &#125; &#125; httpCodec.finishRequest(); if (responseBuilder == null) &#123; realChain.eventListener().responseHeadersStart(realChain.call()); responseBuilder = httpCodec.readResponseHeaders(false); &#125; Response response = responseBuilder .request(request) .handshake(streamAllocation.connection().handshake()) .sentRequestAtMillis(sentRequestMillis) .receivedResponseAtMillis(System.currentTimeMillis()) .build(); int code = response.code(); if (code == 100) &#123; // server sent a 100-continue even though we did not request one. // try again to read the actual response responseBuilder = httpCodec.readResponseHeaders(false); response = responseBuilder .request(request) .handshake(streamAllocation.connection().handshake()) .sentRequestAtMillis(sentRequestMillis) .receivedResponseAtMillis(System.currentTimeMillis()) .build(); code = response.code(); &#125; realChain.eventListener() .responseHeadersEnd(realChain.call(), response); if (forWebSocket &amp;&amp; code == 101) &#123; // Connection is upgrading, but we need to ensure interceptors see a non-null response body. response = response.newBuilder() .body(Util.EMPTY_RESPONSE) .build(); &#125; else &#123; response = response.newBuilder() .body(httpCodec.openResponseBody(response)) .build(); &#125; if (\"close\".equalsIgnoreCase(response.request().header(\"Connection\")) || \"close\".equalsIgnoreCase(response.header(\"Connection\"))) &#123; streamAllocation.noNewStreams(); &#125; if ((code == 204 || code == 205) &amp;&amp; response.body().contentLength() &gt; 0) &#123; throw new ProtocolException( \"HTTP \" + code + \" had non-zero Content-Length: \" + response.body().contentLength()); &#125; return response;&#125; 关于代码在于： long contentLength = request.body().contentLength(); CountingSink requestBodyOut = new CountingSink(httpCodec.createRequestBody(request, contentLength)); BufferedSink bufferedRequestBody = Okio.buffer(requestBodyOut); request.body().writeTo(bufferedRequestBody); bufferedRequestBody.close(); 此段代码将我们的 RequestBody 写到一个与连接相关联的 Sink 上，发送数据。 // RealConnection.java sink = Okio.buffer(Okio.sink(rawSocket)); 这个 sink 会在 Http1Code 构建 CountingSink 的时候用到，实际上数据就是写到这里面的。 对于构建的 BufferedSink，其是以 8192 字节每次写入套接字： // RealBufferedSink.java public long writeAll(Source source) throws IOException &#123; if (source == null) &#123; throw new IllegalArgumentException(\"source == null\"); &#125; else &#123; long totalBytesRead = 0L; long readCount; while((readCount = source.read(this.buffer, 8192L)) != -1L) &#123; totalBytesRead += readCount; this.emitCompleteSegments(); &#125; return totalBytesRead; &#125; &#125; 对于上传文件进度回调的思路看了一下谷歌，很多都是在我们将 RequestBody 读出并写到 sink 的时候进行回调： 比如这个地方：okhttp recipes 有类似的思路 上面这个是针对下载的。 而这个就是针对上传来显示进度的：OkHttp 上传显示进度","categories":[{"name":"RxJava","slug":"RxJava","permalink":"https://gowa2017.github.io/categories/RxJava/"},{"name":"HTTP","slug":"HTTP","permalink":"https://gowa2017.github.io/categories/HTTP/"}],"tags":[{"name":"RxJava","slug":"RxJava","permalink":"https://gowa2017.github.io/tags/RxJava/"}],"keywords":[{"name":"RxJava","slug":"RxJava","permalink":"https://gowa2017.github.io/categories/RxJava/"},{"name":"HTTP","slug":"HTTP","permalink":"https://gowa2017.github.io/categories/HTTP/"}]},{"title":"macOS上用brew安装nginx及ffmpeg实现RTSP转RTMP","slug":"macOS上用brew安装nginx及ffmpeg实现RTSP转RTMP","date":"2019-07-18T14:15:24.000Z","updated":"2019-07-18T14:15:24.000Z","comments":true,"path":"macOS/macOS上用brew安装nginx及ffmpeg实现RTSP转RTMP.html","link":"","permalink":"https://gowa2017.github.io/macOS/macOS上用brew安装nginx及ffmpeg实现RTSP转RTMP.html","excerpt":"","text":"安装ffmpegbrew install ffmpeg --with-ffplay ffplay 是一个播放器，可以直接播放各种流。 支持RTMP的Nginxbrew tap denji/nginxbrew install nginx-full --with-rtmp-modulebrew info nginx-full https://www.jianshu.com/p/cf74a34af15d 推流ffmpeg -re -rtsp_transport tcp -i \"rtsp://host/dss/monitor/params?cameraid=1000025%2412&amp;substream=1\" -f flv -vcodec libx264 -vprofile baseline -acodec aac -ar 44100 -strict -2 -ac 1 -f flv -s 1280x720 -q 10 \"rtmp://localhost:1935/mylive/1\" Nginx 官方配置https://github.com/arut/nginx-rtmp-module","categories":[{"name":"macOS","slug":"macOS","permalink":"https://gowa2017.github.io/categories/macOS/"}],"tags":[{"name":"macOS","slug":"macOS","permalink":"https://gowa2017.github.io/tags/macOS/"}],"keywords":[{"name":"macOS","slug":"macOS","permalink":"https://gowa2017.github.io/categories/macOS/"}]},{"title":"在C++与Java中的一些不同","slug":"在C++与Java中的一些不同","date":"2019-07-13T09:28:36.000Z","updated":"2019-07-13T09:28:36.000Z","comments":true,"path":"Cpp/在C++与Java中的一些不同.html","link":"","permalink":"https://gowa2017.github.io/Cpp/在C++与Java中的一些不同.html","excerpt":"之前是学 C， 后面是用 Java 做安卓开发，现在又有机会来看一下 MFC，但是就对于其中一些概念并不是很明白，或者是因为我并没有完整的看过一些书籍的问题。特别是 MFC 对于 Win32 的封装，看起来有一些很古怪的地方。","text":"之前是学 C， 后面是用 Java 做安卓开发，现在又有机会来看一下 MFC，但是就对于其中一些概念并不是很明白，或者是因为我并没有完整的看过一些书籍的问题。特别是 MFC 对于 Win32 的封装，看起来有一些很古怪的地方。 在 关于Cpp的声明与定义 一文中说到，对于 Cpp 来说，所有要使用的符号（变量，类，对象）以后，都是要先声明然后才可以使用的，声明可以有多处，但是定义只能有一处。所以，通常来说都会将声明放在 .h 文件中，而将实现放在 .cpp 文件中。这只是一个约定的行为而已。 但事实上，对于编译器本身而言，他们对文件是什么扩展名，是不做任何假设。之所以能够将 .h 中的文件进行引入，是因为 #includer 语句的原因而不是其他。 但我就发觉了一个非常不好的习惯，或者只是因为我习惯了 Java 所以不习惯 Cpp 而已么？ 一个文件中定义多个类这个经常能够看到，比如像 VS 还提供了一个叫做 类视图 的东西，在这里看到的东西，和在 解决方案视图，也就是文件视图里面看到的东西是完全不一样的，为什么不将每个类单独定义在一个地方呢？ 更有甚者，在一个文件中定义多个类，定义多个变量，将类的定义和与其他非类的，比如说函数的定义放在一起，这是为什么呢？ 在类中调用非类的函数这才是纳闷的地方。特别是 MFC，在类对象代码内部到处都是调用 API 函数的地方，比如，可以调用 C 的 标准库函数这样。而用 std::print 这样的函数我还好理解一些呢？ 还有什么？ 最终看多很多地方都会说到一个问题，也不是我第一个有这个疑问。因为 Cpp 并不是一种纯对象的语言，其支持面向对象、面向过程、基于对象的变成，所以就不难理解这些了。 这里有个基于对象的说法是：将数据和操作封装在对象中，但是并没有合理的使用多态，继承等面向技术，其实大多数时候我写 Java 也是这样的了","categories":[{"name":"Windows","slug":"Windows","permalink":"https://gowa2017.github.io/categories/Windows/"},{"name":"Cpp","slug":"Cpp","permalink":"https://gowa2017.github.io/categories/Cpp/"}],"tags":[{"name":"Cpp","slug":"Cpp","permalink":"https://gowa2017.github.io/tags/Cpp/"}],"keywords":[{"name":"Windows","slug":"Windows","permalink":"https://gowa2017.github.io/categories/Windows/"},{"name":"Cpp","slug":"Cpp","permalink":"https://gowa2017.github.io/categories/Cpp/"}]},{"title":"关于Cpp的声明与定义","slug":"关于Cpp的声明与定义","date":"2019-07-11T04:21:23.000Z","updated":"2019-07-11T04:21:23.000Z","comments":true,"path":"Cpp/关于Cpp的声明与定义.html","link":"","permalink":"https://gowa2017.github.io/Cpp/关于Cpp的声明与定义.html","excerpt":"一直以来没有细细探究，对于变量的作用域，当遇到 extern, const 等的时候到底会发生什么变化，有什么意义，全局变量到底是怎么样的，所以就会茫然不知所措，所以来细细的看一下一番。","text":"一直以来没有细细探究，对于变量的作用域，当遇到 extern, const 等的时候到底会发生什么变化，有什么意义，全局变量到底是怎么样的，所以就会茫然不知所措，所以来细细的看一下一番。 我们知道，C/C++ 的源文件一般都包括 .c, .cpp, .h 文件，那么这是怎么样工作的呢？这两者有什么区别，在这些文件里面定义或者写的代码到底有什么不同呢？ 首先我们要大概的了解一个过程，就是从我们写的人可读的代码和机器可以执行的代码间还有两步工作需要做，这个是以编译器，和链接器来完成的。 编译。将我们写的代码编译成 obj 文件。 链接。将我们的 obj 文件以一定的格式合并成一个。 我们可以确定的就是，对于一个 .cpp, .c 文件最终肯定会编译出一个 obj 文件的。那么为什么 .h 没有？ 这就是我们使用 .h 文件的用法有关了。 通常，我们会以 #include &quot;header.h&quot; 这样的形式来使用头文件，这样做的意义是什么？这样做的意义是将 header.h 里面包含的内容，复制到 #include 这个位置而已。所以，最终编译的是 .c/.cpp 文件。 事实上我们可以测试一下，我们在一个头文件内声明一个函数，但是并没有对应的 .c/.cpp 实现这个函数，在编译阶段是不会出错的，但在链接阶段却会链接不了。 可能你会问，为什么我包含 stdio.h 的时候却不会？因为编译器已经有了默认实现了。 官方说明一个程序由一个或多个翻译单元组成。而一个翻译单元由一个实现文件（.cpp, .c 等）及其直接或间接包含的 .h 头文件来组成。编译器会将每个翻译单元独立编译，然后由链接器将他们合并为一个程序。 声明与定义我们先来了解这两者之间的区别。 比较笼统概括的说法就是：声明为程序引入了一个符号，而定义指定了这个符号所描述的数据或者代码。编译器需要已经声明的符号有实现才能分配存储空间。 声明所有符号使用前都必须声明不然就会出错。一个符号在程序中可以多次声明，我们可以在不同的编译单元内进行声明同一个符号，但是同一个符号的声明必须是一致的。大多数时候，进行声明的时候其实就已经执行了定义这个操作了，但有几个情况是例外的： 声明的是一个函数原型（没有函数体） 包含 extern 关键词，但并没有进行初始化或者函数体。这表示在当前的翻译单元内定义不是必须的，同时这个符号是外部链接的 对一个类的声明中，声明了一个 static 数据成员。因为静态类成员被所有的类的实力所共享，那么静态类成员就必须在类的声明外进行定义和初始化。 是一个类名称声明，但并没有跟随定义。如 class T; typedef 语句 一个符号在声明符（declarator）后即进行了声明，之后才会进行初始化。 一个对象的声明也是一出，除非其包含 extern 存储类修饰符。（这个我还没弄清楚）。 定义如此我们就能看出声明与定义的区别了。定义是需要分配存储空间的，而大多数时候其实声明就进行了定义。 extern经常我们会用到这个关键词，其实更多的还是我会用到 extern &quot;C&quot; 这个才对。但是，当我们在全局变量上应用此关键词的时候，其意义会依环境而有所不同。 extern 作用于全局变量、函数或者模板声明来指定此符号是链接到外部的。根据 extern 出现上下文的不同，其有四种意义： 在非常量的全局变量中， extern 指明变量或者函数定义在其他的翻译单元内。除了在定义此变量或者函数的文件内不需要 extern，所有其他单元内都必须指定 extern。 在 const 全局变量中，在定义处也要指定 extern。因为，const 全局变量默认只在本单元内可见。 extern “C” 指定该函数在其他地方定义，并使用 C 语言的调用约定。 在模板声明中，它指定该模板，也实例化其他位置。 非常量的全局变量应用 extern当编译前在一个全局变量前发现 extern 时，它会在其他的翻译单元中查找全局变量的定义。 // fileA.cppint i = 43; //声明和定义全局变量 i// fileB.cppextern int i; // 仅仅声明// fileC.cppextern int i; // 仅仅声明// fileD.cppint i = 43; // 报错， i 已经定义过了extern int i = 43; // 报错， i 已经定义过了 const 全局变量应用 extern一个 const 全局变量默认情况下是内部链接的，我们可以使用 extern 来将其定义为外部链接的： // fileA.cppextern const int i = 42;// extern const 定义// fileB.cppextern const int; // extern const 声明 staticstatic 可以用来全局作用域、命名空间作用域、类作用域声明变量和函数。 static 变量也可以在本地作用域进行声明。 static 周期意味着此对象或者变量自程序开始运行时就会分配内存然后在程序终止时回收内存。默认情况下，一个在全局命名空间定义的变量或对象是静态的生命周期和外部的链接域。 static 可以在下面几种情况使用： 当怎么在文件作用域（全局或命名空间作用域）声明变量或函数时，static 说明此变量或者函数是内部链接的，外部不可见。当我们声明一个变量，变量有静态生命周期的时候，编译器会将其初始化为0. 当我们在函数内声明变量时，static 会在多次调用函数中保持此变量的状态。 当我们在类声明内声明一个数据成员时，static 表明此成员被所有此类的实例所共享。static 数据成员必须在文件作用域进行定义。 当我们在类声明中生命一个成员函数时，static 指明此方法为所有的此类实例所共享。静态成员方法不可以调用实例方法，因为其不含有 this 指针。想要达到这个目的，可以将实例作为一个参数传递给 static 方法。","categories":[{"name":"Windows","slug":"Windows","permalink":"https://gowa2017.github.io/categories/Windows/"},{"name":"Cpp","slug":"Cpp","permalink":"https://gowa2017.github.io/categories/Cpp/"}],"tags":[{"name":"Windows","slug":"Windows","permalink":"https://gowa2017.github.io/tags/Windows/"},{"name":"Cpp","slug":"Cpp","permalink":"https://gowa2017.github.io/tags/Cpp/"}],"keywords":[{"name":"Windows","slug":"Windows","permalink":"https://gowa2017.github.io/categories/Windows/"},{"name":"Cpp","slug":"Cpp","permalink":"https://gowa2017.github.io/categories/Cpp/"}]},{"title":"MFC中的多线程","slug":"MFC中的多线程","date":"2019-06-30T13:26:07.000Z","updated":"2019-06-30T13:26:07.000Z","comments":true,"path":"Windows/MFC中的多线程.html","link":"","permalink":"https://gowa2017.github.io/Windows/MFC中的多线程.html","excerpt":"嗯，事实上 MFC 的封装不是这么好用啊。诸如因为我先是了解过安卓，然后再来看 MFC，就觉得 MFC 实在是有点猥琐。线程间的通信，似乎比较简单而强大的方式就是利用 Message 的方式，就如同 Android 中的 Hhandler 一样。","text":"嗯，事实上 MFC 的封装不是这么好用啊。诸如因为我先是了解过安卓，然后再来看 MFC，就觉得 MFC 实在是有点猥琐。线程间的通信，似乎比较简单而强大的方式就是利用 Message 的方式，就如同 Android 中的 Hhandler 一样。 CWinThread对于我们的每一个 MFC 程序来说，都会有一个主线程，和主进程。这两者，是有操作系统来针对每个程序来建立的。通常，我们的主线程会运行在一个从 CWinApp 继承的类中。 大体上可以将 MFC 的线程分为两类：工作线程与 UI 线程，两者的区别就在于是否处理消息。当然，CWinThread 本身都有一个消息队列，而有没有一个消息循环来处理这个队列，就决定了其到底是一个工作线程还是 UI 线程。 如安卓那样，事实上我更愿意将所有的 UI 操作都放在一个线程（主线程），而将其他的文件相关，网络相关的操作都放到另外一个线程，这势必就涉及到线程间如何通信的问题。 通常， CWinThread 实例的生命周期和其创造的线程是一致的，但我们可以通过设置 m_bAutoDelete 为 FALSE 来改变这一行为。 我们可以通过 AfxBeginThread() 方法来建立线程。如果我们想要建立的是一个 UI 线程，那么需要传递给这个函数一个继承自 CWinThread 类的 CRutimeClass。 当然我们其实也可以通过一个两步操作来建立线程，这在需要复用 CWinThread 对象的时候就很有用了： 建立 CWinThread 对象。 调用其 CreateThread 方法。 AfxBeginThreadCWinThread* AfxBeginThread( AFX_THREADPROC pfnThreadProc, LPVOID pParam, int nPriority = THREAD_PRIORITY_NORMAL, UINT nStackSize = 0, DWORD dwCreateFlags = 0, LPSECURITY_ATTRIBUTES lpSecurityAttrs = NULL);CWinThread* AfxBeginThread( CRuntimeClass* pThreadClass, int nPriority = THREAD_PRIORITY_NORMAL, UINT nStackSize = 0, DWORD dwCreateFlags = 0, LPSECURITY_ATTRIBUTES lpSecurityAttrs = NULL); 这两种形式， 主要的区别就是一个接受一个 CRuntimeClass 也就是我们的继承类类型作为参数，一个直接就将函数作为参数了。 例子我们就以多个线程不停的获取当前时间，然后显示到我们的对话框为例来进行展示。 线程间通信通常，我们多个线程之间是需要通信的，比如对于多个线程计算后的结果我需要在主线程（UI线程上最终显示出来），这个时候我们怎么来处理这些个问题。 前面的内容我们已经知道， CWinThread 其实是有消息队列的，同时如果处理 UI 消息的话还会有消息循环，所以我们可以完全以传递消息的形式来进行通信。但我也忍不住会想，那对于没有处理窗口信息的线程又该怎么办呢。 事实上这也是可以的。","categories":[{"name":"Windows","slug":"Windows","permalink":"https://gowa2017.github.io/categories/Windows/"}],"tags":[{"name":"Windows","slug":"Windows","permalink":"https://gowa2017.github.io/tags/Windows/"},{"name":"MFC","slug":"MFC","permalink":"https://gowa2017.github.io/tags/MFC/"}],"keywords":[{"name":"Windows","slug":"Windows","permalink":"https://gowa2017.github.io/categories/Windows/"}]},{"title":"MFC中的字符宏与CString","slug":"MFC中的字符宏与CString","date":"2019-06-29T15:26:00.000Z","updated":"2019-06-29T15:26:00.000Z","comments":true,"path":"Windows/MFC中的字符宏与CString.html","link":"","permalink":"https://gowa2017.github.io/Windows/MFC中的字符宏与CString.html","excerpt":"MFC 的宏太多了，让人目不暇接，回想 Linux 下的多简单呢，各种各样的接口和调用都都非常少，哪里像 MFC 这么恶心。","text":"MFC 的宏太多了，让人目不暇接，回想 Linux 下的多简单呢，各种各样的接口和调用都都非常少，哪里像 MFC 这么恶心。 字符集(CharacterSet)与编码(Encoding)我们先要区分开这两个概念才能理解后面文中说的那么多符号到底是什么东西。 字符集。符号的集合。对于字符集的每个符号，用一个代码来表示，就叫编码。 编码。对于符号的编码，我们需要存储在计算机中，这个就叫存储。 ANSIANSI 是一套字符集，其编码就是 ANSI 编码。 ASNI 中有 8bit 来存储一个字符，所以其支持的符号是有限的，只有最多 256 个，这对于我们中文来说肯定是不够的。 UnicodeUnicode 是一套字符集，其没有定义编码，所以说其有多种实现。也就是说对于 Unicode 有多种形式来存储在计算机上。 UTF-8UTF-8 是 Unicode 的一个编码实现，其使用变长字节来存储 Unicode 编码。 UTF-8 的存储规则如下： 单字节符号。第一位为 0，后面 7 位是其 Unicode 码，在英文字母中， ANSI 与 Unicode 编码一致。 N 字节的符号（N&gt;1）。第 1 字节的前 n 位置 1，n+1 位置 0，后面所有字节的前两位都是 0。其余位就保存了 Unicode 编码。 UTF-8 中，中文字符需要三个字节来存储，英文字符只需要一个字节来存储。 UTF-16/UCS-2固定使用 2byte 的 Unicode 编码。 UTF-32/UCS-4固定使用 4byte 的 Unicode 编码。 MFC 中的应用char wchar_tchar 是 8bit 的，其只能表示应该 ANSI 字符。wchar_t 表示一个宽字符类型，意思是多字节的，可以存储任何 Unicode 字符，因此我们在涉及中文的时候一般都会用到。 MFC 中一般不直接使用这两个类型，而是使用很多定义了的宏。 L这个很简单，这个一般用来放在字符前面，告诉编译器，这是一个 Unicode 字符。 _T _TEXT其定义为： #define _T(x) __T(x)#define _TEXT(x) __T(x) 而根据我们程序使用字符集的不同，__T 有两种定义形式： #define __T(x) L ## x // Unicode#define __T(x) x //ANSI 所以说，_T 会根据我们程序的字符集类型来自动匹配字符的编码。 TEXT_TEXT 定义在 winnt.h 中，其作用与 _T 一致。 使用我们在用到字符的时候，必须告诉编译器，我们的字符是什么类型的，以此才能决定如何存储在文件中去。 因此我们可以使用 _T, _TEXT, TEXT CStringCString, CStringA, CStringW 都是模板类 CStringT 的一个特殊实现。不同在于： CStringW 包含了 wchar_t 类型，支持 Unicode 字符。 CStringA 包含了 char 类型，支持单字节和多字节字符。 CString 根据编译时指定的字符类型决定其应该是什么类型。Unicode 和单字节多字节都支持。 CString 对象支持将字符存在在一个 CStringData 对象内，其接受 C 风格的 NULL 结尾的字符串。CString 可以更高性能的跟踪字符串的长度，但它也支持从存储的字符数据内获取 NULL 字符来支持转换到 LPCWSTR 类型。 有几种类型不需要链接到 MFC 库就能使用：CAtlString[AW]。 构造一个 CString： #include &lt;atlstr.h&gt;int main() &#123; CString aCString = CString(_T(\"A string\")); _tprintf(_T(\"%s\"), (LPCTSTR) aCString);&#125;","categories":[{"name":"Windows","slug":"Windows","permalink":"https://gowa2017.github.io/categories/Windows/"}],"tags":[{"name":"Windows","slug":"Windows","permalink":"https://gowa2017.github.io/tags/Windows/"},{"name":"MFC","slug":"MFC","permalink":"https://gowa2017.github.io/tags/MFC/"}],"keywords":[{"name":"Windows","slug":"Windows","permalink":"https://gowa2017.github.io/categories/Windows/"}]},{"title":"MFC窗口相关方法","slug":"MFC窗口相关方法","date":"2019-06-27T17:06:16.000Z","updated":"2019-06-27T17:06:16.000Z","comments":true,"path":"Windows/MFC窗口相关方法.html","link":"","permalink":"https://gowa2017.github.io/Windows/MFC窗口相关方法.html","excerpt":"在MFC手动建立进程 我们已经知道了如何手动建立一个进程。但我们在建立这个进程后，我们还有很多事情需要做，比如控制这个进程的主窗口啊，移动啊等等，那么我们就需要获得这个进程的窗口信息。","text":"在MFC手动建立进程 我们已经知道了如何手动建立一个进程。但我们在建立这个进程后，我们还有很多事情需要做，比如控制这个进程的主窗口啊，移动啊等等，那么我们就需要获得这个进程的窗口信息。 EnumWindows通过按序传递一个 Handle 到一个我们自定义的回调函数来 枚举所有在屏幕上的顶级的窗口（主窗口）。此方法会在所有的窗口都已经枚举完或我们定义的方法返回 FALSE 时结束。 BOOL EnumWindows( WNDENUMPROC lpEnumFunc, LPARAM lParam); 这个方法比在一个循环中调用 GetWindow() 更安全，因为 GetWindow() 方法可能会进入无限循环或者引用一个已经销毁了的窗口。 执行成功返回 非0 值，失败返回 0 值，这时候可以调用 GetLastError() 来获取错误信息。 如果 lpEnumFunc 返回一个 0值，那么这个函数也会返回 0值。我们就需要在我们的回调函数中返回一个有意义的错误值了。 EnumWindowsProcBOOL CALLBACK EnumWindowsProc( _In_ HWND hwnd, _In_ LPARAM lParam); 此方法接受一个顶层窗口的 Handle，我们在这里面实现我们自己的逻辑 EnumThreadWindows枚举一个线程的非子窗口，通过将此线程拥有的窗口的 Handle 传递给我们自定义的函数来进行实现。 BOOL EnumThreadWindows( DWORD dwThreadId, WNDENUMPROC lpfn, LPARAM lParam); 这个效率应该更高呢。 FindWindow通过窗口名（标题栏名称）或者类名来查找窗口。 HWND FindWindow( LPCSTR lpClassName, LPCSTR lpWindowName); EnumChildWindows枚举某一窗口下的所有子窗口 BOOL EnumChildWindows( HWND hWndParent, WNDENUMPROC lpEnumFunc, LPARAM lParam);","categories":[{"name":"Windows","slug":"Windows","permalink":"https://gowa2017.github.io/categories/Windows/"}],"tags":[{"name":"Windows","slug":"Windows","permalink":"https://gowa2017.github.io/tags/Windows/"}],"keywords":[{"name":"Windows","slug":"Windows","permalink":"https://gowa2017.github.io/categories/Windows/"}]},{"title":"用brew安装老版本的应用","slug":"用brew安装老版本的应用","date":"2019-06-27T15:58:40.000Z","updated":"2019-06-27T15:58:40.000Z","comments":true,"path":"macOS/用brew安装老版本的应用.html","link":"","permalink":"https://gowa2017.github.io/macOS/用brew安装老版本的应用.html","excerpt":"brew 确实很强大，但是平时装东西都是一个 brew install 就完事了。终于有天遇到了想要安装老版本的应用的时候。比如对于鼠须管输入法，默认升级为新的 0.1.12 版本后，使用了新版本的词库，我这老版本的就不能用了，只能回退过去了。","text":"brew 确实很强大，但是平时装东西都是一个 brew install 就完事了。终于有天遇到了想要安装老版本的应用的时候。比如对于鼠须管输入法，默认升级为新的 0.1.12 版本后，使用了新版本的词库，我这老版本的就不能用了，只能回退过去了。 事实上，在 brew 的文档中已经提供了方法来进行安装，只是一直没有细读，都是谷歌一番照着做。今天才想到来看一下是怎么搞的。 关于 brew 的源brew 官方默认有 core/cask 两个源。我们可以通过命令来识别这一点： brew taphomebrew/caskhomebrew/cask-drivershomebrew/core 这些源的内容都是放在 $(brew --repo)/Library/Taps/ 下面的。 我们想要查看每一应用的信息时可以使用： brew edit squirrel 这种形式。 有多个版本可供选择我们在安装前可以搜索一下看是否有多个版本的情况。 brew search gccgcc gcc@4.9 gcc@5 gcc@6 gcc@7 gcc@8 i386-elf-gcc 像这种后面带有 @ 的就可以直接安装不同的版本了。 brew install gcc@4.9 但是有的时候，我们是看不到这种情况的。比如我要装的鼠须管： ==&gt; Formulaesquirrel==&gt; Caskssquirrel ✔ squirrelsql 有同名的，但我需要安装的后面这个。这个时候我们要装老版本我们怎么搞呢？ 通过 pull 的提交来安装我们通过查看 pull 历史来查找我们需要安装的那个版本。 对于 core 源的在 这里查看 对于 cask 源的在 这里查看 比如我想要安装的是 python 3.7.0 版本： brew install https://raw.githubusercontent.com/sashkab/homebrew-core/176823eb82ee1b5ce55a91e5e1bf2f50aa674092/Formula/python.rb 回退 rb 文件版本来安装我们要安装的 squirrel 位于 cask 下面： cd $(brew --repo)/Library/Taps/homebrew/homebrew-cask/Casksgit log squirrel.rb 将这个文件回退到我们想要的版本，然后 brew install 直接安装就是了。","categories":[{"name":"macOS","slug":"macOS","permalink":"https://gowa2017.github.io/categories/macOS/"}],"tags":[{"name":"macOS","slug":"macOS","permalink":"https://gowa2017.github.io/tags/macOS/"}],"keywords":[{"name":"macOS","slug":"macOS","permalink":"https://gowa2017.github.io/categories/macOS/"}]},{"title":"Vim在插入模式和命令模式间自动切换中英文输入法","slug":"Vim在插入模式和命令模式间自动切换中英文输入法","date":"2019-06-26T13:48:00.000Z","updated":"2019-06-26T13:48:00.000Z","comments":true,"path":"Vim/Vim在插入模式和命令模式间自动切换中英文输入法.html","link":"","permalink":"https://gowa2017.github.io/Vim/Vim在插入模式和命令模式间自动切换中英文输入法.html","excerpt":"因为我习惯了用 Vim 因此在编码的时候就想到，如果我们在切换成命令模式的时候输入法会自动的切换为英文就好了。否则的话来回切换编码是非常头疼的事情。这不，在众多使用 vim 模拟这样的情况下没有解决方案，但是对于 Vim 本身倒是有不少的方法。","text":"因为我习惯了用 Vim 因此在编码的时候就想到，如果我们在切换成命令模式的时候输入法会自动的切换为英文就好了。否则的话来回切换编码是非常头疼的事情。这不，在众多使用 vim 模拟这样的情况下没有解决方案，但是对于 Vim 本身倒是有不少的方法。 smartimsmartim 是一个。去工作方式也就是利用了一个插件来监控我们是否进入和离开了 Vim 的模式。根据模式的切换来触发执行系统命令改变键盘布局。 其使用到了一个叫 im-select 的命令，插件内已经包含了。 当时用的时候苦恼了一会的就是，我并不是很清楚我的英文输入方式下的那个输入法id是什么，其实很简单的一个解决办法：我们手动将输入法切换到那个，然后执行 ./im-select 就能打印出来当前的输入法ID了。 fcitx-remote-for-osxfcitx-remote-for-osx 也是一个，工作的原理类似的。","categories":[{"name":"Vim","slug":"Vim","permalink":"https://gowa2017.github.io/categories/Vim/"}],"tags":[{"name":"Vim","slug":"Vim","permalink":"https://gowa2017.github.io/tags/Vim/"}],"keywords":[{"name":"Vim","slug":"Vim","permalink":"https://gowa2017.github.io/categories/Vim/"}]},{"title":"MFC手动建立进程","slug":"MFC手动建立进程","date":"2019-06-22T06:19:04.000Z","updated":"2019-06-22T06:19:04.000Z","comments":true,"path":"Windows/MFC手动建立进程.html","link":"","permalink":"https://gowa2017.github.io/Windows/MFC手动建立进程.html","excerpt":"事实上，手动建立进程是属于 winapi，而不是由 MFC 的封装。通常，我们在想要打开其他应用的时候，就需要在程序中用到 CreateProcess 函数了。","text":"事实上，手动建立进程是属于 winapi，而不是由 MFC 的封装。通常，我们在想要打开其他应用的时候，就需要在程序中用到 CreateProcess 函数了。 CreateProcess这个函数会建立一个新的进程，及其主线程。新进程运行在调用此方法的安全上下文中。 如果当前登录用户是 A，而调用进程是以 B 的身份运行的，那么新的进程会使用 A 进行运行，而不使用 B用户，也就是说，不会继承调用进程的身份信息。 如果想要让新进程以 B 身份运行的话，那么考虑使用 CreateProcessAsUser() 和 CreateProcessWithLogonW()。 基本语法BOOL CreateProcessA( LPCSTR lpApplicationName, LPSTR lpCommandLine, LPSECURITY_ATTRIBUTES lpProcessAttributes, LPSECURITY_ATTRIBUTES lpThreadAttributes, BOOL bInheritHandles, DWORD dwCreationFlags, LPVOID lpEnvironment, LPCSTR lpCurrentDirectory, LPSTARTUPINFOA lpStartupInfo, LPPROCESS_INFORMATION lpProcessInformation); lpApplicationName 要执行的模块名称。可以是完整路径，也可以是一个相对路径。如果是相对路径的话就会在当前目录下进行查找，其不会使用系统路径进行查找。这个名称必须包扩扩展名。此参数也可以是 NULL，那么其将将 lpCommandLine 参数的第 1 段当作模块名称。 lpCommandLine 命令行参数。如果我们 lpApplicationName 为空的情况下，我们可以用 “calc file.txt” 这样的形式来指定这个参数。 lpProcessAttributes 进程属性。一个指向 SECURITY_ATTRIBUTES 数据结构的指针，用来决定函数返回的新进程的 Handle 能否被子进程继承。如果设置为 NULL，那么是不可继承的。 lpThreadAttributes 同上，指定线程属性。 bInheritHandles 如果此参数为 TRUE，在调用进程中的所有可继承的 Handle 都会被新进程继承。 dwCreationFlags 建立标志。 lpEnvironment 指新进程的运行环境。如果指定为 NULL，则和调用进程一致。 lpCurrentDirectory 工作目录。完整路径。如果为 NULL，则和调用进程一致。 lpStartupInfo 指向 STARTUPINFO[EX]的结构。 lpProcessInformation 指向 PROCESS_INFORMATION。 需要注意的是， lpCommandLine 的类型是 LPSTR 表示这是一个可变的，必须用变量的形式来传递不能用常量。不然将会出现异常。这个建立进程，真心的比 linux的，fork-execute 麻烦多了。 返回值如果建立成功，返回值是非0的。如果返回值为0，那么可以用 GetLastError() 来获取错误信息。 备注新进程会被指定一个标识符。这个标识符在进程存在期间都可用。可以用来标识此进程，或者作为 OpenProcess() 参数来打开一个对此进程引用的 Handle。 初始化的线程也会被赋予标识符。同样可以作为参数传递给 OpenThread()。 调用线程可以用 WaitForInputIdle() 函数来等待，直到新的进程初始化完毕，用户已经没有输入。这在父子进程间进行同步是非常有用的，因为 CreateProcess() 不会等待子进程的初始化完毕。具体而言，调用进程可以用 WaitForInputIdle() 来等待直到已经有一个窗口附到了子进程上。 首选方式是使用 ExitProcess() 来结束进程，这个方式会通知将所有的 DLL 都给关掉。 实例#include &lt;windows.h&gt;#include &lt;stdio.h&gt;#include &lt;tchar.h&gt;void _tmain( int argc, TCHAR *argv[] )&#123; STARTUPINFO si; PROCESS_INFORMATION pi; ZeroMemory( &amp;si, sizeof(si) ); si.cb = sizeof(si); ZeroMemory( &amp;pi, sizeof(pi) ); if( argc != 2 ) &#123; printf(\"Usage: %s [cmdline]\\n\", argv[0]); return; &#125; // Start the child process. if( !CreateProcess( NULL, // No module name (use command line) argv[1], // Command line NULL, // Process handle not inheritable NULL, // Thread handle not inheritable FALSE, // Set handle inheritance to FALSE 0, // No creation flags NULL, // Use parent's environment block NULL, // Use parent's starting directory &amp;si, // Pointer to STARTUPINFO structure &amp;pi ) // Pointer to PROCESS_INFORMATION structure ) &#123; printf( \"CreateProcess failed (%d).\\n\", GetLastError() ); return; &#125; // Wait until child process exits. WaitForSingleObject( pi.hProcess, INFINITE ); // Close process and thread handles. CloseHandle( pi.hProcess ); CloseHandle( pi.hThread ); &#125; 成功建立进程后会返回包含了 进程和线程 Handle 的 PROCESS_INFORMATION 结构。这两个 Handle 及时我们指定了安全限制的情况都具有完全的访问权限，如果我们不需要的话，就需要关闭这两个 Handle。","categories":[{"name":"Windows","slug":"Windows","permalink":"https://gowa2017.github.io/categories/Windows/"}],"tags":[{"name":"Windows","slug":"Windows","permalink":"https://gowa2017.github.io/tags/Windows/"}],"keywords":[{"name":"Windows","slug":"Windows","permalink":"https://gowa2017.github.io/categories/Windows/"}]},{"title":"MFC基础概念及基本类","slug":"MFC基础概念及基础类","date":"2019-06-21T15:07:39.000Z","updated":"2019-06-21T15:07:39.000Z","comments":true,"path":"Windows/MFC基础概念及基础类.html","link":"","permalink":"https://gowa2017.github.io/Windows/MFC基础概念及基础类.html","excerpt":"在 Windows-程序工作过程 一问中我们介绍了 Windows 程序的基本工作过程，那么在 MFC 中其又是怎么样工作的呢。","text":"在 Windows-程序工作过程 一问中我们介绍了 Windows 程序的基本工作过程，那么在 MFC 中其又是怎么样工作的呢。 简介MFC 是微软基础类库，是对 windows SDK API 以面向对象的形式进行了封装。将一些模板化的，常规化的代码进行了封装后，我们就可以省却很多事情了。我们从一个最简单的基于对话框的程序来看。 对于使用了 winapi 来的程序来说，其本来是过程式的，但是使用 MFC 将一些功能，模块用对象的形式进行封装，简化了过程，也更加容易写出代码。 模块、进程、线程首先我们来先了解一下这三个概念。 模块：表示的是一个可执行程序（.exe）由 Windows 操作系统加载在内存中的一种表示 进程：操作系统为程序所分配的一系列权限，内存，资源等的集合。 线程：表示的是程序的一个执行路径。 对于 MFC 程序来说，操作系统在加载程序的时候，就会自动的建立一个模块，进程，一个线程。而我们后面所有的东西，都是在后面这么一个线程来开始的。 基本类CObject所有 MFC 类的基类，所有的类都继承自这个类。其最重要的一点就是支持序列化。 CCmdTarget此类是所有消息映射体系结构的基类。所有响应事件或消息的类都应该从这个类继承。如 CWinApp, CWnd 等。从其命名上来看表示的是 Cmd Target ，命令目标，也就不难理解了。 官方的备注是： 这是一个消息映射，会将命令和消息路由到我们编写的用来处理这些命令和消息的函数。（命令 指的是一个从一个菜单项，按钮等来的消息）从 CCmdTarget 继承的关键的框架类包括：CView, CWinApp, CDocument, CWnd, CFrameWnd。如果要构造自己的消息处理的类，那么从这些衍生类进行继承，通常，我们很少会直接继承 CCmdTarget。CCmdTarget 还包含了显示一个沙漏光标函数。这用来在你要提示用户需要一个较长时间的任务需要执行。 CWinThread这个我代表了一个应用内的执行线程。 class CWinThread : public CCmdTarget 应用的主线程通常由一个继承自 CWinApp 的类来提供；而 CWinApp 是继承自 CWinThread 的。同时 CWinThread 允许在一个应用内有多个线程。 CWinThread 支持两种类型的线程：工作线程与 UI 线线程。工作线程不会处理消息，UI 线程线程处理来自系统的各种消息。 CWinApp 及其衍生类是 UI 线程的实例。 CWinThread 对象存在于线程的生命周期内。 CWinThread 用来保证我们的 MFC 应用是线程安全的。框架需要用到的线程定信息保存在线程本地数据内，这是由 CWinThread 来管理的。因为依赖于 CWinThread 来管理这些线程本地数据，所以任何使用 MFC 的线程必须通过 MFC 来建立。使用 API 函数 _beginthread, _beginthreadex 建立的线程是不能使用任何 MFC API 的 要建立一个 MFC 线程，使用 AfxBeginThread。它有两种形式，具体是那种依赖于你到底想要的是一个工作线程还是UI线程。如果想要的是一个 UI 线程，那么需要传递给它一个指向 继承自 CWinThread 的类作为参数；如果只是需要一个工作线程，那么将工作函数及工作参数传递过去就行了。AfxBeginThread 会返回一个指向 CWinThread 对象的指针。 当然，我们可以 先构建一个 CWinThread 对象，然后使用 CreateThread 来建立线程。 这样的两步操作在我们重用 CWinThread 的时候就很实用了。 CWinAppclass CWinApp : public CWinThread MFC 中的主应用程序类将封装 Windows 操作系统的应用程序的初始化、运行和终止。 基于框架的应用程序都必须有且只有一个对象的类派生自CWinApp。 创建窗口之前将构造此对象。 CWinApp 是一个应用对象，其提供了成员函数来初始化我们的应用及开始运行应用。 这个对象是在其他 C++ 全局对象构建的时候构建的，当 Windows 调用 WinMain 函数的时候它已经是可用的了。必须将我们的 CWinApp 对象声明为全局的。 当我们的继承 CWinApp 的时候，需要重写 InitInstance() 方法来建立我们自己的主窗口对象。。 除来 CWinApp 的成员方法，MFC 提供 一些全局函数来访问我们的 CWinApp 对象和其他的全局对象。 AfxGetApp() 获取我们 CWinApp 对象指针。 AfxGetInstanceHandle() 获取一个指向我们当前应用实例的 Handle。 AfxGetResourceHandle() 获取一个指向我们当前应用实例的资源 Handle。 AfxGetAppName() 获取一个指向我们的应用名称的字符串的指针。如果我们已经有了一个指向 CWinApp 对象的指针，我们可以用 m_pszExeName 来获取这个名称。 如果我们想要判断是否已经有一个当前应用的实例在运行，使用一个名称互斥量。如果打开这个互斥量失败，就表示当前没有此应用的实例在运行。 CWndMFC 所有窗口的基类。 class CWnd : public CCmdTarget CWnd 对象与 Windows 的窗口是不一样的，但两者之间有关联。Cwnd 对象的建立和销毁是由其构造器（析构器）完成的。而 Windows 窗口，是 Windows 操作系统的一个数据结构，其由 Create 成员方法来建立，由 Cwnd 的虚 析构器来销毁。DestroyWindow 函数会销毁 Windows 的窗口，但不会销毁 Cwnd 对象本身。 也就是说 Cwnd 对象实际上是持一个 Windows 窗口对象的。 CWnd 类和消息映射机制隐藏了我们的窗口处理函数 WndProc 这么一个事实。由 Windows 发来的消息和通知都由消息映射机制路由到 CWnd 的 On[Message] 函数。我们通过重写 On 方法来处理消息。 CWnd 也允许为我们的应用建立子窗口。 继承 CWnd 来写我们自己的类，然后向其添加成员变量来存储我们应用需要的数据。实现消息控制函数及一个消息映射来决定如何处理消息。 我们用两步来建立一个子窗口。 调用 CWnd 的 构造器来建立 CWnd 对象。 调用 Create 方法来建立子窗口，然后把他附到 CWnd 对象。 当用户要销毁窗口的时候，我们可以销毁 CWnd 对象，或者调用其 DestroyWindow 函数来销毁子窗口。 CFrameWnd，CDialog，CView都继承自这个类。而 UI 控制的类如 CButton 可以直接使用。 CDialogclass CDialog : public CWnd 用来在屏幕上显示一个对话框。 有两种类型的对话框：抢占式或非抢占式的。一个抢占式的对话框在应用要继续之前必须关闭；而非强制式的话可以在没关闭的时候让用户依然去看其他事情。 一个 CDialog 对象是一个对话框模板和一个继承自 CDialog 类的结合。使用对话框编辑器来编辑模板并保存到资源内，然后使用类生成向导来建立一个继承自 CDialog 的类。 一个对话框，和其他的 Windows 窗口一样，从操作系统接收消息。在对话框内，我们更有兴趣的是处理由对话框上的控件发出的消息。我们可以在对话框编辑器上的属性面板上对控件指定处理函数，这个会自动的添加消息映射到我们的衍生类中。 当然，我们也可以完全的手动来写消息映射和处理函数。 数据交换和有效性验证映射是在 CWnd::DoDataExchange() 方法内完成的，系统和用户都会不直接的调用 CWnd::UpdateData() 来间接的调用这个方法。 CFile提供二进制的，不带缓冲的输入输入服务。 TCHAR szBuffer[256]; UINT nActual = 0; CFile myFile;if ( myFile.Open( _T(\"c:\\\\test\\\\myfile.dat\"), CFile::modeCreate | CFile::modeReadWrite ) )&#123; myFile.Write( szBuffer, sizeof( szBuffer ) ); myFile.Flush(); myFile.Seek( 0, CFile::begin ); nActual = myFile.Read( szBuffer, sizeof( szBuffer ) ); &#125;## CStdioFile流式缓冲文件类 CStringCString, CStringA, CStringW 是 CStringT 模板类的特定实现。 CStringT 会根据其支持的字符类型来实现。 CStringW 支持 wchar_t 类型和 Unicode 字符串； CStringA 支持 char 类型，支持多字节或者单字节字符串。CString 支持 wchar_t,char，这依赖与编译的设置。 #include &lt;atlstr.h&gt;int main() &#123; CString aCString = CString(_T(\"A string\")); _tprintf(_T(\"%s\"), (LPCTSTR) aCString); &#125; 实例","categories":[{"name":"Windows","slug":"Windows","permalink":"https://gowa2017.github.io/categories/Windows/"}],"tags":[{"name":"Windows","slug":"Windows","permalink":"https://gowa2017.github.io/tags/Windows/"}],"keywords":[{"name":"Windows","slug":"Windows","permalink":"https://gowa2017.github.io/categories/Windows/"}]},{"title":"COM在程序中的使用","slug":"COM在程序中的使用","date":"2019-06-18T16:14:28.000Z","updated":"2019-06-18T16:14:28.000Z","comments":true,"path":"Windows/COM在程序中的使用.html","link":"","permalink":"https://gowa2017.github.io/Windows/COM在程序中的使用.html","excerpt":"COM 是一个规范，用来规定建立可复用的软件组件。很多我们在程序中使用的特性都是依赖于COM的如。 Graphics (Direct2D) Text (DirectWrite) The Windows Shell The Ribbon control UI animation","text":"COM 是一个规范，用来规定建立可复用的软件组件。很多我们在程序中使用的特性都是依赖于COM的如。 Graphics (Direct2D) Text (DirectWrite) The Windows Shell The Ribbon control UI animation COM 因其难以学习而名声不好。写一个新的 COM 模块是有点恼火。但如果我们只是使用 COM的话，那我们就会发现 COM 就是非常简单的了。 此节展示了怎么样在程序中使用 基于COM 的API。同时也描述了一些 COM 设计背后的原因。如果了解了为什么会设计出 COM，那就可以更搞笑的使用他了。接着也介绍了一推荐的使用 COM 的好的实践。 COM 是一个二进制标准，而不是一个语言标准：其定义了应用与组件间的二进制接口。作为一个二进制标准， COM 与语言无关的，虽然其会映射到特定的 C++ 构造。本节着重于 COM 的三个目标： 接对象的接口与实现分开 管理对象的生命周期 在运行时发现对象的性能。 COM 接口是什么如果熟悉 Java C# 的话，对接口的概念可能是了解的。一个接口定义了一个对象可以提供的方法，而不关于具体的实现。在计算机科学术语里面，这就是说与实现解耦的意思。 在 C++ 中，与接口最进的实现应该是 纯虚类了——一个只包含纯虚方法的类，没有任何其他成员。 初始化 COM 库必须通过 CoInitializeEx() 来初始化 COM 库。每个使用 COM 接口的线程都必须单独调用这个函数。 HRESULT CoInitializeEx(LPVOID pvReserved, DWORD dwCoInit); 第一个参数是保留的，必须是NULL。第二个参数指定了我们程序要使用的线程模型。COM 支持两个不同的线程模型，多线程与宿主线程。 如果我们指定了 宿主线程模型，我们是在作出如下保证： 我们只在一个线程访问每个COM；我们不会在多个线程间共享 COM 接口指针。 线程会有一个消息循环。 如果上面这两个约束任何一个不符合你的预计，那么就使用多线程模型。要实现多线程模型，指定下面的标志到 dwCoInit 参数： COINIT_APARTMENTTHREADED COINIT_MULTITHREADED 通常，建立窗口的线程使用 COINIT_APARTMENTTHREADED，其他线程使用 COINIT_MULTITHREADED。但可能某些 COM 需要一个特定的线程模型。 对于宿主线程模型： HRESULT hr = CoInitializeEx(NULL, COINIT_APARTMENTTHREADED | COINIT_DISABLE_OLE1DDE); HRESULT返回值包含了成功或者失败的代码。","categories":[{"name":"Windows","slug":"Windows","permalink":"https://gowa2017.github.io/categories/Windows/"}],"tags":[{"name":"Windows","slug":"Windows","permalink":"https://gowa2017.github.io/tags/Windows/"}],"keywords":[{"name":"Windows","slug":"Windows","permalink":"https://gowa2017.github.io/categories/Windows/"}]},{"title":"Windows-程序工作过程","slug":"Windows-程序工作过程","date":"2019-06-18T15:46:02.000Z","updated":"2019-06-18T15:46:02.000Z","comments":true,"path":"Windows/Windows-程序工作过程.html","link":"","permalink":"https://gowa2017.github.io/Windows/Windows-程序工作过程.html","excerpt":"我们来写一个最小的 Windows 程序。其只会显示一个空白窗口。","text":"我们来写一个最小的 Windows 程序。其只会显示一个空白窗口。 代码如下： #ifndef UNICODE#define UNICODE#endif #include &lt;windows.h&gt;LRESULT CALLBACK WindowProc(HWND hwnd, UINT uMsg, WPARAM wParam, LPARAM lParam);int WINAPI wWinMain(HINSTANCE hInstance, HINSTANCE, PWSTR pCmdLine, int nCmdShow)&#123; // Register the window class. const wchar_t CLASS_NAME[] = L\"Sample Window Class\"; WNDCLASS wc = &#123; &#125;; wc.lpfnWndProc = WindowProc; wc.hInstance = hInstance; wc.lpszClassName = CLASS_NAME; RegisterClass(&amp;wc); // Create the window. HWND hwnd = CreateWindowEx( 0, // Optional window styles. CLASS_NAME, // Window class L\"Learn to Program Windows\", // Window text WS_OVERLAPPEDWINDOW, // Window style // Size and position CW_USEDEFAULT, CW_USEDEFAULT, CW_USEDEFAULT, CW_USEDEFAULT, NULL, // Parent window NULL, // Menu hInstance, // Instance handle NULL // Additional application data ); if (hwnd == NULL) &#123; return 0; &#125; ShowWindow(hwnd, nCmdShow); // Run the message loop. MSG msg = &#123; &#125;; while (GetMessage(&amp;msg, NULL, 0, 0)) &#123; TranslateMessage(&amp;msg); DispatchMessage(&amp;msg); &#125; return 0;&#125;LRESULT CALLBACK WindowProc(HWND hwnd, UINT uMsg, WPARAM wParam, LPARAM lParam)&#123; switch (uMsg) &#123; case WM_DESTROY: PostQuitMessage(0); return 0; case WM_PAINT: &#123; PAINTSTRUCT ps; HDC hdc = BeginPaint(hwnd, &amp;ps); FillRect(hdc, &amp;ps.rcPaint, (HBRUSH) (COLOR_WINDOW+1)); EndPaint(hwnd, &amp;ps); &#125; return 0; &#125; return DefWindowProc(hwnd, uMsg, wParam, lParam);&#125; wWinMain 是程序入口。当程序运行的时候，其注册一些关于窗口行为的信息。其中最重要的就是 WindowProc 函数。这个函数定义了窗口的行为——其外观，如何与用户交互等等。 接着建立了一个窗口，并获得了表示此窗口的句柄 如果窗口建立成功，程序进入一个 while 循环，直到用户关闭窗口，程序退出。 要注意的是，程序并没有显式的调用 WindowProc，虽然我们说这是程序中最重要的逻辑所在。操作系统通过向程序传递一系列的消息来通信。在 while 循环中的驱动进程。每当程序调用 DispatchMessage 函数的时候，其会不直接的让系统调用 WIndowProc 函数，每个信息一次。 建立窗口窗口类一个 窗口类 定义了一系列多个窗口可能会共有的行为。 每个窗口必须与一个窗口类相关联。要注意的是，一个窗口类，并不是一个 C++ 类。其是一个操作系统内部的数据结构。窗口类在系统运行时注册。如果要注册一个新的窗口类，需要填充 WNDCLASS 结构： // Register the window class. const wchar_t CLASS_NAME[] = L\"Sample Window Class\"; WNDCLASS wc = &#123; &#125;; wc.lpfnWndProc = WindowProc; wc.hInstance = hInstance; wc.lpszClassName = CLASS_NAME; 必须指定下列成员： lpfnWndProc 一个指向应用定义的指针，被称作是窗口程序。 hInstance 应用实例的句柄。从 wWinMain 获取。 lpszClassName 标识窗口类的字符串。 然后用 RegisterClass 函数进行注册到系统： RegisterClass(&amp;wc); 新建窗口HWND hwnd = CreateWindowEx( 0, // Optional window styles. CLASS_NAME, // Window class L\"Learn to Program Windows\", // Window text WS_OVERLAPPEDWINDOW, // Window style // Size and position CW_USEDEFAULT, CW_USEDEFAULT, CW_USEDEFAULT, CW_USEDEFAULT, NULL, // Parent window NULL, // Menu hInstance, // Instance handle NULL // Additional application data ); if (hwnd == NULL) &#123; return 0; &#125; ShowWindow(hwnd, nCmdShow); 窗口消息一个 GUI 应用必须响应用户或者系统的事件。 用户事件。鼠标点击，键盘按下，屏幕触摸，动作等等 系统事件。新设备插入，低电源状态等。 事件可能在程序的任何时间发生，任何顺序。我们如何来组织一个未知的执行流呢？ 因此，系统使用了一个叫做信息传输模型。系统通过向应用窗口传递消息来通信。一个消息只是一个数字的代码来表示特定的事件。例如，如果用户按下了左键，窗口会收到一个如下的消息代码： #define WM_LBUTTONDOWN 0x0201 某些消息会有数据相关联。为了传递消息，系统就会调用窗口程序。 消息循环一个应用可能会接受上千个消息。同时，一个应用可以有多个窗口，每个都有其自己的窗口处理程序。程序如何进行分发消息呢？应用就需要一个循环来获取这些消息并分发到对应的窗口。 对于创建窗口的每个线程，系统都会为其建立一个消息队列。这个队列会保留所有这个线程建立的窗口消息。这个消息队列对我们的程序来说是透明的。我们无法直接操作这个队列。但我们可以通过函数来获取消息： MSG msg;GetMessage(&amp;msg, NULL, 0, 0); 这个函数会从队列首取出一个消息。如果队列为空，函数会阻塞，直到有消息到达，但并不会让我们的程序没有响应。如果我们要进行一些后台任务，我们可以建立一些新的线程来完成。 GetMessage 函数会填充 MSG 数据结构，包括了目标窗口及消息代码。其他的三个参数让我们可以过滤我们想要从队列获取的消息。多数情况下都是 0 值。 虽然 MSG 已经获取了数据，但我们一般不会直接处理，而是会将其传递给两个其他函数。 TranslateMessage(&amp;msg); DispatchMessage(&amp;msg); TranslateMessage 和键盘输入相关，其将按键输入转换为字符。我们不需要清楚其是怎么工作的，只要记住在 DispatchMessage 前调用它就对了。 DispatchMessage 告诉操作系统去调用消息目标窗口的处理程序。换句话说，操作系统会在去 窗口表内寻找窗口的句柄，接着找到其此窗口相关联的函数指针，然后调用它。 当窗口处理程序返回时，其返回到 DispatchMessage。其实就是在消息循环中取出下一个消息。我们必须有一个循环来获取消息并进行分发。 // WARNING: Don't actually write your loop this way.while (1) &#123; GetMessage(&amp;msg, NULL, 0, 0); TranslateMessage(&amp;msg); DispatchMessage(&amp;msg);&#125; 上面这样写，循环永远不会结束。通常，GetMessage 返回一个非0值。如果我们想要退回应用，且跳出循环，调用 PostQuitMessage。 PostQuitMessage(0); 这样才是正确的姿势： // Correct.MSG msg = &#123; &#125;;while (GetMessage(&amp;msg, NULL, 0, 0))&#123; TranslateMessage(&amp;msg); DispatchMessage(&amp;msg);&#125; Posted 消息与 Sent 消息两者的区别可能会混淆： Posting 消息，意味着消息进入消息队列，通过消息循环来分发（GetMessage, DispatchMessage） Sending 意味着消息跳过了队列，系统会直接调用窗口处理程序。 当前，这两个区别不重要。我们的窗口程序处理所有的消息。然而，某些消息跳过了队列然后直接到了我们的窗口处理程序。然而，如果应用在窗口间通信的时候就会有区别了。","categories":[{"name":"Windows","slug":"Windows","permalink":"https://gowa2017.github.io/categories/Windows/"}],"tags":[{"name":"Windows","slug":"Windows","permalink":"https://gowa2017.github.io/tags/Windows/"}],"keywords":[{"name":"Windows","slug":"Windows","permalink":"https://gowa2017.github.io/categories/Windows/"}]},{"title":"Windows-SDK-API编程基本介绍","slug":"Windows-SDK-API编程基本介绍","date":"2019-06-18T14:59:32.000Z","updated":"2019-06-18T14:59:32.000Z","comments":true,"path":"Windows/Windows-SDK-API编程基本介绍.html","link":"","permalink":"https://gowa2017.github.io/Windows/Windows-SDK-API编程基本介绍.html","excerpt":"","text":"教我们怎么样用 Win32 及 COM API 编写桌面应用。原文 Get Started with Win32 and C++ 准备开发环境想要用 C/C++ 来编写在 Windows 中进行开发，就必须先安装微软的SDK，或者包括了 SDK 的集成开发环境如 VC++。SDK 包含了编译和链接我们的程序必要的 头文件 和库文件。也包含了命令行工具来构建应用。虽然可以通过命令行来编译和构建 Windows 应用，但是官方推荐的是用 VS 开发环境来干这个活 Windows 代码约定Windows 的 API 代码命名有些奇怪，比如你会看到 DWORD_PTR,LPRECT 这样的类型，或者 hWnd， pwsz 这样的变量名字。 Windows API 包括很多的函数和组件对象模型（COM）接口。单纯以 C++ 类形式提供的 API 很少。 typdefWindows API 头文件包含了很多的 typedef。很多是在 WinDef.h 头文件内定义的。 BooleanBOOL 被 typedef 为一个整型值。 #define FALSE 0 #define TRUE 1 所以说，很多返回 BOOL 类型的函数可能会返回一个非0的值来表示 真。因此，我们要注意： // Right way.BOOL result = SomeFunctionThatReturnsBoolean();if (result) &#123; ...&#125; 而不要这样写： // Wrong!if (result == TRUE) &#123; ... &#125; 要记住，BOOL 与 C++ 的 bool 并不是一个东西。 Pointers 指针指针类型大多有 P,LP 前缀。下面的声明是等价的。 RECT* rect; // Pointer to a RECT structure.LPRECT rect; // The samePRECT rect; // Also the same. P 代表指针，LP 代表 长指针。 指针精度类型下面的数据类型的大小永远是一个指针大小大小————32（32位程序），64（64位程序）。大小是在编译时决定的。当 32 位的程序在 64 位的系统上运行的时候，数据类型始终还是 4 字节的。 DWORD_PTR INT_PTR LONG_PTR ULONG_PTR UINT_PTR 这些类型用在可能会将一个整型强制转换为指针的时候。 StringsWindows 在UI元素，文件名等中原生支持 Unicode 字符串。 Windows 用 UTF-16 编码来表示 Unicode 字符，意思就是每个字符都是一个 16bit 的值。UTF-16字符，也被叫做 宽字符，用以和 8-bit 的 ANSI 字符区别。 VC++ 编译器支持内建的 wchar_t 类型，WinNT.h 文件也定义了： typedef wchar_t WCHAR; 这两者我们可能都会遇到。如果要声明一个字面意义的宽字符，在字面字符前加上 L。 wchar_t a = L'a';wchar_t *str = L\"hello\"; Unicode 与 ANSI 函数在 Windows 引入 Unicode 的时候，其提供了一过渡的方式，也就是提供了两套 API，一套接受的是 ANSI 字符，一套接受的是 Unicode 字符。 SetWindowTextA takes an ANSI string. SetWindowTextW takes a Unicode string. 内部会将 ANSI 版本转换成 Unicode 版本。 Windows 头文件也定义了一个宏来转换： #ifdef UNICODE#define SetWindowText SetWindowTextW#else#define SetWindowText SetWindowTextA#endif windows(窗口)到底是什么Winodows 的核心就是窗口。 脑海中关于窗口的概念可能会是这样的。 这样的窗口被叫做 应用窗口或主窗口。典型的其有个含有 标题栏，最大化，最小化按钮的框。这个框被叫做 非客户区，意思就是这部分是归 Windows 系统管理的。框里面的部分就是 客户区，由我们的程序管理。 这也是一个窗口。 UI 元素本身，其实也是一个窗口。主要的不同就是：UI 控制元素并不是自身单独存在的，其会相对于一个主窗口而存在。当拖动主窗口的时候，这些控制元素也会移动。。当然，这些控制元素是可以与主窗口进行通信的。（例如，主窗口最到从按钮的点击事件。） 所以当我们想象一个窗口的时候，不要只想到应用窗口，而是从程序的角度去看待他： 占据屏幕的一个区域 在一个时刻可见也可能不可见。 知道如何绘制自身 响应用户或者系统的事件。 父窗口与所有者窗口如果是一个UI控制窗口，其被称为是主窗口的一个子窗口。主窗口是这个UI窗口的父窗口。父窗口提供了用来定位一个子窗口的坐标系统。有父窗口的情况下会影响窗口的风格：例如，子窗口会被裁剪到不会超出父窗口。 另外一个相关的东西就是主窗口与对话框了，当显示一个对话框的时候，主窗口就是所有者窗口，对话框就是被拥有的窗口。一个被拥有的窗口总是在其拥有者之前。当其所有者最小化的时候它会被隐藏，其与所有者一起销毁。 应用窗口拥有对话框，对话框是 两个按钮的父窗口。 Windows Hanldes 句柄Windows 是对象——他们拥有代码和数据——但他们并不是 C++ 类。程序通过一个叫做 handle 的东西来引用窗口。 句柄，是一个不透明的类型。实质上，其只是一个操作系统用来标识对象的整数。窗口句柄的类型是 HWND。句柄通过创建窗口的函数返回：CreateWindow(), CreateWindowEx()。 为了对一个窗口进行操作，我们通过会调用一些以 HWND 为参数的函数。比如，如果我们想重新定位一个窗口： BOOL MoveWindow(HWND hWnd, int X, int Y, int nWidth, int nHeight, BOOL bRepaint); 记住 ：句柄 不是指针。 屏幕窗口坐标坐标以设备无关的像素进行度量。根据任务不同，我们可能会相对于屏幕，窗口，或者窗口的客户区来进行测量坐标。坐标 (0,0) 总是位于左上。 WinMAIN：应用的入口每个 Windows 程序都有一个入口函数，其被命名为 WinMain 或 wWinMain。 int WINAPI wWinMain(HINSTANCE hInstance, HINSTANCE hPrevInstance, PWSTR pCmdLine, int nCmdShow); 这四个参数分别是： hInstance 这是一个被叫做一个实例的句柄 或 模块的句柄。操作系统使用这个来标识一个 exe 。一些特定的窗口函数会需要这个实例句柄——例如，加载图标或位图。 hPrevInstance 没什么意义。在 16-bit 的系统中使用，现在总是0. pCmdLine 包含了 Unicode 字符串的命令行参数 nCmdShow 表示窗口怎么显示。是最小化，最大化，还是正常。 此函数会返回一 int 值。这个值随后就被操作系统使用。 WINAPI 是一个调用约定。一个 调用约定 定义了一个函数如何从调用者处获得参数。例如，其定义了参数在栈上的顺序。 WinMain 与 wWinMain 是一样的，只是其接收的命令行参数是 ANSI 字符。 编译器是如何知道该去调用 wWinMain 而不是 main() 呢？ 微软的C运行时库（CRT）提供了一个 main() 的实现会调用 wWinMain 或者 WinMain。 下面是一个空的 WinMain 函数： INT WinMain(HINSTANCE hInstance, HINSTANCE hPrevInstance, PSTR lpCmdLine, INT nCmdShow)&#123; return 0;&#125;","categories":[{"name":"Windows","slug":"Windows","permalink":"https://gowa2017.github.io/categories/Windows/"}],"tags":[{"name":"Windows","slug":"Windows","permalink":"https://gowa2017.github.io/tags/Windows/"}],"keywords":[{"name":"Windows","slug":"Windows","permalink":"https://gowa2017.github.io/categories/Windows/"}]},{"title":"Spring中的IoC与DI","slug":"Spring中的IoC与DI","date":"2019-06-16T13:29:37.000Z","updated":"2019-06-16T13:29:37.000Z","comments":true,"path":"Java/Spring中的IoC与DI.html","link":"","permalink":"https://gowa2017.github.io/Java/Spring中的IoC与DI.html","excerpt":"通过 Spring 的实现来了解一下 IoC （控制反转） 与 DI （依赖注入）。当然，之前看过的 Dagger 2 也是一个依赖注入的框架。","text":"通过 Spring 的实现来了解一下 IoC （控制反转） 与 DI （依赖注入）。当然，之前看过的 Dagger 2 也是一个依赖注入的框架。 IoCIoC (Inversion of Control) 控制反转，指的是对象的控制或程序的一部分被转移到了容器或者框架。经常这个概念是在面向对象的编程领域内讨论。 与传统编程相比，我们自己的代码会调用一些库情况下，IoC使框架能够控制程序的流程并调用我们的自定义代码。为了达到这个目的，框架使用了一些内建额外行为的抽象。如果我们要自己的行为，我们就必须继承框架的类或以插件的形式提供。 这样做的优点是： 将任务的执行和其实现解耦。 在不同实现间的切换更容易 模块化程序 通过隔离或模拟组件依赖让测试更容易，同时组件间通过约束来进行通信。 控制反转有很多方式能达到，我们主要看一下依赖注入（DI）。 DIDI 是我们用来实现 IoC 的一种模式，在这里将控制进行反转的控制是：设置对象的依赖。这就是说，将对象与其他对象相连接，或将对象“注入”到其他对象，这是由一个组装器而不是由对象本身来完成的。 比如有个例子，Store 依赖于一个接口 Item 。我们传统的形式是下面实现： public class Store &#123; private Item item; public Store() &#123; item = new ItemImpl1(); &#125;&#125; 上面的例子中，我们需要手动初始化和实现 Item 接口。 如果使用 DI 的话，我们就可以如下这样例子，而不用指定 Item 的实现。 public class Store &#123; private Item item; public Store(Item item) &#123; this.item = item; &#125;&#125; 在下面的章节中，我们会展示怎么样通过元数据来指定 Item 的实现。 Spring IoC 容器IoC 容器指的是框架中一个实现了 IoC 的普通角色。 在 Spring 框架中，IoC 容器由接口 ApplicationContext 表示。Spring 容器的责任是实例化，配置，组装对象（Beans）及管理他们的生命周期。 Spring 框架内部提供了这个接口的几种实现：ClassPathXmlApplicationContext，FileSystemXmlApplicationContext 针对本地应用，WebApplicationContext 针对 Web 应用。 为了组装 Beans，容器使用了配置元数据（XML形式或者注解形式）。 我们可以这样手动实例化一个容器： ApplicationContext context = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); 在最开始的例子中，如果我们要设置 item 属性，我们也可以使用元数据。然后，容器就会读取这个元数据，在运行时用它们来组装 Beans。 Spring 中的依赖注入（DI） 可以通过 构造器、setters、字段来实现 基于构造器的 DI如果使用基于构造器的 DI，容器会将我们要实例化的对象的依赖以参数的形式来调用其构造器。 Spring 主要是根据类型来解析参数，后面跟着属性的名称和没有歧义的索引。下面我们来看看一个 Bean 的配置和其使用了注解的依赖： @Configurationpublic class AppConfig &#123; @Bean public Item item1() &#123; return new ItemImpl1(); &#125; @Bean public Store store() &#123; return new Store(item1()); &#125;&#125; @Configuration 注解表明这个类是一个 Bean 定义源。我们可以将其用到多个类上。 @Bean 注解用在方法上来定义了一个 Bean。如果我们不指定一个自定义的名字，那么 Bean 的 Id 默认就和方法名称相同。 对于一个默认是 单例范围 的 Bean，Spring 要先检查一下这个 Bean 是不是已经有一个缓存的实例存在，如果没有才会创建一个新的。如果我们使用 原型作用域，那么每次都会建立一个新的 Bean 实例。 与上面同样方式，不过是用 XML 来定义 Bean 如下： &lt;bean id=\"item1\" class=\"org.baeldung.store.ItemImpl1\" /&gt; &lt;bean id=\"store\" class=\"org.baeldung.store.Store\"&gt; &lt;constructor-arg type=\"ItemImpl1\" index=\"0\" name=\"item\" ref=\"item1\" /&gt; &lt;/bean&gt; Setter DI对于基于 Setter 的 DI，容器会在在调用了一个无参数的构造器后，调用我们类的 setter 方法。 @Beanpublic Store store() &#123; Store store = new Store(); store.setItem(item1()); return store;&#125; &lt;bean id=\"store\" class=\"org.baeldung.store.Store\"&gt; &lt;property name=\"item\" ref=\"item1\" /&gt;&lt;/bean&gt; 对于同样的 Bean，可以结合使用基于构造器的和 Setter 的 DI。Spring 文档推荐使用基于构造器的注入来处理强制的依赖，使用基于 Setter 来处理可选的依赖。 基于字段的 DI可以通过 @Autowired 来进行字段注入。 public class Store &#123; @Autowired private Item item; &#125; 在构建 Store 的时候，如果没有构造器或者setter 方法来注入 Item Bean，容器会使用反射来将 Item 注入到 Store。 当然我们也可以用 XML 来实现： 这个方式可能看起来更简单和清楚，但并不是推荐的用法： 使用反射来注入依赖，会更耗性能一些。 我们太过容易添加很多依赖。当我们使用构造器的时候，我们可能就会想如果我们添加了过多的依赖，我们的这个类是不是已经违反来单一责任原则。 自动装配依赖关系装配 操作允许 Spring 容器在相互协做的 Bean 间通过检查已定义的 Bean 来解析依赖关系。 在 XML 配置中有四种模式可以用来自动装配一个 Bean。 no：默认值。意味这不需要自动装配，我们必须显式的命名依赖。 byName：根据属性的名称去解析。因此，Spring 会用需要设置的属性名称去依赖查找 Bean。 byType：与 byName 类似，只是根据属性的类型去。如果有多个 Bean 有同样的类型就会抛出异常。 constructor：根据构造器的参数来，这意味着，Spring 要查找的是和构造器参数有相同类型的 Bean。 现在，我们在上面的例子中，来自动将 item1 注入到 Store Bean 内： @Bean(autowire = Autowire.BY_TYPE)public class Store &#123; private Item item; public setItem(Item item)&#123; this.item = item; &#125;&#125; 或者直接在属性上指定自动注入： public class Store &#123; @Autowired private Item item;&#125; 如果有多个 Bean 有相同的类型，那么我们需要加上 @Qualifier 注解来通过名字引用 bean： @Autowired@Qualifier(\"item1\")private Item item; 通过 XML 文件来实现： &lt;bean id=\"store\" class=\"org.baeldung.store.Store\" autowire=\"byType\"&gt; &lt;/bean&gt; &lt;bean id=\"item\" class=\"org.baeldung.store.ItemImpl1\" /&gt; &lt;bean id=\"store\" class=\"org.baeldung.store.Store\" autowire=\"byName\"&gt;&lt;/bean&gt; @Autowired, @Resource, @Inject这几个注解可以让类以声明的形式来解析依赖： @AutowiredArbitraryClass arbObject; 而不用直接的实例化它： ArbitraryClass arbObject = new ArbitraryClass(); 三个注解中有两个是属于包 javax.annotation.Resource, javax.inject.Inject。而 @Autowired 是属于包 org.springframework.beans.factory.annotation。 这三个注解都可以通过字段注入或者 Setter 注入来解析依赖。下面会有区分一下这三者的不同。 区别@Autowired和@Inject基本是一样的，因为两者都是使用AutowiredAnnotationBeanPostProcessor来处理依赖注入。但是@Resource是个例外，它使用的是CommonAnnotationBeanPostProcessor来处理依赖注入。当然，两者都是BeanPostProcessor。 @Autowired和@Inject默认 autowired by type可以 通过@Qualifier 显式指定 autowired by qualifier name。 @Resource默认 autowired by field name如果 autowired by field name失败，会退化为 autowired by type可以 通过@Qualifier 显式指定 autowired by qualifier name如果 autowired by qualifier name失败，会退化为 autowired by field name。但是这时候如果 autowired by field name失败，就不会再退化为autowired by type了。 建议多用 @Inject，这是 JSR 330 的规范。@Autowired 是 Spring 的实现，比如 Dagger 就用不了。@Resource 是 JSR 250 是比较老的规范。","categories":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/tags/Java/"},{"name":"Spring","slug":"Spring","permalink":"https://gowa2017.github.io/tags/Spring/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}]},{"title":"关于SprintMVC配置文件的加载及初始化","slug":"关于SprintMVC配置文件的加载及初始化","date":"2019-06-14T23:52:51.000Z","updated":"2019-06-14T23:52:51.000Z","comments":true,"path":"Java/关于SprintMVC配置文件的加载及初始化.html","link":"","permalink":"https://gowa2017.github.io/Java/关于SprintMVC配置文件的加载及初始化.html","excerpt":"我们知道，SpringMVC 是以 Servlet 的形式由 Tomcat 中的容器根据 web app 应用的 web.xml(部署描述符) 配置来启动的。但是，我们写在 xml 文件的配置，是什么时候，用什么样的方式加载和初始化的呢？","text":"我们知道，SpringMVC 是以 Servlet 的形式由 Tomcat 中的容器根据 web app 应用的 web.xml(部署描述符) 配置来启动的。但是，我们写在 xml 文件的配置，是什么时候，用什么样的方式加载和初始化的呢？ Tomcat 容器模型要先了解更多，首先得了解一下 Tomcat 的容器模型是什么样的。 可以和我们在 config/server.xml 中的配置对应起来。 对于我们的 web 应用来说。每个 web 应用对应一个 Context 对象。 然后 Tomcat 会将 web.xml 解析到一个 WebXml 对象， Context 会持有这个对象。同时还会创建 web.xml 内定义的 filter, listener, servlet。 然后就会初始化我们的 Servlet 了。 web.xml 中的配置&lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt; classpath:spring/ApplicationContext-main.xml, classpath:spring/ApplicationContext-dataSource.xml, classpath:spring/ApplicationContext-shiro.xml &lt;/param-value&gt;&lt;/context-param&gt;&lt;listener&gt; &lt;listener-class&gt;org.springframework.web.util.Log4jConfigListener&lt;/listener-class&gt;&lt;/listener&gt;&lt;servlet&gt; &lt;servlet-name&gt;springMvc&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:spring/ApplicationContext-mvc.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;springMvc&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 其中 ： init-param 全局变量 listener 这里 ContextLoaderListener 实现了 ServletContextListener，主要是用来监听 Servlet 的初始化和销毁事件。 servlet 要启动的 Servlet Servlet 的实例化我们知道， Servlet 是由 Tomcat 来进行实例化的。对于 ServletContextListener 来说，当我们初始化和销毁 Servlet 的时候就会收到通知，被调用。 其中事件 ServletContextListener 的 ServletContext 也是由 Tomcat 来负责的。 对于我们定义的 ContextLoaderListener： public void contextInitialized(ServletContextEvent event) &#123; initWebApplicationContext(event.getServletContext());&#125; public WebApplicationContext initWebApplicationContext(ServletContext servletContext) &#123; if (servletContext.getAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE) != null) &#123; throw new IllegalStateException( \"Cannot initialize context because there is already a root application context present - \" + \"check whether you have multiple ContextLoader* definitions in your web.xml!\"); &#125; Log logger = LogFactory.getLog(ContextLoader.class); servletContext.log(\"Initializing Spring root WebApplicationContext\"); if (logger.isInfoEnabled()) &#123; logger.info(\"Root WebApplicationContext: initialization started\"); &#125; long startTime = System.currentTimeMillis(); try &#123; // Store context in local instance variable, to guarantee that // it is available on ServletContext shutdown. if (this.context == null) &#123; this.context = createWebApplicationContext(servletContext); &#125; if (this.context instanceof ConfigurableWebApplicationContext) &#123; ConfigurableWebApplicationContext cwac = (ConfigurableWebApplicationContext) this.context; if (!cwac.isActive()) &#123; // The context has not yet been refreshed -&gt; provide services such as // setting the parent context, setting the application context id, etc if (cwac.getParent() == null) &#123; // The context instance was injected without an explicit parent -&gt; // determine parent for root web application context, if any. ApplicationContext parent = loadParentContext(servletContext); cwac.setParent(parent); &#125; configureAndRefreshWebApplicationContext(cwac, servletContext); &#125; &#125; servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, this.context); ClassLoader ccl = Thread.currentThread().getContextClassLoader(); if (ccl == ContextLoader.class.getClassLoader()) &#123; currentContext = this.context; &#125; else if (ccl != null) &#123; currentContextPerThread.put(ccl, this.context); &#125; if (logger.isDebugEnabled()) &#123; logger.debug(\"Published root WebApplicationContext as ServletContext attribute with name [\" + WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE + \"]\"); &#125; if (logger.isInfoEnabled()) &#123; long elapsedTime = System.currentTimeMillis() - startTime; logger.info(\"Root WebApplicationContext: initialization completed in \" + elapsedTime + \" ms\"); &#125; return this.context; &#125; catch (RuntimeException ex) &#123; logger.error(\"Context initialization failed\", ex); servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, ex); throw ex; &#125; catch (Error err) &#123; logger.error(\"Context initialization failed\", err); servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, err); throw err; &#125;&#125; 在 Servlet 初始化的时候，就会建立一个 Spring 的 应用上下文。同时将其作为 ServletContext 的一个属性挂起来： servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, this.context);```## configureAndRefreshWebApplicationContext()上下建立后，就会解析配置文件，也即是我们定义的 *contextConfigLocation*。```java protected void configureAndRefreshWebApplicationContext(ConfigurableWebApplicationContext wac, ServletContext sc) &#123; if (ObjectUtils.identityToString(wac).equals(wac.getId())) &#123; // The application context id is still set to its original default value // -&gt; assign a more useful id based on available information String idParam = sc.getInitParameter(CONTEXT_ID_PARAM); if (idParam != null) &#123; wac.setId(idParam); &#125; else &#123; // Generate default id... wac.setId(ConfigurableWebApplicationContext.APPLICATION_CONTEXT_ID_PREFIX + ObjectUtils.getDisplayString(sc.getContextPath())); &#125; &#125; wac.setServletContext(sc); String configLocationParam = sc.getInitParameter(CONFIG_LOCATION_PARAM); if (configLocationParam != null) &#123; wac.setConfigLocation(configLocationParam); &#125; // The wac environment's #initPropertySources will be called in any case when the context // is refreshed; do it eagerly here to ensure servlet property sources are in place for // use in any post-processing or initialization that occurs below prior to #refresh ConfigurableEnvironment env = wac.getEnvironment(); if (env instanceof ConfigurableWebEnvironment) &#123; ((ConfigurableWebEnvironment) env).initPropertySources(sc, null); &#125; customizeContext(sc, wac); wac.refresh(); &#125; 默认情况下，我们的 WebApplicationContext 的实现是：XmlWebApplicationContext。会使用我们定义的 contextConfigLocation 参数，然后更新 WebApplicationContext。 AbstractApplicationContext.refresh()这个类继承得比较远，最终调用的是 AbstractApplicationContext.refresh。 public void refresh() throws BeansException, IllegalStateException &#123; synchronized(this.startupShutdownMonitor) &#123; this.prepareRefresh(); ConfigurableListableBeanFactory beanFactory = this.obtainFreshBeanFactory(); this.prepareBeanFactory(beanFactory); try &#123; this.postProcessBeanFactory(beanFactory); this.invokeBeanFactoryPostProcessors(beanFactory); this.registerBeanPostProcessors(beanFactory); this.initMessageSource(); this.initApplicationEventMulticaster(); this.onRefresh(); this.registerListeners(); this.finishBeanFactoryInitialization(beanFactory); this.finishRefresh(); &#125; catch (BeansException var9) &#123; if (this.logger.isWarnEnabled()) &#123; this.logger.warn(\"Exception encountered during context initialization - cancelling refresh attempt: \" + var9); &#125; this.destroyBeans(); this.cancelRefresh(var9); throw var9; &#125; finally &#123; this.resetCommonCaches(); &#125; &#125;&#125; 这个方法中干的活是比较多的了。重要的是在 obtainFreshBeanFactory 内开始进行解析 bean。 AbstractApplicationContextprotected ConfigurableListableBeanFactory obtainFreshBeanFactory() &#123; refreshBeanFactory(); ConfigurableListableBeanFactory beanFactory = getBeanFactory(); if (logger.isDebugEnabled()) &#123; logger.debug(\"Bean factory for \" + getDisplayName() + \": \" + beanFactory); &#125; return beanFactory;&#125; AbstractRefreshableApplicationContext@Overrideprotected final void refreshBeanFactory() throws BeansException &#123; if (hasBeanFactory()) &#123; destroyBeans(); closeBeanFactory(); &#125; try &#123; DefaultListableBeanFactory beanFactory = createBeanFactory(); beanFactory.setSerializationId(getId()); customizeBeanFactory(beanFactory); loadBeanDefinitions(beanFactory); synchronized (this.beanFactoryMonitor) &#123; this.beanFactory = beanFactory; &#125; &#125; catch (IOException ex) &#123; throw new ApplicationContextException(\"I/O error parsing bean definition source for \" + getDisplayName(), ex); &#125;&#125;@Overridepublic final ConfigurableListableBeanFactory getBeanFactory() &#123; synchronized (this.beanFactoryMonitor) &#123; if (this.beanFactory == null) &#123; throw new IllegalStateException(\"BeanFactory not initialized or already closed - \" + \"call 'refresh' before accessing beans via the ApplicationContext\"); &#125; return this.beanFactory; &#125;&#125; XmlWebApplicationContext@Overrideprotected void loadBeanDefinitions(DefaultListableBeanFactory beanFactory) throws BeansException, IOException &#123; // Create a new XmlBeanDefinitionReader for the given BeanFactory. XmlBeanDefinitionReader beanDefinitionReader = new XmlBeanDefinitionReader(beanFactory); // Configure the bean definition reader with this context's // resource loading environment. beanDefinitionReader.setEnvironment(getEnvironment()); beanDefinitionReader.setResourceLoader(this); beanDefinitionReader.setEntityResolver(new ResourceEntityResolver(this)); // Allow a subclass to provide custom initialization of the reader, // then proceed with actually loading the bean definitions. initBeanDefinitionReader(beanDefinitionReader); loadBeanDefinitions(beanDefinitionReader);&#125;protected void loadBeanDefinitions(XmlBeanDefinitionReader reader) throws IOException &#123; String[] configLocations = getConfigLocations(); if (configLocations != null) &#123; for (String configLocation : configLocations) &#123; reader.loadBeanDefinitions(configLocation); &#125; &#125;&#125; loadBeanDefinitions() 就会根据我们定义的路径去寻找 bean 的 xml 文件，进行解析了。 AbstractApplicationContextfinishBeanFactoryInitialization(beanFactory);初始化 bean。 public void preInstantiateSingletons() throws BeansException &#123; if (this.logger.isDebugEnabled()) &#123; this.logger.debug(\"Pre-instantiating singletons in \" + this); &#125; List&lt;String&gt; beanNames = new ArrayList(this.beanDefinitionNames); Iterator var2 = beanNames.iterator(); while(true) &#123; while(true) &#123; String beanName; RootBeanDefinition bd; do &#123; do &#123; do &#123; if (!var2.hasNext()) &#123; var2 = beanNames.iterator(); while(var2.hasNext()) &#123; beanName = (String)var2.next(); Object singletonInstance = this.getSingleton(beanName); if (singletonInstance instanceof SmartInitializingSingleton) &#123; final SmartInitializingSingleton smartSingleton = (SmartInitializingSingleton)singletonInstance; if (System.getSecurityManager() != null) &#123; AccessController.doPrivileged(new PrivilegedAction&lt;Object&gt;() &#123; public Object run() &#123; smartSingleton.afterSingletonsInstantiated(); return null; &#125; &#125;, this.getAccessControlContext()); &#125; else &#123; smartSingleton.afterSingletonsInstantiated(); &#125; &#125; &#125; return; &#125; beanName = (String)var2.next(); bd = this.getMergedLocalBeanDefinition(beanName); &#125; while(bd.isAbstract()); &#125; while(!bd.isSingleton()); &#125; while(bd.isLazyInit()); if (this.isFactoryBean(beanName)) &#123; final FactoryBean&lt;?&gt; factory = (FactoryBean)this.getBean(\"&amp;\" + beanName); boolean isEagerInit; if (System.getSecurityManager() != null &amp;&amp; factory instanceof SmartFactoryBean) &#123; isEagerInit = (Boolean)AccessController.doPrivileged(new PrivilegedAction&lt;Boolean&gt;() &#123; public Boolean run() &#123; return ((SmartFactoryBean)factory).isEagerInit(); &#125; &#125;, this.getAccessControlContext()); &#125; else &#123; isEagerInit = factory instanceof SmartFactoryBean &amp;&amp; ((SmartFactoryBean)factory).isEagerInit(); &#125; if (isEagerInit) &#123; this.getBean(beanName); &#125; &#125; else &#123; this.getBean(beanName); &#125; &#125; &#125;&#125; DispatchServlet 继承关系DispatcherServlet &lt;- FrameworkServlet &lt;- HttpServletBean &lt;- HttpServlet &lt;- GenericServlet 我们知道 HttpServlet 也是规范的一部分，所以说，我们要关注的内容是从 HttpServletBean 开始的。 HttpServletBean.init()这个类是 HttpServlet 的直接继承，其主要的作用是： 将 web.xml 内 servlet 标签当作 bean properties 对待。 对于一个 Servlet 来说，当其实例化后，容器（Tomcat）就会立刻调用其 init(ServletConfig) 方法。 对于一个 Servlet 来说，其 ServletConfig 即是 web.xml 内的配置。 // GenericServlet public void init(ServletConfig config) throws ServletException &#123;this.config = config;this.init(); &#125; // HttpServletBean@Overridepublic final void init() throws ServletException &#123; if (logger.isDebugEnabled()) &#123; logger.debug(\"Initializing servlet '\" + getServletName() + \"'\"); &#125; // Set bean properties from init parameters. // 这段代码，即是将 web.xml 内配置的所有 context-param 进行处理 try &#123; PropertyValues pvs = new ServletConfigPropertyValues(getServletConfig(), this.requiredProperties); BeanWrapper bw = PropertyAccessorFactory.forBeanPropertyAccess(this); ResourceLoader resourceLoader = new ServletContextResourceLoader(getServletContext()); bw.registerCustomEditor(Resource.class, new ResourceEditor(resourceLoader, getEnvironment())); initBeanWrapper(bw); bw.setPropertyValues(pvs, true); &#125; catch (BeansException ex) &#123; logger.error(\"Failed to set bean properties on servlet '\" + getServletName() + \"'\", ex); throw ex; &#125; // Let subclasses do whatever initialization they like. initServletBean(); if (logger.isDebugEnabled()) &#123; logger.debug(\"Servlet '\" + getServletName() + \"' configured successfully\"); &#125;&#125; FrameworkServlet.initServletBean()这就是 Spring 的 web 框架的 Servlet。其以一个基于 JavaBean 的形式与一个 Spring 应用上下文相集成。我们之前初始化的 wac 在此处被使用。 @Overrideprotected final void initServletBean() throws ServletException &#123; getServletContext().log(\"Initializing Spring FrameworkServlet '\" + getServletName() + \"'\"); if (this.logger.isInfoEnabled()) &#123; this.logger.info(\"FrameworkServlet '\" + getServletName() + \"': initialization started\"); &#125; long startTime = System.currentTimeMillis(); try &#123; this.webApplicationContext = initWebApplicationContext(); initFrameworkServlet(); &#125; catch (ServletException ex) &#123; this.logger.error(\"Context initialization failed\", ex); throw ex; &#125; catch (RuntimeException ex) &#123; this.logger.error(\"Context initialization failed\", ex); throw ex; &#125; if (this.logger.isInfoEnabled()) &#123; long elapsedTime = System.currentTimeMillis() - startTime; this.logger.info(\"FrameworkServlet '\" + getServletName() + \"': initialization completed in \" + elapsedTime + \" ms\"); &#125;&#125; Servlet 接口和请求响应对象对于 web 应用来说，通过继承 javax.servlet.http.HttpServlet 来实现 Servlet。 init(…): Initialize the servlet. destroy(…): Terminate the servlet. doGet(…): Execute an HTTP GET request. doPost(…): Execute an HTTP POST request. doPut(…): Execute an HTTP PUT request. doDelete(…): Execute an HTTP DELETE request. service(…): Receive HTTP requests and, by default, dispatch them to the appropriate doXXX() methods. getServletInfo(…): Retrieve information about the servlet. Servlet Context 基础一个 Servlet Context(上下文) 是一个实现了 javax.servlet.ServletContext 接口的实例。 一个 Servlet 上下文对象提供了 Servlet 的运行环境信息（如服务器名称），允许单一 JVM (支持多 JVM 的容器需要实现资源复用变量) 同一组内的 Servlets 间进行资源共享。 一个 Servlet 上下文提供了应用运行实例的范围信息。通过这个算法，每个 web 应用都用特定的 classloader 来加载同时其运行时对象和其他 web 应用都是不同的。 单一 Host 内可拥有多个 Servlet 上下文对象。 获取一个上下文可以使用一个上下文配置对象的 getServletContext() 方法来获取一个 Servlet 上下文。 Servlet 配置对象一个 servlet configuration objec 包含了一个 Servlet 初始化和启动参数，其是 javax.servlet.ServletConfig 的一个实例。 可以通过 Servlet 的 getServletConfig() 来获取其配置对象。此方法在 javax.servlet.Servlet 定义，默认实现在 javax.servlet.http.HttpServlet 中。 ServletContext getServletContext() 获取 Servlet 的上下文 String getServletName() 获取 Servlet 名称 Enumeration getInitParameterNames() 获取 Servlet 的初始化参数。 String getInitParameter(String name) 获取某一初始化参数的值。","categories":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/tags/Java/"},{"name":"SpringMVC","slug":"SpringMVC","permalink":"https://gowa2017.github.io/tags/SpringMVC/"},{"name":"Sprin","slug":"Sprin","permalink":"https://gowa2017.github.io/tags/Sprin/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}]},{"title":"Retrofit下载文件及ResponseBody解析","slug":"Retrofit下载文件及ResponseBody解析","date":"2019-06-11T15:29:34.000Z","updated":"2019-06-11T15:29:34.000Z","comments":true,"path":"Android/Retrofit下载文件及ResponseBody解析.html","link":"","permalink":"https://gowa2017.github.io/Android/Retrofit下载文件及ResponseBody解析.html","excerpt":"看多数文章都说明用 Retrofit 来下载大文件的时候需要用 @Streaming 注解来避免 OOM，当下载的文件的时候，返回的值是一个 ResponseBody。事实上，很少有文章说明，这背后到底是怎么工作的。","text":"看多数文章都说明用 Retrofit 来下载大文件的时候需要用 @Streaming 注解来避免 OOM，当下载的文件的时候，返回的值是一个 ResponseBody。事实上，很少有文章说明，这背后到底是怎么工作的。 从 call 看起从 Retrofit 的 call 接口来看，我们通常使用的方式是这样的： @GET@StreamingCall&lt;ResponseBody&gt; download(@Url String url); 上面的代码中我们定义了一个 Retrofit 方法 download()，对每个 Retrofit 方法的调用都会发送一个请求到 web 服务器，然后得到一个响应。 我们的调用，会产生其对应的 HTTP 请求和响应。 public interface Call&lt;T&gt; extends Cloneable &#123; /** * Synchronously send the request and return its response. * * @throws IOException if a problem occurred talking to the server. * @throws RuntimeException (and subclasses) if an unexpected error occurs creating the request * or decoding the response. */ Response&lt;T&gt; execute() throws IOException; /** * Asynchronously send the request and notify &#123;@code callback&#125; of its response or if an error * occurred talking to the server, creating the request, or processing the response. */ void enqueue(Callback&lt;T&gt; callback); /** * Returns true if this call has been either &#123;@linkplain #execute() executed&#125; or &#123;@linkplain * #enqueue(Callback) enqueued&#125;. It is an error to execute or enqueue a call more than once. */ boolean isExecuted(); /** * Cancel this call. An attempt will be made to cancel in-flight calls, and if the call has not * yet been executed it never will be. */ void cancel(); /** True if &#123;@link #cancel()&#125; was called. */ boolean isCanceled(); /** * Create a new, identical call to this one which can be enqueued or executed even if this call * has already been. */ Call&lt;T&gt; clone(); /** The original HTTP request. */ Request request();&#125; 对于每个 Retrofit 方法来讲，泛型 T 代表了要返回的响应体类型。(Response body type。) Response需要先注意的是， okhttp 与 Retrofit 都有 Response 这个类，但实际上 Retrofit.Response 只是对 okhttp.Response 的封装，提供了一些更简单好用的方法而已。 okhttp.Response 是一个对 HTTP 协议响应的一个完整 Java 表示。其内部持有相应码，请求信息等等内容： public final class Response implements Closeable &#123; final Request request; final Protocol protocol; final int code; final String message; final @Nullable Handshake handshake; final Headers headers; final @Nullable ResponseBody body; final @Nullable Response networkResponse; final @Nullable Response cacheResponse; final @Nullable Response priorResponse; final long sentRequestAtMillis; final long receivedResponseAtMillis;&#125; ResponseBody这是 OkHttp 定义的类。其是一个字节流，代表了从服务器到客户端的一个一次性的流。其背后都一个活跃的到 web 服务器的连接在支持。 ResponseBody 所代表的流只能消费一次。 ResponseBody 必须被关闭。因为每个 ResponseBody 都是有受限的资源来支持的（如套接字数量，打开文件数量），如果不关闭，就会造成资源泄漏，造成性能的下降。 这个可以用来流式操作很大的响应。不论是超过了内存大小的响应，甚至还是超过了本地存储大小的响应（如视频播放）这都是可以的。因为这个类不会将响应完全缓存到内存，所以是无法再次阅读这个响应里字节内容。 可以用 bytes(),string() 方法来将整个响应读到内存；或者用 source(), byteStream(), charStream() 来将响应变成一个流。 通常，就 HTTP1.1 来说，如果服务端返回的数据长度是已知的，在接收完数据后，就由客户端主动关闭连接结束通信。这有一个潜在的意思就是，在数据没有接收完之前，客户端与服务端的 TCP 连接是不会断开的。 有一种情况，客户端将永远也不会主动断开连接。也即：客户端返回的内容 contentLength 字段未知，而且也没有 chunked 标识。但一般来说都不会有这样的情况存在。 思考其实应该是我想得太多，Retrofit/OkHTTP 所言，ResponseBody 不会将数据全部缓存到内存，说的是系统的用户态。 在内核态，确切的来说，是在 TCP 协议栈的实现来说，是完全会将服务端发送的数据放到协议栈内，然后分发到应用程序的。我们从 ResponseBody 读取数据，事实上也就是向内核协议栈拿数据，将内核态中内存的内容取到用户区去。 OK，那么就算了解了这背后的道理了，想太多也不是好事。 Streaming对于 Streaming 而言，就是说要将返回的值流式化，而不读进内存，由用户来决定如何从流读取，最终关闭流。 在我们 build Retrofit 实例的时候，添加了默认的 Converts: // Add the built-in converter factory first. This prevents overriding its behavior but also// ensures correct behavior when using converters that consume all types.converterFactories.add(new BuiltInConverters());converterFactories.addAll(this.converterFactories);converterFactories.addAll(platform.defaultConverterFactories()); 对于 BuiltInConverters 而言，其会根据注解来决定，是使用哪一种类型的 Converter： @Override public @Nullable Converter&lt;ResponseBody, ?&gt; responseBodyConverter( Type type, Annotation[] annotations, Retrofit retrofit) &#123; if (type == ResponseBody.class) &#123; return Utils.isAnnotationPresent(annotations, Streaming.class) ? StreamingResponseBodyConverter.INSTANCE : BufferingResponseBodyConverter.INSTANCE; &#125; if (type == Void.class) &#123; return VoidResponseBodyConverter.INSTANCE; &#125; if (checkForKotlinUnit) &#123; try &#123; if (type == Unit.class) &#123; return UnitResponseBodyConverter.INSTANCE; &#125; &#125; catch (NoClassDefFoundError ignored) &#123; checkForKotlinUnit = false; &#125; &#125; return null;&#125; 当我们的返回类型是 ResponseBody ，同时加上了 @Streaming 注解的时候，就会返回 StreamingResponseBodyConverter。 对比 StreamingResponseBodyConverter 与 BufferingResponseBodyConverter 的 convert() 方法即可知晓其中的道理： @Override public ResponseBody convert(ResponseBody value) &#123; @Override public ResponseBody convert(ResponseBody value) throws IOException &#123; try &#123; // Buffer the entire body to avoid future I/O. return Utils.buffer(value); &#125; finally &#123; value.close(); &#125;&#125; 前者会直接返回 ResponseBody 这个一次性的流，而后者，则会缓存到内存区；两者之后都会关闭 ResponseBody。 区别主要就是在这里了。 文件的下载那么这个时候就很简单了，将 ResponseBody 调用其中一些方法，变成一个输入流，然后写到输出流就OK了。","categories":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"},{"name":"Retrofit","slug":"Retrofit","permalink":"https://gowa2017.github.io/tags/Retrofit/"}],"keywords":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}]},{"title":"Github上的MySQL高可用","slug":"Github上的MySQL高可用","date":"2019-06-08T13:42:11.000Z","updated":"2019-06-08T13:42:11.000Z","comments":true,"path":"MySQL/Github上的MySQL高可用.html","link":"","permalink":"https://gowa2017.github.io/MySQL/Github上的MySQL高可用.html","excerpt":"Github 使用 MySQL 作为主要的数据库，其可用性是非常的严格的。对于 Github 网站自身，其 API 入登录认证等都需要访问数据库。我们必须运行多个 MySQL 群集来服务不同的业务和任务。我们的群集使用传统的​主从​设置，在这种设置中，一个群集中的一个节点（Master）接受写操作。剩下的群集节点异步的从 Master 重放变更并提供读流量。","text":"Github 使用 MySQL 作为主要的数据库，其可用性是非常的严格的。对于 Github 网站自身，其 API 入登录认证等都需要访问数据库。我们必须运行多个 MySQL 群集来服务不同的业务和任务。我们的群集使用传统的​主从​设置，在这种设置中，一个群集中的一个节点（Master）接受写操作。剩下的群集节点异步的从 Master 重放变更并提供读流量。 Master 的可用性非常的严格。如果没有了 Master，一个群集就无法接受写操作：所有需要持久化的数据都无法持久化。所有涉及道数据变更的操作如：提交、问题、用户创建、审阅等都会失败。 为了支持写操作我们很明显，需要一个可用的可写入节点。同样重要的是，我们需要能识别和发现那个节点。 在失败的情况下，在 Master 崩溃的情况下，我们必须确保一个新的 Master 的存在，且其能快速的宣告自身。用来检测失败，故障转移，宣告新 Master 身份的时间就构成了所有的停服时间。 这篇文章展示了 Github 上的 MySQL 高可用及 Master 服务的发现解决方案，此方案可以让我们可信的执行一个跨数据中心操作，容忍数据中心隔离，同时很短的时间进行故障切换。 高可用目标在想要实现高可用之前，我们需要问自己几个问题，以便我们更好的进行决策。例如： 能容忍多久的宕机时间？ 故障检测的可靠性如何？能否容忍误报（过早的故障迁移）？ 故障迁移的可靠性如何？何处可能出现失败？ 解决方案跨数据中心工作起来怎么样？在低延迟和高延迟网络情况下的表现如何？ 方法能否容忍一个完全的数据中心宕机或网络隔离？ 用什么算法来避免脑裂（在一个群集内两个服务器都宣告自己是 Master，相互都不知道对方可以接受写操作）？ 能否接受数据丢失？ 从基于 VIP 和 DNS 的发现迁移在之前的实现中，我们使用： orchestrator 来检查故障和故障迁移 使用 VIP 和 DNS 来发现 Master client 使用一个域名，如 mysql-writer-1.github.net 来发现可写节点。这个域名会解析到一个 VIP（绑定在 Master 主机上）。 这样，在正常情况下， clients 只需要解析域名，连接到解析后的IP就可以了。 下面三复制的拓扑，分布在三个数据中心： 如果 Master 宕机，在复制中我们必须将一个提升为 Master。 orchestrator 将会检查故障，提升一个新 Master，接着重新设置域名/VIP。所有的 Client 都不知道 Master已经变更：它们都只拥有一个标示 Master 的域名，这个域名现在解析到了一个新的 Master。然而，我们思考一下： VIP 是协作性的：其被所有的数据库服务器拥有和宣告。为了获取或者释放一个VIP，一个服务器必须发送一个 ARP 请求。拥有这个 VIP 的服务器必须在新的 Master 需要之前释放这个 VIP。这会有一些影响： 一个有序的故障迁移操作会首先联系宕机的 Master 并要求其释放 VIP，然后联系新的 Master 让其使用这个 VIP。但是，如果老的 Master 不可达或者拒绝释放 VIP 怎么办？ 我们可能会出现脑裂的情况：两台主机都宣告拥有相同的 VIP。不同的 Client 会连接到不同的主机去，这依赖于其最短网络路径。 Master 依赖于两个个独立的服务器来相互协作确定，这是不可靠的。 及时老的 Master 确实配合，但是这个工作流程浪费了时间：我们需要在切换到新的 Master 前等待联系老的 Master 进行响应。 例如 VIP 改变这样的事件，已经存在的 client 与 master 之间的连接不保证会从老服务器断开，依然可能出现脑裂。 在我们的部分配置中，VIP 受物理位置的约束。他们被一个路由器或者交换机所拥有。因此，我们只能重新将 VIP 配置到位置相知的服务器上。实际上，当我们无法将 VIP 配置到另外一个数据中心提上来的 Master 时，就不得不做 DNS 的变更。 DNS 变更的传播需要时间。clients 会缓存 DNS 的解析结果一定的时间。那么一个跨数据中心的迁移就会花费更多的时间。 上面这些限制已经足够推动我们去研究新的解决方案了，但我们需要更多的考虑： 通过 pt-heartbeat 服务，Master 间通过心跳来进行自注入，这是为了进行滞后测量和节流控制。在新的 Master 上，这个服务必须踢出。可能的话，这个服务也会在老的 Master 上关闭。 同样 Pseudo-GTID 注入由 masters 自身管理。在新的 Master 上踢出，当然，完美实现的话还需要在 老的 Master 上关闭。 新的 Master 会被设置为可写。可能的话，老的 Master 设置为只读。 这些额外的步骤是导致总停机时间的一个因素，并引入了自己的故障和摩擦。 上面这个解决方案能工作，Github 在这种方案下也成功的工作了，但是我们希望我们的 HA 在以下方面进行提高： 数据中心不可知 容忍数据中心故障 移除不可靠的协同工作流程 减少宕机时间 进可能少的故障迁移。 Github HA：orchestrator, Consul, GLB在新的方案中，解决了上面的大多数问题，且有了一些附带的提升。当前的 HA 配置是： orchestrator 进行检测和故障迁移。我们使用一个跨数据中心的 orchestrator/raft 配置。下面会介绍。 Consul 来进行服务发现。 GLB/HAProxy 在 clients 和可写节点间作为一个代理层。 GLB 是开源的。 anycast 进行网络路由 正常流程正常请下，通过 GLP/HAProxy 连接到可写节点。 应用永远不会意识到 Master 的变化。和之前的方案一样，他们使用一个域名。例如，对于 cluster1 的 Master 可能是 mysql-writer-1.github.net。在我们当前的配置中，这个域名被解析到一个 anycast IP。 使用 anycast 技术后，域名会解析到一个IP地址，但是流量却是根据 client 的位置进行路由。实际上，在每个数据中心我们都有 GLB（高可用负载均衡器，部署在多个盒子上）。到 mysql-writer-1.github.net 的流量总是会路由到当地数据中心的 GLB 群集上。也就是说，所有 clients 都由 本地代理提供服务。 我们在 HAProxy 之上运行 GLB。 HAProxy 有写入池：每个 Mysql Cluster 一个池，每个池只有一个后端服务器： cluster 的 Master 服务器。所有数据中心的 GLB/HAProxy 都有相同的写入池。因此，如果应用想要连接到 mysql-writer-1.github.net 的时候，其不用关心是连接到了哪个 GLB。其总是会被路由到 cluster1 的 Master 节点。 对于应用而言，在 GLB 处就停止了服务发现，也不需要重新进行发现。把流量路由到正确的地方这是 GLB 的责任。 GLB 是如何知道哪些服务器作为后端的？我们如何在 GLB 间传递修改呢？ 通过 Consul 进行发现Consul 因其服务发现解决方法而知名，同时也提供了 DNS 服务。在我们的解决方案中，我们只将其使用为一个高可用键值存储。 我们将每个群集的 Master 都写到这个 Consul 的键值存储中。对于每个群集，会有一系列的 KV 项来表示这个群集 Master 的 fqdn，port, ipv4, ipv6。 每个 GLP/HAproxy 都运行 consul-templates：一个监听 Consul 数据变更的服务。consul-template 会产生一个有效的配置文件，并能根据这个文件的变更来重新加载 HAProxy。 这样，Consule 中每个 Master 信息的变更都会被 GLB/HAProxy 观察到，并以此来重新配置，将新的 Master 配置为一个群集中的唯一项，接着重新加载来反应这些变化。 在 Github 中，我们在每个数据中心有一个 Consul 配置，每个配置都是高可用的。然而，这些配置与其他数据中心是相互独立的。他们不会相互复制和共享数据。 那么如果在数据中心之间传播 Consul 的数据呢？ orchestrator/raft我们使用一个 orchestrator/raft 配置：orchestrator 节点通过 raft 共识算法来与其他节点通信。在每个数据中心中我们有一个或两个 orchestrator 节点。 orchestrator 的作用是进行故障检测，MySQL 故障迁移，已经将 master 的改变通知到 Consul。故障迁移由一个 orchestrator/raft 领导节点来操作，但是 master 的变更信息通过 raft 算法在 orchestrator 节点间进行传播。 一个 orchestrator 节点收到 master 变更的通知后，会与其本地的 Consul 进行通信：都会在 Consul KV Store 中写入一个信息。拥有多个 orchestrator 节点的数据中心会对 Consul 有多个写入。 流程总览在一个 Master 崩溃的情况下： orchestrator 检测到故障 orchestrator/raft 开始进行恢复。选举出一个新的 Master orchestrator/raft 会将 Master 的变更宣告到所有的 raft 群集节点 每个 orchestrator/raft 成员收到一个领导节点的变更通知。然后他们会以收到的 Master 信息来写入到本地的 Consule 的 KV Store 中。 每个 GLB/HAProxy 都有一个 consul-templating 在运行，他们会观察 Consul KV Store 的变化，并重新配置和加载 HAProxy Client 的流量就会被重定向到新的 Master 这样，每个组件都有其清晰的任务，整个设计进行了解耦并且非常简单。orchestrator 不知道 GLB 的存在。 Consul 也不需要知道信息是从哪里来的。HAProxy 只需要关心 Consul。 Client 只需要关心 HAProxy。 然后，我们这里就少了一些其他的需要： 不需要 DNS 变更的传播 没有 TTL 不需要故障的 Master 的配合。 更多细节为了让这个流程更安全，我们还做了下面的事情： HAProxy 配置了一个非常低的 hard-stop-after 属性。当其在一个 写入池 中重新加载一个后端服务器的时候，其会自动终止所有在老的 Master 上的连接。 配置了 hard-stop-after 后，我们就不再需要与客户端进行协作，同时这个减少了出现脑裂的概率。 我们不需要 Consul 保持一直可用。实际上，只需要在故障迁移的时候 Consul 可用就行了。如果 Consul 碰巧也不工作了，GLB 会在最后已知的那个服务器上进行操作，而不会有什么激烈的变化。 GLB 设置来识别新变更的 Master。与我们的 context-aware MySQL pools 类似，其会在后端做一个检查来确认其是否需要一个可写节点。如果我们不小心从 Consul 中删除了 Master 的信息，没问题；空的项目会被忽略。如果我们在 Consul 中写入了一个不是 Master 的信息，也没有问题； GBL 会拒绝更新。 orchestrator/raft 故障检测orchestrator 使用一个整体的方式来检测故障，因此变得非常可靠。我们不会观察到误报：因此不会出现过早的迁移，因此也不会增加额外的宕机时间。 orchestrator/raft 进一步解决了整个数据中心网络隔离的问题。一个 DC 网络隔离会引起混乱：在 DC 内部的服务器间可以相互通信。是当前 DC 与其他网络隔离，还是其他的 DC 被网络隔离了？ 在 orchestrator/raft 中，raft 领导节点是唯一进行故障迁移的节点。一个领导节点是获得了组内大多数支持的那个节点。我们 orchestrator 节点的部署，不会让任何一个数据中心投票就成为领导节点，而必须剩下的 n -1 个数据中心共同来决定。 在一个 DC 网络隔离的情况下，当前 DC 内的 orchestrator 节点将会与其他 DC 间的节点断开连接。那么，当前DC 内的 orchestrator 就不会成为 raft 群集的领导节点。如果有这样的节点成为了领导节点，那他将会被踢下去。其他的 DC 会重新选取一个领导节点。 那么在隔离的 DC 内需要一个 master 么。orchestrator 会将其他正常 DC 内的服务器作为其 Master。我们通过将决策委托给非隔离DC中的领导者来缓解DC隔离。 快速宣告更快的宣告 Master 的变更可以减少宕机时间？那么这如何达到。 当 orchestrator 开始故障迁移，其观察将要被提升的那些服务器。其了解复制规则且遵守提示和限制，以此来作出最佳的决定。 其会了解，一个将要提升的服务器也是一理想候选人： 没有什么会阻止选举这个服务器（有可能用户已经将此服务器设置为首选） 此服务器可以作为其他所有兄弟服务器的副本 当遇到这样的服务器时，即使需要异步开始修复复制树（这个操作通常需要几秒钟。），orchestrator 也会将这个服务器设置为可写，将这个进行宣告（在我们的场景下是写到 Consul KV Store 中）。 很可能在我们的GLB服务器完全重新加载时，复制树已经完好无损，但并不是严格要求的。服务器可以很好接收写入！ 半同步复制在 MySQL的半同步复制中，如果一个事务进行提交，只有提交所产生的变化已经被至少一个 Slave 库所知晓，Master 才会进行确认。其提供了一个达到无损故障迁移的方式：对于 Master 的变化，要么已经完成，要么等待应用到 slave 库上。 一致性带来成本：可用性风险。如果没有 slave 确认收到了变化，master 就会阻塞，写入就会停止。幸运的是，这里有一个超时设置，在经过了这个设置的时间后，主服务器可以恢复到异步复制模式。 我们把这个超时时间设置为：500ms。这个时间完全足够将变化在 当前 DC内进行传播，当然，到其他 DC 间也是可能够的。 我们在本地DC副本上启用半同步，并且在 Master 死亡的情况下，我们期望（尽管不严格执行）无损故障转移。完全DC故障的无损故障转移成本很高，我们不期望它。 在尝试半同步超时时，我们还观察到了一种对我们有利的行为：在主服务器故障的情况下，我们能够影响理想候选人的身份。通过在指定服务器上启用半同步，并将其标记为候选服务器，我们可以通过影响故障结果来减少总停机时间。 心跳注入我们选择一直运行 pt-heartbeat 服务，而不是只是 选举/踢出 Master 的时候进行 启动/停止。这个需要打个补丁来让 pt-heartbeat 服务适应服务器在 read-only 状态的变化或者完全的崩溃。 当前 pt-heartbeat 服务运行在 Master 和 slave 上。在 Master 上，他们产生心跳事件。在 slave 上，他们确认当前的服务器是 read-only，和进行常规的状态检查。当一个服务器被选举为 Master 的时候， pt-heartbeat 会检查此服务器是否为可写，同时开始产生心跳事件。 orchestrator 权限委托同时我们让 orchestrator 来做下面的事情： 伪GTID注入 设置被选举为 Master 服务器为 可写，清楚其 slave 状态 可能的话，设置老的 Master 为 read-only 在 新的 Master 上，这会减少摩擦。被选举为 Master 的服务器很明显是需要在线的和可用的，不然我们就不会选举它了。因此，让orchestrator直接将更改应用于提升的 Master 是有道理的。 限制与缺点代理层让应用不清楚 Master 的身份，但同时其也向 Master 屏蔽了 应用的身份。Master 看到的所有连接都是从代理来的，我们丢失了实际的连接源头信息。 随着分布式系统的发展，我们仍然处于未处理的情况。 需要注意的是，在一个数据中心隔离的情况下，我们假设 Master 就在这个数据中心中，在这个数据中心的应用依然可以向这个 Master 写入。当网络恢复的时候，这可能会导致数据的不一致性。我们努力通过在一个隔离的DC中 实现一个可靠的 STONITH 来减少脑裂的情况。和之前一样，在我们将 Master 关闭前可能会有短时间的脑裂。避免脑裂的操作成本非常高。 还有些场景：故障迁移时 Consul 停止；局部的 DC 隔离；等等。分布式的系统不可能把所有的问题都解决，所以只能先解决最重要的。 结果我们的 orchestrator/GLB/Consul 提供了我们如下功能： 可靠的故障检测 数据中心不敏感的故障迁移 通常是无损故障转移 数据中心隔离的支持 减少脑裂 不依赖协作 多数情况下 10-13秒的宕机","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://gowa2017.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://gowa2017.github.io/tags/MySQL/"}],"keywords":[{"name":"MySQL","slug":"MySQL","permalink":"https://gowa2017.github.io/categories/MySQL/"}]},{"title":"RealVNC的VNC-Viewer连接到VM虚拟机出错的问题","slug":"RealVNC的VNC-Viewer连接到VM虚拟机出错的问题","date":"2019-06-02T14:46:30.000Z","updated":"2019-06-02T14:46:30.000Z","comments":true,"path":"Linux/RealVNC的VNC-Viewer连接到VM虚拟机出错的问题.html","link":"","permalink":"https://gowa2017.github.io/Linux/RealVNC的VNC-Viewer连接到VM虚拟机出错的问题.html","excerpt":"","text":"OS: CentOS 7 x64 开启了 vncserver，对于 Linux 系统本身而言，用 VNC Viewer 连接没有问题。 问题出在我用 KVM 添加了一个虚拟机，配置好 VNC 连接后无法连接。报出的错误是： RFB protocol error: invalid message type ... 通过搜索，找到了结果： 看这里 解决办法： 在 Options 设置中，将 Picture quality 设置为 High，设置为 Automatic 是无法识别。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/tags/Linux/"},{"name":"VNC","slug":"VNC","permalink":"https://gowa2017.github.io/tags/VNC/"}],"keywords":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}]},{"title":"RxJava的blocking操作符","slug":"RxJava的blocking操作符","date":"2019-05-31T13:20:30.000Z","updated":"2019-05-31T13:20:30.000Z","comments":true,"path":"RxJava/RxJava的blocking操作符.html","link":"","permalink":"https://gowa2017.github.io/RxJava/RxJava的blocking操作符.html","excerpt":"之所以有这样的场景，是因为当我想像 Stream API 那样使用 Observable 的时候出现了问题。所以就来了解一下 blocking 操作符到底是怎么样工作的。","text":"之所以有这样的场景，是因为当我想像 Stream API 那样使用 Observable 的时候出现了问题。所以就来了解一下 blocking 操作符到底是怎么样工作的。 首先，我们知道对于 Observer 与 Observable 的关系是： Observable.subscribe(Observer) 之后， Observable 就会调用 Observer 的方法 onNext(), onError(), onComplete() 方法来发送数据和通知。 同时呢，对于在 Observable 上应用的每个操作符，都会返回一个新的 Observable。新成的 Observable 会将之前的 Observable 当作 Upstream。（在代码中可以看到是表示为 source, upstream 等） 同时，新返回的 Observable 会用一个内部的 Observer 来和 upstream 进行连接。 blockingFirst()对于在 Observable 上应用这个操作符： public final T blockingFirst() &#123; BlockingFirstObserver&lt;T&gt; observer = new BlockingFirstObserver&lt;T&gt;(); subscribe(observer); T v = observer.blockingGet(); if (v != null) &#123; return v; &#125; throw new NoSuchElementException();&#125; 是不是，就是用一个 BlockingFirstObserver 来连接 Observable ，接着就执行了 blockingGet() 方法。 BlockingFirstObserver 继承自 BlockingBaseObserver（继承自 CountDownLatch）。 CountDownLatch我们先来看一下 CountDownLatch 这个类到底是对什么的抽象。CountDownLatch 位于 java.util.concurrent 包下，是 Java 内建的类。 根据 JavaDoc： CountDownLatch 是一个同步助手，其允许一个或多个线程在一系列其他线程正在执行的操作完成前进行等待。其需要一个 count 参数来进行初始化。其 await() 方法在 当前的 count 值为0前等待（可以通过 countDown() 方法来减少）。在 count 为 0 后，所有等待的线程都被唤醒，后续所有的 await() 方法调用都会立刻返回。这个过程是不可逆的———— count 值不能被重置。如果我们需要重置 count，可以考虑使用 CyclicBarrier。 Sync 与状态CountDownLatch 持有一个其内部的类 Sync 的实例，Sync 继承自 AbstractQueuedSynchronizer。其是一个有状态的类，用来作为很多同步操作的基础。 private static final class Sync extends AbstractQueuedSynchronizer &#123; private static final long serialVersionUID = 4982264981922014374L; Sync(int count) &#123; setState(count); &#125; int getCount() &#123; return getState(); &#125; protected int tryAcquireShared(int acquires) &#123; return (getState() == 0) ? 1 : -1; &#125; protected boolean tryReleaseShared(int releases) &#123; // Decrement count; signal when transition to zero for (;;) &#123; int c = getState(); if (c == 0) return false; int nextc = c-1; if (compareAndSetState(c, nextc)) return nextc == 0; &#125; &#125;&#125;private final Sync sync; await()BlockingFirstObserver 会调用 blockingGet 方法： public final T blockingGet() &#123; if (getCount() != 0) &#123; try &#123; BlockingHelper.verifyNonBlocking(); await(); &#125; catch (InterruptedException ex) &#123; dispose(); throw ExceptionHelper.wrapOrThrow(ex); &#125; &#125; Throwable e = error; if (e != null) &#123; throw ExceptionHelper.wrapOrThrow(e); &#125; return value;&#125; 如前文所述，如果当前的 count 值（状态） 不为0，那么就会调用其父类 CountDownLatch 的 await() 方法，进入等待： public void await() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1);&#125; 不过根据我观察代码发现一个问题，事实上虽然说的是 blocking 的形式去获取数据。在我们不使用 subscribeOn 操作符的情况下，事实上代码： public final T blockingFirst() &#123; BlockingFirstObserver&lt;T&gt; observer = new BlockingFirstObserver&lt;T&gt;(); subscribe(observer); T v = observer.blockingGet(); if (v != null) &#123; return v; &#125; throw new NoSuchElementException();&#125; 在 subscribe 的时候， Observable 就开始发射数据，等到调用 blockingGet() 方法的时候，数据都已经发射过来了，看起来是不会进入阻塞状态的呢。 countDown()在源 Observable 发射数据的时候，其实就已经改变了锁的状态(count 值)了，所以呢，不会阻塞了。 public final class BlockingFirstObserver&lt;T&gt; extends BlockingBaseObserver&lt;T&gt; &#123; @Override public void onNext(T t) &#123; if (value == null) &#123; value = t; upstream.dispose(); countDown(); &#125; &#125; @Override public void onError(Throwable t) &#123; if (value == null) &#123; error = t; &#125; countDown(); &#125;&#125;","categories":[{"name":"RxJava","slug":"RxJava","permalink":"https://gowa2017.github.io/categories/RxJava/"}],"tags":[{"name":"RxJava","slug":"RxJava","permalink":"https://gowa2017.github.io/tags/RxJava/"}],"keywords":[{"name":"RxJava","slug":"RxJava","permalink":"https://gowa2017.github.io/categories/RxJava/"}]},{"title":"RxJava使用Schedulers时进行的线程切换","slug":"RxJava使用Schedulers时进行的线程切换","date":"2019-05-28T13:54:50.000Z","updated":"2019-05-28T13:54:50.000Z","comments":true,"path":"RxJava/RxJava使用Schedulers时进行的线程切换.html","link":"","permalink":"https://gowa2017.github.io/RxJava/RxJava使用Schedulers时进行的线程切换.html","excerpt":"默认情况下，RxJava 是单线程的。所谓单线程指的是，Observable 及所有的操作符都会我们调用 Subscribe 方法的线程上完成。我们可以通过 SubscribeOn 操作符来改变这一行为，通过用此操作符来指定 Observable 在不同的 Scheduler 上进行执行工作，而 ObserveOn() 用来告诉 Observable 往哪个 Scheduler 发送通知。","text":"默认情况下，RxJava 是单线程的。所谓单线程指的是，Observable 及所有的操作符都会我们调用 Subscribe 方法的线程上完成。我们可以通过 SubscribeOn 操作符来改变这一行为，通过用此操作符来指定 Observable 在不同的 Scheduler 上进行执行工作，而 ObserveOn() 用来告诉 Observable 往哪个 Scheduler 发送通知。 对于 SubscribeOn() 来说，其指定 Observable 在哪个线程开始执行，而无论我们在才操作符链中的哪个位置调用 SubscribeOn()。 ObserveOn() 正好相反，其会影响在其后的操作符执行的线程。因此，我们可能会多次调用 ObserveOn()。 在进行研究之前，我们先要了解 Scheduler 是什么东西。 Scheduler根据 JavaDoc 的定义： Scheduler 指定了一个 API 用以调度以 Runnable 形式提供的工作单元，这些 Runnable 可能是会立刻执行、延迟一段时间或者周期性的重复；Scheduler 也代表在异步界限上的抽象：保证这些工作单元会被一些底层的任务执行方案以统一的属性和保证所执行（如自定义 Thread，event loop，Executor 或 Actor 系统），而不论底层的执行方案具体是怎么样的。 Scheduler 中的 Scheduler.Worker 可以通过 createWorker() 方法来建立，它们运行在相互隔离的情况下调度多个 Runnable。每个 Worker 中的多个 Runnable 保证会非交叉顺序执行。非延迟的 Runnable 保证会以一个 FIFO 的形式执行，但这可能会与有延迟的 Runnable 相重叠。可以用 Disposable.dispose() 方法来取消当前 Worker 中的任务，而不会影响其他的 Worker 实例。 对于方法 scheduleDirect(Runnable), Scheduler.Worker.schedule(Runnable) 的实现中鼓励我们调用 RxJavaPlugins.onSchedule(Runnable) 来允许一个 scheduler 钩子在原始的 Runnable 提交到底层的执行方案前可以操纵（封装或替换）此 Runnable。 在 Schedule 抽象类中对于方法 scheduleDirect() 的默认实现，是对我们用 createWorker() 为每个 Runnable 建立出来的 Scheduler.Worker 实例中的 schedule() 方法的一个代理。事实上 RxJava 鼓励我们在实现中，不要为每个任务都创建一个 Worker，因为这是比较耗费时间和内存的。 SchedulersSchedulers 是一个工厂类，用来获取一些我们常用的 Schduler。例如： computation io trampoline newThread single 我们以 io 为例开探究一下。 Schedulers.io()本来比较简单的逻辑，但是我是不懂为什么设计来转这么多弯子的。 在 Schedulers 内会初始化 IoScheduler。 static final Scheduler IO;IO = RxJavaPlugins.initIoScheduler(new IOTask()); IoTask 是一个 Callable 的实现，简单的返回 IoHolder的默认值。 static final class IOTask implements Callable&lt;Scheduler&gt; &#123; @Override public Scheduler call() throws Exception &#123; return IoHolder.DEFAULT; &#125;&#125; IoHolder 是 IoScheduler 的容器： static final class IoHolder &#123; static final Scheduler DEFAULT = new IoScheduler();&#125; IoScheduler 才是具体对 Scheduler 的实现。 OK，现在我们大概知道 IoScheduler 是什么了。 SubscribeOn我们知道，每个操作符都会返回一个新的 Observable。例如我们应用 map() 会返回一个 ObservableMap。同理，应用 subscribeOn() 会返回一个 ObservableSubscribeOn。 public ObservableSubscribeOn(ObservableSource&lt;T&gt; source, Scheduler scheduler) &#123; super(source); this.scheduler = scheduler;&#125; ObservableSubscribeOn 对象持有了我们指定的调度器 scheduler。 对于一般的 Observable 如 ObservableMap 来说，其在 subscribeActual() 中实现的内容是比较简单的，用一个 MapObserver 来订阅上游就OK了。 @Overridepublic void subscribeActual(Observer&lt;? super U&gt; t) &#123; source.subscribe(new MapObserver&lt;T, U&gt;(t, function));&#125; 而 ObservableSubscribeOn 则比较复杂一些： @Overridepublic void subscribeActual(final Observer&lt;? super T&gt; observer) &#123; final SubscribeOnObserver&lt;T&gt; parent = new SubscribeOnObserver&lt;T&gt;(observer); observer.onSubscribe(parent); parent.setDisposable(scheduler.scheduleDirect(new SubscribeTask(parent)));&#125; 在这里，按照常规的思考，在 ObservableSubscribeOn 中应该是使用 SubscribeOnObserver(parent) 来订阅上游 source 的。 一般来说，我们以 Observable.subscribe(Observer) void subscribe(@NonNull Observer&lt;? super T&gt; observer); 的形式开始的时候，在 Observable 都会调用 Observer 的 onSubscribe 方法。 void onSubscribe(@NonNull Disposable d); SubscribeOnObserver.setDisposable()代码很简单， parent.setDisposable(scheduler.scheduleDirect(new SubscribeTask(parent))); 只是一 scheduler 内调度了一个任务，来执行平时我们执行的代码： final class SubscribeTask implements Runnable &#123; private final SubscribeOnObserver&lt;T&gt; parent; SubscribeTask(SubscribeOnObserver&lt;T&gt; parent) &#123; this.parent = parent; &#125; @Override public void run() &#123; source.subscribe(parent); &#125;&#125; 可以理解为，是在另外一个 scheduler 内对 source 上游进行了订阅。 这就导致了所有的 subscribe 操作在那个新的线程上执行。所以说，subscribeOn 只有距离源最近的那个会生效，及时多次执行，后面的也不会导致线程的切换。 observeOn对于 observeOn 会返回一个 ObservableObserveOn，之后用 ObserveOnObserver 将其与上游联系起来。 需要注意的是，ObserveOnObserver 持有一个 worker 实例，对于所有的数据，都会通过 worker 来调度执行。 最后线程的切换都是通过作为中间联系的 Observer 来进行的。","categories":[{"name":"RxJava","slug":"RxJava","permalink":"https://gowa2017.github.io/categories/RxJava/"}],"tags":[{"name":"RxJava","slug":"RxJava","permalink":"https://gowa2017.github.io/tags/RxJava/"}],"keywords":[{"name":"RxJava","slug":"RxJava","permalink":"https://gowa2017.github.io/categories/RxJava/"}]},{"title":"RxJava的聚合操作函数collect与groupby","slug":"RxJava的聚合操作函数collect与groupby","date":"2019-05-27T15:03:55.000Z","updated":"2019-05-27T15:03:55.000Z","comments":true,"path":"RxJava/RxJava的聚合操作函数collect与groupby.html","link":"","permalink":"https://gowa2017.github.io/RxJava/RxJava的聚合操作函数collect与groupby.html","excerpt":"RxJava 提供了一些类似与 stream 的方法，恰好我们在 API26 以下的安卓是无法使用 stream API的，所以尝试用这种方式来使用，但是会有坑的。","text":"RxJava 提供了一些类似与 stream 的方法，恰好我们在 API26 以下的安卓是无法使用 stream API的，所以尝试用这种方式来使用，但是会有坑的。 groupBy对一个 Observable 使用 groupBy 后，会返回 ObservableGroupBy。一般情况下，我们只指定 keySelector 就行了，其他的使用默认值，当然，有的时候我们还会指定 valueSelector。 public final &lt;K, V&gt; Observable&lt;GroupedObservable&lt;K, V&gt;&gt; groupBy(Function&lt;? super T, ? extends K&gt; keySelector, Function&lt;? super T, ? extends V&gt; valueSelector, boolean delayError, int bufferSize) &#123; ObjectHelper.requireNonNull(keySelector, \"keySelector is null\"); ObjectHelper.requireNonNull(valueSelector, \"valueSelector is null\"); ObjectHelper.verifyPositive(bufferSize, \"bufferSize\"); return RxJavaPlugins.onAssembly(new ObservableGroupBy&lt;T, K, V&gt;(this, keySelector, valueSelector, bufferSize, delayError));&#125; keySelector 用来选择组的键，我们也可以把他当做组的ID。可以理解为：对于发射的每个值，通过 keySelector 来赋予一个组的ID。之后我们就可以根据组 ID 来干很多事情了。 List&lt;Dict&gt; lst = new ArrayList&lt;&gt;();lst.add(new Dict(\"1\", \"A\"));lst.add(new Dict(\"2\", \"B\"));lst.add(new Dict(\"1\", \"B\"));lst.add(new Dict(\"2\", \"A\"));lst.add(new Dict(\"3\", \"B\"));lst.add(new Dict(\"3\", \"A\"));Observable.fromIterable(lst) .groupBy(new Function&lt;Dict, String&gt;() &#123; @Override public String apply(Dict dict) throws Exception &#123; return dict.getValue()+\"group\"; &#125; &#125;) .subscribe(grp -&gt; grp.subscribe( d -&gt; System.out.println(d))); 简单而言，groupBy 会将每个元素都赋予一个组ID，然后将组ID相同元素放在一个 Observable 内发射出来。 collect这个操作符就比较猥琐了。根据定义：collect 将会有限个元素的源发射的数据装到一个可变的数据结构内，然后返回一个会发射这个数据结构的 Single。 collect 是 reduce 的简化操作，不需像 reduce 那些需要在处理每个元素的时候都返回状态。 要求 upstream 必须要发射 onComplete 通知。 public final &lt;U&gt; Single&lt;U&gt; collect(Callable&lt;? extends U&gt; initialValueSupplier, BiConsumer&lt;? super U, ? super T&gt; collector) &#123; ObjectHelper.requireNonNull(initialValueSupplier, \"initialValueSupplier is null\"); ObjectHelper.requireNonNull(collector, \"collector is null\"); return RxJavaPlugins.onAssembly(new ObservableCollectSingle&lt;T, U&gt;(this, initialValueSupplier, collector));&#125; 其需要的两个参数： initialValueSupplier 数据结构构造方法 collector 泛型参数： U 表示返回值（数据结构）的类型 T upstream 发射元素的类型 List&lt;Dict&gt; lst = new ArrayList&lt;&gt;();lst.add(new Dict(\"1\", \"A\"));lst.add(new Dict(\"2\", \"B\"));lst.add(new Dict(\"1\", \"B\"));lst.add(new Dict(\"2\", \"A\"));lst.add(new Dict(\"3\", \"B\"));lst.add(new Dict(\"3\", \"A\"));HashMap&lt;String,Integer&gt; res =Observable.fromIterable(lst) .groupBy(dict -&gt; dict.getValue() + \"group\") .collect(HashMap&lt;String, Single&lt;Long&gt;&gt;::new, (m, e) -&gt; m.put(e.getKey(), e.count())) .flatMap((Function&lt;HashMap&lt;String, Single&lt;Long&gt;&gt;, SingleSource&lt;HashMap&lt;String, Integer&gt;&gt;&gt;) stringSingleHashMap -&gt; &#123; HashMap&lt;String,Integer&gt; map = new HashMap&lt;&gt;(); stringSingleHashMap.forEach((k,v)-&gt;map.put(k,v.blockingGet().intValue())); return Single.just(map); &#125;) .blockingGet();System.out.println(res);","categories":[{"name":"RxJava","slug":"RxJava","permalink":"https://gowa2017.github.io/categories/RxJava/"}],"tags":[{"name":"RxJava","slug":"RxJava","permalink":"https://gowa2017.github.io/tags/RxJava/"}],"keywords":[{"name":"RxJava","slug":"RxJava","permalink":"https://gowa2017.github.io/categories/RxJava/"}]},{"title":"RxJava使用blockingGet造成麻烦问题","slug":"RxJava使用blockingGet造成麻烦问题","date":"2019-05-27T14:08:46.000Z","updated":"2019-05-27T14:08:46.000Z","comments":true,"path":"RxJava/RxJava使用blockingGet造成麻烦问题.html","link":"","permalink":"https://gowa2017.github.io/RxJava/RxJava使用blockingGet造成麻烦问题.html","excerpt":"","text":"当使用 RxJava 和 Andorid 一起进行开发的时候，一不小心就中招了。一断不起眼的代码，就让线程永远的阻塞了下去。 问题代码List&lt;ComChangePersonInfo&gt; personInfos ;List&lt;MaterialInfo&gt; lst) ; Map&lt;String, Integer&gt; map = Observable.fromIterable(lst) .filter(m -&gt; TextUtils.equals(m.getMtype(), AppConstant.ComRegMaterialType.CARD)) .groupBy(m -&gt; m.getAboutPerson()) .collect(HashMap::new, (BiConsumer&lt;Map&lt;String, Integer&gt;, GroupedObservable&lt;String, MaterialInfo&gt;&gt;) (m, observable) -&gt; m.put(observable.getKey(), observable.count().blockingGet().intValue())) .blockingGet(); 这段代码的背景是： personInfos 保存的是一些人员信息 lst 保存的是一些证件信息。证件信息通过 MateriInfo.AboutPerson = ComChangePersonInfo.Id 进行关联，我需要的是为 AppConstant.ComRegMaterialType.CARD 这种类型 我现在想做的就是验证一下，每个人是否都传了两张证件信息。 所以我就想着，将 lst 进行一下分组，得出一个 Map，里面保存了每个 personId 的图片数量。 结果就造成了 ANR 。 问题在 groupBy 之前是没有什么问题的，正常。 我们知道一个流开始发射数据是在我们调用 subscribe 方法的时候开始的，但事实上对于 blockingGet 也会开始进行订阅。 public final T blockingGet() &#123; BlockingMultiObserver&lt;T&gt; observer = new BlockingMultiObserver&lt;T&gt;(); subscribe(observer); return observer.blockingGet();&#125; 我们在 .collect() 中就开始订阅 GroupObservable 开始发射数据，同时阻塞线程开始等待，直到上游数据.groupBy() 发送完毕。 但事实上这个时候是无法获取到数据的，为什么？ GroupObservable 是由 .groupBy() 被 .collect() 订阅后才会发送的，但因为我们线程阻塞了，我们永远也无法走到最后的那个 .blockingGet()，所以就造成了死锁。 ANR 当然就是这样了。 搜索谷歌，大多说对于 blocking 操作，和安卓的使用有点不太好用。 解决办法 放弃 RxJava 的方式。 不要在 collect 内进行 blockingGet 操作。 我们换个方式想，对于 collect() 操作来说，其不会马上就将数据往下游发射，而是要等到上游数据发射完毕，发出了 onComplete 通知，才会往下游发送数据，这就好办了。 List&lt;ComChangePersonInfo&gt; personInfos ;List&lt;MaterialInfo&gt; lst) ; Map&lt;String, Integer&gt; map = Observable.fromIterable(lst) .filter(m -&gt; TextUtils.equals(m.getMtype(), AppConstant.ComRegMaterialType.CARD)) .groupBy(m -&gt; m.getAboutPerson()) .collect(HashMap&lt;String,Single&lt;Long&gt;::new, (BiConsumer&lt;Map&lt;String, Single&lt;Long&gt;&gt;, GroupedObservable&lt;String, MaterialInfo&gt;&gt;) (m, observable) -&gt; m.put(observable.getKey(), observable.count())) .flatMap((Function&lt;HashMap&lt;String, Single&lt;Long&gt;&gt;, SingleSource&lt;HashMap&lt;String, Integer&gt;&gt;&gt;) stringSingleHashMap -&gt; &#123; HashMap&lt;String,Integer&gt; map = new HashMap&lt;&gt;(); stringSingleHashMap.forEach((k,v)-&gt;map.put(k,v.blockingGet().intValue())); return Single.just(map); &#125;) .blockingGet();","categories":[{"name":"RxJava","slug":"RxJava","permalink":"https://gowa2017.github.io/categories/RxJava/"}],"tags":[{"name":"RxJava","slug":"RxJava","permalink":"https://gowa2017.github.io/tags/RxJava/"}],"keywords":[{"name":"RxJava","slug":"RxJava","permalink":"https://gowa2017.github.io/categories/RxJava/"}]},{"title":"关于RxJava操作符链式调用的理解","slug":"关于RxJava操作符链式调用的理解","date":"2019-05-25T15:05:16.000Z","updated":"2019-05-25T15:05:16.000Z","comments":true,"path":"RxJava/关于RxJava操作符链式调用的理解.html","link":"","permalink":"https://gowa2017.github.io/RxJava/关于RxJava操作符链式调用的理解.html","excerpt":"源于想要知道，对于链式调用背后的工作原理是什么，上游与下游间的通信是如何进行的。","text":"源于想要知道，对于链式调用背后的工作原理是什么，上游与下游间的通信是如何进行的。 前言经常我们会看到这样的写法： source.operator1().operator2().operator3().subscribe(consumer);source.flatMap(value -&gt; source.operator1().operator2().operator3()); 站在 operator2 的位置，左边称为 UpStream，右边直到 subscriber/consumer 都称作 DownStream。 如果我们把每个操作符单独放在一行的话看起来会更明了： source .operator1() .operator2() .operator3() .subscribe(consumer) Observable的三个状态对于每个 Observable 都会经历三个状态，配置、订阅、运行。 配置(Assembly Time)Flowable&lt;Integer&gt; flow = Flowable.range(1, 5).map(v -&gt; v * v).filter(v -&gt; v % 3 == 0); 这个状态会对 Observable 应用多个操作符，在这个时候，数据还没有开始流动。 订阅（Subscription Time）一个中间状态，表示当 subscribe() 被调用的时候。 运行时(Runtime)这个时候， Observable 就开始发射数据了。 Observable.create(emitter -&gt; &#123; while (!emitter.isDisposed()) &#123; long time = System.currentTimeMillis(); emitter.onNext(time); if (time % 2 != 0) &#123; emitter.onError(new IllegalStateException(\"Odd millisecond!\")); break; &#125; &#125;&#125;).subscribe(System.out::println, Throwable::printStackTrace); 例子我们以一个简单的例子来分析： Observable.fromArray(\"A\",\"B\",\"C\") .map( v-&gt; v + \"1\") .subscribe(System.out::println); 配置阶段也即是对 Observable 应用 map() 操作符的阶段： public final &lt;R&gt; Observable&lt;R&gt; map(Function&lt;? super T, ? extends R&gt; mapper) &#123; ObjectHelper.requireNonNull(mapper, \"mapper is null\"); return RxJavaPlugins.onAssembly(new ObservableMap&lt;T, R&gt;(this, mapper));&#125; 每个操作符，其实都是返回了一个全新的 Observable，同时返回的每个 Observable 都保留了其操作符应用的对象，也就是其 UpStream。 这个例子中，map() 操作符，新建了一个 ObservableMap，同时其对我们最开始的 source 有一个引用。 订阅阶段当我们调用 subscribeOn() 的时候，实际上，是在我们最后一个操作符返回的 Observable 上进行的。 同时我们也知道，对于每个 Observable.subscribeOn() 其实最终执行的都是由实现类的 subscribeActual() 方法。 对于 ObservableMap： @Overridepublic void subscribeActual(Observer&lt;? super U&gt; t) &#123; source.subscribe(new MapObserver&lt;T, U&gt;(t, function));&#125; 其用一个 MapObserver 来订阅了其 UpStream。 对于我们例子中的 ObservableFromArray, 其会建立一个 FromArrayDisposable 对象： @Overridepublic void subscribeActual(Observer&lt;? super T&gt; observer) &#123; FromArrayDisposable&lt;T&gt; d = new FromArrayDisposable&lt;T&gt;(observer, array); observer.onSubscribe(d); if (d.fusionMode) &#123; return; &#125; d.run();&#125; 很惊喜的发现，其会将 MapObserver 称作 DownStream 。 FromArrayDisposable(Observer&lt;? super T&gt; actual, T[] array) &#123; this.downstream = actual; this.array = array;&#125; 运行时当数据开始流动，我们的 FromArrayDisposable 开始发射数据： void run() &#123; T[] a = array; int n = a.length; for (int i = 0; i &lt; n &amp;&amp; !isDisposed(); i++) &#123; T value = a[i]; if (value == null) &#123; downstream.onError(new NullPointerException(\"The \" + i + \"th element is null\")); return; &#125; downstream.onNext(value); &#125; if (!isDisposed()) &#123; downstream.onComplete(); &#125;&#125; 可以看到，数据都是直接丢给了 MapObserver的，接着 MapObserver 又把数据丢给了我们定义的 Consumer： @Overridepublic void onNext(T t) &#123; if (done) &#123; return; &#125; if (sourceMode != NONE) &#123; downstream.onNext(null); return; &#125; U v; try &#123; v = ObjectHelper.requireNonNull(mapper.apply(t), \"The mapper function returned a null value.\"); &#125; catch (Throwable ex) &#123; fail(ex); return; &#125; downstream.onNext(v);&#125; 总结 在配置阶段。按照操作符应用的顺序，形成 Observable 的链式关系。 在订阅阶段。从最后一个 Observable 开始，内部以不同类型的 Observer 来从后往前传递订阅关系。 发射阶段。最开始的 Observable 会通过上下游间的 Observer 来传递数据，直到我们定义的消费者。","categories":[{"name":"RxJava","slug":"RxJava","permalink":"https://gowa2017.github.io/categories/RxJava/"}],"tags":[{"name":"RxJava","slug":"RxJava","permalink":"https://gowa2017.github.io/tags/RxJava/"}],"keywords":[{"name":"RxJava","slug":"RxJava","permalink":"https://gowa2017.github.io/categories/RxJava/"}]},{"title":"关于在Module中添加aar包无效的问题","slug":"关于在Module中添加aar包无效的问题","date":"2019-05-10T14:04:50.000Z","updated":"2019-05-10T14:04:50.000Z","comments":true,"path":"Android/关于在Module中添加aar包无效的问题.html","link":"","permalink":"https://gowa2017.github.io/Android/关于在Module中添加aar包无效的问题.html","excerpt":"情况是因为要接入各种 SDK，大多都是以 aar 包的形式来提供的。所以想着将所有的 aar 包放在一个 module 内，其他 module 依赖这个 aar 包就行了。但显然，事实是残酷的，我想得太简单了呢。","text":"情况是因为要接入各种 SDK，大多都是以 aar 包的形式来提供的。所以想着将所有的 aar 包放在一个 module 内，其他 module 依赖这个 aar 包就行了。但显然，事实是残酷的，我想得太简单了呢。 为了偷懒，在大华 SDK DEMO 中他写了一些简单的逻辑和界面，我也不想自己重新写了，就直接将 DEMO 以 module 的形式进行了集成。下面就开始这个过程。 关于 flatDir当我们要指定本地某个目录内寻找依赖的时候，我们一般会利用 flatDir 来将目录添加到 repositories： repositories &#123; flatDir &#123; dirs 'lib' &#125; flatDir &#123; dirs 'lib1', 'lib2' &#125;&#125; 关于资源类型的说明，可以参考： Repository Types 回顾过程创建 module aars创建一个名为 aars 的模块，将所有的 aar 包都放在 libs 目录下。 aars/build.gradle：配置如下 apply plugin: 'com.android.library'android &#123; compileSdkVersion Integer.parseInt(COMPILE_SDK_VERSION) defaultConfig &#123; minSdkVersion Integer.parseInt(MIN_SDK_VERSION) targetSdkVersion Integer.parseInt(TARGET_SDK_VERSION) versionCode 1 versionName \"1.0\" testInstrumentationRunner \"android.support.test.runner.AndroidJUnitRunner\" &#125; buildTypes &#123; release &#123; minifyEnabled false proguardFiles getDefaultProguardFile('proguard-android-optimize.txt'), 'proguard-rules.pro' &#125; &#125;&#125;dependencies &#123; implementation fileTree(dir: 'libs', include: ['*.jar']) implementation fileTree(dir: 'libs', include: ['*.aar']) implementation \"com.android.support:appcompat-v7:$&#123;SUPPORT_LIB_VERSION&#125;\" testImplementation 'junit:junit:4.12' androidTestImplementation 'com.android.support.test:runner:1.0.2' androidTestImplementation 'com.android.support.test.espresso:espresso-core:3.0.2'&#125; 依赖 aars 的 module新建了一个 dhsdk 模块，依赖于 aars 内的很多内容。很天真的直接就添加了依赖： dhsdk/build.gradle: apply plugin: 'com.android.library'android &#123; compileSdkVersion Integer.parseInt(COMPILE_SDK_VERSION) buildToolsVersion BUILDTOOLS_VERSION defaultConfig &#123; minSdkVersion Integer.parseInt(MIN_SDK_VERSION) targetSdkVersion Integer.parseInt(TARGET_SDK_VERSION) versionCode 6 versionName \"1.6\" &#125; buildTypes &#123; release &#123; minifyEnabled false proguardFiles getDefaultProguardFile('proguard-android.txt'), 'proguard-rules.pro' &#125; &#125;&#125;dependencies &#123; implementation fileTree(include: ['*.jar'], dir: 'libs') implementation \"com.android.support:appcompat-v7:$&#123;SUPPORT_LIB_VERSION&#125;\" implementation \"com.android.support:design:$&#123;SUPPORT_LIB_VERSION&#125;\" implementation \"com.android.support:recyclerview-v7:$&#123;SUPPORT_LIB_VERSION&#125;\" implementation 'com.github.CymChad:BaseRecyclerViewAdapterHelper:2.9.34' implementation project(':pulltofresh') implementation project(':aars')&#125; 结果是什么呢？在 dhsdk 这个模块中，根本就找不到在 aars 中添加的那些依赖的 aar。 依赖失败这是因为：implementation 所实现的依赖，对于其他模块，是不可见的。如果，我们想要将 aars 模块中的依赖的 aar 的内容都对依赖它的模块可见，需要用 api 来进行替换： aars/build.gradle api fileTree(dir: 'libs', include: ['*.aar']) 这样，我们的 dhsdk 就依赖成功了。 同理，如果我们要在 app 中想要依赖到 aars 中的内容，那么也必须让 dhsdk 以 api 的形式来依赖 aars。 implementation 与 api implementation 声明完全内部的依赖，不会暴露到消费者。 api 声明完全导出到消费者的依赖。","categories":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"},{"name":"AAR","slug":"AAR","permalink":"https://gowa2017.github.io/tags/AAR/"}],"keywords":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}]},{"title":"使用Room进行持久化","slug":"使用Room进行持久化","date":"2019-05-08T02:14:56.000Z","updated":"2019-05-08T02:14:56.000Z","comments":true,"path":"Android/使用Room进行持久化.html","link":"","permalink":"https://gowa2017.github.io/Android/使用Room进行持久化.html","excerpt":"Room 是谷歌推荐的架构组件之一，用来进行本地数据的持久化，其在 Sqlite 上提供了一些更方便使用的封装。但是事实上我感觉其使用相对 ObjectBox 好像更麻烦一些。","text":"Room 是谷歌推荐的架构组件之一，用来进行本地数据的持久化，其在 Sqlite 上提供了一些更方便使用的封装。但是事实上我感觉其使用相对 ObjectBox 好像更麻烦一些。 Room 基本组件有三个主要的组成部分： DataBase 包含数据库持有者，作为应用程序的到应用持久化，关系型数据的底层连接的主要访问点。使用 @Database 注解的类需要满足三个条件： 是一个继承自 RoomDatabase 的抽象类 包含一个列表，列表内是所有与此注解类的相关联的实体类。 有一个无参抽象方法，返回一个以 @Dao 注解的类 可以在运行时，通过调用 Room.databaseBuilder() 或者 Room.inMemoryDatabaseBuilder() 来获得一个 Database 的实例。 Entity 代表数据库中的一个表 Dao 包含用来访问数据库的方法。 应用使用 Room 数据库来获取与其相关的数据访问对象（DAOs）。 使用 Dao 来获取实体，同时将修改后的数据保存回实体。 Entity 使用 get/set 获取与修改对应表上的列值。 使用示例Entity@Entitypublic class User &#123; @PrimaryKey public int uid; @ColumnInfo(name = \"first_name\") public String firstName; @ColumnInfo(name = \"last_name\") public String lastName;&#125; Dao@Daopublic interface UserDao &#123; @Query(\"SELECT * FROM user\") List&lt;User&gt; getAll(); @Query(\"SELECT * FROM user WHERE uid IN (:userIds)\") List&lt;User&gt; loadAllByIds(int[] userIds); @Query(\"SELECT * FROM user WHERE first_name LIKE :first AND \" + \"last_name LIKE :last LIMIT 1\") User findByName(String first, String last); @Insert void insertAll(User... users); @Delete void delete(User user);&#125; Database（一般设置为单例）@Database(entities = &#123;User.class&#125;, version = 1)public abstract class AppDatabase extends RoomDatabase &#123; public abstract UserDao userDao();&#125; 获取 Database 实例AppDatabase db = Room.databaseBuilder(getApplicationContext(), AppDatabase.class, \"database-name\").build();","categories":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"},{"name":"Room","slug":"Room","permalink":"https://gowa2017.github.io/tags/Room/"}],"keywords":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}]},{"title":"Android中的一些菜单","slug":"Android中的一些菜单","date":"2019-05-06T13:32:26.000Z","updated":"2019-05-06T13:32:26.000Z","comments":true,"path":"Android/Android中的一些菜单.html","link":"","permalink":"https://gowa2017.github.io/Android/Android中的一些菜单.html","excerpt":"","text":"今天是遇到一个猥琐的需求，想要像现在的苹果一样，在 app 内截图，于是就用了一个 ImageView 来浮动，点击用 PopupWindow 来显示全部的内容。但是呢，还是不很清楚里面的原理，所以来回顾一下用过但没有深酒过的一些菜单用法。 SpinnerSpinner 继承自 AdapterView。 Spinner -&gt; AbsSpinner -&gt; AdapterView -&gt; ViewGroup 所以其使用是需要一个 Adapter 的，因为对于 AdapterView ，其子视图依赖于一个 Adapter，其从 Adapter 内已加载的项目来显示。 为 Spinner 填充数据基本的步骤就是构造一个 adapter，这个 adapter 可以有多种。常见的有三种： @see android.widget.ArrayAdapter @see android.widget.CursorAdapter @see android.widget.SimpleCursorAdapter // Get a Spinner and bind it to an ArrayAdapter that// references a String array.Spinner s1 = (Spinner) findViewById(R.id.spinner1);ArrayAdapter adapter = ArrayAdapter.createFromResource( this, R.array.colors, android.R.layout.simple_spinner_item);adapter.setDropDownViewResource(android.R.layout.simple_spinner_dropdown_item);s1.setAdapter(adapter);// Load a Spinner and bind it to a data query.private static String[] PROJECTION = new String[] &#123; People._ID, People.NAME &#125;;Spinner s2 = (Spinner) findViewById(R.id.spinner2);Cursor cur = managedQuery(People.CONTENT_URI, PROJECTION, null, null);SimpleCursorAdapter adapter2 = new SimpleCursorAdapter(this, android.R.layout.simple_spinner_item, // Use a template // that displays a // text view cur, // Give the cursor to the list adapter new String[] &#123;People.NAME&#125;, // Map the NAME column in the // people database to... new int[] &#123;android.R.id.text1&#125;); // The \"text1\" view defined in // the XML templateadapter2.setDropDownViewResource(android.R.layout.simple_spinner_dropdown_item);s2.setAdapter(adapter2); 响应用户的选择事件可以通过 AdapterView.onItemClickListener 来捕捉用户的选择动作： // Create a message handling object as an anonymous class.private OnItemClickListener messageClickedHandler = new OnItemClickListener() &#123; public void onItemClick(AdapterView parent, View v, int position, long id) &#123; // Display a messagebox. Toast.makeText(context,\"You've got an event\",Toast.LENGTH_SHORT).show(); &#125;&#125;;// Now hook into our object and set its onItemClickListener member// to our class handler object.historyView = (ListView)findViewById(R.id.history);historyView.setOnItemClickListener(messageClickedHandler); 这是一个比较简单的做法，但是有的时候可能我们显示的数据都不是这么简单的，比如我需要对一些来源于网络的字典进行适配的话，我就必须要自己定义一个 Adapter 了。 自定义一个 Adapter对于 Spinner.setAdapter(SpinnerAdapter adapter) 来说，其需要一个 SpinnerAdapter 接口的实现作为参数。恰好，BaseAdapter 就实现了它。 public abstract class BaseAdapter implements ListAdapter, SpinnerAdapter &#123;&#125; 所以我们来设计一个抽象的 Adapter，其接受一个类型参数指定了我们要适配的元素序列的类型： public abstract class MyCommonSpinnerAdapter&lt;T&gt; extends BaseAdapter &#123; private static final String TAG = \"MyCommonSpinnerAdapter\"; private List&lt;T&gt; data; private Context mContext; public MyCommonSpinnerAdapter(List&lt;T&gt; data, Context context) &#123; this.data = data; mContext = context; &#125; @Override public int getCount() &#123; return data == null ? 0 : data.size(); &#125; @Override public Object getItem(int position) &#123; return data == null ? null : data.get(position); &#125; @Override public long getItemId(int position) &#123; return position; &#125; @Override public View getView(int position, View convertView, ViewGroup parent) &#123; Log.d(TAG, \"getView: \"); ViewHolder h = null; if (convertView == null) &#123; h = new ViewHolder(); convertView = LayoutInflater.from(mContext).inflate(R.layout.item_simple_spinner_list, null); h.mTextView = convertView.findViewById(R.id.item); convertView.setTag(h); &#125; else &#123; h = (ViewHolder) convertView.getTag(); &#125; h.mTextView.setText(getText(data.get(position))); return convertView; &#125; public abstract String getText(T data); public static class ViewHolder &#123; TextView mTextView; &#125;&#125; 一般来说，我们的重点都在 getView() 方法上。很多时候，可能都会有人问， convertView 是什么，从哪里来？ 事实上这个不看一下源代码果然是不会知道的。 对于 Spinner 的父类 AbsSpinner 而言，其在构建的时候，就会初始化一个可回收的视图数组: final RecycleBin mRecycler = new RecycleBin();class RecycleBin &#123; private final SparseArray&lt;View&gt; mScrapHeap = new SparseArray&lt;View&gt;(); public void put(int position, View v) &#123; mScrapHeap.put(position, v); &#125; View get(int position) &#123; // System.out.print(\"Looking for \" + position); View result = mScrapHeap.get(position); if (result != null) &#123; // System.out.println(\" HIT\"); mScrapHeap.delete(position); &#125; else &#123; // System.out.println(\" MISS\"); &#125; return result; &#125; void clear() &#123; final SparseArray&lt;View&gt; scrapHeap = mScrapHeap; final int count = scrapHeap.size(); for (int i = 0; i &lt; count; i++) &#123; final View view = scrapHeap.valueAt(i); if (view != null) &#123; removeDetachedView(view, true); &#125; &#125; scrapHeap.clear(); &#125;&#125; SparseArray 默认会是 10 个元素。public SparseArray() &#123; this(10);&#125; 在 AbsSpinner 的 onMeasure() 方法中，会根据当前选择的位置来显示视图： int selectedPosition = getSelectedItemPosition();if (selectedPosition &gt;= 0 &amp;&amp; mAdapter != null &amp;&amp; selectedPosition &lt; mAdapter.getCount()) &#123; // Try looking in the recycler. (Maybe we were measured once already) View view = mRecycler.get(selectedPosition); if (view == null) &#123; // Make a new one view = mAdapter.getView(selectedPosition, null, this); if (view.getImportantForAccessibility() == IMPORTANT_FOR_ACCESSIBILITY_AUTO) &#123; view.setImportantForAccessibility(IMPORTANT_FOR_ACCESSIBILITY_YES); &#125; &#125; if (view != null) &#123; // Put in recycler for re-measuring and/or layout mRecycler.put(selectedPosition, view); if (view.getLayoutParams() == null) &#123; mBlockLayoutRequests = true; view.setLayoutParams(generateDefaultLayoutParams()); mBlockLayoutRequests = false; &#125; measureChild(view, widthMeasureSpec, heightMeasureSpec); preferredHeight = getChildHeight(view) + mSpinnerPadding.top + mSpinnerPadding.bottom; preferredWidth = getChildWidth(view) + mSpinnerPadding.left + mSpinnerPadding.right; needsMeasuring = false; &#125;&#125; 调用 adapter 获取 View 后，会将返回的 childView 放在 Recycler 内。 也就是说，当 adapter 通过 xml 文件扩张了一个视图后，会将视图的结构放在扩张后的 convertView 的 tag 内，这样下次进行使用的时候，将不需要再次进行 findViewById 等操作。可以直接通过 ViewHolder 来进行对应的 convertView 内部的操作。 实现的模式有点像 RecyclerView 呢。 PopupMenuPopupMenu 会以一个给定 View 作为锚点，显示一个弹出菜单。 除了每个 View 都会需要一个 Context 外， PopupMenu 需要知道其锚点 View，还有一个菜单，这样其就可以显示出来了。 public PopupMenu(Context context, View anchor, int gravity, int popupStyleAttr, int popupStyleRes) &#123; &#125; 通过 PopupMenu 的成员可以看出其很简单： private final Context mContext;private final MenuBuilder mMenu;private final View mAnchor;private final MenuPopupHelper mPopup; 我们可以从其 show() 方法来看背后的过程： public void show() &#123; mPopup.show();&#125; public void show() &#123; if (!this.tryShow()) &#123; throw new IllegalStateException(\"MenuPopupHelper cannot be used without an anchor\"); &#125;&#125;public boolean tryShow() &#123; if (this.isShowing()) &#123; return true; &#125; else if (this.mAnchorView == null) &#123; return false; &#125; else &#123; this.showPopup(0, 0, false, false); return true; &#125;&#125;private void showPopup(int xOffset, int yOffset, boolean useOffsets, boolean showTitle) &#123; MenuPopup popup = this.getPopup(); popup.setShowTitle(showTitle); if (useOffsets) &#123; int hgrav = GravityCompat.getAbsoluteGravity(this.mDropDownGravity, ViewCompat.getLayoutDirection(this.mAnchorView)) &amp; 7; if (hgrav == 5) &#123; xOffset += this.mAnchorView.getWidth(); &#125; popup.setHorizontalOffset(xOffset); popup.setVerticalOffset(yOffset); float density = this.mContext.getResources().getDisplayMetrics().density; int halfSize = (int)(48.0F * density / 2.0F); Rect epicenter = new Rect(xOffset - halfSize, yOffset - halfSize, xOffset + halfSize, yOffset + halfSize); popup.setEpicenterBounds(epicenter); &#125; popup.show();&#125; 事实上，其本质都是利用 ListPopupWindow，然后在其上显示内容的。 PopupWindowPopupWindow 可以用来显示任何 View。其是一个浮动的容器，位于当前 Activity 的最上方。其有两种方式来进行显示： View 的下拉 固定位置显示 我们也固定位置显示来看一下： public void showAtLocation(View parent, int gravity, int x, int y) &#123; mParentRootView = new WeakReference&lt;&gt;(parent.getRootView()); showAtLocation(parent.getWindowToken(), gravity, x, y);&#125;public void showAtLocation(IBinder token, int gravity, int x, int y) &#123; if (isShowing() || mContentView == null) &#123; return; &#125; TransitionManager.endTransitions(mDecorView); detachFromAnchor(); mIsShowing = true; mIsDropdown = false; mGravity = gravity; final WindowManager.LayoutParams p = createPopupLayoutParams(token); preparePopup(p); p.x = x; p.y = y; invokePopup(p);&#125; 想要 PopupWindow 正式显示，其必须要有一个 ContentView ，也就是需要一个内容视图。 我们知道，所有的内容需要显示，都必须间接或者直接的继承自 View。所以说，我们光有这对象是无法在屏幕上显示的。在 preparePopup() 方法中，就做了建立 View 的事情： private void preparePopup(WindowManager.LayoutParams p) &#123; if (mContentView == null || mContext == null || mWindowManager == null) &#123; throw new IllegalStateException(\"You must specify a valid content view by \" + \"calling setContentView() before attempting to show the popup.\"); &#125; // The old decor view may be transitioning out. Make sure it finishes // and cleans up before we try to create another one. if (mDecorView != null) &#123; mDecorView.cancelTransitions(); &#125; // When a background is available, we embed the content view within // another view that owns the background drawable. if (mBackground != null) &#123; mBackgroundView = createBackgroundView(mContentView); mBackgroundView.setBackground(mBackground); &#125; else &#123; mBackgroundView = mContentView; &#125; mDecorView = createDecorView(mBackgroundView); // The background owner should be elevated so that it casts a shadow. mBackgroundView.setElevation(mElevation); // We may wrap that in another view, so we'll need to manually specify // the surface insets. p.setSurfaceInsets(mBackgroundView, true /*manual*/, true /*preservePrevious*/); mPopupViewInitialLayoutDirectionInherited = (mContentView.getRawLayoutDirection() == View.LAYOUT_DIRECTION_INHERIT);&#125; 如果我们为 PopupWindow 指定了背景，那么会建立一个 View 来包含着 ContentView，然后这个新建立的 View 就将背景设置为我们指定；但如果我们没有指定背景的话，那就直接将 contentView 作为背景 View 了。 接着，根据背景 View 来建立一个 decorView，实际上就是一个 FrameLayout。 在 invokePopup() 方法中，会了解这个 FrameLayout，添加到 PhoneWindow ，我们 Activity 最底层的容器上。所以说，这个 FrameLayout 是与我们默认情况下的 Activity 的decorView 是平级的哦。","categories":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"},{"name":"Spinner","slug":"Spinner","permalink":"https://gowa2017.github.io/tags/Spinner/"},{"name":"PopupMenu","slug":"PopupMenu","permalink":"https://gowa2017.github.io/tags/PopupMenu/"},{"name":"PopupWindow","slug":"PopupWindow","permalink":"https://gowa2017.github.io/tags/PopupWindow/"},{"name":"Dialog","slug":"Dialog","permalink":"https://gowa2017.github.io/tags/Dialog/"}],"keywords":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}]},{"title":"Android中进行混淆的时候保留某些类的问题","slug":"Android中进行混淆的时候保留某些类的问题","date":"2019-05-03T14:44:51.000Z","updated":"2019-05-03T14:44:51.000Z","comments":true,"path":"Android/Android中进行混淆的时候保留某些类的问题.html","link":"","permalink":"https://gowa2017.github.io/Android/Android中进行混淆的时候保留某些类的问题.html","excerpt":"之前与遇到过，对于某些类其实可以不用进行混淆的。比如对于 Gson 进行序列与反序列化的类，如果在默认的情况下进行了混淆的话，那么其将不能正确的进行解析出想要的结果，或序列化成我们想要的格式。（除非指定了 SerialableName 注解，但如果是嵌套了多种类型的话就比较麻烦了），所以之前遇到的时候是在 proguard-pro 中进行了一个 keep 的设置。","text":"之前与遇到过，对于某些类其实可以不用进行混淆的。比如对于 Gson 进行序列与反序列化的类，如果在默认的情况下进行了混淆的话，那么其将不能正确的进行解析出想要的结果，或序列化成我们想要的格式。（除非指定了 SerialableName 注解，但如果是嵌套了多种类型的话就比较麻烦了），所以之前遇到的时候是在 proguard-pro 中进行了一个 keep 的设置。 混淆会生成的文件位于 /build/outputs/mapping/release/ 下： dump.txt APK文件中所有类文件的内部结构 mapping.txt 原始与混淆过的类、方法、字段间的转换。 seeds.txt 未混淆的类与成员 usage.txt 从APK移除的代码 自定义保留事实了，谷歌提供了两种方法来解决保留某些类不进行混淆的问题： 使用注解支持库的情况下，可以在我们想要保留的类、方法、字段上添加 @Keep 注解。 在 ProGuard 配置文件内添加一行 -keep 说明。 第一种方法很简单，我们来看一下第二种。 ProGuardProGuard 是一个 Java 类文件压缩器、优化器、混淆和预校验器。 压缩阶段：检查和移除没有使用的类、方法、字段、属性。 优化阶段：分析和优化方法的字节码。 混淆阶段：以短的，无意义的名称来重命名剩下的类，字段，方法。这会让代码更小，更高效，更难被逆向。 预校验：会给类添加校验信息。 这几个步骤都是可选的。实际上，ProGuard 也可以用来仅仅列出应用中的无用代码，或者进行预校验。 Entry Points为了决定哪些代码需要保留，哪些代码需要丢弃或混淆，我们必须指定一个或多个切入点。切入点 通常是比较典型的，拥有 main 方法，小程序等。 使用ProGuard 的使用非常的详细，在这里有它的一个比较完善的说明文档。 keep -keep [,modifier, …] class_specification 指定需要保留的类或类成员作为切入点。 -keepclassmembers [,modifier,…] class_specification 如果类是保留的，那么制定其需要保留的类成员。 -keepclasseswithmembers [,modifier,…] class_specification 当所有指定需要的类成员条件都存在的时候，保留这个类及其成员。 -keepnames class_specification，-keep,allowshrinking class_specification 如果没有被移除的话，指定需要保留其名字的类或类成员。 -keepclassmembernames class_specification， -keepclassmembers,allowshrinking class_specification 如果没有被移除的话，指定需要保留的类成员。 -keepclasseswithmembernames class_specification，-keepclasseswithmembers,allowshrinking class_specification 在压缩阶段后，如果所有指定的类成员都存在的话，保留指定的类和类成员。class_specification 类指定器，这是比较复杂的一个东西了。 一个 class_specification 是类和类成员的模板。其基本的语法如下： [@annotationtype] [[!]public|final|abstract|@ ...] [!]interface|class|enum classname [extends|implements [@annotationtype] classname][&#123; [@annotationtype] [[!]public|private|protected|static|volatile|transient ...] &lt;fields&gt; | (fieldtype fieldname); [@annotationtype] [[!]public|private|protected|static|synchronized|native|abstract|strictfp ...] &lt;methods&gt; | &lt;init&gt;(argumenttype,...) | classname(argumenttype,...) | (returntype methodname(argumenttype,...)); [@annotationtype] [[!]public|private|protected|static ... ] *; ...&#125;] 其中： [] 表示其内容是可选的。 ... 表示可存在多个 | 表示可选值 () 进行分组 ! 表示表示非的意思。 规则： 每个类名都必须是全引用的，类名可以包含正则表达式： ? 单个字符，但不包括包分隔符。 任意字符，但不包括包分隔符。 mypackage.*Test* 会匹配mypackage.YourTestApplication,但不会匹配 mypackage.mysubpackage.MyTest。mypackage.* 会匹配所有包内的类，但不包括子包内的类。 任何内容，包括子包，包括包分隔符。`.Text` 会匹配所有包的 所有 Test 类（除了根包）， 字典和方法都不包含参数名字。也可能有以下的几种符号： 构造器 任意字段 任意方法 任何字段或方法 上面的通配符都不包括返回类型，只有 &lt;init&gt; 有一个参数列表 字段和方法名都可能包含正则表达式。? 表示方法中的单个字符，* 表示方法中的任何部分的字符。 所以想要保留一个类-keep cn.google.com.**&#123;*;&#125; 会将 cn.google.com 下所有的类，所有子包中的类的所有字段和方法都保留。","categories":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"}],"keywords":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}]},{"title":"关于Python做数据库同步的一些库及使用","slug":"关于Python做数据库同步的一些库及使用","date":"2019-04-28T13:23:29.000Z","updated":"2019-04-28T13:23:29.000Z","comments":true,"path":"Python/关于Python做数据库同步的一些库及使用.html","link":"","permalink":"https://gowa2017.github.io/Python/关于Python做数据库同步的一些库及使用.html","excerpt":"之前有用过 Python 来做 Oracle 与 MySQL， MySQL 与 MySQL 之间的同步。但是一直没有仔细探究这几个库的用法。现在就好好来看看。","text":"之前有用过 Python 来做 Oracle 与 MySQL， MySQL 与 MySQL 之间的同步。但是一直没有仔细探究这几个库的用法。现在就好好来看看。 MySQLdb这玩意不 Python 3.0 并不支持。因为我需要用到 Python 3.0 所以就放弃他了吧。 Mysqlclient完全兼容MySQLdb的衍生版；同时兼容Python3.x 是Django ORM的依赖工具。 原生SQL操作数据库。 PyMySQLGithub 上的 PyMySQL 是一个纯 Python 实现的 MySQL 客户端，基于 PEP249。很多 API 都与 MySQLdb 相似。但不支持 __mysql 提供的那些低级底层 API 如 data_seek, store_result, user_result 等。 文档地址在这里 要求是在 MySQL 5.5 以上 或 MariaDB 5.5 以上使用。 但是貌似我用在 MySQL 5.1.73 上也没有问题？ 习惯了 MySQLdb 的可以这样来获取与其一样的使用方法： pymysql.install_as_MySQLdb() SQLAlchemySQLAlchemy 是一个 ORM （对象关系映射），其提供了非常强大的性能及方便性。 既支持原生 SQL，又支持 ORM 的工具； 原理SQL 数据库在行为上与对象集合不同，其更关注数据的容量和性能：对象集合与行或列数据也不一样，其更关注抽象出来的东西。SQLAlchemy 是为了在这其中取得平衡。 SQLAlchemy 认为 数据库应该是一个相关的代数引擎，而不仅仅是表的集合。可以从表，join 以及其他的选择语句来获取；所有这些来源都可以看做是一个巨大的数据结构。SQLAlchemy的表达式语言建立在这个概念的核心之上。 SQLAlchemy以其对象关系映射器（ORM）而闻名，ORM是一个提供数据映射器模式的可选组件，其中类可以以开放式，多种方式映射到数据库，允许对象模型和数据库模式从一开始就以完全分离的方式开发。 PandasPandas 是一个数据分析库，当然其提供了很多操作数据的方法。对于帧（二维数据），其提供很多类似与 SQL 的的方法，如 join, update 等。 对于二维数据 DataFrame，其有几类方法或值。 统计（针对轴，如 size, shape, ndim, 转换（astype, copy, isna(), notna(), bool()） 索引及遍历（at, iat, loc, iloc, items(), keys()） 二元操作 函数应用（apply, applymap, agg, aggregate, transform, groupby, rolling） 计算及描述（count, diff）等 重建索引，选择，标签操作（add_prefix, add_suffix, align, reindex） 变形，排序，转置 结合，联接，合并（append(), assign(), join(), merge(), update()） 序列号及IO（一批 to/from 方法） IO顶级方法。定义在 pandas 命名空间内 read_table() read_csv() read_sql() 可以读取查询也可以读取一个表。根据输入定位到下面的两个方法中。依赖于一个 SQLAlchemy 实例。 read_sql_table() 读取一个表 read_sql_query() 读取一个查询 DataFrame.to_sql() 将数据帧写到数据库中。依赖于一个 SQLAlchemy 实例。 read_json() …. 使用使用 SQLAlchemy 来连接，Pandas 来处理，然后 DataFrame 来写入。","categories":[{"name":"Python","slug":"Python","permalink":"https://gowa2017.github.io/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://gowa2017.github.io/tags/Python/"}],"keywords":[{"name":"Python","slug":"Python","permalink":"https://gowa2017.github.io/categories/Python/"}]},{"title":"IdeaVim的的一些使用","slug":"IdeaVim的的一些使用","date":"2019-04-22T13:14:22.000Z","updated":"2019-04-22T13:14:22.000Z","comments":true,"path":"Java/IdeaVim的的一些使用.html","link":"","permalink":"https://gowa2017.github.io/Java/IdeaVim的的一些使用.html","excerpt":"虽然使用了 IdeaVim 来在 Android Studio 来进行代码的编辑其实很多地方还是用得不是非常的顺溜。很多 VIM 相关的知识也忘记得差不多了。比如很多 Idea 本身提供的方法快捷键实在是无法满足我的需求，所以很有必要了解一下更多详细的内容。这是一个翻译文档，但是会很有用的。原文地址","text":"虽然使用了 IdeaVim 来在 Android Studio 来进行代码的编辑其实很多地方还是用得不是非常的顺溜。很多 VIM 相关的知识也忘记得差不多了。比如很多 Idea 本身提供的方法快捷键实在是无法满足我的需求，所以很有必要了解一下更多详细的内容。这是一个翻译文档，但是会很有用的。原文地址 移动和操作符移动命令可以在操作符命令后使用，这样就可以在移动过的文本上进行操作。进行操作的文本就是在移动前的位置，和移动后位置之间的文本。操作符通常用来进行改变或者删除文本。下面是一些可用的操作符： c change d delete y yank to register(不会改变文本) ~ 大小写切换(需要启用 tildeop) g~ 大小写切换 gu 转换为小写，后面可以跟移动命令。可以试试 guw guk gU 转换为大写。 ! 外部命令 右移 &lt; 左移 如果移动和操作前都有一个计数，那么这两个计数会相乘。例如 2d3w 会删除 6 个单词。 在操作应用后，光标通常位于进行操作的文本左面。如 yfe 不会移动光标，但 yFe 会移动光标。 操作会影响整行，或者在移动前后位置间的文本。通常，在行间移动会影响行（面向行），而在行内的移动则会影响字符（面向字符）。然而，这也有一些例外。 对于面向字符的移动可能是包含性的或排他性的。如果是包含性的，那么移动开始和结束位置都会包含在操作中。而如果是排他性的，最后一个字符到行结束都不会包含在操作中。面向行的移动总是包含起始和结束位置。 Which motions are linewise, inclusive or exclusive is mentioned below. Thereare however, two general exceptions: If the motion is exclusive and the end of the motion is in column 1, theend of the motion is moved to the end of the previous line and the motionbecomes inclusive. Example: “}” moves to the first line after a paragraph,but “d}” will not include that line. If the motion is exclusive, the end of the motion is in column 1 and thestart of the motion was at or before the first non-blank in the line, themotion becomes linewise. Example: If a paragraph begins with some blanksand you do “d}” while standing on the first non-blank, all the lines ofthe paragraph are deleted, including the blanks. If you do a put now, thedeleted lines will be inserted below the cursor position. Instead of first giving the operator and then a motion you can use Visualmode: mark the start of the text with “v”, move the cursor to the end of thetext that is to be affected and then hit the operator. The text between thestart and the cursor position is highlighted, so you can see what text willbe operated upon. This allows much more freedom, but requires more keystrokes and has limited redo functionality. See the chapter on Visual mode 左右移动 h &lt;Left&gt; CTRL-H &lt;BS&gt;左移一个字符 l &lt;Right&gt; &lt;Space&gt; 右移一个字符 0 行的第一个字符 &lt;Home&gt; ^行内第一个非空白字符 $ &lt;End&gt; 行尾。但在命令前加上计数的时候，会向下前进 count - 1 行。 g_行内最后一个非空白字符。加上 count 计数时会向下前进 count -1 行。 g0 g&lt;Home&gt; 当开开启 wrap 设置时。会走到屏幕上显示的当前行的第一个字符。当行的长度大于屏幕宽度的时候，这和 0 的效果不同。 g^wrap 为 on 时，移动到屏幕上第一个非空白字符。 gm 和 g0 类似。走动屏幕中央（当字符不够到屏幕中间是，尽可能多的移动） g$ g&lt;End&gt; 移动到屏幕右边 |前进到某一列 5l f{char} 前进到 char 字符出现的地方。如果前面加上 count，则会前进到第 count 次出现的地方。如 2fi F{char} 同上，不过是由右至左移动。 t{char} 和 f 命令类似，不过不包括查找的那个字符。 T{char} 和 F 命令类似，不过不包括查找的那个字符。 ; 重复上一个 f, F, T, t 命令 count 次。 , 同 ;，不过是从右至左移动。 上面这些命令会移动光标动行内特定的列。 上下移动 k &lt;Up&gt; &lt;CTRL-P&gt; 向上一行 j &lt;Down&gt; &lt;CTRL-J&gt; &lt;NL&gt; &lt;CTRL-N&gt; 向下一行 gk g&lt;Up&gt; 在屏幕上显示的行上进行移动。在 wrap on 的时候与 k 的效果不同。 gj g&lt;Down&gt; 同上 ，不过往下移动。 - 移动到往上 count 行的第一个非空白字符 - CTRL-M &lt;CR&gt; 向下移动 count 行到第一个非空白字符 _ &lt;underscore&gt; 向下移动 count - 1 行到第一个非空白字符 G 前面加上 count，移动到指定行的第一个非空白字符。如果不加 count，移动到最后一行。 &lt;C-End&gt; 前进到第 count 行，最后一个字符。默认会到最后一行。 &lt;C-Home&gt; gg 前进到第 count 行。如果没有 count，会走到第一行的第一个非空白字符。 :[range] 指定行号。多个行号的话使用最后一个。 {count}% 移动到文件的百分比处的行的第一个非空白字符 :[range]go[to] [count] [count]go。前进到缓冲区内的 count 字节处。 count 默认是 1，表示文件的开始。[range] 表示从指定的 byte 处开始。 单词移动 &lt;S-Right&gt; w 按单词前进到下一个单词首。 &lt;C-Right&gt; W 按单词前进。就我尝试而言，W 只会把空白当作单词分隔附，而 w 会将各种符号都当作分隔符。 e E 到单词尾部。E 同 W的意义。 &lt;S-Left&gt; b 按词回退到词首。 &lt;C-Left&gt; B 按词回退到词首。 ge gE 左移到词尾 [w VIM 中没有这个命令。驼峰式右移一个词 [b VIM 中没有这个命令。驼峰式左移一个词 ]w VIM 中没有这个命令。驼峰式右移到词尾。 ]b VIM 中没有这个命令。驼峰式左移到词尾。文本对象移动 有三种类型的文本对象。 句子。句子的定义是：从当前位置到以 ., !, ?结束，同时后面跟着空格或Tab，或者是行尾。在 ., !, ? 和后面的空白或行结束间可能有多个封闭的 ), ], }, &quot;, &#39;。一个段和节的界限也是句子的界限。在 cpoptions 中如果出现了 J 标志，那么在上述的三个标点符号后至少要跟两个空白；多个 Tabs 不会被识别为空白。句子的定义不能被更改。 段落。一个段落在每个空行后开始，或者在 paragraphs选项中的字符对标记的段落宏后开始。默认的是 IPLPPPQPP LIpplpipbp，对应了宏 .IP，.LP 等。（这是些 nroff 的宏，所以 . 必须在第一列）。一个节的界限也是段落的界限。 注意：段落并不包含第一列是 {, } 的情况。 注意：只包含空白符的行也不是一个段落的界限 节。节从第一列是 &lt;C-L&gt; 处开始，或者从定义节的宏处开始，这些宏在 sections 选项定义。默认的是 SHNHH HUnhsh，定义了节从 nroff 宏 .SH, .NH, .H, .HU, .nh, .sh。处开始。 ], ] 命令在第一列是 {, } 处结束。在 C 程序中用来找到函数的开始和结束非常的有用。注意：这命令的第一个字符决定了搜索的风向，第二个字符决定了寻找的括号类型。 ( 按句回退。 ) 按句前进 g( 按句回退到句末。 g) 按句前进到句末。 { 按段落回退 } 按段落前进 ]] 按节前进到第一列是 { 的位置。如果是在一个操作符后使用，那么就会走到 } 在第一列的地方。 ][ 到下一个首列是 } 的位置。 [[ 到前一个首列是 { 的位置。 [] 到前一个首列是 } 的位置 文本对象选择这些命令只能是在 Visual 模式或者在操作符后使用。以 a 开头的命令会选择一个对象（包括空白），i 开始的命令不包含空白（或者仅仅只是空白）。i 开头的命令选择的文本总是比 a 少。 a&quot; 双引号字符串 a&#39; 单引号字符串 `a`` 反引号内的字符 aw 一个单词。 iw 单词间的空白会也被看作单词。 aW iW as is ap ip a] a[ 一个 [] 块。 i] i[ a) a( ab 一个语句块。哈哈就是 () 中的内容了，比如函数参数可以一下子删除。 i) i( ib a&gt; a&lt; 一个 &lt;&gt; 块。xml 文件内用。 i&gt; i&lt; a} a{ aB 一个 {} 块。删除函数体也很有用 i} i{ iB 标记跳转更多动作 ]m 下一个方法的开始。 ]M 下一个方法的结束。 [m 上一个方法的开始。 [M 上一个方法的结束。 H Head 屏幕顶部 M Middle 屏幕中部 L 屏幕底部","categories":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/tags/Java/"},{"name":"VIM","slug":"VIM","permalink":"https://gowa2017.github.io/tags/VIM/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}]},{"title":"Gson常规使用-fromJson()","slug":"Gson常规使用-fromJson()","date":"2019-04-21T13:26:33.000Z","updated":"2019-04-21T13:26:33.000Z","comments":true,"path":"Android/Gson常规使用-fromJson().html","link":"","permalink":"https://gowa2017.github.io/Android/Gson常规使用-fromJson().html","excerpt":"Gson 是一个非常棒的用来解析 Json 对象到 Java 对象的库，或者将 Java 对象转换成为 Json 的库。不过有些细节还值得探讨一下。","text":"Gson 是一个非常棒的用来解析 Json 对象到 Java 对象的库，或者将 Java 对象转换成为 Json 的库。不过有些细节还值得探讨一下。 TypeTokenTypeToken 代表了一个泛型。对于 Java 而言，因为泛型擦除的原因，在运行时是无法知道泛型信息的，但是 TypeToken 可以。 例如我们可以这样来获取 List&lt;String&gt; 的泛型信息： TypeToken&lt;List&lt;String&gt;&gt; list = new TypeToken&lt;List&lt;String&gt;&gt;()&#123;&#125;; 在这里要注意的是，因为 TypeToken 构造函数是 protected 的，所以只能用匿名内部类的形式进行构造。 但对于类似 Class &lt;?&gt; 这样有通配符的泛型类是不行的。 TypeToken()protected TypeToken() &#123; this.type = getSuperclassTypeParameter(getClass()); this.rawType = (Class&lt;? super T&gt;) $Gson$Types.getRawType(type); this.hashCode = type.hashCode();&#125; 在这里我们可以看到， RawType 表示的是接受了泛型参数而形成的泛型类。 Type 则是衍生后的那个类。例如，对于 List。 Type = List RawType = List fromJson通常，我们的做法是将 JSON 字符串转换为 Java 对象，其需要一个 Type 作为参数的。 根据 Class 来进行转换实际上，也是强制将 Class 转换为一个 Type 后调用。public &lt;T&gt; T fromJson(String json, Class&lt;T&gt; classOfT) throws JsonSyntaxException &#123; Object object = fromJson(json, (Type) classOfT); return Primitives.wrap(classOfT).cast(object);&#125; 根据 Type 转换构造一个 StringReader 来进行转换。 对于 StringReader 可以调用 read() 读取一个字符；或者调用 read(char cbuf[], int off, int len) 来从 off 便宜处读取 len 个字符到 cbuff 中。 public &lt;T&gt; T fromJson(String json, Type typeOfT) throws JsonSyntaxException &#123; if (json == null) &#123; return null; &#125; StringReader reader = new StringReader(json); T target = (T) fromJson(reader, typeOfT); return target;&#125; 构造 JsonReader更进一步，以 StringReader 为基础，构造一个 JsonReader。 JsonReader 会从 StrinReader 中读取 Json 元素。public &lt;T&gt; T fromJson(Reader json, Type typeOfT) throws JsonIOException, JsonSyntaxException &#123; JsonReader jsonReader = newJsonReader(json); T object = (T) fromJson(jsonReader, typeOfT); assertFullConsumption(object, jsonReader); return object;&#125; 最终转换public &lt;T&gt; T fromJson(JsonReader reader, Type typeOfT) throws JsonIOException, JsonSyntaxException &#123; boolean isEmpty = true; boolean oldLenient = reader.isLenient(); reader.setLenient(true); try &#123; reader.peek(); isEmpty = false; TypeToken&lt;T&gt; typeToken = (TypeToken&lt;T&gt;) TypeToken.get(typeOfT); TypeAdapter&lt;T&gt; typeAdapter = getAdapter(typeToken); T object = typeAdapter.read(reader); return object; &#125; catch (EOFException e) &#123; /* * For compatibility with JSON 1.5 and earlier, we return null for empty * documents instead of throwing. */ if (isEmpty) &#123; return null; &#125; throw new JsonSyntaxException(e); &#125; catch (IllegalStateException e) &#123; throw new JsonSyntaxException(e); &#125; catch (IOException e) &#123; // TODO(inder): Figure out whether it is indeed right to rethrow this as JsonSyntaxException throw new JsonSyntaxException(e); &#125; finally &#123; reader.setLenient(oldLenient); &#125;&#125; Map 的解析在我们安卓进行解析的时候，有一个比较蛋疼的事情就是，我们的解析器无法解析属于 Map 类型的返回值。 因此我准备用 Gson 来解决这个问题，用 Gson 就很简单了。 new Gson().fromJson(strBody, new TypeToken&lt;Map&lt;String,List&lt;SrvRes&gt;&gt;&gt;()&#123;&#125;.getType()); 这样也就 OK 了。","categories":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"},{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/tags/Java/"},{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"},{"name":"JSON","slug":"JSON","permalink":"https://gowa2017.github.io/tags/JSON/"},{"name":"Gson","slug":"Gson","permalink":"https://gowa2017.github.io/tags/Gson/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"},{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}]},{"title":"RecyclerView的converView与viewHolder","slug":"RecyclerView的converView与viewHolder","date":"2019-04-21T04:54:17.000Z","updated":"2019-04-21T04:54:17.000Z","comments":true,"path":"Android/RecyclerView的converView与viewHolder.html","link":"","permalink":"https://gowa2017.github.io/Android/RecyclerView的converView与viewHolder.html","excerpt":"当前 ListView 很多时候都已经被 RecyclerView 替代了。相对而言，RecyclerView 更加的灵活和高级。 在 RecyclerView 中，几种不同的组件相互工作来显示数据。RecyclerView 通过我们提供的 LayoutManager 来获取 View 进行填充。","text":"当前 ListView 很多时候都已经被 RecyclerView 替代了。相对而言，RecyclerView 更加的灵活和高级。 在 RecyclerView 中，几种不同的组件相互工作来显示数据。RecyclerView 通过我们提供的 LayoutManager 来获取 View 进行填充。 RecyclerView 中的 View 通过 view holder 来进行表示。view holder 对象是我们继承 了 RecyclerView.ViewHolder 的类的实例。每个 View Holder 负责用一个 View 来显示单个的数据项。 RecyclerView 只会创建能在屏幕上显示的那么多个 view holder。当用户滑动列表的时候，RecyclerView 会将离开屏幕的 view 绑定到新滑动到屏幕的数据项。 view holder 通过 adapter 进行管理，我们会通过继承 RecyclerView.Adapter 来实现。adapter 会根据需要来创建 view holder，然后将数据绑定到 view holder。其通过将 view holder 给到一个位置，然后调用 adapter 的 onBindViewHolder() 方法。这个方法会使用 view holder 的位置来决定其应该显示什么数据。 RecyclerView 做了很多优化，我们自己就不用干这些事情了： 当列表第一次展示，其会在列表的两边都绑定一些 view holder。例如，如果视图要显示 0-9 位置的数据，RecyclerView 会创建这些 view holder，但是他也可能会创建位置 10 的 view holder。这样，如果用户滑动列表的话，下一个元素就会立马显示出来。 当用户滑动列表的时候，RecyclerView 根据需要创建 view holder。其也会保存已经离开了屏幕的 view holder，以便复用。这样， view holder 不用重新创建及从布局扩张，而只需要更新 view holder 的内容就行了。 当显示的内容变了。可以耐用 RecyclerView.Adapter.notify...()方法。 使用如果我们在 Activity 内添加一个 RecyclerView，我们一般会有如下的代码： public class MyActivity extends Activity &#123; private RecyclerView recyclerView; private RecyclerView.Adapter mAdapter; private RecyclerView.LayoutManager layoutManager; @Override protected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); setContentView(R.layout.my_activity); recyclerView = (RecyclerView) findViewById(R.id.my_recycler_view); // use this setting to improve performance if you know that changes // in content do not change the layout size of the RecyclerView recyclerView.setHasFixedSize(true); // use a linear layout manager layoutManager = new LinearLayoutManager(this); recyclerView.setLayoutManager(layoutManager); // specify an adapter (see also next example) mAdapter = new MyAdapter(myDataset); recyclerView.setAdapter(mAdapter); &#125; // ...&#125; 同时我们还需要一个 适配器： public class MyAdapter extends RecyclerView.Adapter&lt;MyAdapter.MyViewHolder&gt; &#123; private String[] mDataset; // Provide a reference to the views for each data item // Complex data items may need more than one view per item, and // you provide access to all the views for a data item in a view holder public static class MyViewHolder extends RecyclerView.ViewHolder &#123; // each data item is just a string in this case public TextView textView; public MyViewHolder(TextView v) &#123; super(v); textView = v; &#125; &#125; // Provide a suitable constructor (depends on the kind of dataset) public MyAdapter(String[] myDataset) &#123; mDataset = myDataset; &#125; // Create new views (invoked by the layout manager) @Override public MyAdapter.MyViewHolder onCreateViewHolder(ViewGroup parent, int viewType) &#123; // create a new view TextView v = (TextView) LayoutInflater.from(parent.getContext()) .inflate(R.layout.my_text_view, parent, false); ... MyViewHolder vh = new MyViewHolder(v); return vh; &#125; // Replace the contents of a view (invoked by the layout manager) @Override public void onBindViewHolder(MyViewHolder holder, int position) &#123; // - get element from your dataset at this position // - replace the contents of the view with that element holder.textView.setText(mDataset[position]); &#125; // Return the size of your dataset (invoked by the layout manager) @Override public int getItemCount() &#123; return mDataset.length; &#125;&#125; 布局管理器会调用 适配器 的 onCreateViewHolder() 方法。这个方法需要构造一个 RecyclerView.ViewHolder，同时设置其用来显示内容的 View。ViewHoler 的类型必须与 Adapter 类签名声明的类型一致。通常，会通过扩张一个 xml 布局文件来获取视图。因为此时 VH 并没有被赋予实际的值，所以方法不会设置View 的内容。 接着布局管理器会将 VH 与数据相绑定。其通过调用 onBindViewHolder()方法来达成，同时会将 VH 在 RecyclerView 中的位置作为参数。 总结RecyclerView 的内容通过 VH 进行表示，VH 会与一个 VIEW 绑定，这个VIEW 一般通过 xml 布局文件进行扩张。 RecyclerView 只会创建屏幕上能能够显示的那么多个 VH，滑出屏幕的会缓存也进行复用。 RecyclerView 中的 VH 保留了对 VIEW 中各个控件的引用，每次需要改变内容的时候不需要 findViewById()，直接对引用的控件进行操作即可。","categories":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"}],"keywords":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}]},{"title":"Android-View的绘制过程","slug":"Android-View的绘制过程","date":"2019-04-21T02:22:02.000Z","updated":"2019-04-21T02:22:02.000Z","comments":true,"path":"Android/Android-View的绘制过程.html","link":"","permalink":"https://gowa2017.github.io/Android/Android-View的绘制过程.html","excerpt":"","text":"当一个 Activity 获取焦点的时候，其会被请求绘制其布局。Android 框架会控制绘制的过程，但是 Activity 必须提供其布局层级的根节点。 绘制从布局的根节点开始。其会被要求测试和汇制布局树。通过遍历布局树及渲染位于有效区域内的 View 来进行绘制。 按照顺序，每个 ViewGroup 负责请求其子 View 进行绘制（draw()方法），每个 View 负责绘制自己。因为布局树是预先定义的，这就意味着 父视图会在子视图之前（之下）进行绘制，兄弟视图则根据其出现的顺序而定。 Android 框架并不会绘制在有效区域外的 View ，不过其也会关心绘制 View 的背景。可以通过调用 View 的 invalidate() 方法来强制绘制。 测量测量阶段通过方法 measure(int, int) 实现，其会由上至下遍历布局树。在这个递归遍历中，每个 View 都会将其尺寸规范向下推送。在测量阶段的结束，每个 View 都保存了其尺寸。 第二个阶段发生在 layout(int, int, int, int) 中，其也是由上至下的。在这个阶段中，每个父视图的责任是根据上一阶段测量出的个子视图的尺寸来定位其所有的子视图。 当一个 View 对象的 measure() 方法返回时，其 getMeasuredWidth(), getMeasureHeight() 的值必须被设置，其子视图的这两个方法的值也必须被设置。 View 测量后的宽度和高度必须满足其父视图给予的约束。这保证在测量阶段结束时，所有的父视图都会接受其子视图的尺寸。 一个父视图 View 可能会多次调用 measure() 方法。比如，当父视图以未指定的规格来测量子视图以知道子视图想要显示的尺寸，如果子视图返回的尺寸太大或太小的时候就会再次以实际的规格来调用 measure() 。 测量阶段使用两个类来进行沟通规格。View 使用 ViewGroup.LayoutParams 来告诉其父视图其想要被如何测量及定位。此类仅仅用来描述 View 想要其宽和高是什么样的。可以有下面三个值： 一个确定的值 MATCH_PARENT 想要和父视图一样宽。 WARP_CONTENT 只需要包围视图内容即可 MeasureSpec 对象用来从父到子向下推送规格。有三种形式： UNSPECIFIED 用来决定子视图的规格。例如，一个 LinearLayout 可能会宽为 EXACTLY 的 240，高为 UNSPECIFIED 来找出子视图希望有多高。 EXACTLY 确切的值。子视图必须使用这个值，且子视图的后面也必须满足在这个值内。 AT MOST： 最大值。子视图必须保证其及其子视图不超过这个值 布局阶段为了初始化一个布局，使用 requestLayout()。","categories":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"}],"keywords":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}]},{"title":"关于Type接口与Class类的一些","slug":"关于Type接口与Class类的一些","date":"2019-04-14T14:01:21.000Z","updated":"2019-04-14T14:01:21.000Z","comments":true,"path":"Java/关于Type接口与Class类的一些.html","link":"","permalink":"https://gowa2017.github.io/Java/关于Type接口与Class类的一些.html","excerpt":"主要的问题是在于 Gson 在解析泛型化的类型的时候，因为泛型擦除的问题，无法解析出我想要的类型。所以得想个办法解决不是。？","text":"主要的问题是在于 Gson 在解析泛型化的类型的时候，因为泛型擦除的问题，无法解析出我想要的类型。所以得想个办法解决不是。？ 类型擦除根据官方文档 泛型擦除。 泛型的引入是为了提供更严格的编译时类型检测及支持泛型编程。为了实现泛型，Java 的编译器会对下面的情况进行类型擦除： 将所有泛型的类型参数替换为他们的界限(bounds)或Object（泛型类型参数没有界限）。因此产生的字节码，只有普通的类，接口和方法。 为了保证类型安全会在必要的时候插入类型转换(cast) 在扩展的泛型类型中，会生成桥接方法来保证多态。 类型擦除保证参数化的类型不会产生新的类，因此泛型不会导致运行时的负载问题。 也就是说，如果我们传递一个泛型化的类型给 Gson 在运行的时候，其是不知道具体的类型是什么的。比如我们的服务端返回的结构是这样的： public class SrvRes&lt;T&gt; &#123;private int state;private T data;&#125; 在 Gson 解析的时候实际上是按: public class SrvRes&lt;Object&gt;&#123;private int state;private Object data;&#125; 其结果就是会报错，得出一个 LinkTreeMap 无法转换为 Object 的错误。 我们要做的就是在运行时获取这个类的类型。 也就是说，接受泛型参数的类实例，是不包括类型参数信息的。 只用通过泛型化参数继承而来的类，才能从其父类获得泛型信息。 Type 接口接口位于 java.lang.reflect 包内，只定义了一个方法 getTypeName() public interface Type &#123; default String getTypeName() &#123; return toString(); &#125;&#125; 其有四个子接口。 ParameterizedType 接口对于这个接口的解释，应该说这是是一个以参数类型与父类结合后形成的类。比如一个泛型类 SrvRes ，这个不是一个 ParameterizedType 的实现。必须通过 T 实际的值后形成的类才是，比如： public class Res extends SrvRes&lt;Res&gt;&#123;&#125; 我们以 SrvRes t = new SrvRes() 的形式，实际上不是一个参数化类型，t 在这里只是一个对象，运行时，怎么也无法获取到泛型信息。 而对于 Res 在构造的时候就会保存其泛型信息。 此接口继承自 Type。其代表了一个参数化的类型，如 Collection。当一个反射方法调用时如果需要这个类型，那么其会被创建。当一个参数化的类型 p 建立后，p 初始化的泛型声明被解析，所有 p 需要的类型参数都会被递归创建。 public interface ParameterizedType extends Type &#123; Type[] getActualTypeArguments(); Type getRawType(); // 获取用来表示声明了此接口或Class的对象 Type getOwnerType();// 获取包含此类型属于哪个外部类。&#125; 当我看到这的时候我很困惑，我如何能通过这个接口获得我构造的 SrvRes 类的类型参数。实际上我是无法获取到的，因为这个类我们没有实现 ParameterizedType 接口；也没有指定任何父类，所以说其直接的父类是 Object，Object 并没有实现 ParameterizedType 接口。 可是查明就网络上的很多文章，都能通过 getClass().getGenericSuperclass() 来获取泛型父类，以此来获取 ParameterizedType 接口。这是为何？ 仔细想想也就明白了。因为 类型擦除的原因， SrvRes 实际上运行时是 SrvRes 当然无法获取其泛型信息。 而对于 Res extends SrvRes 其并没有泛型参数，当然可以获取其类型了。 public class Res extends SrvRes&lt;Res&gt; &#123;&#125;Res t = new Res();ParameterizedType pt = (ParameterizedType) t.getClass().getGenericSuperclass();System.out.println(pt.getActualTypeArguments()[0]);System.out.println(pt.getOwnerType());System.out.println(pt.getRawType()); 输出： class Resnullclass SrvRes TypeVariablepublic interface TypeVariable&lt;D extends GenericDeclaration&gt; extends Type, AnnotatedElement &#123; Type[] getBounds(); D getGenericDeclaration(); String getName(); AnnotatedType[] getAnnotatedBounds();&#125; WildcardTypepublic interface WildcardType extends Type &#123; Type[] getUpperBounds(); Type[] getLowerBounds();&#125; GenericArrayTypepublic interface GenericArrayType extends Type &#123; Type getGenericComponentType();&#125; GenericDeclaration 接口位于 java.lang.reflect; 包中。所有定义了类型变量的类都会实现这个接口。 public interface GenericDeclaration extends AnnotatedElement &#123; /** * Returns an array of &#123;@code TypeVariable&#125; objects that * represent the type variables declared by the generic * declaration represented by this &#123;@code GenericDeclaration&#125; * object, in declaration order. Returns an array of length 0 if * the underlying generic declaration declares no type variables. * * @return an array of &#123;@code TypeVariable&#125; objects that represent * the type variables declared by this generic declaration * @throws GenericSignatureFormatError if the generic * signature of this generic declaration does not conform to * the format specified in * &lt;cite&gt;The Java&amp;trade; Virtual Machine Specification&lt;/cite&gt; */ public TypeVariable&lt;?&gt;[] getTypeParameters();&#125; Class 类Class 类位于 java.lang 包中，其实现了 Type 接口: public final class Class&lt;T&gt; implements java.io.Serializable, GenericDeclaration, Type, AnnotatedElement &#123; public String getTypeName() &#123; if (isArray()) &#123; try &#123; Class&lt;?&gt; cl = this; int dimensions = 0; while (cl.isArray()) &#123; dimensions++; cl = cl.getComponentType(); &#125; StringBuilder sb = new StringBuilder(); sb.append(cl.getName()); for (int i = 0; i &lt; dimensions; i++) &#123; sb.append(\"[]\"); &#125; return sb.toString(); &#125; catch (Throwable e) &#123; /*FALLTHRU*/ &#125; &#125; return getName(); &#125;&#125; 演示一下方法的使用： System.out.println(Gson.class.getTypeName());List&lt;String&gt; ls = new ArrayList&lt;&gt;();System.out.println(ls.getClass().getTypeName());Map&lt;String,String&gt; ms = new HashMap&lt;&gt;();System.out.println(ms.getClass().getTypeName());Map&lt;String,List&lt;String&gt;&gt; mls = new HashMap&lt;&gt;();System.out.println(mls.getClass().getTypeName()); 输出是： com.google.gson.Gsonjava.util.ArrayListjava.util.HashMapjava.util.HashMap","categories":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/tags/Java/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}]},{"title":"Java的Lambda-方法引用及Stream","slug":"Java的Lambda-方法引用及Stream","date":"2019-04-09T14:30:31.000Z","updated":"2019-04-09T14:30:31.000Z","comments":true,"path":"Java/Java的Lambda-方法引用及Stream.html","link":"","permalink":"https://gowa2017.github.io/Java/Java的Lambda-方法引用及Stream.html","excerpt":"Lambda, Stream, Method Reference 是 Java 迈向函数式编程，操作符式的操作重要的一步。能让我们的代码更精简，更紧凑，手也更轻松些。","text":"Lambda, Stream, Method Reference 是 Java 迈向函数式编程，操作符式的操作重要的一步。能让我们的代码更精简，更紧凑，手也更轻松些。 Lambda在我们实现一个匿名类的时候，只需要悄悄的 new 一下就行了。但是实际上我不得不写一长串代码，即使这个类只或接口只包含了一个方法。同时了，语法看起来也是不太友好的。 经常，我们会把函数做一个参数传递给另外一个方法，比如在安卓中我们对 View 设置事件监听函数的时候。 语法一个 lambda 表示式由以下几部分组成： (a,b,c) 由括号包围起来的，逗号分隔的参数列表。我们可以忽略参数的类型。如果参数只有一个，那么可以忽略括号。也即是说 (a) 与 a 与相同的效果。 箭头 -&gt; 函数体。可以是一个表达式，或者是一个语句块。如果只有一个表达式，执行的时候会返回表达式的值。如果是 {} 语句话，就要加上 return ... 语句。不过，是一个 void 返回值的方法，也可以同表达式那样使用。 lambda 和 方法声明看起来很相似；我们也可以把他看作是匿名方法。 Method References我们用 lambda 在很多时候都只是为了调用一个已经存在的方法。 Method References 可以让我们很用 lambda 来调用一个已经存在的方法。 引用静态方法。ContainingClass::staticMethodName 引用实例方法。containingObject::instanceMethodName 专有类型的实例方法。ContainingType::methodName 引用构造器。ClassName::new Stream我们会用 集合 Collections 来干什么？不仅仅是存储数据，我们还经常要从里面获取数据。 比如： for (Person p : roster) &#123; System.out.println(p.getName());&#125; 可以转换为: roster .stream() .forEach(e -&gt; System.out.println(e.getName()); 管道与流一个 管道 是有序的聚合操作序列。 roster .stream() .filter(e -&gt; e.getGender() == Person.Sex.MALE) .forEach(e -&gt; System.out.println(e.getName())); 用 for-loop 的话就是这种形式： for (Person p : roster) &#123; if (p.getGender() == Person.Sex.MALE) &#123; System.out.println(p.getName()); &#125;&#125; 管道包含： 一个源。可以是一个集合，一个数组，一个生成函数，一个 I/O 通道。 0 或 多个中间操作。一个中间操作，会产生一个新的流，如 filter。 流 stream 是一个序列的元素。和集合不一样的是，它不是一个存储元素的数据结构。一个流从一个源携带值通过管道。 一个 中止操作。如 forEach 会产生一个非流的结果，比如一个基础类型，一个集合，也可能什么都不产生。 double average = roster .stream() .filter(p -&gt; p.getGender() == Person.Sex.MALE) .mapToInt(Person::getAge) .average() .getAsDouble(); 聚合操作与迭代的不同聚合操作，如 forEach，与迭代器看起来很像。但有一些根本的不同： 使用内部迭代 聚合操作没有像 next() 这样的方法来指示处理集合中的下一个元素。 从流中处理元素 支持用 lambda 作为参数 流的获取 Collection.stram(), Collection.parallelStream() 集合 Arrays.stream(Object[]) 数组 Stream.of(Object[]), IntStream.range(int, int) or Stream.iterate(Object, UnaryOperator); steam 类的静态工厂方法 BufferedReader.lines(); 文件行 Files 内获取文件路径 Random.ints() BitSet.stream(), Pattern.splitAsStream(java.lang.CharSequence), and JarFile.stream(). APIhttps://docs.oracle.com/javase/8/docs/api/java/util/stream/Stream.html 中间操作 concat distinct filter flatMap flatMapToDouble flatMapToInt flatMapToLong generate iterate limit map skip sorted 中止操作 collect count findAny findFirst forEach forEachOrdered of peek 其他操作 allMatch anyMatch builder max min noneMatch reduce toArray 关于 Collector 的一些方法Collector 是一个接口，你定义用一些用来对 Stream 进行减少操作的方法。 所以的 减少操作（reduction operation） 将多个元素整合在一个结果中。 其有三个泛型参数： Collector T 进行减少操作的元素类型 A 减少操作的可变的方法，可由我们定义 R 返回的结果类型 方法 BiConsumer accumulator() 将一个值当到一个结果容器中的函数 Set characteristics() 返回特征集合 BinaryOperator&lt; A &gt; combiner() 将两个结果合并 Function finisher() Collectors实现了接口 Collector，提供一系列非常实用的方法。 安卓上使用 Stream","categories":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/tags/Java/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}]},{"title":"了解locale环境变量","slug":"了解locale环境变量","date":"2019-04-09T12:41:33.000Z","updated":"2019-04-09T12:41:33.000Z","comments":true,"path":"Linux/了解locale环境变量.html","link":"","permalink":"https://gowa2017.github.io/Linux/了解locale环境变量.html","excerpt":"locale 可以用几个环境变量来改变。当然，之前在 TLPI 上看到过，但是都忘记得差不多了。正好遇到了，macOS 中在 vim 用 + 寄存器复制出来的中文是乱码的。所以需要了解一下。locale 被位置敏感的程序用来渲染文字，正确的显示货币值，时间和日期的格式等等。","text":"locale 可以用几个环境变量来改变。当然，之前在 TLPI 上看到过，但是都忘记得差不多了。正好遇到了，macOS 中在 vim 用 + 寄存器复制出来的中文是乱码的。所以需要了解一下。locale 被位置敏感的程序用来渲染文字，正确的显示货币值，时间和日期的格式等等。 原因macOS 在英文界面的时候，我查看了一下 locale 相关的变量： $ localeLANG=LC_COLLATE=\"C\"LC_CTYPE=\"UTF-8\"LC_MESSAGES=\"C\"LC_MONETARY=\"C\"LC_NUMERIC=\"C\"LC_TIME=\"C\"LC_ALL= 再切换到中文界面： $ localeLANG=\"zh_CN.UTF-8\"LC_COLLATE=\"zh_CN.UTF-8\"LC_CTYPE=\"zh_CN.UTF-8\"LC_MESSAGES=\"zh_CN.UTF-8\"LC_MONETARY=\"zh_CN.UTF-8\"LC_NUMERIC=\"zh_CN.UTF-8\"LC_TIME=\"zh_CN.UTF-8\"LC_ALL= 看来影响的原因就是因为 locale 设置的问题。 格式locale 的格式类似 language[_territory][.codeset][@modifier]。 例如 ： zh_CN.UTF-8 language ISO 639 language code 语言代码 territory ISO 3166 country code 国家代码 .codeset character set 字符集或者是编码形式如 ISO-8859-1 和 UTF-8 modifier 变量解释LANG安装的默认 locale。 在没有设置 LC_* 变量的情况下，就会使用 LANG 变量。 LCALL 覆盖 LANG 及其他 LC* 变量的设置。 LC_COLLATE 影响用来排序和正则式的规则。设置为 C 会让 ls 命令将 . 放在前面，大写的比小写的更前面。 LC_TIME 时间日期格式。 LC_CTYPE 代表 正则 表达式 匹配, 字符类(character classification), 转换, 区分大小写 的 比较, 以及 宽字符 函数. LC_MESSAGES 代表 可以 本地化的 消息 (自然语言) LC_MONETARY 代表 货币 格式. LC_NUMERIC 代表 数字 格式 (比如 小数点 和 千位分组符).","categories":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/tags/Linux/"}],"keywords":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}]},{"title":"Retrofit对象的建立及与RxJava的使用","slug":"Retrofit对象的建立及与RxJava的使用","date":"2019-04-07T15:36:17.000Z","updated":"2019-04-07T15:36:17.000Z","comments":true,"path":"Android/Retrofit对象的建立及与RxJava的使用.html","link":"","permalink":"https://gowa2017.github.io/Android/Retrofit对象的建立及与RxJava的使用.html","excerpt":"对于 Retrofit 的使用，我们一般会利用 Retrofit.Builder 来填写参数后，建立一个 Retrofit 对象，接着就以此对象来根据我们编写的接口生成 所以的 Call，当配合 RxJava 使用的时候，我很好奇这其中的过程是怎么样的。","text":"对于 Retrofit 的使用，我们一般会利用 Retrofit.Builder 来填写参数后，建立一个 Retrofit 对象，接着就以此对象来根据我们编写的接口生成 所以的 Call，当配合 RxJava 使用的时候，我很好奇这其中的过程是怎么样的。 前言在开始用这个东西之前，我们有必要了解一下， Retrofit 到底是什么。根据官方文档上的介绍：Retrofit官方网站 使用 Retrofit ，我们可以将 HTTP 接口调用，转换为对一个 Java 接口的调用。 Retrofit 类会自动生成我们定义的 Java 接口的实现。 调用这个生成的接口实现，就会对远程服务器进行调用。 Retrofit 所做的事情主要是： 生成我们定义的接口实现。 调用底层的 OkHttp 来进行远程调用。 管理往返数据。 Retrofit 对象的建立一般来说，我们会这样来建立一个 Retrofit 对象： Retrofit retrofit = new Retrofit.Builder() .baseUrl(\"https://api.github.com/\") .addConverterFactory(GsonConverterFactory.create()) .addCallAdapterFactory(RxJava2CallAdapterFactory.create()) .build(); 接着，让 Retrofit 实例，根据接口来生成一个请求对象： GitHubService gitHubService = retrofit.create(GitHubService.class); 在这里， GitHubService.class 是我们编写的接口。 每个 retrofit 实例都有 ConverterFactory 与 CallAdapterFactory 列表，其存的都是工厂类，当我们需要 Converter 或 CallAdapter 的时候，调用工厂类的 create() 方法来建立对象。 private final List&lt;Converter.Factory&gt; converterFactories = new ArrayList&lt;&gt;();private final List&lt;CallAdapter.Factory&gt; callAdapterFactories = new ArrayList&lt;&gt;(); 对于callFactory 我们一般都用默认的。 private @Nullable okhttp3.Call.Factory callFactory; retrofit.create()根据接口，生成接口的实现。 默认情况下， Retrofit.create() 方法会返回一个代表 HTTP 请求的 Call 对象。 Call 的泛型参数就表示表示了响应内容的类型，会被 Convert.Factory 实例中的某一个进行转换。 public &lt;T&gt; T create(final Class&lt;T&gt; service) &#123; // 验证我们的传递的 service。 1. 是一个接口； 2. 接口不能继承其他接口。 Utils.validateServiceInterface(service); // 是否立即加载接口定义的所有方法[到 Retrofit 缓存]。 if (this.validateEagerly) &#123; this.eagerlyValidateMethods(service); &#125; // 建立一个代理对象。调用此对象的方法会调用到代理类的对应方法。 return Proxy.newProxyInstance(service.getClassLoader(), new Class[]&#123;service&#125;, new InvocationHandler() &#123; private final Platform platform = Platform.get(); private final Object[] emptyArgs = new Object[0]; public Object invoke(Object proxy, Method method, @Nullable Object[] args) throws Throwable &#123; if (method.getDeclaringClass() == Object.class) &#123; return method.invoke(this, args); &#125; else &#123; return this.platform.isDefaultMethod(method) ? this.platform.invokeDefaultMethod(method, service, proxy, args) : Retrofit.this.loadServiceMethod(method).invoke(args != null ? args : this.emptyArgs); &#125; &#125; &#125;);&#125; 在 invoke() 方法中，会检查我们传递的 service 是否是一个对象（我们传递的接口，当然不会），或者是一个默认方法（默认方法指的是：public non-abstarct 的实例方法，我们这里也不是）。 所以，当我们以 Observable&lt;List&lt;Repo&gt;&gt; service = gitHubService.listRepos(&quot;octocat&quot;); 的形式调用 retrofit 对象的时候，实则调用的是: loadServiceMethod(method).invoke(args != null ? args : emptyArgs); ServiceMethod对于接口中的每个方法调用，都是建立在 ServiceMethod 的调用上的。对于接口中定义的每个方法，都会用 loadServiceMethod() 来生成方法的实现。 Retrofit.loadServiceMethod()ServiceMethod&lt;?&gt; loadServiceMethod(Method method) &#123; ServiceMethod&lt;?&gt; result = serviceMethodCache.get(method); if (result != null) return result; synchronized (serviceMethodCache) &#123; result = serviceMethodCache.get(method); if (result == null) &#123; result = ServiceMethod.parseAnnotations(this, method); serviceMethodCache.put(method, result); &#125; &#125; return result;&#125; 这首先会从 serviceMethodCache 缓存中获取一下看看有没有已经建立好的，如果没有的话，就会根据注解来建立一个新的 ServiceMethod。 ServiceMethod.parseAnnotations()因为我们会在方法上，参数上添加各种注解，如：@GET,@POST,@QUERY,@BODY 等，所以就要根据这些注解，来分析用哪个 RequestFactory 来处理。 也就说，根据我们的注解，来决定要建立何种类型的请求。 所以此方法做了两个工作： 根据注解确定我们要用的 RequestFactory 是什么。 方法的返回类型不能是不可识别的或空类型。 static &lt;T&gt; ServiceMethod&lt;T&gt; parseAnnotations(Retrofit retrofit, Method method) &#123; RequestFactory requestFactory = RequestFactory.parseAnnotations(retrofit, method); Type returnType = method.getGenericReturnType(); if (Utils.hasUnresolvableType(returnType)) &#123; throw methodError(method, \"Method return type must not include a type variable or wildcard: %s\", returnType); &#125; if (returnType == void.class) &#123; throw methodError(method, \"Service methods cannot return void.\"); &#125; return HttpServiceMethod.parseAnnotations(retrofit, method, requestFactory);&#125; HttpServiceMethod.parseAnnotations()HttpServiceMethod 是 ServiceMethod 的继承与实现。其会根据我们传递的 retrofit, method, RequestFactor 来建立一个 HttpServiceMethod。 HtppServiceMethod 是一个非常核心的东西，其实现了很多重要的逻辑。 找到 CallAdapter。 找到 responseConverter 使用默认的 callFactory。 最终返回一个 HttpServiceMethod。 static &lt;ResponseT, ReturnT&gt; HttpServiceMethod&lt;ResponseT, ReturnT&gt; parseAnnotations( Retrofit retrofit, Method method, RequestFactory requestFactory) &#123; CallAdapter&lt;ResponseT, ReturnT&gt; callAdapter = createCallAdapter(retrofit, method); Type responseType = callAdapter.responseType(); if (responseType == Response.class || responseType == okhttp3.Response.class) &#123; throw methodError(method, \"'\" + Utils.getRawType(responseType).getName() + \"' is not a valid response body type. Did you mean ResponseBody?\"); &#125; if (requestFactory.httpMethod.equals(\"HEAD\") &amp;&amp; !Void.class.equals(responseType)) &#123; throw methodError(method, \"HEAD method must use Void as response type.\"); &#125; Converter&lt;ResponseBody, ResponseT&gt; responseConverter = createResponseConverter(retrofit, method, responseType); okhttp3.Call.Factory callFactory = retrofit.callFactory; return new HttpServiceMethod&lt;&gt;(requestFactory, callFactory, callAdapter, responseConverter);&#125; HttpServiceMethod.createCallAdapter()在 HttpServiceMethod 中，会根据 retrofit 对象和 接口方法来查找 CallAdapter。 private static &lt;ResponseT, ReturnT&gt; CallAdapter&lt;ResponseT, ReturnT&gt; createCallAdapter( Retrofit retrofit, Method method) &#123; Type returnType = method.getGenericReturnType(); Annotation[] annotations = method.getAnnotations(); try &#123; //noinspection unchecked return (CallAdapter&lt;ResponseT, ReturnT&gt;) retrofit.callAdapter(returnType, annotations); &#125; catch (RuntimeException e) &#123; // Wide exception range because factories are user code. throw methodError(method, e, \"Unable to create call adapter for %s\", returnType); &#125;&#125; 具体的逻辑就是在 Retrofit 实里的 CallAdapterFactory 中根据 method 返回值的泛型类型及 注解来查找。 public CallAdapter&lt;?, ?&gt; callAdapter(Type returnType, Annotation[] annotations) &#123; return nextCallAdapter(null, returnType, annotations);&#125;public CallAdapter&lt;?, ?&gt; nextCallAdapter(@Nullable CallAdapter.Factory skipPast, Type returnType, Annotation[] annotations) &#123; checkNotNull(returnType, \"returnType == null\"); checkNotNull(annotations, \"annotations == null\"); int start = callAdapterFactories.indexOf(skipPast) + 1; for (int i = start, count = callAdapterFactories.size(); i &lt; count; i++) &#123; CallAdapter&lt;?, ?&gt; adapter = callAdapterFactories.get(i).get(returnType, annotations, this); if (adapter != null) &#123; return adapter; &#125; 在上述遍历 CallAdapterFactory 列表的过程中，当然会遍历到我们添加的 RxJava2CallAdapterFactory。 对于 RxJava2CallAdapterFactory 的 get 方法，我们来看一下具体的逻辑： @Nullablepublic CallAdapter&lt;?, ?&gt; get(Type returnType, Annotation[] annotations, Retrofit retrofit) &#123; Class&lt;?&gt; rawType = getRawType(returnType); if (rawType == Completable.class) &#123; return new RxJava2CallAdapter(Void.class, this.scheduler, this.isAsync, false, true, false, false, false, true); &#125; else &#123; boolean isFlowable = rawType == Flowable.class; boolean isSingle = rawType == Single.class; boolean isMaybe = rawType == Maybe.class; // 返回类型的泛型 raw 类型必须是 RxJava 支持的类型 if (rawType != Observable.class &amp;&amp; !isFlowable &amp;&amp; !isSingle &amp;&amp; !isMaybe) &#123; return null; &#125; else &#123; boolean isResult = false; boolean isBody = false; // 返回的类型，必须是泛型类型（必须泛型化） if (!(returnType instanceof ParameterizedType)) &#123; String name = isFlowable ? \"Flowable\" : (isSingle ? \"Single\" : (isMaybe ? \"Maybe\" : \"Observable\")); throw new IllegalStateException(name + \" return type must be parameterized as \" + name + \"&lt;Foo&gt; or \" + name + \"&lt;? extends Foo&gt;\"); &#125; else &#123; // 因为RxJava 这些泛型容器的都只有一个泛型参数，所以说需要拿到泛型参数的上界类型。如 getParameterUpperBound(1, Map&lt;String, ? extends Runnable&gt; ) 会返回 Runnable。 Type observableType = getParameterUpperBound(0, (ParameterizedType)returnType); // 拿到上界类型还不够，对于是一个泛型类型，还需要拿到声明此泛型的对象类型。如 List&lt;String&gt; 会返回 List。 Class&lt;?&gt; rawObservableType = getRawType(observableType); Type responseType; // 这里表明，我们的返回类型不能是 Single&lt;Response&gt;，而必须是泛型化的，如 Single&lt;Response&lt;String&gt;&gt;。 if (rawObservableType == Response.class) &#123; if (!(observableType instanceof ParameterizedType)) &#123; throw new IllegalStateException(\"Response must be parameterized as Response&lt;Foo&gt; or Response&lt;? extends Foo&gt;\"); &#125; responseType = getParameterUpperBound(0, (ParameterizedType)observableType); &#125; else if (rawObservableType == Result.class) &#123; if (!(observableType instanceof ParameterizedType)) &#123; throw new IllegalStateException(\"Result must be parameterized as Result&lt;Foo&gt; or Result&lt;? extends Foo&gt;\"); &#125; responseType = getParameterUpperBound(0, (ParameterizedType)observableType); isResult = true; // 通常情况下，我们都没有使用 Result, Response ，所以都用到下面这个类型。如 Single&lt;DictInfo&gt;。isBody 说明，我们的返回类型，就直接是响应回来的数据了。 &#125; else &#123; responseType = observableType; isBody = true; &#125; return new RxJava2CallAdapter(responseType, this.scheduler, this.isAsync, isResult, isBody, isFlowable, isSingle, isMaybe, false); &#125; &#125; &#125;&#125; 其运作的逻辑，就是看我们的返回类型是不是 RxJava 支持的那些类型。 检查返回值是否是 Completable。 检查是否是泛型返回类型 获取返回泛型的第一个泛型参数类型。 泛型参数的如果是 Response.class 其必需泛型化，如 Observable","categories":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/tags/Java/"},{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"}],"keywords":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}]},{"title":"RxJava的一些基本概念及文档","slug":"RxJava的一些基本概念及文档","date":"2019-04-04T13:27:57.000Z","updated":"2019-04-04T13:27:57.000Z","comments":true,"path":"RxJava/RxJava的一些基本概念及文档.html","link":"","permalink":"https://gowa2017.github.io/RxJava/RxJava的一些基本概念及文档.html","excerpt":"一直以来都很想在项目中使用这个东西。但是以前没有时间，对 观察者 模式也不太理解。但最终要重新写模块的时候，发现，对于多个网络请求进行合并处理的话，交给 RxJava 是比较简单的，而不用我们自己去在 Handler 进行非常头疼的处理。","text":"一直以来都很想在项目中使用这个东西。但是以前没有时间，对 观察者 模式也不太理解。但最终要重新写模块的时候，发现，对于多个网络请求进行合并处理的话，交给 RxJava 是比较简单的，而不用我们自己去在 Handler 进行非常头疼的处理。 关于一些理论性的东西可以查看 官方文档 背景在编程任务中，我们或多或少都希望点写的代码能够按照我们的编写的顺序执行。但是在 ReactiveX 中，指令可能会并行执行然后 观察者Observer 以任意的顺序捕捉他们的结果。 与调用一个方法不同，我们以 Observables 的形式定义了一个获取和转换数据的机制，然后为其 “订阅” 一个 Observer ：这时，我们之前定义的机制 Observables 就开始动作，而 Observer 也准备好了捕捉其发射的数据并作出响应。 这样做的一个好处是，当我们有一堆的任务需要制定，而彼此之间又互不依赖的时候，我们可以同时启动这些任务，而不是一个一个的去执行————我们所有任务的执行时间只会和其中耗费时间最长的一个相等。 对于描述这种异步编程有很多术语。我们的文档中会使用 Observer subscribe Observables 观察者 订阅 可观察对象 Observables emits items or send notifications by calling observers’s method 可观察对象通过调用观察者的方法来发射数据或者通知。Reactive Streams 基本接口 首先我们要明确： Reactive Streams 是一个进行响应式编程的规范，而 RxJava 是 Reactive Streams 2.0 版本一个 Java 实现。有很多语言或者说很多库都对 Reactive Streams 进行了实现。 对于 Reactive Streams 其定义了几个基本的接口： Publisher&lt;T&gt; 一个 Publisher 是一个可能无限序列元素的提供者，其根据 Subscriber(S) 的需求进行发布。一个 Publisher 可能会与多个 Subscriber 相关联。 Subscriber&lt;T&gt; 当我们提供一个 Subscriber 的实例给 Publisher.subscribe(Subscriber) 的时候，Subscriber 的 onSubscribe(Subscription) 方法会被调用。只有当 Subscription.request(long) 被调用的时候，Subscriber 才会收到通知。 Processor&lt;T,R&gt; Processor 代表了一个处理阶段 ———— 其即是一个 Publisher ，也是一个 Subscriber，并遵守两者的一些约束。 Subscription Subscription 表示 Subscriber 与 Publisher 之间一对一的生命周期。 public interface Publisher&lt;T&gt; &#123; void subscribe(Subscriber&lt;? super T&gt; var1);&#125;public interface Subscriber&lt;T&gt; &#123; void onSubscribe(Subscription var1); void onNext(T var1); void onError(Throwable var1); void onComplete();&#125;public interface Processor&lt;T, R&gt; extends Subscriber&lt;T&gt;, Publisher&lt;R&gt; &#123;&#125;public interface Subscription &#123; void request(long var1); void cancel();&#125; Publisher在 RxJava 2 中， Flowable 实现了 Publisher 接口。但是对于 Observable, Single, Completable, Maybe 却不是直接的实现了 Publisher。 Subscriber当以这种形式 Publisher.subscribe(Subscriber) 执行代码的时候，在 Publisher 和 Subscriber 间有一个 Subscription 作为桥梁进行通信。 一个 Subscriber 必须通过 Subscription.request(long n) 来发送请求信号，然后 Publisher 才会调用 onNext()。 SubscriptionSubscription.request(), Subscription.cancel() 必须在 Subscriber 上下文内执行。 工作过程Publisher.subscribe(Subscriber) 执行过程中，其实内部会有一个 Subscription， Subscriber 持有这个 Subscription，以此来向 Publisher 发送信号。 Observable对于 Observable, Single, Completable, Maybe 都不是直接的实现 Publisher ，那么它又是怎么实现的。其实他们实现的是一个与 Publisher 相似的接口： public interface ObservableSource&lt;T&gt; &#123; /** * Subscribes the given Observer to this ObservableSource instance. * @param observer the Observer, not null * @throws NullPointerException if &#123;@code observer&#125; is null */ void subscribe(@NonNull Observer&lt;? super T&gt; observer);&#125;public interface SingleSource&lt;T&gt; &#123; /** * Subscribes the given SingleObserver to this SingleSource instance. * @param observer the SingleObserver, not null * @throws NullPointerException if &#123;@code observer&#125; is null */ void subscribe(@NonNull SingleObserver&lt;? super T&gt; observer);&#125;public interface CompletableSource &#123; /** * Subscribes the given CompletableObserver to this CompletableSource instance. * @param co the CompletableObserver, not null * @throws NullPointerException if &#123;@code co&#125; is null */ void subscribe(@NonNull CompletableObserver co);&#125;public interface MaybeSource&lt;T&gt; &#123; /** * Subscribes the given MaybeObserver to this MaybeSource instance. * @param observer the MaybeObserver, not null * @throws NullPointerException if &#123;@code observer&#125; is null */ void subscribe(@NonNull MaybeObserver&lt;? super T&gt; observer);&#125; public interface Observer&lt;T&gt; &#123; void onSubscribe(@NonNull Disposable var1); void onNext(@NonNull T var1); void onError(@NonNull Throwable var1); void onComplete();&#125;// 所有的 Observable 都要实现 subscribeActual 方法。在这个方法中决定是如何发射数据 使用哪种 Subscription 来通知Subcriberpublic abstract class Observable&lt;T&gt; implements ObservableSource&lt;T&gt; &#123; protected abstract void subscribeActual(Observer&lt;? super T&gt; var1)&#125; 所以，再不用傻傻的疑问，为什么看起来 RxJava 2 很多地方并没有用到定义的几个基本接口了，但是概念是相似的一致的。 其基本的工作形式是一样的： Publisher.subscribe(Subscriber&lt;? super T&gt; var1);Observable.subscribe(Observer&lt;? super T&gt; observer)) 使用 subscribe() 方法，在 发布者与订阅者（可观察对象与观察者）间建立了联系，发布者（可观察对象）会在后续发射数据的时候，通知 订阅者（观察者）。 基本类RxJava的项目地址在这里 RxJava 2 的特性由几个基本的类上进行操作来体现： io.reactivex.Flowable: 0..N 流, 支持 Reactive-Streams 和背压 io.reactivex.Observable: 0..N 流,不支持背压 io.reactivex.Single: 只有一项数据或错误的流。 io.reactivex.Completable: 只有一个完成或者错误信号的流 io.reactivex.Maybe:一个没有数据项，或者只有一个项，或只有一个错误的流。 根据我的观察， Flowable 实现了 Reactive-Streams 的 Publisher* 接口。 一个例子： Flowable 例子Flowable 实现了 Publisher 接口。 import io.reactivex.functions.Consumer;Flowable.just(\"Hello world\") .subscribe(new Consumer&lt;String&gt;() &#123; @Override public void accept(String s) &#123; System.out.println(s); &#125; &#125;); 可能会有疑问，不是应该 subscribe(Subcriber) 么，为什么这里是一个 Consumer 呢，其实这只是一个简化而已，最终还是使用了 Subscriber 的。 // 可以看到，只有 onNext 是我们定义的 Consumer ，而 onSubscribe 则会弄成了内部的实现 RequestMax.INSTANCEpublic final Disposable subscribe(Consumer&lt;? super T&gt; onNext) &#123; return this.subscribe(onNext, Functions.ON_ERROR_MISSING, Functions.EMPTY_ACTION, RequestMax.INSTANCE);&#125;// 构造了应该 Subscriber LambdaSubscriberpublic final Disposable subscribe(Consumer&lt;? super T&gt; onNext, Consumer&lt;? super Throwable&gt; onError, Action onComplete, Consumer&lt;? super Subscription&gt; onSubscribe) &#123; ObjectHelper.requireNonNull(onNext, \"onNext is null\"); ObjectHelper.requireNonNull(onError, \"onError is null\"); ObjectHelper.requireNonNull(onComplete, \"onComplete is null\"); ObjectHelper.requireNonNull(onSubscribe, \"onSubscribe is null\"); LambdaSubscriber&lt;T&gt; ls = new LambdaSubscriber(onNext, onError, onComplete, onSubscribe); this.subscribe((FlowableSubscriber)ls); return ls;&#125;public final void subscribe(FlowableSubscriber&lt;? super T&gt; s) &#123; ObjectHelper.requireNonNull(s, \"s is null\"); try &#123; Subscriber&lt;? super T&gt; z = RxJavaPlugins.onSubscribe(this, s); ObjectHelper.requireNonNull(z, \"The RxJavaPlugins.onSubscribe hook returned a null FlowableSubscriber. Please check the handler provided to RxJavaPlugins.setOnFlowableSubscribe for invalid null returns. Further reading: https://github.com/ReactiveX/RxJava/wiki/Plugins\"); this.subscribeActual(z); &#125; catch (NullPointerException var4) &#123; throw var4; &#125; catch (Throwable var5) &#123; Exceptions.throwIfFatal(var5); RxJavaPlugins.onError(var5); NullPointerException npe = new NullPointerException(\"Actually not, but can't throw other exceptions due to RS\"); npe.initCause(var5); throw npe; &#125;&#125;protected abstract void subscribeActual(Subscriber&lt;? super T&gt; var1); 当我们以 Flowable.just() 的形式建立一个 Flowable 的时候，实际上是返回的是： public final class FlowableJust&lt;T&gt; extends Flowable&lt;T&gt; implements ScalarCallable&lt;T&gt; &#123; private final T value; public FlowableJust(T value) &#123; this.value = value; &#125; protected void subscribeActual(Subscriber&lt;? super T&gt; s) &#123; s.onSubscribe(new ScalarSubscription(s, this.value)); &#125; public T call() &#123; return this.value; &#125;&#125; 最终我们真实代码的 实现应该是: FlowableJust&lt;String&gt;.subscribeActual(LambdaSubscriber s);protected void subscribeActual(LambdaSubscriber s) &#123; s.onSubscribe(new ScalarSubscription(s, this.value));&#125; 在这里，就出现了我们用 Subscription(ScalarSubscription) 将 Publisher(FlowableJust) 和 Subscriber(LambdaSubscriber,Consumer) 相关联的事实。 前面说到： Subscriber 通过调用 Subscription 的 request() 方法来请求数据。 继续往下查看代码的执行流会发现，确实是这样的: public void onSubscribe(Subscription s) &#123; if (SubscriptionHelper.setOnce(this, s)) &#123; try &#123; this.onSubscribe.accept(this); &#125; catch (Throwable var3) &#123; Exceptions.throwIfFatal(var3); s.cancel(); this.onError(var3); &#125; &#125;&#125;public static enum RequestMax implements Consumer&lt;Subscription&gt; &#123; INSTANCE; private RequestMax() &#123; &#125; public void accept(Subscription t) throws Exception &#123; t.request(9223372036854775807L); &#125;&#125;public void request(long n) &#123; if (SubscriptionHelper.validate(n)) &#123; if (this.compareAndSet(0, 1)) &#123; Subscriber&lt;? super T&gt; s = this.subscriber; s.onNext(this.value); if (this.get() != 2) &#123; s.onComplete(); &#125; &#125; &#125;&#125; 总结一下执行流程： Flowable.just() 会返回一个 FlowableJust 对象。 Flowable.subscribe(Consumer) 会封装一个 LambdaSubscriber，其中 onSubscribe 会设置为 RequestMax.INSTANCE 此对象的 accept 方法会直接调用 Subscription 的 request 方法。 FlowableJust.subscribeActual(LambdaSubscriber) 会使用 ScalarSubscription 来调用 LambdaSubscriber.onSubscribe() 方法。 调用 ScalarSubscription.accept()，最终，将值直接丢给了 LambdaSubscriber.onSubscribe。 事实上关键在于：不同的 发布者 (FlowableJust, FlowableRange …) 会使用不同的 Subscription（ScalarSubscription，FlowableRange.RangeConditionalSubscription())来通知 Subscriber。 Publisher subscribe Subcriber 过程其实是是 Publisher 以一个 Subcription 作为参数调用 Subcriber 的 onSubscribe 方法。 Observable 例子Observable.range(1,10).subscribe(new Consumer&lt;Integer&gt;() &#123; @Override public void accept(Integer integer) throws Exception &#123; System.out.println(integer); &#125;&#125;); Observable.range(1,10) 返回 ObservableRange。 ObservableRange 构造 LambdaObserver(onNext, Functions.ON_ERROR_MISSING, Functions.EMPTY_ACTION, Functions.emptyConsumer()） ObservableRange.subscribeActual(LambdaObserver o) 会使用 ObservableRange.RangeDisposable 来通知 LambdaObserver。LambdaObserver.onSubscribe(ObservableRange.RangeDisposable) ObservableRange.RangeDisposable.run() 开始发射数据。 static final class RangeDisposable extends BasicIntQueueDisposable&lt;Integer&gt; &#123; private static final long serialVersionUID = 396518478098735504L; final Observer&lt;? super Integer&gt; downstream; final long end; long index; boolean fused; RangeDisposable(Observer&lt;? super Integer&gt; actual, long start, long end) &#123; this.downstream = actual; this.index = start; this.end = end; &#125; void run() &#123; if (!this.fused) &#123; Observer&lt;? super Integer&gt; actual = this.downstream; long e = this.end; for(long i = this.index; i != e &amp;&amp; this.get() == 0; ++i) &#123; actual.onNext((int)i); &#125; if (this.get() == 0) &#123; this.lazySet(1); actual.onComplete(); &#125; &#125; &#125; Observerable.create()我们再开看一个更通用一些的，底层一些的做法。根据 Reactivx对于Create操作符的定义。 Create 操作符可以让我们以最基本的方式来建立一个 Observable。对操作符 Create 传递一个以 Observer 作为参数的函数。就是这个函数，可以让我们建立的对象看起来就像一个 Observable ————也就是适当的调用 Observer 的 onNext, onError, onCompleted 方法。 @CheckReturnValue @NonNull @SchedulerSupport(value=\"none\")public static &lt;T&gt; Observable&lt;T&gt; create(ObservableOnSubscribe&lt;T&gt; source) Observable.create(new ObservableOnSubscribe&lt;String&gt;() &#123; public void subscribe(ObservableEmitter&lt;String&gt; emitter) throws Exception &#123; emitter.onNext(\"hello world\"); emitter.onComplete(); &#125;&#125;).subscribe(System.out::println); 查看源码，此方法返回的是一个 ObservableCreate 对象。其以我们实现的 ObservableOnSubscribe 接口（数据发射逻辑）作为参数。 public static &lt;T&gt; Observable&lt;T&gt; create(ObservableOnSubscribe&lt;T&gt; source) &#123; ObjectHelper.requireNonNull(source, \"source is null\"); return RxJavaPlugins.onAssembly(new ObservableCreate&lt;T&gt;(source));&#125;public ObservableCreate(ObservableOnSubscribe&lt;T&gt; source) &#123; this.source = source;&#125; 我们也知道，当我们调用 Observable.subscribe() 方法的时候，实际上调用的是 Observable 具体实现的 subscribeActual() 方法。 在此方法中我们看到，为 Observer 建立了一个 CreateEmitter，然后我们的 Observable 就会调用这个 CreateEmitter 来发射数据。 @Overrideprotected void subscribeActual(Observer&lt;? super T&gt; observer) &#123; CreateEmitter&lt;T&gt; parent = new CreateEmitter&lt;T&gt;(observer); observer.onSubscribe(parent); try &#123; source.subscribe(parent); &#125; catch (Throwable ex) &#123; Exceptions.throwIfFatal(ex); parent.onError(ex); &#125;&#125; 从上面代码的过程我们可以总结出： Observable.create(ObservableOnSubscribe) 会返回一个 Observable 对象，同时内部建立一个 CreateEmitter。 当返回对象的 subscribe()方法被调用时，会将 CreateEmitter 作为 Disposable 递交给 Observer。（Disposable 与 Subscription 作用一致，不过是为了避免概念上的混淆）。 返回对象对调用 ObservableOnSubscribe.subscribe(CreateEmitter) 开始我们的发射逻辑。 CreateEmitter 持有了 Observer ，所以其可以将信号递交给 Observer。 事实上，当我们调用 CreateEmitter.onNext() 的时候，最终还是调用的 Observer.onNext()： static final class CreateEmitter&lt;T&gt; extends AtomicReference&lt;Disposable&gt; implements ObservableEmitter&lt;T&gt;, Disposable &#123; private static final long serialVersionUID = -3434801548987643227L; final Observer&lt;? super T&gt; observer; CreateEmitter(Observer&lt;? super T&gt; observer) &#123; this.observer = observer; &#125; @Override public void onNext(T t) &#123; if (t == null) &#123; onError(new NullPointerException(\"onNext called with null. Null values are generally not allowed in 2.x operators and sources.\")); return; &#125; if (!isDisposed()) &#123; observer.onNext(t); &#125; &#125; @Override public void onError(Throwable t) &#123; if (!tryOnError(t)) &#123; RxJavaPlugins.onError(t); &#125; &#125; // .....&#125; 这个并不是以 Subscription request()来请求数据的欸。 总结 Observable 需要实现 protected abstract void subscribeActual(Observer&lt;? super T&gt; var1); 方法。 在 subscribeActual 需要实现是 Disposable 来通知 Observer 的具体逻辑。 Subscription 与 Disposable在 RxJava 1 中， rx.Subscription 响应流及源生命周期管理，也即是取消对一个序列的订阅和释放一般资源（如调度任务）。 Reactive-Streams 规范使用了这个名字来指明一个 source 与 consumer 间的交互点：org.reactivestreams.Subscription允许从上游请求数据和取消这个序列。 为了避免名称上的冲突，所以将 rx.Subscription 更名为 io.reactivex.Disposable。","categories":[{"name":"RxJava","slug":"RxJava","permalink":"https://gowa2017.github.io/categories/RxJava/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/tags/Java/"},{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"},{"name":"RxJava","slug":"RxJava","permalink":"https://gowa2017.github.io/tags/RxJava/"},{"name":"RxAndroid","slug":"RxAndroid","permalink":"https://gowa2017.github.io/tags/RxAndroid/"}],"keywords":[{"name":"RxJava","slug":"RxJava","permalink":"https://gowa2017.github.io/categories/RxJava/"}]},{"title":"View的绘制过程","slug":"View的绘制过程","date":"2019-04-02T09:46:48.000Z","updated":"2019-04-02T09:46:48.000Z","comments":true,"path":"Android/View的绘制过程.html","link":"","permalink":"https://gowa2017.github.io/Android/View的绘制过程.html","excerpt":"虽然看了很多文章，但是不自己追踪看一下代码，还是不怎么给力。就从 Activity 的 setContentView() 开始来了解一下具体的工作流程。","text":"虽然看了很多文章，但是不自己追踪看一下代码，还是不怎么给力。就从 Activity 的 setContentView() 开始来了解一下具体的工作流程。 Activity.setContentView()public void setContentView(@LayoutRes int layoutResID) &#123; getWindow().setContentView(layoutResID); initWindowDecorActionBar();&#125; 在这里 getWindow() 会返回一个 Window 对象，这是一个最顶级的抽象类，我们可以认为这是手机屏幕显示最顶级的一个对象。在 Android 中，其只有一个实现： android.view.PhoneWindow。其源码位于 android.internal.policy.PhoneWindow 下。 Activity 只是负责生命周期的相关，而视图的绘制，则是 Window 来负责的。 PhoneWindow.setContentView()我先来了解一下 PhoneWindow 的几个成员。 DecorView mDecor; window 最顶级的视图，包含了 window 的修饰。本质上是一个 FrameLayout。 ViewGroup mContentParent; 放置我们定义布局的等。要么就是 mDecor 要么就是是 mDecor 的子视图。 LayoutInflater mLayoutInflater; 从上下文上来的布局扩展器 @Overridepublic void setContentView(int layoutResID) &#123; // Note: FEATURE_CONTENT_TRANSITIONS may be set in the process of installing the window // decor, when theme attributes and the like are crystalized. Do not check the feature // before this happens. if (mContentParent == null) &#123; installDecor(); &#125; else if (!hasFeature(FEATURE_CONTENT_TRANSITIONS)) &#123; mContentParent.removeAllViews(); &#125; if (hasFeature(FEATURE_CONTENT_TRANSITIONS)) &#123; final Scene newScene = Scene.getSceneForLayout(mContentParent, layoutResID, getContext()); transitionTo(newScene); &#125; else &#123; mLayoutInflater.inflate(layoutResID, mContentParent); &#125; mContentParent.requestApplyInsets(); final Callback cb = getCallback(); if (cb != null &amp;&amp; !isDestroyed()) &#123; cb.onContentChanged(); &#125; mContentParentExplicitlySet = true;&#125; mContentParent 是一个 ViewGroup 用来放我们的 layout 内的内容。如果 mContentParent 还挖初始化，就会安装一个。 如果已经初始化，那么删除其中的所有子视图， inflate 一下 layout 文件。 DecorViewPhoneWindow 有一个 DecorView 成员 mDecor。这个是所有视图显示的根，其本质，是一个 FrameLayout。 在我们 setContentView() 中首先会保证 DecorView 的存在。如果不存在，则会调用 installDecor() 方法。 mDecor 比较简单，直接 new 一个出来就行了。至于 DecorView 里面装了什么，我们还需要看一下其 generateLayout() 方法。 // 代码有省略 private void installDecor() &#123; mForceDecorInstall = false; if (mDecor == null) &#123; mDecor = generateDecor(-1); mDecor.setDescendantFocusability(ViewGroup.FOCUS_AFTER_DESCENDANTS); mDecor.setIsRootNamespace(true); if (!mInvalidatePanelMenuPosted &amp;&amp; mInvalidatePanelMenuFeatures != 0) &#123; mDecor.postOnAnimation(mInvalidatePanelMenuRunnable); &#125; &#125; else &#123; mDecor.setWindow(this); &#125; if (mContentParent == null) &#123; mContentParent = generateLayout(mDecor); // Set up decor part of UI to ignore fitsSystemWindows if appropriate. mDecor.makeOptionalFitsSystemWindows(); final DecorContentParent decorContentParent = (DecorContentParent) mDecor.findViewById( R.id.decor_content_parent); if (decorContentParent != null) &#123; mDecorContentParent = decorContentParent; mDecorContentParent.setWindowCallback(getCallback()); if (mDecorContentParent.getTitle() == null) &#123; mDecorContentParent.setWindowTitle(mTitle); &#125; &#125; &#125; &#125; generateLayout(DecorView decor)其本质，是根据 features 来选择内部的布局 id。然后，将此布局扩张后加到 DecorView 中。这些资源文件我们可以从 android-.data.res.layout 中来进行查看。 但是，无论哪个布局，其必定会含有 ID_ANDROID_CONTENT(com.android.internal.R.id.content) 这个 ID。 protected ViewGroup generateLayout(DecorView decor) &#123; // Inflate the window decor. int layoutResource; int features = getLocalFeatures(); // System.out.println(\"Features: 0x\" + Integer.toHexString(features)); if ((features &amp; (1 &lt;&lt; FEATURE_SWIPE_TO_DISMISS)) != 0) &#123; layoutResource = R.layout.screen_swipe_dismiss; setCloseOnSwipeEnabled(true); &#125; else if ((features &amp; ((1 &lt;&lt; FEATURE_LEFT_ICON) | (1 &lt;&lt; FEATURE_RIGHT_ICON))) != 0) &#123; if (mIsFloating) &#123; TypedValue res = new TypedValue(); getContext().getTheme().resolveAttribute( R.attr.dialogTitleIconsDecorLayout, res, true); layoutResource = res.resourceId; &#125; else &#123; layoutResource = R.layout.screen_title_icons; &#125; // XXX Remove this once action bar supports these features. removeFeature(FEATURE_ACTION_BAR); // System.out.println(\"Title Icons!\"); &#125; else if ((features &amp; ((1 &lt;&lt; FEATURE_PROGRESS) | (1 &lt;&lt; FEATURE_INDETERMINATE_PROGRESS))) != 0 &amp;&amp; (features &amp; (1 &lt;&lt; FEATURE_ACTION_BAR)) == 0) &#123; // Special case for a window with only a progress bar (and title). // XXX Need to have a no-title version of embedded windows. layoutResource = R.layout.screen_progress; // System.out.println(\"Progress!\"); &#125; else if ((features &amp; (1 &lt;&lt; FEATURE_CUSTOM_TITLE)) != 0) &#123; // Special case for a window with a custom title. // If the window is floating, we need a dialog layout if (mIsFloating) &#123; TypedValue res = new TypedValue(); getContext().getTheme().resolveAttribute( R.attr.dialogCustomTitleDecorLayout, res, true); layoutResource = res.resourceId; &#125; else &#123; layoutResource = R.layout.screen_custom_title; &#125; // XXX Remove this once action bar supports these features. removeFeature(FEATURE_ACTION_BAR); &#125; else if ((features &amp; (1 &lt;&lt; FEATURE_NO_TITLE)) == 0) &#123; // If no other features and not embedded, only need a title. // If the window is floating, we need a dialog layout if (mIsFloating) &#123; TypedValue res = new TypedValue(); getContext().getTheme().resolveAttribute( R.attr.dialogTitleDecorLayout, res, true); layoutResource = res.resourceId; &#125; else if ((features &amp; (1 &lt;&lt; FEATURE_ACTION_BAR)) != 0) &#123; layoutResource = a.getResourceId( R.styleable.Window_windowActionBarFullscreenDecorLayout, R.layout.screen_action_bar); &#125; else &#123; layoutResource = R.layout.screen_title; &#125; // System.out.println(\"Title!\"); &#125; else if ((features &amp; (1 &lt;&lt; FEATURE_ACTION_MODE_OVERLAY)) != 0) &#123; layoutResource = R.layout.screen_simple_overlay_action_mode; &#125; else &#123; // Embedded, so no decoration is needed. layoutResource = R.layout.screen_simple; // System.out.println(\"Simple!\"); &#125; mDecor.startChanging(); mDecor.onResourcesLoaded(mLayoutInflater, layoutResource); ViewGroup contentParent = (ViewGroup)findViewById(ID_ANDROID_CONTENT); if (contentParent == null) &#123; throw new RuntimeException(\"Window couldn't find content container view\"); &#125;&#125; 以 screen_title.xml 为例，其中 @android:id/content 就是我们 setContentView() 会设置的地方。 &lt;LinearLayout xmlns:android=\"http://schemas.android.com/apk/res/android\" android:orientation=\"vertical\" android:fitsSystemWindows=\"true\"&gt; &lt;!-- Popout bar for action modes --&gt; &lt;ViewStub android:id=\"@+id/action_mode_bar_stub\" android:inflatedId=\"@+id/action_mode_bar\" android:layout=\"@layout/action_mode_bar\" android:layout_width=\"match_parent\" android:layout_height=\"wrap_content\" android:theme=\"?attr/actionBarTheme\" /&gt; &lt;FrameLayout android:layout_width=\"match_parent\" android:layout_height=\"?android:attr/windowTitleSize\" style=\"?android:attr/windowTitleBackgroundStyle\"&gt; &lt;TextView android:id=\"@android:id/title\" style=\"?android:attr/windowTitleStyle\" android:background=\"@null\" android:fadingEdge=\"horizontal\" android:gravity=\"center_vertical\" android:layout_width=\"match_parent\" android:layout_height=\"match_parent\" /&gt; &lt;/FrameLayout&gt; &lt;FrameLayout android:id=\"@android:id/content\" android:layout_width=\"match_parent\" android:layout_height=\"0dip\" android:layout_weight=\"1\" android:foregroundGravity=\"fill_horizontal|top\" android:foreground=\"?android:attr/windowContentOverlay\" /&gt;&lt;/LinearLayout&gt; 现在我们明白布局来源的关系了。 Activity &lt;- PhoneWindow &lt;- DecorView &lt;- R.id.content Flags与Features在 generateLayout() 中，我发现了很多地方调用了 setFlags() 与 requestFeature() 两个方法。 首先获取到 Window 的 Style。TypedArray a = getWindowStyle(); 根据 a 中的值类设置各种 Flag 与 Feature。 一个是设置 Window 的标志，一个是开展一些扩展的属性。 public void setFlags(int flags, int mask) &#123; final WindowManager.LayoutParams attrs = getAttributes(); attrs.flags = (attrs.flags&amp;~mask) | (flags&amp;mask); mForcedWindowFlags |= mask; dispatchWindowAttributesChanged(attrs);&#125;public boolean requestFeature(int featureId) &#123; final int flag = 1&lt;&lt;featureId; mFeatures |= flag; mLocalFeatures |= mContainer != null ? (flag&amp;~mContainer.mFeatures) : flag; return (mFeatures&amp;flag) != 0;&#125; 到此，一个 Activity 算是建立完成了。 ActivityThread.handleResumeActivity()在要进行显示绘制的Activity的时候，会向 ActivityThread 发送一个 RESUME_ACTIVITY 消息： final void handleResumeActivity(IBinder token, boolean clearHide, boolean isForward, boolean reallyResume, int seq, String reason) &#123; ActivityClientRecord r = mActivities.get(token); if (!checkAndUpdateLifecycleSeq(seq, r, \"resumeActivity\")) &#123; return; &#125; // If we are getting ready to gc after going to the background, well // we are back active so skip it. unscheduleGcIdler(); mSomeActivitiesChanged = true; // TODO Push resumeArgs into the activity for consideration r = performResumeActivity(token, clearHide, reason); if (r != null) &#123; final Activity a = r.activity; if (localLOGV) Slog.v( TAG, \"Resume \" + r + \" started activity: \" + a.mStartedActivity + \", hideForNow: \" + r.hideForNow + \", finished: \" + a.mFinished); final int forwardBit = isForward ? WindowManager.LayoutParams.SOFT_INPUT_IS_FORWARD_NAVIGATION : 0; // If the window hasn't yet been added to the window manager, // and this guy didn't finish itself or start another activity, // then go ahead and add the window. boolean willBeVisible = !a.mStartedActivity; if (!willBeVisible) &#123; try &#123; willBeVisible = ActivityManager.getService().willActivityBeVisible( a.getActivityToken()); &#125; catch (RemoteException e) &#123; throw e.rethrowFromSystemServer(); &#125; &#125; if (r.window == null &amp;&amp; !a.mFinished &amp;&amp; willBeVisible) &#123; r.window = r.activity.getWindow(); View decor = r.window.getDecorView(); decor.setVisibility(View.INVISIBLE); ViewManager wm = a.getWindowManager(); WindowManager.LayoutParams l = r.window.getAttributes(); a.mDecor = decor; l.type = WindowManager.LayoutParams.TYPE_BASE_APPLICATION; l.softInputMode |= forwardBit; if (r.mPreserveWindow) &#123; a.mWindowAdded = true; r.mPreserveWindow = false; // Normally the ViewRoot sets up callbacks with the Activity // in addView-&gt;ViewRootImpl#setView. If we are instead reusing // the decor view we have to notify the view root that the // callbacks may have changed. ViewRootImpl impl = decor.getViewRootImpl(); if (impl != null) &#123; impl.notifyChildRebuilt(); &#125; &#125; if (a.mVisibleFromClient) &#123; if (!a.mWindowAdded) &#123; a.mWindowAdded = true; wm.addView(decor, l); &#125; else &#123; // The activity will get a callback for this &#123;@link LayoutParams&#125; change // earlier. However, at that time the decor will not be set (this is set // in this method), so no action will be taken. This call ensures the // callback occurs with the decor set. a.onWindowAttributesChanged(l); &#125; &#125; // If the window has already been added, but during resume // we started another activity, then don't yet make the // window visible. &#125; else if (!willBeVisible) &#123; if (localLOGV) Slog.v( TAG, \"Launch \" + r + \" mStartedActivity set\"); r.hideForNow = true; &#125; // Get rid of anything left hanging around. cleanUpPendingRemoveWindows(r, false /* force */); // The window is now visible if it has been added, we are not // simply finishing, and we are not starting another activity. if (!r.activity.mFinished &amp;&amp; willBeVisible &amp;&amp; r.activity.mDecor != null &amp;&amp; !r.hideForNow) &#123; if (r.newConfig != null) &#123; performConfigurationChangedForActivity(r, r.newConfig); if (DEBUG_CONFIGURATION) Slog.v(TAG, \"Resuming activity \" + r.activityInfo.name + \" with newConfig \" + r.activity.mCurrentConfig); r.newConfig = null; &#125; if (localLOGV) Slog.v(TAG, \"Resuming \" + r + \" with isForward=\" + isForward); WindowManager.LayoutParams l = r.window.getAttributes(); if ((l.softInputMode &amp; WindowManager.LayoutParams.SOFT_INPUT_IS_FORWARD_NAVIGATION) != forwardBit) &#123; l.softInputMode = (l.softInputMode &amp; (~WindowManager.LayoutParams.SOFT_INPUT_IS_FORWARD_NAVIGATION)) | forwardBit; if (r.activity.mVisibleFromClient) &#123; ViewManager wm = a.getWindowManager(); View decor = r.window.getDecorView(); wm.updateViewLayout(decor, l); &#125; &#125; r.activity.mVisibleFromServer = true; mNumVisibleActivities++; if (r.activity.mVisibleFromClient) &#123; r.activity.makeVisible(); &#125; &#125; if (!r.onlyLocalRequest) &#123; r.nextIdle = mNewActivities; mNewActivities = r; if (localLOGV) Slog.v( TAG, \"Scheduling idle handler for \" + r); Looper.myQueue().addIdleHandler(new Idler()); &#125; r.onlyLocalRequest = false; // Tell the activity manager we have resumed. if (reallyResume) &#123; try &#123; ActivityManager.getService().activityResumed(token); &#125; catch (RemoteException ex) &#123; throw ex.rethrowFromSystemServer(); &#125; &#125; &#125; else &#123; // If an exception was thrown when trying to resume, then // just end this activity. try &#123; ActivityManager.getService() .finishActivity(token, Activity.RESULT_CANCELED, null, Activity.DONT_FINISH_TASK_WITH_ACTIVITY); &#125; catch (RemoteException ex) &#123; throw ex.rethrowFromSystemServer(); &#125; &#125;&#125;","categories":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"}],"keywords":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}]},{"title":"Tomcat服务器架构","slug":"Tomcat服务器架构","date":"2019-03-31T14:55:41.000Z","updated":"2019-03-31T14:55:41.000Z","comments":true,"path":"Java/Tomcat服务器架构.html","link":"","permalink":"https://gowa2017.github.io/Java/Tomcat服务器架构.html","excerpt":"简单的了解一下其基本的容器，再配合配置文件来了解一下。","text":"简单的了解一下其基本的容器，再配合配置文件来了解一下。 术语Server在 Tomcat 的世界中， Server 代表了整个容器。 Tomcat 提供了了 Server 接口的一个默认实现，很少有用户会自定义 Server. Service一个 Service 存在于一个 Server 中，其是一个中间组件，其将多个 Connector 连接到一个 Engine。 Service 元素也很好由用户定义，默认的实现很简单但是也高效。 Engine一个 Engine 代表了对一特定 Service 的请求处理管道。一个 Service 可能有多个Connector， Engine 会处理所有 Connector 上的请求，并将请求返回到对应的 Connector 上去。 Engine 接口可能也会自定义来实现，但很不常见。 Host一个 Host 是一个网络名称与此 Tomcat 服务器的关联。 Engine 可有多个 Hosts，Host 元素也支持别名。用户很少自定义 Host ，因为默认的实现提供了很重要的附件功能。 Connector管理与客户端的连接。Tomcat 内会有多个 Connector，所有的 Connector 都实现了接口 Connector。包括 Coyote Connector （用来支持大部分 HTTP 流量，特别是当将 Tomcat 作为一个独立服务器时）， JK2 Connector（实现了 AJP 协议，用来连接 Tomcat 到 Apache HTTPD 服务器） ContextContext 代表了一个网页应用。一个 Host 可能会有多个 Context，每个都有一个唯一的路径。 Context 接口可以自定义进行实现，但是很少。因为默认的有很重要的附加功能。 配置示例ContextContext 代表了一个 网页应用（Web Application），其运行于一个 Host 下面。每个 网页应用 都基于一个 Web Application）Archive(WAR) 文件，或者是一个对应的包含了已解压文件的目录，可以参考 Servlet 规范来了解。 Catalina 通过最长匹配请求的 URI 与 Context 路径来找出使用哪个 网页应用来处理请求。一旦选定， Context 就会选择一个 Servlet 来处理进入的请求，查找顺序及内容根据在 web application deployment descriptor 文件（必须位于网页应用层级内的 /WEB-INF/web.xml）定义的 servlet 映射。 可以定义任意数量的 Context。但每个 Context 必须有唯一的路径。但路径是一个 0 长度的字符串的时候，那么这个就是默认 Context 。没有匹配上任何其他 Context 的请求都会由此 Context 进行处理。 Context 可能会定义下下面几个地方： $CATALINA_HOME/conf/context.xml。 所有的 webapps 都会加载。 $CATALINA_HOME/conf/[enginename]/[hostname]/context.xml.defalut。 特定 Host 下 特定的 Engine 加载。 $CATALINA_HOME/conf/[enginename]/[hostname]/ 目录下的 .xml 文件中。 当上面几个文件都不存在的情况下，会复制 /META-INFO/context.xml server.xml 中的 Host 元素下。 web.xml前面说到， Tomcat 会根据最长路径匹配来选择 Context ，然后 Context 会根据其定义的 Servlet 映射来选择对应的Servlet 来处理请求。 这些 Servlet 就是在 web.xml 中进行定义配置的。 https://docs.oracle.com/cd/B14099_19/web.1012/b14017/filters.htm 有几种类型的元素： context-param 一些变量 [event] listener 事件监听器 [servlet] filter 用来预处理请求或者后处理响应。 filter-mapping servlet servlet-mapping error-page jsps Servlets 与 URL 路径web.xml 定义了 URL 路径与 Servlet 的映射。 Spring MVC web.xml对于 Spring MVC 而言，有一个最重要的 DispatcherServlet。 可以看到，使用不同的配置文件，针对不同的路径，对其进行了不同的定义。分别为 不过我们主要用了第一个。 &lt;servlet&gt; &lt;servlet-name&gt;springServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath*:/spring/spring-mvc*.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;springServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; &lt;servlet&gt; &lt;servlet-name&gt;ModelRestServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;/act/rest/spring-mvc-modeler.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;ModelRestServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/service/*&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; &lt;servlet&gt; &lt;servlet-name&gt;RestServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;/act/rest/spring-mvc-rest.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;RestServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/rest/*&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 那么，根据前文的描述，最终请求都会到达 DispatcherServlet 中进行处理，而如何处理，在前面一篇文章中已经进行了描述 FilterFilter 是用来预处理请求及后处理响应的。在 Servlet 容器调用 Servlet 一个方法的时候，HTTP 请求默认情况是直接传输给 Servlet。而 Servlet 产生的响应也是直接发送到客户端的，容器不会对内容进行任何的修改。在这种场景下，Servlet 必须处理请求并产生所有的响应。 但有的时候，预处理请求会非常的有用。有的时候，从一个 Servlet 的类中修改响应也有有用。加密就是一个例子。如果 Servlet 产生比较敏感的数据，那么这些数据以可读的形式在网络上传输。一个 Filter 就能加密响应。当然，这要求客户端能够进行解密内容。 Filter 不是 Servlet，他们不会重写 HttpServlet 的方法，例如 doGet(), doPost()。Filter 只是实现了接口 javax.servlet.Filter。 init() destroy() doFilter() 如何调用 Filter Filter 调用的顺序依赖于在 web.xml 中出现的顺序。而响应的顺序则恰好相反。 Evnet Listenerservlet 规范包含了跟踪关键事件的能力，这就是通过 event listener 来实现的。 有两个级别的 listener Servlet 上下文级别（application-level）事件 这些事件应用servlet 上下文对象上调用资源或状态。 Session-level 事件 在 HTTP Session 对象上调用的事件。 每个级别的事件都有两种事件分类： 生命周期改变 属性改变。 初始化我们应用中的 web.xml 中定义的 servlet 会进行初始化。我们重点看一下 dispatchServlet。 其继承层级： DispatcherServlet &lt;- FrameworkServlet &lt;- HttpServletBean &lt;- HttpServlet &lt;- GenericServlet HttpServlet 之上久是规范定义的了。所以 Spring 是从 HttpServletBean 开始关注的。 Servlet.init() 会被调用以进行初始化。 HttpServletBean.init()此方法会将 web.xml 中配置的属性映射到 ServletBean 的属性中，及中调用子类的初始化方法。 @Overridepublic final void init() throws ServletException &#123; if (logger.isDebugEnabled()) &#123; logger.debug(\"Initializing servlet '\" + getServletName() + \"'\"); &#125; // Set bean properties from init parameters. try &#123; PropertyValues pvs = new ServletConfigPropertyValues(getServletConfig(), this.requiredProperties); BeanWrapper bw = PropertyAccessorFactory.forBeanPropertyAccess(this); ResourceLoader resourceLoader = new ServletContextResourceLoader(getServletContext()); bw.registerCustomEditor(Resource.class, new ResourceEditor(resourceLoader, getEnvironment())); initBeanWrapper(bw); bw.setPropertyValues(pvs, true); &#125; catch (BeansException ex) &#123; logger.error(\"Failed to set bean properties on servlet '\" + getServletName() + \"'\", ex); throw ex; &#125; // Let subclasses do whatever initialization they like. initServletBean(); if (logger.isDebugEnabled()) &#123; logger.debug(\"Servlet '\" + getServletName() + \"' configured successfully\"); &#125;&#125; FrameworkServlet.initServletBean()此方法的目的是建立 Web 应用的上下文。 @Overrideprotected final void initServletBean() throws ServletException &#123; getServletContext().log(\"Initializing Spring FrameworkServlet '\" + getServletName() + \"'\"); if (this.logger.isInfoEnabled()) &#123; this.logger.info(\"FrameworkServlet '\" + getServletName() + \"': initialization started\"); &#125; long startTime = System.currentTimeMillis(); try &#123; this.webApplicationContext = initWebApplicationContext(); initFrameworkServlet(); &#125; catch (ServletException ex) &#123; this.logger.error(\"Context initialization failed\", ex); throw ex; &#125; catch (RuntimeException ex) &#123; this.logger.error(\"Context initialization failed\", ex); throw ex; &#125; if (this.logger.isInfoEnabled()) &#123; long elapsedTime = System.currentTimeMillis() - startTime; this.logger.info(\"FrameworkServlet '\" + getServletName() + \"': initialization completed in \" + elapsedTime + \" ms\"); &#125;&#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/tags/Java/"},{"name":"Tomcat","slug":"Tomcat","permalink":"https://gowa2017.github.io/tags/Tomcat/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}]},{"title":"SpringMVC是怎么样工作的","slug":"SpringMVC是怎么样工作的","date":"2019-03-31T02:10:17.000Z","updated":"2019-03-31T02:10:17.000Z","comments":true,"path":"Java/SpringMVC是怎么样工作的.html","link":"","permalink":"https://gowa2017.github.io/Java/SpringMVC是怎么样工作的.html","excerpt":"偶尔看到一篇对 SpringMVC 讲得很好的文章。原文地址在 https://stackify.com/spring-mvc/","text":"偶尔看到一篇对 SpringMVC 讲得很好的文章。原文地址在 https://stackify.com/spring-mvc/ ServletTomcat 是一个 Servlet 容器，很自然地，每个发送到 Tomcat 网页服务器的请求都会一个 Java Servlet 处理。所以呢 Spring 网页应用的入口就是 Servlet。 简单来说，一个 Servlet 就是 一个 Java 网页应用中的一个核心组件；其是一个底层概念，不会在特定的编程模式上涉及太多。 一个 HTTP Servlet 只能接收一个 HTTP 请求，处理，然后发回一个响应。 DispatcherServletDispatcherServlet 是 Spring MVC 的核心。 对于一个网页应用程序开发者来说最想做的事情就是把下面这些非常无聊而重复的任务和有用的业务逻辑分开： 将一个 HTTP 请求映射到一个特定的处理方法 解析 HTTP 的请求数据和请求头到 DTOs（数据传输对象） 或者 domain 对象。 MVC 间的交互 对 DTOs, domain 对象生成响应。 DispatcherServlet 干的就是上面这些事情， 其就是 Spring MVC 的核心，接收所有到我们应用请求的核心组件。 DispatcherServlet 是可扩展的，其允许我们对很多任务插入已存在的或者新的适配器。 将请求映射到一个处理此请求的类或方法（实现 HandlerMapping 接口）。 使用一个特定的模式来处理请求，比如一个常规 servlet，一个复杂点的 MVC 工作流，或者只是一个 POJO bean 中的方法。（实现 HandlerAdapter 接口） 通过名称来解析 Views，允许我们使用不同的模板引擎，XML,XSLT或者其他的 View 技术（实现 ViewResolver 接口） 使用默认的 Apache Common File uploading 实现来解析多部分的请求，或者，编写我们自己的 MultipartResolve。 使用 LocaleResolver 来解析 locale。包括 cookie, session, header等。 HTTP 请求处理过程首先，让我们来追踪一下到我们的控制层中的并返回到浏览器（前端）的简单 HTTP 请求， DispatcherServlet 的继承层级很深，但很值得深入探究一下。 GenericServlet &lt;- HttpServlet &lt;- HttpServletBean &lt;- FrameworkServlet &lt;-DispatcherServlet GenericServletGenericServlet 是 Servlet 规范的一部分，并不直接关注 HTTP。你定义了一个接收所有的请求并产生响应的 service() 方法。 public abstract void service(ServletRequest req, ServletResponse res) throws ServletException, IOException; ServletRequest，ServletResponse 方法参数与 HTTP 协议没有什么关系。 每个请求到达服务器的时候都会调用这个方法。 HttpServletHttpServlet 关注 HTTP 的实现，也是规范的一部分。 更实际点来说，HttpServlet 是一个实现了 service() 方法的抽象类。这个方法，通过 HTTP 的方法类型来分隔请求，看起来似乎是这样： protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; String method = req.getMethod(); if (method.equals(METHOD_GET)) &#123; // ... doGet(req, resp); &#125; else if (method.equals(METHOD_HEAD)) &#123; // ... doHead(req, resp); &#125; else if (method.equals(METHOD_POST)) &#123; doPost(req, resp); // ... &#125; HttpServletBeanHttpServletBean 是在层级中第一个 Spring 关注的类。 Spring 使用 web.xml 或 WebApplicationInitializer 中的 init-param 值来注入 bean 的属性。 对于到达应用的请求，doGet(), doPost() 会根据请求类型来被调用。 FrameworkServletFrameworkServlet 用一个 应用程序上下文来整合了 Servlet 功能，实现了 ApplicationContextAware 接口。当然，创建一个自己的 应用程序上下文也是可以的。 上面说到，HttpServletBean 会用 init-params 来注入 bean 属性。所以，如果在此 servlet 中一个上下文类名在 contextClass init-params 参数中提供，那么指定的类就会创建一个实例来作为应用的上下文。否则的话，使用一个默认的 XmlWebApplicationContext 实例。 一个 XML 配置已经过时了， Spring Boot 默认 通过 AnnotationConfigWebApplicationContext 来配置 DispatcherServlet 。当然，我们也可以进行修改。 DispatcherServlet 统一请求处理HttpServlet.service()方法通过 HTTP 的动词类型（get,post）来路由请求，在底层 servlet 上环境中工作得很好。然而，在 Spring MVC 这个级别的抽象，方法类型只是可以用来进行映射请求到处理器的一个参数。 因此，FrameworkServlet 类的另外一个主要功能是将处理逻辑放到单一的 processRequest() 方法中，其会按序调用 doService()方法。 @Overrideprotected final void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; processRequest(request, response);&#125;@Overrideprotected final void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; processRequest(request, response);&#125;// … DispatcherServlet: 丰富请求最后，DispatcherServlet() 实现了 doService() 方法。在这里，其会给请求添加上一些有用的对象，在接下来的处理过程中有利于我们的处理过程：应用上下文，区域解析器，主题解析器，主题源等等。 request.setAttribute(WEB_APPLICATION_CONTEXT_ATTRIBUTE, getWebApplicationContext());request.setAttribute(LOCALE_RESOLVER_ATTRIBUTE, this.localeResolver);request.setAttribute(THEME_RESOLVER_ATTRIBUTE, this.themeResolver);request.setAttribute(THEME_SOURCE_ATTRIBUTE, getThemeSource()); 同样，doService()方法会这样好输入和输出快速映射(Flash Map)。 Flash Map 基本上是一个用来在请求间立刻传递参数的模式。这在有的时候会只有用，比如重定向。 FlashMap inputFlashMap = this.flashMapManager .retrieveAndUpdate(request, response);if (inputFlashMap != null) &#123; request.setAttribute(INPUT_FLASH_MAP_ATTRIBUTE, Collections.unmodifiableMap(inputFlashMap));&#125;request.setAttribute(OUTPUT_FLASH_MAP_ATTRIBUTE, new FlashMap()); 接着 doService() 会调用 doDispatch() 方法进行请求分发。 DispatcherServlet：请求分发dispatch() 的主要目的是：找出请求的处理器，将请求/响应参数传递过去。 handler 可以是任意类型的对象，而不局限于一个特定的接口。这就意味着，Spring 需要找到一个知道如何与 handler 对话的 adapter。 为了找到与请求匹配的 handler， Spring 会遍历所有已注册的 HandlerMapping 接口的实现。实现的类型有很多种。 SimpleUrlHandlerMapping 允许将一个请求的URL 映射到一个特定的处理 bean。例如，可以通过将一个 java.util.Properties实例注入到 mappings 属性中： /welcome.html=ticketController/show.html=ticketController 可能使用最广泛的 handler 映射是 RequestMappingHandlerMapping了，其将一个请求映射到一个@Controller 注解的类中，一个 @RequestMapping 注解的方法上。 注意，Spring 关注的方法是用 @GetMapping, @PostMapping 对应注解的。这些注解，通过 @RequestMapping 元注解来标记。 doDispatch() 方法也会关心一些其他 HTTP 相关的任务。 请求处理现在，Spring 决定了请求的handler，业绩 handler 的 adapter，是时候最终处理这个请求了。下面是 HandlerAdapter.handle() 方法的签名。注意到 handler 可以选择怎么处理请求很重要： 向响应写入数据或者返回 null 返回一个 ModleAndView 对象，由 DispatcherServlet 渲染 @NullableModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception; 这里有几种类型的 handler。 下面演示的是 SimpleControllerHandlerAdapter 如何处理一个 Spring MVC 中控制器实例的（不要与 @Controller 注解的 POJO 混淆）。 控制器中的处理器返回的 ModelAndView 对象不会被自身渲染，而是由 DispatchServlet 渲染： public ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; return ((Controller) handler).handleRequest(request, response);&#125; 第二个是 SimpleServletHandlerAdapter，它会将一个常规的 Servlets 改为一个请求 handler。 一个 Servlet 对于 ModelAndView 是一点也不清楚的，其只是简单的处理一下请求，将结果渲染到响应对象中。所以，这个 adapter 返回 null 而不是 ModelAndView。 public ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; ((Servlet) handler).service(request, response); return null;&#125; 在我们的情况中，控制器是一个 POJO，然后方法上使用了 @RequestMapping 注解，所以每个 handler 都是控制器类的一个方法。对于这样的 handler 类型， Spring 使用 RequestMappingHandlerAdapter 类。 处理参数及Handler方法的返回值通常，控制器中的 handler 方法，并不会使用 HttpServletRequest, HttpServletResponse 作为参数，而是会使用很多其他的类型，比如 domain 对象，路径参数等等。 同时，在控制器方法中，我们并不一定需要返回一个 ModleAndView 实例。我们可能会返回一个 View 名称，一个 ResponseEntity 或者一个将会被转换为 JSON 响应的 POJO。 RequestMappingHandlerAdapter 保证 handler 方法的参数从 HttpServletRequest 内进行解析，同时，根据 handler 方法的返回值来创建 ModelAndView。 下面这些位于 RequestMappingHandlerAdapter 中的代码保证了上述的实现： ServletInvocableHandlerMethod invocableMethod = createInvocableHandlerMethod(handlerMethod);if (this.argumentResolvers != null) &#123; invocableMethod.setHandlerMethodArgumentResolvers( this.argumentResolvers);&#125;if (this.returnValueHandlers != null) &#123; invocableMethod.setHandlerMethodReturnValueHandlers( this.returnValueHandlers);&#125; argumentResolvers 对象是一个不同 HandlerMethodArgumentResolver 实例的复合。 这里有超过 30 种不同的参数解析器实现。他们允许从请求中解压出任何形式的信息，同时将其提供给 handler 方法。参数包括： URL 路径变量，请求体参数，请求头，cookies, session 等。 returnValueHandlers 对象是 HandlerMethodReturnValueHandler 对象的复合。同样也有很多种不同的 value handlers，他们能处理方法的返回值，然后创建 adapter 需要的 ModelAndView 对象。 具体而言，但我们从 hello() 方法中返回字符串，使用的是 ViewNameMethodReturnValueHandler 来处理返回值。但是当我们从 login() 返回一个 ModelAndView 的时候，Spring 使用的是 ModelAndViewMethodReturnValueHandler 来进行处理。 渲染 View到现在，Spring 已经处理完 HTTP 请求，同时有了一个 ModelAndView 对象，接下来就必须渲染出 HTML 网页到浏览器给用户。这个基于 ModelAndView 对象中的 model 及封装好的视图。 同时要注意到，我们可能会渲染一个 JSON 对象，或者 XML，或者其他任何能通过 HTTP 协议传输的类型数据。我们会在接下来的REST-一节中进行介绍。 回到 DispatcherServlet ，render() 方法会首先通过 LocaleResolver 实例来设置区域。我们现在来假设我们使用的浏览器正确的设置了 Accpet 头，那么默认情况下会使用 AcceptHeaderLocaleResolver。 在渲染期间，ModelAndView 对象可能已经包含了一个对选定 View 的引用，或者只是一个 View 名称，也可能什么都没有（此时依赖于一个默认的 view）。 因为 hello(), login() 方法都将期望的视图通过字符串名称来指定，必须通过这个名称来进行查找。所以，这就是 ViewResolver 列表开始表演的地方。 for (ViewResolver viewResolver : this.viewResolvers) &#123; View view = viewResolver.resolveViewName(viewName, locale); if (view != null) &#123; return view; &#125;&#125; 这是一个 ViewResolver 实例的列表，包括了 ThymeleafViewResoleve（thymeleaf-spring5集成库提供）。这个 resolver 知道去哪里查找 View，然后返回对应的 View 实例。 在调用了 View 的 render() 方法后，Spring 通过将 HTML 页面发送到用户的浏览器来完结请求。 REST 支持在典型的 MVC 场景之外，我们一样可以用这个框架来建立 REST 网页服务。 简单来说，你可以接受一个资源作为输入，指定一个 POJO 作为方法参数，用 @RequestBody 进行注解。也可以将此方法加上 @ResponseBody 注解来表示其结果必须直接通过转换为一个 HTTP 响应。 import org.springframework.web.bind.annotation.RequestBody;import org.springframework.web.bind.annotation.ResponseBody;@ResponseBody@PostMapping(\"/message\")public MyOutputResource sendMessage( @RequestBody MyInputResource inputResource) &#123; return new MyOutputResource(\"Received: \" + inputResource.getRequestMessage());&#125; 为了将内部的 DTOs 转换为 REST 表示，框架使用了 HttpMessageConverter 架构。例如，实现中的一个例子是 MappingJackson2HttpMessageConverter，其能将 model 对象和 JSON 对象间通过 Jackson 库进行转换。 为了简化 REST API 的创建，Spring 介绍了 @RestController 注解。 这对默认会使用 @ResponseBody 语义来说非常的方便，避免了在每个 REST 控制器上进行显式的设置。 import org.springframework.web.bind.annotation.RestController;@RestControllerpublic class RestfulWebServiceController &#123; @GetMapping(\"/message\") public MyOutputResource getMessage() &#123; return new MyOutputResource(\"Hello!\"); &#125;&#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/tags/Java/"},{"name":"Spring","slug":"Spring","permalink":"https://gowa2017.github.io/tags/Spring/"},{"name":"SpringMVC","slug":"SpringMVC","permalink":"https://gowa2017.github.io/tags/SpringMVC/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}]},{"title":"对于TextView或者普通的View应用Selector","slug":"对于TextView或者普通的View应用Selector","date":"2019-03-24T13:53:26.000Z","updated":"2019-03-24T13:53:26.000Z","comments":true,"path":"Android/对于TextView或者普通的View应用Selector.html","link":"","permalink":"https://gowa2017.github.io/Android/对于TextView或者普通的View应用Selector.html","excerpt":"","text":"说是 Selector ，其实在官方的定义中，有两个概念。 ColorStateList 与 StateListDrawable 两个概念。一个是根据对象的状态来改变颜色，而一个是根据状态的对象来绘制的内容。ColorStateList 位于 res/colors/.xml 中，StateListDrawable 位于 res/drawable/.xml 中 起因TabHost 是很好的，但是用来做标签页的时候感觉麻烦了点。我完全可以根据选中的状态来更新我的 Tab 显示。更换前后背景色，字体颜色。 ColorStateList语法&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;selector xmlns:android=\"http://schemas.android.com/apk/res/android\" &gt; &lt;item android:color=\"hex_color\" android:state_pressed=[\"true\" | \"false\"] android:state_focused=[\"true\" | \"false\"] android:state_selected=[\"true\" | \"false\"] android:state_checkable=[\"true\" | \"false\"] android:state_checked=[\"true\" | \"false\"] android:state_enabled=[\"true\" | \"false\"] android:state_window_focused=[\"true\" | \"false\"] /&gt;&lt;/selector&gt; 状态根据名字就能明白其意义： pressed 按下 focused 获取焦点 selected 选中 Tab checkable 可选 CheckBox checked 已选 CheckBox enable 启用 state_window_focused 应用窗口获取焦点。 我们在 layout 中，对于 TextView 应用 android:color=@color/tv_state_color 即可应用我们定义的状态颜色列表了。 当然，由于TextView 是没有状态的，所以我只设置了 selected 的状态色。然后在 Java 代码中手动设置了视图的选中状态。 StateListDrawable语法： &lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;selector xmlns:android=\"http://schemas.android.com/apk/res/android\" android:constantSize=[\"true\" | \"false\"] android:dither=[\"true\" | \"false\"] android:variablePadding=[\"true\" | \"false\"] &gt; &lt;item android:drawable=\"@[package:]drawable/drawable_resource\" android:state_pressed=[\"true\" | \"false\"] android:state_focused=[\"true\" | \"false\"] android:state_hovered=[\"true\" | \"false\"] android:state_selected=[\"true\" | \"false\"] android:state_checkable=[\"true\" | \"false\"] android:state_checked=[\"true\" | \"false\"] android:state_enabled=[\"true\" | \"false\"] android:state_activated=[\"true\" | \"false\"] android:state_window_focused=[\"true\" | \"false\"] /&gt;&lt;/selector&gt; 唉差不多一个意思了。详细参考这里 Shape可以利用形状来绘制各种我们需要的内容。比如圆角啊，光标啊，椭圆等等。 &lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;shape xmlns:android=\"http://schemas.android.com/apk/res/android\" android:shape=[\"rectangle\" | \"oval\" | \"line\" | \"ring\"] &gt; &lt;corners android:radius=\"integer\" android:topLeftRadius=\"integer\" android:topRightRadius=\"integer\" android:bottomLeftRadius=\"integer\" android:bottomRightRadius=\"integer\" /&gt; &lt;gradient android:angle=\"integer\" android:centerX=\"float\" android:centerY=\"float\" android:centerColor=\"integer\" android:endColor=\"color\" android:gradientRadius=\"integer\" android:startColor=\"color\" android:type=[\"linear\" | \"radial\" | \"sweep\"] android:useLevel=[\"true\" | \"false\"] /&gt; &lt;padding android:left=\"integer\" android:top=\"integer\" android:right=\"integer\" android:bottom=\"integer\" /&gt; &lt;size android:width=\"integer\" android:height=\"integer\" /&gt; &lt;solid android:color=\"color\" /&gt; &lt;stroke android:width=\"integer\" android:color=\"color\" android:dashWidth=\"integer\" android:dashGap=\"integer\" /&gt;&lt;/shape&gt; 这里解释一下几个选项就OK corners 圆角半径 gradient 渐变 size 大小 solid 填充色 stroke 绘制的画笔颜色。","categories":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"},{"name":"Selector","slug":"Selector","permalink":"https://gowa2017.github.io/tags/Selector/"}],"keywords":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}]},{"title":"Bash中对字符的操作","slug":"Bash中对字符的操作","date":"2019-03-24T12:05:22.000Z","updated":"2019-03-24T12:05:22.000Z","comments":true,"path":"Linux/Bash中对字符的操作.html","link":"","permalink":"https://gowa2017.github.io/Linux/Bash中对字符的操作.html","excerpt":"问题的来源是在安卓开发的时候，美工更换了各种图标。需要进行替换。但是有一个蛋疼的问题就是，我们的 app 是分渠道的，有的资源是公用的，所以名称也是一致。我不能将图标进行替换，因为那样会影响其他渠道的图标显示。但是当我将图标放到渠道包的资源目录下的时候，因为出现了一个苦恼的问题。因为美工不专业，做的图标是 xhdpi的，那么如果是在 xxhdpi 或者是 xxhdpi 的分辨率下，读取的将不是我放在渠道包的 xhdpi 下的图标。","text":"问题的来源是在安卓开发的时候，美工更换了各种图标。需要进行替换。但是有一个蛋疼的问题就是，我们的 app 是分渠道的，有的资源是公用的，所以名称也是一致。我不能将图标进行替换，因为那样会影响其他渠道的图标显示。但是当我将图标放到渠道包的资源目录下的时候，因为出现了一个苦恼的问题。因为美工不专业，做的图标是 xhdpi的，那么如果是在 xxhdpi 或者是 xxhdpi 的分辨率下，读取的将不是我放在渠道包的 xhdpi 下的图标。 因此，就想着将此图标改个名字。但是图标都是很多的哦，总不能一个个 命名吧。所以准备把文件名都加上一个 _new 来表示新的UI。 最终来说，很简单就能实现了： for f in `ls *.png`; do mv $f $&#123;f/%.png/_new.png&#125;; done 同时又来查阅了一下其操作方法。 参数替换TLDP上的文档 对于一个变量，我们可以用 ${var[:-+?=]default} 的形式来进行使用。 ${parameter-default} 如果 parameter(变量) 没有设置（声明），就使用 default （字符） ${parameter=default} 如果 parameter(变量) 没有设置（声明），则将 parameter 的值设置为 default（字符） ${parameter+alt_value} 如果 parameter 已经设置（声明），使用 alt_value（字符），否则使用 null 字符。 ${parameter?err_msg} 如果 parameter 没有设置，就会打印错误消息 err_msg，同时以退出状态 1 结束脚本。如果已设置，就使用他。 : 可以用在 -=+ 前，表示将已声明但值为 null 也进行匹配。 长度/子字符 ${&#35;parameter} 得出字符长度。 ${var#Pattern} 移除到 Pattern 的匹配在短的地方。echo ${PWD#*/} ${var##Pattern} 移除到 Pattern 匹配最长的地方。echo ${PWD##*/} ${var%Pattern} 最短匹配，从右至左 echo ${PWD%/*} ${var%%Pattern} 最长匹配，从右至左。echo ${PWD%%/*} 变量扩展/替换 ${var:pos} 截短 pos 前的内容 ${PWD:8} ${var:pos:len} 从 pos 处开始，截取 len 个字符 ${PWD:8:2} ${var/Pattern/Replacement} 替换一次 ${var//Pattern/Replacement} 全部替换 ${var/#Pattern/Replacement} 匹配开头进行替换。${PWD/#\\/Users/\\/What} ${var/%Pattern/Replacement} 匹配结尾进行替换。${PWD/%\\/source/\\/What} ${!varprefix*}, ${!varprefix@} 所有以 varprefix 开头的变量。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/tags/Linux/"},{"name":"Shell","slug":"Shell","permalink":"https://gowa2017.github.io/tags/Shell/"},{"name":"Bash","slug":"Bash","permalink":"https://gowa2017.github.io/tags/Bash/"}],"keywords":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}]},{"title":"用OminiFocus做一个自己的事务管理系统","slug":"用OminiFocus做一个自己的事务管理系统","date":"2019-03-21T00:05:54.000Z","updated":"2019-03-21T00:05:54.000Z","comments":true,"path":"GTD/用OminiFocus做一个自己的事务管理系统.html","link":"","permalink":"https://gowa2017.github.io/GTD/用OminiFocus做一个自己的事务管理系统.html","excerpt":"之前用过滴答清单，发觉过滤器不是那么好用。所以就试用了一下 OminiFocus 这个被广大群众推荐的工具。事实上这个工具的入门有点让人苦恼，首先要对 GTD 的概念有一个明确的框架概念才能好好的用起来。","text":"之前用过滴答清单，发觉过滤器不是那么好用。所以就试用了一下 OminiFocus 这个被广大群众推荐的工具。事实上这个工具的入门有点让人苦恼，首先要对 GTD 的概念有一个明确的框架概念才能好好的用起来。 对于 GTD 介绍，GTD 只是一套理解和规则，掌握了他的理论及规则，用什么工具都可以实现 GTD。就比如书上，就是用文件夹，便签等来处理也是可以的。 流程图 没找到书上的图片，就把别人画的弄过来，其实是一样的。 GTD 一书都是根据这个流程来进行讲解的，很多人觉得这书太过啰嗦了，但其实对于理解一下为什么那样做，确实是很有必要啰嗦详细介绍的。但是当我们理解了之后，就不再需要那么详细的东西了，将其概括为我们自己的行动就行了。 目的建立一个 GTD 目的： 解放大脑，不要让我们的脑海里面存在很多“悬而未决”的事务而降低效率。 在不同的情境（环境，时间，工具）下能立刻知道，并能立刻执行一个动作，推动事务的完成。 有效的回顾和跟踪自己事务的完成情况。 基于上面三个目的，简单的几个步骤就是： 收集。将所有的想法，待办事项到一个地方。 Ominifocus 中，叫做 Inbox 处理。在 Inbox 中的内容，我们应该抽时间及时进行清空。如何清空？考虑每一条记录下一个确切的动作应该是什么；如果有多个动作的，还要将其转换为项目。 清单。我们将 Inbox 中的所有事务的下一步动作都整理好后，根据不同的场景或我们自己的要求来定义对应的清单。这里，就会用到 OminiFocus 的透视功能。 回顾。系统需要不停的完善，事务的完成情况需要不断的进行跟踪，委派他人的事项需要进行跟进。 项目的定义必须多个动作才能完成的一个事务，叫做项目。 收集通过 mail drop 来将所有的待办事务进行收集到 Inbox。 处理事实上这是最难的一步。我们必须提交的安排和判断，对于每个事务我们的下一步动作是什么，这（些）动作需要在什么时候完成，需要多少时间，要什么工具才能完成。 对于暂时不需要完成的动作，我们该怎么处理？是丢弃还是归档，还是抽时间进行阅读？还是需要在有用的时候进行参考？ 一个只需要两分钟就能完成的动作，请立刻执行。 对于自己不是最适合完成这个动作的，委派给最适合完成的人完成，自己进行跟踪。 分类对于我们的每个事务，如果需要多个动作的，那么需要转换为项目。是不是上很多时候，我们的事务都需要多个动作，而不是可以一下子完成的。所以有必要将我们的项目（多个动作），或单个动作进行分类。这利用到了 OminiFocus 的 文件夹（Folder） 功能。如何分类，完全看自己的需求。就我而言，完将其分为： 工作 生活 学习 。。。。 这是一个比较大的一级分类，比如工作，其下可以根据工作的类型：执行，沟通，反馈；或者是开发，BUG 等等。。全看自己如何进行组织。 是按性质，还是按项目进行分类，这是一个比较艰难的抉择。但只有自己保持一个清晰的概念，这不是一个特别重大的问题。当你在对 Inbox 事务进行处理的时候，不要因此犹豫该放在什么地方就OK了。 附加属性OminFoucs 对每个动作，都提供了一些额外附加的属性。大体分为： 状态。活跃，完成，标注 标签。自定义 日期。持续时间，推迟日期，截止日期 重复 。。。 其提供的过滤器，可以对上面的这些属性进行过滤，形成透视。 OminiFocus 术语有必要了解一下其术语，方才能更好的设计我们的系统。 具体完整的列表查看 这里 Item 条目：Ominifocus 数据库中对任务和待办事项的表示。条目类型包括：Inbox 条目，动作，项目，分组。 Available 可用性：一种条目状态和包括未被屏蔽，推迟和暂停的条目视图选项。 Blocked 屏蔽：在一个序列化项目中的非第一个可用动作状态，根据在项目中的位置来计算。通过移动动作的位置到最上面可以改变这个状态。 On Hold 暂停：与我们当前的计划不相关的项目或标签的状态。 过滤器虽然当前其提供了不少的过滤器，但是实际上还是有局限性的，我们为了更符合自己的要求，不能不设计一套适合自己用的标签系统。 从上面的过滤选项来看，其大体分为： 动作状态 可用性 截止日期 持续时间 标签状态 活跃标签是否有可用动作 标签 项目状态 活跃项目是否有可用性动作 归属文件夹或项目 项目状态Due Soon，即将截止，关于这个 Due Soon 默认定义的是 2 天内。Flagged 表示标注为重要事项。 可用性动作的可用性从 推迟日期，项目类型，项目或标签的状态 进行计算。 有几种情况： First Available：第一个可用。 Available：可用 Remaining：等待。表示未完成或丢弃的条目。 Completed：完成 标签与项目标签与项目都是有状态的。活跃，完成，暂停。完成，丢弃。 透视将 Inbox 中的条目进行处理过后，我们已经有了一大串的动作列表。我现在关注的问题是，在不同的环境，不同的条件下： 我该干什么。 更细致一点，如果我现在只有20分钟，我需要在我该干的事务中找出 我现在能干什么 而有的事情，我们必须得在特定的时间完成，所以我还需要知道： 我必须干完什么。 所以我们可以把事务分为： 有截止日期的 Due 需要尽快执行的 使用标签：Schedule 委派他人完成需要跟进的 使用标签 AssignTo 时间不迫切，但是需要做的。 Recently 时间充足的时候可以做一下的 SomeDay 动作的执行优先级： 标签 Schedule Today ThisWeek ThisMonth Recently AssignTo Json Jack …. 工作清单Today过滤出 Due Soon （我定义为当天，拥有截止日期的才会有此提示）。 或 有标签 Today的。 这样做的意义是：如果过了 Due Date 还没有完成，那么因为有 Today 标签，我在过滤的时候，依然能看到我超期的任务需要在今天完成。 排序： Due Date Next下一步要做的工作。使用标签中的 ThisWeek, ThisMonth 及有一个 Due 的动作。 在处理 Next 之前，确保先把 Today 内的事务处理完毕。 排序：Due Future将来需要完成的任务，不需要截止日期。但是需要打上一个 Recently 标签即可，或者有一个非活跃（SomeDay）的标签。 排序： Recently, SomeDay Wait过滤出有标签 AssignTo 的事务。","categories":[{"name":"GTD","slug":"GTD","permalink":"https://gowa2017.github.io/categories/GTD/"}],"tags":[{"name":"GTD","slug":"GTD","permalink":"https://gowa2017.github.io/tags/GTD/"}],"keywords":[{"name":"GTD","slug":"GTD","permalink":"https://gowa2017.github.io/categories/GTD/"}]},{"title":"Gson使用泛型时候遇到问题","slug":"Gson使用泛型时候遇到问题","date":"2019-03-20T13:02:51.000Z","updated":"2019-03-20T13:02:51.000Z","comments":true,"path":"Android/Gson使用泛型时候遇到问题.html","link":"","permalink":"https://gowa2017.github.io/Android/Gson使用泛型时候遇到问题.html","excerpt":"今天在想统一使用 Gson 进行获取服务端数据后出现了一个头疼的问题。对于使用泛型的时候会出现 LinkTreeMap 不能 Cast To 对象的问题。通过谷歌，了解原因。","text":"今天在想统一使用 Gson 进行获取服务端数据后出现了一个头疼的问题。对于使用泛型的时候会出现 LinkTreeMap 不能 Cast To 对象的问题。通过谷歌，了解原因。 返回格式我们的服务端返回的数据格式都是一致的。 &#123; \"state\": 200, \"data\": &#125; data 有的时候会是个对象，有的时候是个列表。很自然的就构造一个 Java 类： public class ServerApiResult&lt;T&gt; &#123; private int state; private T data;&#125; 我们统一处理网络请求的类： @Overridepublic void onResponse(Call&lt;ServerApiResult&gt; call, Response&lt;ServerApiResult&gt; response) &#123; Response&lt;ServerApiResult&gt; res = response; ServerApiResult data = response.body(); // 请求成功，http 协议返回代码 200-300 if (res.isSuccessful()) &#123; if (data.getState() != 200) &#123; if (data.getData() == null || TextUtils.isEmpty(data.getData().toString())) &#123; if (!TextUtils.isEmpty(CodeConfig.getCodeTip(data.getState()))) &#123; onFail(CodeConfig.getCodeTip(data.getState())); &#125; else &#123; onFail(\"请求失败，请重试\"); &#125; &#125; else &#123; onFail(data.getData().toString()); &#125; return; &#125; Log.d(TAG, \"onResponse: \" + data.getData()); Log.d(TAG, \"onResponse: \"+data.getClass()); Log.d(TAG, \"onResponse: \"+data.getData().getClass()); onSuccessfull(data.getData()); &#125; else &#123; onFail(res.message()); &#125;&#125; 结果就是会在下面的调用中抛出异常： UncaughtException detected: java.lang.ClassCastException: com.google.gson.internal.LinkedTreeMap cannot be cast to cn.nanming.smartcompany.ui.activity.comregister.requester.entity.ComRegisterBaseInfo Call&lt;ServerApiResult&gt; req = netClient.getBaseInfo(sn);req.enqueue(new NetCallback&lt;ComRegisterBaseInfo&gt;() &#123; @Override public void onSuccessfull(ComRegisterBaseInfo data) &#123; callback.success(data); &#125;&#125;); 通过 Log.d 打印出的日志来看。 返回的数据本身，转换是成功的。而对于 data 字段，其属于泛型，Gson 没有进行转换，而是保存在了一个 LinkedTreeMap 中，直接使用是不行的。 那怎么破？这是因为 JAVA 的类型擦除在做怪。 类型擦除根据 Java 官方文档。 将泛型的所有类型参数都替换为其绑定的类型，若没有绑定的类型，则替换为 object。生成的字节码就只会是普通的类，接口或方法。 插入类型转换来保护类型安全。 生成桥接方法来保护级承了泛型的多态。 具体点来个例子： public class Node&lt;T&gt; &#123; private T data; private Node&lt;T&gt; next; public Node(T data, Node&lt;T&gt; next) &#123; this.data = data; this.next = next; &#125; public T getData() &#123; return data; &#125; // ...&#125; 将会擦除过程中，会替换为： public class Node&lt;T&gt; &#123; private T data; private Node&lt;T&gt; next; public Node(T data, Node&lt;T&gt; next) &#123; this.data = data; this.next = next; &#125; public T getData() &#123; return data; &#125; // ...&#125; 但如果泛型有绑定类型： public class Node&lt;T extends Comparable&lt;T&gt;&gt; &#123; private T data; private Node&lt;T&gt; next; public Node(T data, Node&lt;T&gt; next) &#123; this.data = data; this.next = next; &#125; public T getData() &#123; return data; &#125; // ...&#125; 则会替换成： public class Node &#123; private Comparable data; private Node next; public Node(Comparable data, Node next) &#123; this.data = data; this.next = next; &#125; public Comparable getData() &#123; return data; &#125; // ...&#125; 所以，实际上我们的 ServerApiResult 并不知道我们的 data 类型。 官方文档查看官方文档针对泛型一节的说明： 当我们调用 toJson(obj) 的时候，Gson 会调用 obj.getClass() 来获取字段信息来序列化。同样，我们调用 fromJson(obj, MyClass.class) 的时候根据传递了一个 Class 对象过去。这工作得很好，但是遇到泛型就悲剧了。当 obj 是泛型的时候，泛型的信息会被擦除Java 类型擦除。例如： class Foo&lt;T&gt; &#123; T value;&#125;Gson gson = new Gson();Foo&lt;Bar&gt; foo = new Foo&lt;Bar&gt;();gson.toJson(foo); // May not serialize foo.value correctlygson.fromJson(json, foo.getClass()); // Fails to deserialize foo.value as Bar 上面的例子，并不会解析出类型 Bar 的值。因为 Gson 调用 foo.getClass() 来获取类信息，但这个方法返回的是一个 raw 类， Foo.class。也就说 Gson 并不知道这个对象的类型是 Foo，同上，因为类型擦除，其是 Bar 被解释为 Object，存在 LinkedTreeMap 中。 提供的解决方法是使用 TypeToken 类： Type fooType = new TypeToken&lt;Foo&lt;Bar&gt;&gt;() &#123;&#125;.getType();gson.toJson(foo, fooType);gson.fromJson(json, fooType); fooType之所以能获取，是因为后面的代码是定义了一个匿名本地内部类，且有一个方法 getType() 返回了全部的参数类型。 TypeToken&lt;T&gt; 表示一个类型 T。Java 当前没有提供表示一个泛型的方法，这个类可以。强制建立这么一个类可以让我们在运行时获取类型信息。 Map 的解析在我们安卓进行解析的时候，有一个比较蛋疼的事情就是，我们的解析器无法解析属于 Map 类型的返回值。 因此我准备用 Gson 来解决这个问题，用 Gson 就很简单了。 new Gson().fromJson(strBody, new TypeToken&lt;Map&lt;String,List&lt;SrvRes&gt;&gt;&gt;()&#123;&#125;.getType()); 这样也就 OK 了。","categories":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"},{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/tags/Java/"},{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"},{"name":"JSON","slug":"JSON","permalink":"https://gowa2017.github.io/tags/JSON/"},{"name":"Gson","slug":"Gson","permalink":"https://gowa2017.github.io/tags/Gson/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"},{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}]},{"title":"FragmentTabHost的使用","slug":"FragmentTabHost的使用","date":"2019-03-13T14:56:35.000Z","updated":"2019-03-13T14:56:35.000Z","comments":true,"path":"Android/FragmentTabHost的使用.html","link":"","permalink":"https://gowa2017.github.io/Android/FragmentTabHost的使用.html","excerpt":"为了实现标签页切换。之前用过 TabLayout 但是似乎现在都淘汰了？所以看了一下官方介绍的 FragmentTabHost 看起来很简单的，但是想要定制的话就发现了些问题。","text":"为了实现标签页切换。之前用过 TabLayout 但是似乎现在都淘汰了？所以看了一下官方介绍的 FragmentTabHost 看起来很简单的，但是想要定制的话就发现了些问题。 事实上，FragmentTabHost 就是对 TabHost 类的一个继承，只不过，其是用 Fragment 来显示 Tab 内容。所以在查看相关知识例子的时候，谷歌看到大多是关于 TabHost的。 布局布局很简单，定义一个 FragmentTabHost，然后再用一个装载内容的 FrameLayout 视图就行了。 &lt;android.support.v4.app.FragmentTabHost android:id=\"@+id/fth\" android:layout_width=\"match_parent\" android:layout_height=\"wrap_content\" android:layout_below=\"@id/ll_status3\" /&gt;&lt;FrameLayout android:id=\"@+id/fly\" android:layout_width=\"match_parent\" android:layout_height=\"wrap_content\" /&gt; 代码应用fth.setup(this, getSupportFragmentManager(), R.id.fly); // 设置内容容器ID 为 R.id.fly// 添加两个 Tab setIndicator()可以用 View 作为参数 fth.addTab(fth.newTabSpec(\"all\").setIndicator(\"全程\"), ComRegisterMainFragmentAllElectronic.class, null);fth.addTab(fth.newTabSpec(\"half\").setIndicator(\"半程\"), ComRegisterMainFragmentHalfElectronic.class, null); 就是这么简单。 但我遇到的问题是，我想要自定义 Tab 显示的颜色，背景，字体的时候没有找到好用的方法。其只提供了 View 相关的方法，关于一些具体实现 如 TextView 的方法无法获取到呢。 源码追踪FragmentTabHost.setup()public void setup(Context context, FragmentManager manager, int containerId) &#123; ensureHierarchy(context); // Ensure views required by super.setup() super.setup(); mContext = context; mFragmentManager = manager; mContainerId = containerId; ensureContent(); mRealTabContent.setId(containerId); // We must have an ID to be able to save/restore our state. If // the owner hasn't set one at this point, we will set it ourselves. if (getId() == View.NO_ID) &#123; setId(android.R.id.tabhost); &#125;&#125; TabHost.setup()从这个方法中可以看到： TabHost 使用 com.android.internal.R.id.tabs 作为 tabs 的容器。 使用 com.android.internal.R.id.tabcontent 作为标签内容的容器。而且必须是 FrameLayout 但这些内容从哪里来呢？在 FragmentTabHost 中已经默认为我们进行了设置。 public void setup() &#123; mTabWidget = findViewById(com.android.internal.R.id.tabs); if (mTabWidget == null) &#123; throw new RuntimeException( \"Your TabHost must have a TabWidget whose id attribute is 'android.R.id.tabs'\"); &#125; // KeyListener to attach to all tabs. Detects non-navigation keys // and relays them to the tab content. mTabKeyListener = new OnKeyListener() &#123; public boolean onKey(View v, int keyCode, KeyEvent event) &#123; switch (keyCode) &#123; case KeyEvent.KEYCODE_DPAD_CENTER: case KeyEvent.KEYCODE_DPAD_LEFT: case KeyEvent.KEYCODE_DPAD_RIGHT: case KeyEvent.KEYCODE_DPAD_UP: case KeyEvent.KEYCODE_DPAD_DOWN: case KeyEvent.KEYCODE_ENTER: return false; &#125; mTabContent.requestFocus(View.FOCUS_FORWARD); return mTabContent.dispatchKeyEvent(event); &#125; &#125;; mTabWidget.setTabSelectionListener(new TabWidget.OnTabSelectionChanged() &#123; public void onTabSelectionChanged(int tabIndex, boolean clicked) &#123; setCurrentTab(tabIndex); if (clicked) &#123; mTabContent.requestFocus(View.FOCUS_FORWARD); &#125; &#125; &#125;); mTabContent = findViewById(com.android.internal.R.id.tabcontent); if (mTabContent == null) &#123; throw new RuntimeException( \"Your TabHost must have a FrameLayout whose id attribute is \" + \"'android.R.id.tabcontent'\"); &#125;&#125; FragmentTabHost.ensureHierarchy()private void ensureHierarchy(Context context) &#123; // If owner hasn't made its own view hierarchy, then as a convenience // we will construct a standard one here. if (findViewById(android.R.id.tabs) == null) &#123; LinearLayout ll = new LinearLayout(context); ll.setOrientation(LinearLayout.VERTICAL); addView(ll, new FrameLayout.LayoutParams( ViewGroup.LayoutParams.MATCH_PARENT, ViewGroup.LayoutParams.MATCH_PARENT)); TabWidget tw = new TabWidget(context); tw.setId(android.R.id.tabs); tw.setOrientation(TabWidget.HORIZONTAL); ll.addView(tw, new LinearLayout.LayoutParams( ViewGroup.LayoutParams.MATCH_PARENT, ViewGroup.LayoutParams.WRAP_CONTENT, 0)); FrameLayout fl = new FrameLayout(context); fl.setId(android.R.id.tabcontent); ll.addView(fl, new LinearLayout.LayoutParams(0, 0, 0)); mRealTabContent = fl = new FrameLayout(context); mRealTabContent.setId(mContainerId); ll.addView(fl, new LinearLayout.LayoutParams( LinearLayout.LayoutParams.MATCH_PARENT, 0, 1)); &#125;&#125; 解决办法使用 newTabSpec(“all”).setIndicator( View ) 来实现我们自定义的视图。","categories":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"}],"keywords":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}]},{"title":"Android中APP的启动过程","slug":"Android中APP的启动过程","date":"2019-03-12T15:03:24.000Z","updated":"2019-03-12T15:03:24.000Z","comments":true,"path":"Android/Android中APP的启动过程.html","link":"","permalink":"https://gowa2017.github.io/Android/Android中APP的启动过程.html","excerpt":"安卓系统实质上是 Linux 内核的，其在 init 进程启动后，会启动 Zygote 进程。这个进程，会开启第一个 Java VM，预先加载很多与安卓系统框架相关的以及通用的一些资源。接着就会开个套接字来监听请求，根据请求来开启新的进程，VM来执行APP。一旦收到新的请求, Zygote会基于自身预先加载的VM来孵化出一个新的VM创建一个新的进程。","text":"安卓系统实质上是 Linux 内核的，其在 init 进程启动后，会启动 Zygote 进程。这个进程，会开启第一个 Java VM，预先加载很多与安卓系统框架相关的以及通用的一些资源。接着就会开个套接字来监听请求，根据请求来开启新的进程，VM来执行APP。一旦收到新的请求, Zygote会基于自身预先加载的VM来孵化出一个新的VM创建一个新的进程。 启动Zygote之后, init进程会启动runtime进程. Zygote会孵化出一个超级管理进程—-System Server. SystemServer会启动所有系统核心服务, 例如Activity Manager Service, 硬件相关的Service等. 到此, 系统准备好启动它的第一个App进程—-Home进程了. Zygote init 进程及其他内核进程启动后，就会执行 /system/bin/app_process（源代码：https://github.com/android/platform_frameworks_base/blob/master/cmds/app_process/app_main.cpp。事实上，这个程序调用的是AndroidRuntime.start()（源代码：https://github.com/android/platform_frameworks_base/blob/master/core/jni/AndroidRuntime.cpp，参数：com.android.internal.os.ZygoteInit, start-system-server AndroidRuntime.start() 启动 Java VM，调用 ZygoteInit.main()https://github.com/android/platform_frameworks_base/blob/master/core/java/com/android/internal/os/ZygoteInit.java，参数是 start-system-server。 ZygoteInit.main() 首先注册套接字（根据从套接字上收到的请求来 fork 进程）。接着就会预加载很多的类及许多的 xml, drawable 资源。接着调用 startSystemServer() fork 一个新进程来执行 com.android.server.SystemServer https://github.com/android/platform_frameworks_base/blob/master/services/java/com/android/server/SystemServer.java SystemServer fork 后，runSelectLoopMode() 被调用。这是一个while(true)的循环，从监听的套接字上获取请求。一旦有命名到达，就会调用 ZygoteConnection.runOnce()https://github.com/android/platform_frameworks_base/blob/master/core/java/com/android/internal/os/ZygoteConnection.java。 ZygoteConnection.runOnce()调用 Zygote.forkAndSpecialize() https://github.com/CyanogenMod/android_libcore/blob/gingerbread/dalvik/src/main/java/dalvik/system/Zygote.java来 fork 进程。 在启动 SystemServer 的过程中，会启动一个叫做 ActivityManagerService 的核心服务。用来管理我们的 Activity。https://android.googlesource.com/platform/frameworks/base/+/4f868ed/services/core/java/com/android/server/am/ActivityManagerService.java。这个时候，我们的启动器，也就是桌面，也已经启动了。 事实是，当我们用 startActivity(intent) 这样的形式来启动 app 的时候，最终，请求都是发送给 ActivityManagerService 的。 根据 intent 解析出对应的 ActivityInfo, ApplicationInfo，进行构造启动。 参考参考： http://multi-core-dump.blogspot.com/2010/04/android-application-launch.htmlhttps://link.jianshu.com/?t=http://multi-core-dump.blogspot.com/2010/04/android-application-launch-part-2.htmlhttp://liuwangshu.cn/framework/booting/3-syetemserver.html","categories":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"}],"keywords":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}]},{"title":"Android数据的存储方式","slug":"Android数据的存储方式","date":"2019-03-12T14:10:53.000Z","updated":"2019-03-12T14:10:53.000Z","comments":true,"path":"Android/Android数据的存储方式.html","link":"","permalink":"https://gowa2017.github.io/Android/Android数据的存储方式.html","excerpt":"安卓存储有内外之分，同时还提供了一存储键值对的 SharedPreference ，SQLite等共五种存储方式。","text":"安卓存储有内外之分，同时还提供了一存储键值对的 SharedPreference ，SQLite等共五种存储方式。 SharedPreferences支持数据类型：布尔值、浮点值、整型值、长整型和字符串。一个应用可拥有多个。 使用方法： getSharedPreferences() - 如果您需要多个按名称（使用第一个参数指定）识别的首选项文件，请使用此方法。 getPreferences() - 如果您只需要一个用于 Activity 的首选项文件，请使用此方法。 由于这将是用于 Activity 的唯一首选项文件，因此无需提供名称。 要写入值： 调用 edit() 以获取 SharedPreferences.Editor。 使用 putBoolean() 和 putString() 等方法添加值。 使用 commit() 提交新值 要读取值，请使用 getBoolean() 和 getString() 等 SharedPreferences 方法。 ContextImpl/Context我们在程序的始终，都会一直遇到一个叫做上下文的东西。 Context 是一个抽象类，而我们的 Activity 就继承自 Context。所以可以使用 Context 定义的很多方法，也就是后面我们会说道的很多关于存储的方法。 但是 Context 的实现，实际上是位于 ContextImpl.java 中，这个类，在开发代码的时候没有看到，只在谷歌的源码目录上找到了： https://android.googlesource.com/platform/frameworks/base/+/master/core/java/android/app/ContextImpl.java 内部存储内部存储是设备内部自身的存储，是由安卓系统严格进行管理的。保存在内部存储中的文件，其他应用和用户是无法访问的。文件会随着APP的卸载而删除。 要创建私有文件并写入到内部存储： 使用文件名称和操作模式调用 openFileOutput()。 这将返回一个 FileOutputStream。 使用 write() 写入到文件。 使用 close() 关闭流式传输。 我们来看一下代码的实现： final LoadedApk packageInfo = systemContext.mPackageInfo;@Overridepublic FileInputStream openFileInput(String name) throws FileNotFoundException &#123; File f = makeFilename(getFilesDir(), name); return new FileInputStream(f);&#125;private File makeFilename(File base, String name) &#123; if (name.indexOf(File.separatorChar) &lt; 0) &#123; return new File(base, name); &#125; throw new IllegalArgumentException( \"File \" + name + \" contains a path separator\");&#125;@Overridepublic File getFilesDir() &#123; synchronized (mSync) &#123; if (mFilesDir == null) &#123; mFilesDir = new File(getDataDir(), \"files\"); &#125; return ensurePrivateDirExists(mFilesDir); &#125;&#125;@Overridepublic File getDataDir() &#123; if (mPackageInfo != null) &#123; File res = null; if (isCredentialProtectedStorage()) &#123; res = mPackageInfo.getCredentialProtectedDataDirFile(); &#125; else if (isDeviceProtectedStorage()) &#123; res = mPackageInfo.getDeviceProtectedDataDirFile(); &#125; else &#123; res = mPackageInfo.getDataDirFile(); &#125; if (res != null) &#123; if (!res.exists() &amp;&amp; android.os.Process.myUid() == android.os.Process.SYSTEM_UID) &#123; Log.wtf(TAG, \"Data directory doesn't exist for package \" + getPackageName(), new Throwable()); &#125; return res; &#125; else &#123; throw new RuntimeException( \"No data directory found for package \" + getPackageName()); &#125; &#125; else &#123; throw new RuntimeException( \"No package details found for package \" + getPackageName()); &#125;&#125; 可以看到，我们打开的输入文件目录应该是位于 /data/data/applicaiontid/files/ 目录下的。（小米手机是这样，其他手机就不知道了，要看手机定义的数据目录） 要从内部存储读取文件： 调用 openFileInput() 并向其传递要读取的文件名称。 这将返回一个 FileInputStream。 使用 read() 读取文件字节。 然后使用 close() 关闭流式传输。 对于位于 res/raw 中的文件，可以用 openRawResource(R.raw.&lt;filename&gt;) 来打开。 缓存文件如果您想要缓存一些数据，而不是永久存储这些数据，应该使用 getCacheDir() 来打开一个 File，它表示您的应用应该将临时缓存文件保存到的内部目录。 当设备的内部存储空间不足时，Android 可能会删除这些缓存文件以回收空间。 但您不应该依赖系统来为您清理这些文件， 而应该始终自行维护缓存文件，使其占用的空间保持在合理的限制范围内（例如 1 MB）。 当用户卸载您的应用时，这些文件也会被移除。 @Overridepublic File getCacheDir() &#123; synchronized (mSync) &#123; if (mCacheDir == null) &#123; mCacheDir = new File(getDataDir(), \"cache\"); &#125; return ensurePrivateCacheDirExists(mCacheDir, XATTR_INODE_CACHE); &#125;&#125; /data/data/applicaiontid/cache 目录。 其他方法 getFilesDir() 获取 /data/data/applicaiontid/files 目录 getDir(String name, int mode) 获取/data/data/applicaiontid/app_name 目录 deleteFile() 删除/data/data/applicaiontid/files 下文件 fileList() 列出 /data/data/applicaiontid/files 外部存储在使用之前我们都要检查介质是否可用： /* Checks if external storage is available for read and write */public boolean isExternalStorageWritable() &#123; String state = Environment.getExternalStorageState(); if (Environment.MEDIA_MOUNTED.equals(state)) &#123; return true; &#125; return false;&#125;/* Checks if external storage is available to at least read */public boolean isExternalStorageReadable() &#123; String state = Environment.getExternalStorageState(); if (Environment.MEDIA_MOUNTED.equals(state) || Environment.MEDIA_MOUNTED_READ_ONLY.equals(state)) &#123; return true; &#125; return false;&#125; 更多内容请参考：Android的文件系统探究 一文。","categories":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"}],"keywords":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}]},{"title":"Java内部类与嵌套类","slug":"Java内部类与嵌套类","date":"2019-03-09T07:31:05.000Z","updated":"2019-03-09T07:31:05.000Z","comments":true,"path":"Java/Java内部类与嵌套类.html","link":"","permalink":"https://gowa2017.github.io/Java/Java内部类与嵌套类.html","excerpt":"虽然在写安卓代码的时候，似乎到处都在用到 inner class，比如直接 new 一个回调的时候，及使用 adapter 的时候也在用到嵌套类，或者是 Builder 模式的时候，都有用到，但没有来了解过具体的内涵。所以今天就来看看。原文","text":"虽然在写安卓代码的时候，似乎到处都在用到 inner class，比如直接 new 一个回调的时候，及使用 adapter 的时候也在用到嵌套类，或者是 Builder 模式的时候，都有用到，但没有来了解过具体的内涵。所以今天就来看看。原文 Nested与Inner我们用 class 声明一个类，然后在此类中再用 class 声明一个类，这个类就是嵌套类。 class OuterClass &#123; ... class NestedClass &#123; ... &#125;&#125; 嵌套类可以用 static 来进行修饰，这种叫做 静态嵌套类 static nested class。 Builder 好像就经常这样用；如果不用 static，就叫做 内部类 inner class 嵌套类是外部类的一个成员。非静态嵌套类（内部类 inner class）可以访问外部类的其他成员，即使其他成员使用 private 进行修饰。而 静态嵌套类 则没有访问外部类成员的权限。 作为外部类的成员，嵌套类可以用 private, public, protected 来修饰。 为什么使用嵌套类使用嵌套类最主要的原因包括下面： 将只在一个地方使用的多个类逻辑上分组在一起：某个类如果只对其他一个类有用，把他们逻辑上组织在一起的话，就让包看起来更精简。 增加封装：考虑两个顶级类 A, B，B 需要访问被声明为 private 的A中成员。通过在 A 中隐藏 B，B 就可以访问 A 中成员，同时，外部世界也不知道 B 这个东西。 代码更加可读和易维护 静态嵌套类 和类的方法和变量一样，静态嵌套类是与其外部类相关联的。 和静态类的方法一样，静态嵌套类不能直接引用其外部类中定义的变量和方法，其必须通过一个实例化后的对象来访问。 静态嵌套类与外部类的实例对象进行交互，看起来就跟其他顶级类进行交互一样。实际上，静态嵌套类行为上就是一个顶级类，只不是为了包管理的方便而把他嵌套了起来。 静态嵌套类这样进行引用： OuterClass.StaticNestedClass 要实例化静态嵌套类的，可如下操作： OuterClass.StaticNestedClass nestedObject = new OuterClass.StaticNestedClass(); 内部类和实例化后的对象内的方法和变量一样，内部类与其外部类对象进行关联，可以直接访问外部类对象中的变量和方法。同时，内部类与对象相关联，所以其不可以定义任何静态的成员。 内部类的对象，存在于外部类对象中： class OuterClass &#123; ... class InnerClass &#123; ... &#125;&#125; 想要实力化内部类，那么必须要先实例化外部类。 OuterClass.InnerClass innerObject = outerObject.new InnerClass(); Shadowing内部类中声明的名称和覆盖外部类中的同样名称： public class ShadowTest &#123; public int x = 0; class FirstLevel &#123; public int x = 1; void methodInFirstLevel(int x) &#123; System.out.println(\"x = \" + x); System.out.println(\"this.x = \" + this.x); System.out.println(\"ShadowTest.this.x = \" + ShadowTest.this.x); &#125; &#125; public static void main(String... args) &#123; ShadowTest st = new ShadowTest(); ShadowTest.FirstLevel fl = st.new FirstLevel(); fl.methodInFirstLevel(23); &#125;&#125; 输出将会是： x = 23this.x = 1ShadowTest.this.x = 0 序列化序列化内部类，包括本地和匿名的类，是非常不推荐的。 Local/匿名类本地类本地类（local） 是一个在块内定义的类。典型的是在方法体内看见本地类。 public class LocalClassExample &#123; static String regularExpression = \"[^0-9]\"; public static void validatePhoneNumber( String phoneNumber1, String phoneNumber2) &#123; final int numberLength = 10; // Valid in JDK 8 and later: // int numberLength = 10; class PhoneNumber &#123; String formattedPhoneNumber = null; PhoneNumber(String phoneNumber)&#123; // numberLength = 7; String currentNumber = phoneNumber.replaceAll( regularExpression, \"\"); if (currentNumber.length() == numberLength) formattedPhoneNumber = currentNumber; else formattedPhoneNumber = null; &#125; public String getNumber() &#123; return formattedPhoneNumber; &#125; // Valid in JDK 8 and later:// public void printOriginalNumbers() &#123;// System.out.println(\"Original numbers are \" + phoneNumber1 +// \" and \" + phoneNumber2);// &#125; &#125; PhoneNumber myNumber1 = new PhoneNumber(phoneNumber1); PhoneNumber myNumber2 = new PhoneNumber(phoneNumber2); // Valid in JDK 8 and later:// myNumber1.printOriginalNumbers(); if (myNumber1.getNumber() == null) System.out.println(\"First number is invalid\"); else System.out.println(\"First number is \" + myNumber1.getNumber()); if (myNumber2.getNumber() == null) System.out.println(\"Second number is invalid\"); else System.out.println(\"Second number is \" + myNumber2.getNumber()); &#125; public static void main(String... args) &#123; validatePhoneNumber(\"123-456-7890\", \"456-7890\"); &#125;&#125; 访问外部类本地类可以访问外部类中的成员。前面例子中，PhoneNumber 构造器访问了 LocalClassExample.regularExpression。 另外，本地类也可以访问本地变量。然而，本地类只能访问声明为 final 的本地变量。当本地类访问外部类的本地变量或者参数的时候，其会捕获那个变量或者参数。例如，PhoneNumber 构造器访问了 numberLength 因为其被声明为 final。 然而，从 Jave SE 8 开始，本地类可以访问声明为 final 的或者是 实际上是 final 的本地变量和参数。变量或参数在初始化后就不再改变的被认为是实际上 final 的。 例如，假设我们的 numberLength 不声明为 final，我们尝试改变它的值： PhoneNumber(String phoneNumber) &#123; numberLength = 7; String currentNumber = phoneNumber.replaceAll( regularExpression, \"\"); if (currentNumber.length() == numberLength) formattedPhoneNumber = currentNumber; else formattedPhoneNumber = null;&#125; 因为赋值语句 numberLength = 7，numberLength 不再被视为实际上 final 的，Java 编译器会抛出一个错误 “local variables referenced from an inner class must be final or effectively final” 从 Java SE 8 开始，在方法内声明的本地类可以访问方法的参数， public void printOriginalNumbers() &#123; System.out.println(\"Original numbers are \" + phoneNumber1 + \" and \" + phoneNumber2);&#125; shadowing本地类同名的字段会覆盖外部类中的同名字段。 本地类与内部类相似本地类和内部类都不能定义任何静态的成员。静态方法中的内部类，如类 PhoneNumber ，定义在静态方法 validatePhoneNumber() 中，其只能访问外部类中的静态成员。如果不将 regularExpression 声明为 static, Java 编译器会抛出错误 non-static variable regularExpression cannot be referenced from a static context 本地类是非静态的，因为其可以访问外部类对象的成员。所以其也不能拥有静态声明。 不能在块中声明接口，接口本质上是静态的： public void greetInEnglish() &#123; interface HelloThere &#123; public void greet(); &#125; class EnglishHelloThere implements HelloThere &#123; public void greet() &#123; System.out.println(\"Hello \" + name); &#125; &#125; HelloThere myGreeting = new EnglishHelloThere(); myGreeting.greet(); &#125; 不能在本地类中声明静态初始化方法或者成员接口： public void sayGoodbyeInEnglish() &#123; class EnglishGoodbye &#123; public static void sayGoodbye() &#123; System.out.println(\"Bye bye\"); &#125; &#125; EnglishGoodbye.sayGoodbye();&#125; 本地类中可以有静态恒定常量（基本类型，String 且被声明为 final，并进行初始化）。 public void sayGoodbyeInEnglish() &#123; class EnglishGoodbye &#123; public static final String farewell = \"Bye bye\"; public void sayGoodbye() &#123; System.out.println(farewell); &#125; &#125; EnglishGoodbye myEnglishGoodbye = new EnglishGoodbye(); myEnglishGoodbye.sayGoodbye();&#125; 匿名类匿名类可以使代码更简单，可以在声明的时候自己进行初始化。他们和本地类相似，但没有一个名字。当只需要使用一次本地类的时候就可以这样做。 本地类是类声明，而匿名类则是表达式，这意味着我们在另外的表达式中定义类。public class HelloWorldAnonymousClasses &#123; interface HelloWorld &#123; public void greet(); public void greetSomeone(String someone); &#125; public void sayHello() &#123; class EnglishGreeting implements HelloWorld &#123; String name = \"world\"; public void greet() &#123; greetSomeone(\"world\"); &#125; public void greetSomeone(String someone) &#123; name = someone; System.out.println(\"Hello \" + name); &#125; &#125; HelloWorld englishGreeting = new EnglishGreeting(); HelloWorld frenchGreeting = new HelloWorld() &#123; String name = \"tout le monde\"; public void greet() &#123; greetSomeone(\"tout le monde\"); &#125; public void greetSomeone(String someone) &#123; name = someone; System.out.println(\"Salut \" + name); &#125; &#125;; HelloWorld spanishGreeting = new HelloWorld() &#123; String name = \"mundo\"; public void greet() &#123; greetSomeone(\"mundo\"); &#125; public void greetSomeone(String someone) &#123; name = someone; System.out.println(\"Hola, \" + name); &#125; &#125;; englishGreeting.greet(); frenchGreeting.greetSomeone(\"Fred\"); spanishGreeting.greet(); &#125; public static void main(String... args) &#123; HelloWorldAnonymousClasses myApp = new HelloWorldAnonymousClasses(); myApp.sayHello(); &#125; &#125; 经常性的我们会看到上面这这样的用法，就是需要一个接口实现的时候，我们会 new 一个接口出来，事实上这样的操作，指的是 new 出一个实现了 HelloWorld 接口的匿名内部类。 访问外部类变量，声明和访问匿名类成员和本地类一样，匿名类可以捕捉变量，其和本地类相同的访问外部类： 匿名类可以访问外部类的成员 不能访问外部类中没有声明为 final 或实际上 final 的成员或参数 同名声明会覆盖 不能声明成员接口或者静态初始化器 可以静态的恒定变量。 可以在匿名类中声明： 字段 方法 实例视始化器 本地类 但是不能在匿名类中声明构造器","categories":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/tags/Java/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}]},{"title":"使用ThreadPool进行线程管理","slug":"使用ThreadPool进行线程管理","date":"2019-03-09T07:03:15.000Z","updated":"2019-03-09T07:03:15.000Z","comments":true,"path":"Java/使用ThreadPool进行线程管理.html","link":"","permalink":"https://gowa2017.github.io/Java/使用ThreadPool进行线程管理.html","excerpt":"从以前 Posix C 上的经验来说，线程是一个永远不会停止的话题啊。但是，线程的新建，销毁，初始化其实开销都是相对有点大的。同时，如果无限制的进行线程的抢占和使用，在资源受限（移动设备）时，就会影响性能了。所以才有了利用线程池来管理线程的这么一个做法。","text":"从以前 Posix C 上的经验来说，线程是一个永远不会停止的话题啊。但是，线程的新建，销毁，初始化其实开销都是相对有点大的。同时，如果无限制的进行线程的抢占和使用，在资源受限（移动设备）时，就会影响性能了。所以才有了利用线程池来管理线程的这么一个做法。 基本原理对于线程池来说，我们设计我们想要执行的任务，但是具体怎么执行，什么时候执行，我们交给了线程池。这样就跟我们的任务的设计和执行相分离。 也即是说，我们把想要执行的 Runnable 丢给线程池就可以了。 相关的对象 Executor 接口，只有一个方法 execute Callable 接口，类似 Runnable 但是可以返回值。 Future 类似 JS 的 Promise ，异步任务的返回结果 ExecutorService 接口，对 Executor 的扩展，Executor 太过简单了，所以这个接口增加了线程池中的线程管理功能。 ThreadPoolExecutor 类。实现了 ExecutorService 。也就是说其实现了对线程池管理的很多方法。 ScheduledThreadPoolExecutor。类，扩展了 ThreadPoolExecutor，增加了定时调度线程功能。 Executors 类。一个工厂和常用方法的集合，一些特定类型的 Executor 由他可以直接实例化。 Executors此类可以直接利用其工厂方法，获取一些 ExecutorService 对象。 static final int DEFAULT_THREAD_POOL_SIZE = 4;ExecutorService executorService = Executors.newFixedThreadPool(DEFAULT_THREAD_POOL_SIZE);ExecutorService executorService = Executors.newCachedThreadPool();ExecutorService executorService = Executors.newSingleThreadExecutor(); newFixedThreadPool 固定线程数量的线程池 newCachedThreadPool 队列中有任务的时候，就会创建线程；队列空了大于60秒，就会被空闲线程回收。 newSingleThreadExecutor 只有一个线程。 简单的向线程池添加任务： executorService.execute(new Runnable()&#123; @Override public void run()&#123; callBlockingFunction(); &#125;&#125;);Future future = executorService.submit(new Callable()&#123; @Override public Object call() throws Exception &#123; callBlockingFunction(); return null; &#125;&#125;); 在第二个方法中，Future 可以用来获取返回结果 Future.get()，还可以取消一个任务 Future.cancel()。 ThreadPoolExecutor我们可能并不满足于上面那些简单的使用，所以有了ThreadPoolExecutor。 我们在建立 ThreadPoolExecutor 的实例的时候，可以给予很多参数来控制我们所需要的线程数量，驻留时间等等。 int NUMBER_OF_CORES = Runtime.getRuntime().availableProcessors();int KEEP_ALIVE_TIME = 1;TimeUnit KEEP_ALIVE_TIME_UNIT = TimeUnit.SECONDS;BlockingQueue&lt;Runnable&gt; taskQueue = new LinkedBlockingQueue&lt;Runnable&gt;();ExecutorService executorService = new ThreadPoolExecutor(NUMBER_OF_CORES, NUMBER_OF_CORES*2, KEEP_ALIVE_TIME, KEEP_ALIVE_TIME_UNIT, taskQueue, new BackgroundThreadFactory()); private static class BackgroundThreadFactory implements ThreadFactory &#123; private static int sTag = 1; @Override public Thread newThread(Runnable runnable) &#123; Thread thread = new Thread(runnable); thread.setName(\"CustomThread\" + sTag); thread.setPriority(Process.THREAD_PRIORITY_BACKGROUND); // A exception handler is created to log the exception from threads thread.setUncaughtExceptionHandler(new Thread.UncaughtExceptionHandler() &#123; @Override public void uncaughtException(Thread thread, Throwable ex) &#123; Log.e(Util.LOG_TAG, thread.getName() + \" encountered an error: \" + ex.getMessage()); &#125; &#125;); return thread; &#125;&#125; 使用我们来看一下 Google 官方架构栏图中 todo-mvp 中对 Executor 的使用。 在类 app/src/main/java/com/example/android/architecture/blueprints/todoapp/util/AppExecutors.java 中，定义了三种类型的 Executor。 diskIO networkIO mainThread public class AppExecutors &#123; private static final int THREAD_COUNT = 3; private final Executor diskIO; private final Executor networkIO; private final Executor mainThread; @VisibleForTesting AppExecutors(Executor diskIO, Executor networkIO, Executor mainThread) &#123; this.diskIO = diskIO; this.networkIO = networkIO; this.mainThread = mainThread; &#125; public AppExecutors() &#123; this(new DiskIOThreadExecutor(), Executors.newFixedThreadPool(THREAD_COUNT), new MainThreadExecutor()); &#125; public Executor diskIO() &#123; return diskIO; &#125; public Executor networkIO() &#123; return networkIO; &#125; public Executor mainThread() &#123; return mainThread; &#125; private static class MainThreadExecutor implements Executor &#123; private Handler mainThreadHandler = new Handler(Looper.getMainLooper()); @Override public void execute(@NonNull Runnable command) &#123; mainThreadHandler.post(command); &#125; &#125;&#125; public class DiskIOThreadExecutor implements Executor &#123; private final Executor mDiskIO; public DiskIOThreadExecutor() &#123; mDiskIO = Executors.newSingleThreadExecutor(); &#125; @Override public void execute(@NonNull Runnable command) &#123; mDiskIO.execute(command); &#125;&#125; 可以看到，diskIO 只启用了一个线程的线程池，而 networkIO，启了三个线程，主线程的是直接将要执行的代码 Post 过去。 使用Runnable runnable = new Runnable() &#123; @Override public void run() &#123; final List&lt;Task&gt; tasks = mTasksDao.getTasks(); mAppExecutors.mainThread().execute(new Runnable() &#123; @Override public void run() &#123; if (tasks.isEmpty()) &#123; // This will be called if the table is new or just empty. callback.onDataNotAvailable(); &#125; else &#123; callback.onTasksLoaded(tasks); &#125; &#125; &#125;); &#125;&#125;;mAppExecutors.diskIO().execute(runnable); Runnable runnable = new Runnable() &#123; @Override public void run() &#123; final Task task = mTasksDao.getTaskById(taskId); mAppExecutors.mainThread().execute(new Runnable() &#123; @Override public void run() &#123; if (task != null) &#123; callback.onTaskLoaded(task); &#125; else &#123; callback.onDataNotAvailable(); &#125; &#125; &#125;); &#125;&#125;;mAppExecutors.diskIO().execute(runnable);","categories":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/tags/Java/"},{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"},{"name":"AppExecutors","slug":"AppExecutors","permalink":"https://gowa2017.github.io/tags/AppExecutors/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}]},{"title":"MySQL存储过程中的游标","slug":"MySQL存储过程中的游标","date":"2019-03-07T14:34:52.000Z","updated":"2019-03-07T14:34:52.000Z","comments":true,"path":"MySQL/MySQL存储过程中的游标.html","link":"","permalink":"https://gowa2017.github.io/MySQL/MySQL存储过程中的游标.html","excerpt":"好久没有写 MySQL 相关的东西了，今天遇到一个棘手的问题。需要计算，两个时间之间所经历过的工作日及工作时。非常的头疼，想到的实现方式，要么直接刷 SQL，比较麻烦；要么把表都导出来，然后 Python 获取处理后进行更新。想到其实这个任务也不是非常重，最终决定用存储过程来解决。","text":"好久没有写 MySQL 相关的东西了，今天遇到一个棘手的问题。需要计算，两个时间之间所经历过的工作日及工作时。非常的头疼，想到的实现方式，要么直接刷 SQL，比较麻烦；要么把表都导出来，然后 Python 获取处理后进行更新。想到其实这个任务也不是非常重，最终决定用存储过程来解决。 CREATE PROCEDURE | FUNCTION从语法上来看，我发现，MySQL 中，过程与函数的区别就是：过程没有定义值，而函数定义了返回值。 但实际上过程可以通过参数来进行值的返回的，同时，也只有过程能把参数指定为 IN,OUT。 而函数必须包含 RETURN 语句。 CREATE PROCEDURE sp_name ([proc_parameter[,...]]) [characteristic ...] routine_body CREATE FUNCTION sp_name ([func_parameter[,...]]) RETURNS type [characteristic ...] routine_body proc_parameter: [ IN | OUT | INOUT ] param_name type func_parameter: param_name type type: Any valid MySQL data type characteristic: LANGUAGE SQL | [NOT] DETERMINISTIC | &#123; CONTAINS SQL | NO SQL | READS SQL DATA | MODIFIES SQL DATA &#125; | SQL SECURITY &#123; DEFINER | INVOKER &#125; | COMMENT 'string' routine_body: Valid SQL procedure statement or statements 例子DELIMITER //CREATE PROCEDURE curdemo()BEGIN DECLARE done INT DEFAULT FALSE; DECLARE a CHAR(16); DECLARE b, c INT; DECLARE cur1 CURSOR FOR SELECT id,data FROM test.t1; DECLARE cur2 CURSOR FOR SELECT i FROM test.t2; DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE; OPEN cur1; OPEN cur2; read_loop: LOOP FETCH cur1 INTO a, b; FETCH cur2 INTO c; IF done THEN LEAVE read_loop; END IF; IF b &lt; c THEN INSERT INTO test.t3 VALUES (a,b); ELSE INSERT INTO test.t3 VALUES (a,c); END IF; END LOOP; CLOSE cur1; CLOSE cur2;END//DELIMITER ; 相关语法BEGIN … END一般来说，我们把复合语句都用 BEGIN ... END 包裹起来。 DECLARESQL变量名不能和列名一样。如果SELECT … INTO这样的SQL语句包含一个对列的参考，并包含一个与列相同名字的 局部变量，MySQL当前把参考解释为一个变量的名字。例如，在下面的语句中，xname 被解释为到xname variable 的参考而不是到xname column的： DECLARE var_name[,...] type [DEFAULT value]-- 声明条件，它将一个名字和指定的错误条件关联起来。这个名字可以随后被用在DECLARE HANDLER语句中DECLARE condition_name CONDITION FOR condition_value-- 这个语句指定每个可以处理一个或多个条件的处理程序。如果产生一个或多个条件，指定的语句被执行。DECLARE handler_type HANDLER FOR condition_value[,...] sp_statementcondition_value: SQLSTATE [VALUE] sqlstate_value | mysql_error_codeDECLARE handler_type HANDLER FOR condition_value[,...] sp_statementhandler_type: CONTINUE | EXIT | UNDO condition_value: SQLSTATE [VALUE] sqlstate_value | condition_name | SQLWARNING | NOT FOUND | SQLEXCEPTION | mysql_error_code DECLARE 只能在 BEGIN ... END 内声明变量，条件处理程序等。 游标声明光标必须在声明处理程序之前被声明，并且变量和条件必须在声明光标或处理程序之前被声明。 DECLARE cursor_name CURSOR FOR select_statement 这个语句声明一个光标。也可以在子程序中定义多个光标，但是一个块中的每一个光标必须有唯一的名字。 SELECT语句不能有INTO子句。 打开OPEN cursor_name 这个语句打开先前声明的光标。 获取这个语句用指定的打开光标读取下一行（如果有下一行的话），并且前进光标指针。变量要先进行声明。FETCH cursor_name INTO var_name [, var_name] ... 关闭CLOSE cursor_name 这个语句关闭先前打开的光标。 如果未被明确地关闭，光标在它被声明的复合语句的末尾被关闭。 流程控制IFIF search_condition THEN statement_list [ELSEIF search_condition THEN statement_list] ... [ELSE statement_list]END IF CASECASE case_value WHEN when_value THEN statement_list [WHEN when_value THEN statement_list] ... [ELSE statement_list]END CASEOr:CASE WHEN search_condition THEN statement_list [WHEN search_condition THEN statement_list] ... [ELSE statement_list]END CASE 这里介绍的用在 存储程序里的CASE语句与12.2节，“控制流程函数”里描述的SQL CASE表达式的CASE语句有轻微不同。这里的CASE语句不能有ELSE NULL子句，并且用END CASE替代END来终止。 LOOP[begin_label:] LOOP statement_listEND LOOP [end_label] LEAVELEAVE label ITERATEITERATE label ITERATE只可以出现在LOOP, REPEAT, 和WHILE语句内。ITERATE意思为：“再次循环。” CREATE PROCEDURE doiterate(p1 INT)BEGIN label1: LOOP SET p1 = p1 + 1; IF p1 &lt; 10 THEN ITERATE label1; END IF; LEAVE label1; END LOOP label1; SET @x = p1;END REPEAT[begin_label:] REPEAT statement_listUNTIL search_conditionEND REPEAT [end_label] REPEAT语句内的语句或语句群被重复，直至search_condition 为真。 REPEAT 语句可以被标注。 除非begin_label也存在，end_label才能被用，如果两者都存在，它们必须是一样的。 WHILE[begin_label:] WHILE search_condition DO statement_listEND WHILE [end_label] WHILE语句内的语句或语句群被重复，直至search_condition 为真。 WHILE语句可以被标注。 除非begin_label也存在，end_label才能被用，如果两者都存在，它们必须是一样的。 用户变量形如 @a 这样的变量。用户变量与连接有关。也就是说，一个客户端定义的变量不能被其它客户端看到或使用。当客户端退出时，该客户端连接的所有变量将自动释放。 SET @var_name = expr [, @var_name = expr] ... 或者用 SELECT ： SELECT @t1:=(@t2:=1)+@t3:=4,@t1,@t2,@t3; 在SELECT语句中，表达式发送到客户端后才进行计算。这说明在HAVING、GROUP BY或者ORDER BY子句中，不能使用包含SELECT列表中所设的变量的表达式。例如，下面的语句不能按期望工作： SELECT (@aa:=id) AS a，(@aa+3) AS b from tbl_name HAVING b=5； 当你用SELECT @@var_name搜索一个变量时(也就是说，不指定global.、session.或者local.)，MySQL返回SESSION值（如果存在），否则返回GLOBAL值。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://gowa2017.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://gowa2017.github.io/tags/MySQL/"},{"name":"SQL","slug":"SQL","permalink":"https://gowa2017.github.io/tags/SQL/"}],"keywords":[{"name":"MySQL","slug":"MySQL","permalink":"https://gowa2017.github.io/categories/MySQL/"}]},{"title":"Vue开发使用ESLint-Vuter-Prettier来进行代码格式化与检查","slug":"Vue开发使用ESLint-Vuter-Prettier来进行代码格式化与检查","date":"2019-02-22T11:53:38.000Z","updated":"2019-02-22T11:53:38.000Z","comments":true,"path":"JavaScript/Vue开发使用ESLint-Vuter-Prettier来进行代码格式化与检查.html","link":"","permalink":"https://gowa2017.github.io/JavaScript/Vue开发使用ESLint-Vuter-Prettier来进行代码格式化与检查.html","excerpt":"某个项目需要用到。但是代码风格不一致的问题，和 eslint 老报错的问题很是困扰了哦，网络上找的文章一般都是直接贴配置文件，很坑，总是不能达到目的，所以来看一下官方文档。","text":"某个项目需要用到。但是代码风格不一致的问题，和 eslint 老报错的问题很是困扰了哦，网络上找的文章一般都是直接贴配置文件，很坑，总是不能达到目的，所以来看一下官方文档。 描述首先看一下三个东西的描述都是怎么样的： Vetur：一个专门针对Vue开发的 VS code 插件。 ESlint： 插件式JavaScript和JSX检查工具 Prettier 代码格式化工具 我们就先明确我们的目标，使用 Vetur 来进行 Vue 的开发，同时给 Vetur 配置好代码格式化组件，接着，使用 ESLint 来检查代码。 Vetur 包含了针对 vue 的很多功能，比如说代码提示，补全等等，格式化只是其中的一个功能。我们重点关注一下格式化的功能。 VuterVS Code 插件安装很简单，直接搜索安装就行了。接着我们就在工程（或者全局）的 settings.json 内进行配置。 安装文档 格式化根据官方文档 Formatting，进行配置。 可用的格式化工具有： prettier: For css/scss/less/js/ts. prettier-eslint: For js. Run prettier and eslint —fix. prettyhtml: For html. stylus-supremacy: For stylus. vscode-typescript: For js/ts. The same js/ts formatter for VS Code. 当前默认的 Formatter 如下： &#123; \"vetur.format.defaultFormatter.html\": \"prettyhtml\", \"vetur.format.defaultFormatter.css\": \"prettier\", \"vetur.format.defaultFormatter.postcss\": \"prettier\", \"vetur.format.defaultFormatter.scss\": \"prettier\", \"vetur.format.defaultFormatter.less\": \"prettier\", \"vetur.format.defaultFormatter.stylus\": \"stylus-supremacy\", \"vetur.format.defaultFormatter.js\": \"prettier\", \"vetur.format.defaultFormatter.ts\": \"prettier\"&#125; Vetur bundles all the above formatters. When Vetur observes a local install of the formattesr, it’ll prefer to use the local version.Vetur 已经打包了所有的格式化工具。如果本地有安装一个版本的话，会优先调用本地的版本。 这里我们什么都不用改，默认使用 prettier 来格式化就行。 根据官方文档的说明， Vetur 已经打包了所有可用的格式化工具。 Prettier（可不安装，Vetur 已打包）可以通过自定义快捷键来触发格式化文档： editor.action.formatDocument editor.action.formatSelection 开启保存时格式化 &#123; \"editor.formatOnSave\": true&#125; 还可以针对特定的语言才开启： &#123; // Set the default \"editor.formatOnSave\": false, // Enable per-language \"[javascript]\": &#123; \"editor.formatOnSave\": true &#125;&#125; 配置对于 prettier 的配置方式有多种： .prettierrc 文件。 直接在工程中的 settings.json 内配置。 在 Home 目录下写一个 .prettierrc 文件。 .prettierrc 文件的优先级高于 settings.json 的设置。 配置文件会从两个地方读取： 从 prettier 配置文件读取，文件查找顺序查看 Configuration File .editorconfig 如果不存在 prettier 的配置文件，那么就从 settings.json 读取。 prettier.printWidth (default: 80) prettier.tabWidth (default: 2) prettier.singleQuote (default: false) prettier.trailingComma (default: ‘none’) prettier.bracketSpacing (default: true) prettier.jsxBracketSameLine (default: false) prettier.parser (default: ‘babylon’) - JavaScript only prettier.semi (default: true) prettier.useTabs (default: false) prettier.proseWrap (default: ‘preserve’) prettier.arrowParens (default: ‘avoid’) prettier.jsxSingleQuote (default: false) prettier.htmlWhitespaceSensitivity (default: ‘css’) prettier.endOfLine (default: ‘auto’) prettier.eslintIntegration (default: false) - JavaScript and TypeScript only 控制是否 prettier-eslint i 来替代 prettier。 prettier.tslintIntegration (default: false) - JavaScript and TypeScript only prettier.stylelintIntegration (default: false) - CSS, SCSS and LESS only prettier.requireConfig (default: false) prettier.ignorePath (default: .prettierignore) prettier.disableLanguages (default: [“vue”]) 我觉得我应该开启的选项有： &#123; \"prettier.semi\": false, \"prettier.singleQuote\": true, \"prettier.eslintIntegration\": true \"prettier.disableLanguages\": [] &#125; 不知道为什么会 vue 给关掉呢。 ESLintESLint 用来做代码检查，经过上面的步骤，我们代码是按照 prettier 的格式来进行格式化的。但 ESLint 的检查规则与其有不一样的地方。介于我们不想有冲突产生，所以我们有两种办法来将 prettier 与 ESLint 集成。 我们首先开启 ESLint： &#123; \"eslint.enable\": true, \"eslint.autoFixOnSave\": true, \"eslint.validate\": [ \"javascript\", \"javascriptreact\", &#123; \"language\": \"vue\", \"autoFix\": true &#125; ]&#125; eslint.autoFixOnSave 选项会配置自动修复检查到的问题。 问题ESLint 除了代码检查外，还会做一些代码格式化的功能。我们可以： 关闭 ESLint 的格式化规则，按照 prettier 的来进行格式化。 ESLint 按照 prettier 的规则来进行格式化。 ESLint 运行 Prettier安装插件 https://github.com/prettier/eslint-plugin-prettier yarn add --dev prettier eslint-plugin-prettier 配置 .eslintrc.js &#123; \"plugins\": [\"prettier\"], \"rules\": &#123; \"prettier/prettier\": \"error\" &#125;&#125; 关闭 ESLint 格式化规则安装 https://github.com/prettier/eslint-config-prettier yarn add --dev eslint-config-prettier 编辑 .eslintrc.js &#123; \"extends\": [\"prettier\"]&#125; 同时使用以上两种方法eslint-plugin-prettier 有一个 recommended 配置，其开启了 eslint-plugin-prettier 和 eslint-config-prettier。 &#123; \"extends\": [\"plugin:prettier/recommended\"]&#125; 记住要先安装两个插件： yarn add --dev eslint-plugin-prettier eslint-config-prettier 最终解决方案 安装 Vetur 插件 安装 ESLint 插件 VS Code settings 配置：&#123; \"editor.formatOnSave\": true, // 保存时格式化 \"javascript.format.enable\": false, // 关闭自带的格式化 \"eslint.enable\": true, // 启用eslint \"eslint.autoFixOnSave\": true, // 保存时自动修复 \"eslint.validate\": [ \"javascript\", \"javascriptreact\", \"vue\" ], // eslint 识别格式 \"vetur.format.defaultFormatterOptions\": &#123; \"prettier\": &#123; \"singleQuote\": true, \"semi\": false &#125;, // vetur 调用 prettier 的配置 &#125;&#125; .eslintrc.js// https://eslint.org/docs/user-guide/configuringmodule.exports = &#123; root: true, parserOptions: &#123; parser: 'babel-eslint' &#125;, env: &#123; browser: true &#125;, // https://github.com/vuejs/eslint-plugin-vue#priority-a-essential-error-prevention // consider switching to `plugin:vue/strongly-recommended` or `plugin:vue/recommended` for stricter rules. extends: ['plugin:vue/essential'], // required to lint *.vue files plugins: ['vue',], // add your custom rules here rules: &#123; // allow debugger during development 'no-debugger': process.env.NODE_ENV === 'production' ? 'error' : 'off', semi: ['error', 'never'], // 取消分号 quotes: ['error', 'single'] // 使用单引号 &#125;&#125;","categories":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://gowa2017.github.io/categories/JavaScript/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://gowa2017.github.io/tags/JavaScript/"},{"name":"Vue","slug":"Vue","permalink":"https://gowa2017.github.io/tags/Vue/"}],"keywords":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://gowa2017.github.io/categories/JavaScript/"}]},{"title":"关于Cocos2d-Lua使用NDK编译过程的解析","slug":"关于Cocos2d-Lua使用NDK编译过程的解析","date":"2019-02-07T13:56:30.000Z","updated":"2019-02-07T13:56:30.000Z","comments":true,"path":"Cocos2d-X/关于Cocos2d-Lua使用NDK编译过程的解析.html","link":"","permalink":"https://gowa2017.github.io/Cocos2d-X/关于Cocos2d-Lua使用NDK编译过程的解析.html","excerpt":"由于使用NDK编译打包安卓的时候出现了一些麻烦，所以来看一下整个编译过程是怎么样样的。一般来说是把引擎编译成动态库，然后在 Java 写的安卓代码内进行调用。Android NDK 是一组允许您将 C 或 C++（“原生代码”）嵌入到 Android 应用中的工具。 能够在 Android 应用中使用原生代码对于想执行以下一项或多项操作的开发者特别有用：","text":"由于使用NDK编译打包安卓的时候出现了一些麻烦，所以来看一下整个编译过程是怎么样样的。一般来说是把引擎编译成动态库，然后在 Java 写的安卓代码内进行调用。Android NDK 是一组允许您将 C 或 C++（“原生代码”）嵌入到 Android 应用中的工具。 能够在 Android 应用中使用原生代码对于想执行以下一项或多项操作的开发者特别有用： mk 文件在项目的 app/jni 目录下，会有 Application.mk 和 Android.mk 两个文件。 Android.mk：必须在 jni 文件夹内创建 Android.mk 配置文件。 ndk-build 脚本将查看此文件，其中定义了模块及其名称、要编译的源文件、版本标志以及要链接的库。 Application.mk：此文件枚举并描述您的应用需要的模块。 这些信息包括：用于针对特定平台进行编译的 ABI。工具链。要包含的标准库（静态和动态 STLport 或默认系统）。 一般工作流程 编写 C/C++ 代码。 编写 Android.mk,Application.mk 文件。 ndk-build 读取上面的两个文件，然后生成静态库或者共享库。 Java 代码内进行调用库内代码。 NDK 的核心目的之一是让您将 C 和 C++ 源代码构建为可用于应用的共享库。 Android.mkAndroid.mk 文件位于项目 jni/ 目录的子目录中，用于向构建系统描述源文件和共享库。 它实际上是构建系统解析一次或多次的微小 GNU makefile 片段。 Android.mk 文件用于定义 Application.mk、构建系统和环境变量所未定义的项目范围设置。 它还可替换特定模块的项目范围设置。 Android.mk 的语法用于将源文件分组为模块。 模块是静态库、共享库或独立可执行文件。 可在每个 Android.mk 文件中定义一个或多个模块，也可在多个模块中使用同一个源文件。 构建系统只会将共享库放入应用软件包。 此外，静态库可生成共享库。 除了封装库之外，构建系统还可为您处理各种其他详细信息。例如，您无需在 Android.mk 文件中列出标头文件或生成的文件之间的显式依赖关系。 NDK 构建系统会自动为您计算这些关系。 因此，您应该能够享受到未来 NDK 版本中新工具链/平台支持的优点，而无需接触 Android.mk 文件。 基本知识LOCAL_PATHAndroid.mk 文件必须首先定义 LOCAL_PATH 变量： LOCAL_PATH := $(call my-dir) 此变量表示源文件在开发树中的位置。在这里，构建系统提供的宏函数 my-dir 将返回当前目录（包含 Android.mk 文件本身的目录）的路径。 CLEAR_VARS下一行声明 CLEAR_VARS 变量，其值由构建系统提供。 include $(CLEAR_VARS) CLEAR_VARS 变量指向特殊 GNU Makefile，可为您清除许多 LOCAL_XXX 变量，例如 LOCAL_MODULE、LOCAL_SRC_FILES 和 LOCAL_STATIC_LIBRARIES。 请注意，它不会清除 LOCAL_PATH。此变量必须保留其值，因为系统在单一 GNU Make 执行环境（其中所有变量都是全局的）中解析所有构建控制文件。 在描述每个模块之前，必须声明（重新声明）此变量。 LOCAL_MODULE接下来，LOCAL_MODULE 变量将存储您要构建的模块的名称。请在应用中每个模块使用一个此变量。 LOCAL_MODULE := hello-jni 每个模块名称必须唯一，且不含任何空格。构建系统在生成最终共享库文件时，会将正确的前缀和后缀自动添加到您分配给 LOCAL_MODULE 的名称。 例如，上述示例会导致生成一个名为 libhello-jni.so 的库。 LOCAL_SRC_FILES下一行枚举源文件，以空格分隔多个文件： LOCAL_SRC_FILES := hello-jni.c LOCAL_SRC_FILES 变量必须包含要构建到模块中的 C 和/或 C++ 源文件列表。 最后一行帮助系统将所有内容连接到一起： include $(BUILD_SHARED_LIBRARY) BUILD_SHARED_LIBRARY 变量指向 GNU Makefile 脚本，用于收集您自最近 include 后在 LOCAL_XXX 变量中定义的所有信息。 此脚本确定要构建的内容及其操作方法。 示例目录中有更复杂的示例，包括您可以查看的带注释的 Android.mk 文件。 此外，示例：native-activity 详细说明了该示例的 Android.mk 文件。 最后，变量和宏提供本节中变量的进一步信息。 LOCAL_LDLIBS链接外部库： LOCAL_LDLIBS := -llog -landroid -lEGL -lGLESv1_CM LOCAL_STATIC_LIBRARIES指明静态库名称。 LOCAL_STATIC_LIBRARIES := android_native_app_glue import-module$(call import-module,android/native_app_glue)","categories":[{"name":"Cocos2d-X","slug":"Cocos2d-X","permalink":"https://gowa2017.github.io/categories/Cocos2d-X/"}],"tags":[{"name":"Cocos2d-X","slug":"Cocos2d-X","permalink":"https://gowa2017.github.io/tags/Cocos2d-X/"}],"keywords":[{"name":"Cocos2d-X","slug":"Cocos2d-X","permalink":"https://gowa2017.github.io/categories/Cocos2d-X/"}]},{"title":"使用国内阿里的Google镜像源加快依赖下载速度","slug":"使用国内阿里的Google镜像源加快依赖下载速度","date":"2019-02-07T13:49:33.000Z","updated":"2019-02-07T13:49:33.000Z","comments":true,"path":"Android/使用国内阿里的Google镜像源加快依赖下载速度.html","link":"","permalink":"https://gowa2017.github.io/Android/使用国内阿里的Google镜像源加快依赖下载速度.html","excerpt":"现在官方新建的项目默认会使用 google() 和 jcenter() 两个仓库，但是速度都不是很快，所以需要更换为阿里的镜像。","text":"现在官方新建的项目默认会使用 google() 和 jcenter() 两个仓库，但是速度都不是很快，所以需要更换为阿里的镜像。 官方设置buildscript &#123; repositories &#123; jcenter() google() &#125; dependencies &#123; classpath 'com.android.tools.build:gradle:3.1.3' // NOTE: Do not place your application dependencies here; they belong // in the individual module build.gradle files &#125;&#125;allprojects &#123; repositories &#123; jcenter() google() &#125;&#125; 修改后buildscript &#123; repositories &#123;// mavenCentral()// jcenter()// google() maven &#123; url 'https://plugins.gradle.org/m2/' &#125; maven &#123; url 'http://maven.aliyun.com/nexus/content/repositories/google' &#125; maven &#123; url 'http://maven.aliyun.com/nexus/content/groups/public/' &#125; maven &#123; url 'http://maven.aliyun.com/nexus/content/repositories/jcenter'&#125; &#125; dependencies &#123; classpath 'com.android.tools.build:gradle:3.0.1' &#125;&#125;allprojects &#123; repositories &#123;// mavenCentral()// jcenter()// google() maven &#123; url 'https://plugins.gradle.org/m2/' &#125; maven &#123; url 'http://maven.aliyun.com/nexus/content/repositories/google' &#125; maven &#123; url 'http://maven.aliyun.com/nexus/content/groups/public/' &#125; maven &#123; url 'http://maven.aliyun.com/nexus/content/repositories/jcenter'&#125; &#125;&#125; 阿里镜像仓库地址 阿里镜像仓库地址","categories":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"},{"name":"Gradle","slug":"Gradle","permalink":"https://gowa2017.github.io/tags/Gradle/"}],"keywords":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}]},{"title":"关于使用PureMVC-LUA进行开发的一个过程","slug":"关于使用PureMVC-LUA进行开发的一个过程","date":"2019-02-03T13:04:18.000Z","updated":"2019-02-03T13:04:18.000Z","comments":true,"path":"Cocos2d-X/关于使用PureMVC-LUA进行开发的一个过程.html","link":"","permalink":"https://gowa2017.github.io/Cocos2d-X/关于使用PureMVC-LUA进行开发的一个过程.html","excerpt":"不要问我为什么，业务需要，有用到，所以来了解一下这么个例子。暂不说其优劣。","text":"不要问我为什么，业务需要，有用到，所以来了解一下这么个例子。暂不说其优劣。 简介PureMVC官方网站地址 官方网站上没有 Lua 的实现，属于个人作者做的。 puremvc-lua项目地址 最佳实践中文版 说道 MVC 自然就少不了 Model, View, Controler。但在不同的框架中其表现的意义是不一样的。 关系图 Model, View, Controler, Facade 类都是单例模式。 Model 缓存了对 Proxies 的引用，View 缓存对 Mediators 的引用，Controler 维护对 Command 类的映射，这些 Command 是无状态的，只有在需要的时候才建立。由 Facede 来初始化 Model, View, Controler，同时提供一个类来访问三着所有公共的方法。 Mediators 操作 View Components（视图组件），Proxy 操作数据模型（包括服务），Command 负责比较复杂的活动（比如APP启动，关闭等）。Proxies，Mediators，Commands 都会用到 Facade 来用其他两者进行通信。 Model管理 Proxies，Proxies 进行实际的数据操作。 Proxies 可以通知 View 和 Controler。 View管理 Mediators，同时操作从 View Components 来的事件，及将数据传递给 视图组件。 Controler管理 Commands， Commands 是业务逻辑所在。 Commands 可以通知 View， 更新 Model。 实现PureMVC 的入口，是 Facade，用在 Cococs-2dx Lua ，那么就是在 main.lua 中获取一个 Facade 实例。 我们通过继承 Facade 来自定义一个 AppFacade。 AppFacade = class(\"AppFacade\", puremvc.Facade)function AppFacade:ctor(key) self.super.ctor(self, key) --invote base methodendfunction AppFacade:initializeController() --invote base method self.super.initializeController(self) self:initCommand()end--注册游戏Commandfunction AppFacade:initCommand() local StartupCommand = require(\"client.src.controller.command.StartupCommand\") local LoadViewCommand = require(\"client.src.controller.command.LoadViewCommand\") local UnLoadViewCommand = require(\"client.src.controller.command.UnLoadViewCommand\") self:registerCommand(GAME_COMMAMD.START_UP, StartupCommand) self:registerCommand(GAME_COMMAMD.LOAD_VIEW, LoadViewCommand) self:registerCommand(GAME_COMMAMD.UNLOAD_VIEW, UnLoadViewCommand)endfunction AppFacade:startup() self:sendNotification(GAME_COMMAMD.START_UP)end--脚本重启function AppFacade.restartup(key) local key = key or \"DefaultKey\" AppFacade.removeCore(key) AppFacade:getInstance():sendNotification(GAME_COMMAMD.START_UP)endfunction AppFacade:getInstance(key) local key = key or \"DefaultKey\" local instance = self.instanceMap[key] if nil ~= instance then return instance end if nil == self.instanceMap[key] then self.instanceMap[key] = AppFacade.new(key) end return self.instanceMap[key]end Command 注册在我们自定义的 Facade 中，我们注册了三个通知的处理类。事实上， Facade 作为一个全局的容器，容纳所有的对象，通过容器获取想要的对象进行操作。 注册通知，实际上就是在 Facade 的 Controler 内增加一个映射。 function Facade:registerCommand(notificationName, commandClassRef) self.controller:registerCommand(notificationName, commandClassRef) end function Controller:registerCommand(notificationName, commandClassRef) assert(type(notificationName) == \"string\", \"notificationName expected string\") assert(type(commandClassRef) == \"table\", \"commandClassRef expected table\") if(self.commandMap[notificationName] == nil) then self.view:registerObserver(notificationName, Observer.new(self.executeCommand, self)); end self.commandMap[notificationName] = commandClassRefend 这里需要注意的是 Observer.new(self.executeCommand, self)); 观察者的通知方法(notifyMethod)，就是 Controler的 executeCommand 方法： function Controller:executeCommand(note) local commandClassRef = self.commandMap[note:getName()] if(commandClassRef == nil) then return end local commandInstance = commandClassRef.new() commandInstance:initializeNotifier(self.multitonKey) commandInstance:execute(note)end 通知上下文，就是 Controler 本身。 function View:registerObserver(notificationName, observer) if self.observerMap[notificationName] ~= nil then table.insert(self.observerMap[notificationName], observer) else self.observerMap[notificationName] = &#123;observer&#125; endend 除了在 Controler 中增加一个通知类型到处理类的映射，还会在 View 中注册观察者。 在 View 中，有个类型的通知，可能有多个观察者。 启动在我们的 main.lua 中，调用 AppFacade 的 startup() 方法。 local function main() AppFacade:getInstance():startup()endlocal status, msg = xpcall(main, __G__TRACKBACK__)if not status then print(msg)end 其本质，也就是发送了一个通知出去： function AppFacade:startup() self:sendNotification(GAME_COMMAMD.START_UP)end 我们的通知，将会由我们注册的映射类处理，在前面的代码中，我们可以知道，其是 StartupCommand。 通知处理self:sendNotification(GAME_COMMAMD.START_UP) 调用的是 Facade 类中的方法： function Facade:sendNotification(notificationName, body, type) self:notifyObservers(Notification.new(notificationName, body, type))endfunction Facade:notifyObservers(notification) if self.view ~= nil then self.view:notifyObservers(notification) endend 其本质，是在 View 中，将所有此通知类型观察者都进行通知。 function View:notifyObservers(notification) if self.observerMap[notification:getName()] ~= nil then local observers_ref = self.observerMap[notification:getName()] for _, o in pairs(observers_ref) do o:notifyObserver(notification) end endend function Observer:notifyObserver(notification) self.notify(self.context, notification)end 前文说到，观察者的通知方法，已经被设置为 Controler 的 executeCommand 方法， function Controller:executeCommand(note) local commandClassRef = self.commandMap[note:getName()] if(commandClassRef == nil) then return end local commandInstance = commandClassRef.new() commandInstance:initializeNotifier(self.multitonKey) commandInstance:execute(note)end 此方法所做的就是根据通知类型，获取对应的类进行实例化，然后调用其 execute 方法。在我们这里，其实据执行的 StartupCommand:execute() 方法： function StartupCommand:execute(note) self.super.execute(self, note) --@parm1 消息命令 --@parm2 合并到 context.data 中，作为状态被传递到 Mediator 使用，使用 context.data 在场景之间传递信息非常方便 --@parm3 消息命令附带信息 ? 这个信息是发到哪里去了？ self:sendNotification(GAME_COMMAMD.PUSH_VIEW, &#123;&#125;, VIEW_LIST.WELLCOME_SCENE) --self:sendNotification(GAME_COMMAMD.PUSH_VIEW, &#123;&#125;, VIEW_LIST.WELLCOME_SCENE)end SubCommand其会先执行父类中的 execute 方法，再执行自定义的方法。由于我们之前添加了三个子 Command ，所以会优先执行： local PrepModelCommand = require(\"client.src.controller.command.PrepModelCommand\")local PrepControllerCommand = require(\"client.src.controller.command.PrepControllerCommand\")local PrepViewCommand = require(\"client.src.controller.command.PrepViewCommand\") function MacroCommand:execute(note) -- SIC- TODO optimize while(#self.subCommands &gt; 0) do local ref= table.remove(self.subCommands, 1) local cmd= ref.new() cmd:initializeNotifier(self.multitonKey) cmd:execute(note) endend 以 PrepViewCommand 为例： function PrepViewCommand:execute(note) self.super.ctor(self) local ViewMediator = require(\"client.src.view.mediator.ViewMediator\") self.facade:registerMediator(ViewMediator.new())end 其向 Facade 注册了一个 ViewMediator。 我们简单看一下其注册过程： function Facade:registerMediator(mediator) if self.view ~= nil then self.view:registerMediator(mediator) endend function View:registerMediator(mediator) if self.mediatorMap[mediator:getMediatorName()] ~= nil then return end mediator:initializeNotifier(self.multitonKey) self.mediatorMap[mediator:getMediatorName()] = mediator local interests = mediator:listNotificationInterests() if #interests &gt; 0 then local observer = Observer.new(mediator.handleNotification, mediator) for _, i in pairs(interests) do self:registerObserver(i, observer) end end mediator:onRegister()end 在这里，比较需要重点注意的是，每个 ViewMediator 会关注多个通知类型，那么就要为每个通知类型建立一个观察者，每个观察者的处理函数，及上下文都一样。 在我们这个 ViewMediator 中其关注的通知类型有几种： function ViewMediator:listNotificationInterests() self.super.listNotificationInterests(self) --该mediator关心的消息 return &#123; GAME_COMMAMD.PUSH_VIEW, GAME_COMMAMD.POP_VIEW, GAME_COMMAMD.PLAY_EFFECT, GAME_COMMAMD.PLAY_ONE_EFFECT &#125;end 当其中一种通知到来的时候，就会调用其通知处理函数： function ViewMediator:handleNotification(notification) self.super.handleNotification(self, notification) local msgName = notification:getName() local msgData = notification:getBody() local msgType = notification:getType() --local contextProxy = AppFacade:getInstance():retrieveProxy(\"ContextProxy\") --处理收到的消息 printf(\"msgName:%s Line:%d Command:%s\", msgName, debug.getinfo(1).currentline, msgName) if (msgName == GAME_COMMAMD.PUSH_VIEW) then --self:sendNotification(GAME_COMMAMD.LOAD_VIEW, ) --local context = Context.new() or contextProxy:findContextByName(msgType) -- load context nData --[[ if (type(msgData) == \"table\") then for k, v in pairs(msgData) do context.data[k] = v end end--]] assert(msgType ~= nil, \"PushView Name expected not nil\") local mediatorClass = nil local viewClass = nil --创建上下文环境 if (msgType == VIEW_LIST.WELLCOME_SCENE) then mediatorClass = nil viewClass = require(\"client.src.view.component.WelcomeScene\") elseif (msgType == VIEW_LIST.LOGON_SCENE) then mediatorClass = nil viewClass = require(\"client.src.plaza.views.LogonScene\") elseif (msgType == VIEW_LIST.CLIENT_SCENE) then mediatorClass = require(\"client.src.view.mediator.ClientSceneMediator\") viewClass = require(\"client.src.plaza.views.ClientScene\") elseif (msgType == VIEW_LIST.ROOM_LIST_LAYER) then mediatorClass = require(\"client.src.view.mediator.RoomListMediator\") viewClass = require(\"client.src.plaza.views.layer.plaza.RoomListLayer\") elseif (msgType == VIEW_LIST.GONGGAO_LAYER) then mediatorClass = nil viewClass = require(\"client.src.plaza.views.layer.plaza.GongGaoLayer\") elseif (msgType == VIEW_LIST.VIP_LAYER) then mediatorClass = nil viewClass = require(\"client.src.plaza.views.layer.plaza.VIPLayer\") elseif (msgType == VIEW_LIST.GONGGAO_IOS_LAYER) then mediatorClass = nil viewClass = require(\"client.src.plaza.views.layer.plaza.GongGaoLayerIOS\") elseif (msgType == VIEW_LIST.PERSON_LAYER) then mediatorClass = require(\"client.src.view.mediator.UserInfoMediator\") viewClass = require(\"client.src.plaza.views.layer.plaza.UserInfoLayer\") elseif (msgType == VIEW_LIST.POPWAIT_LAYER) then mediatorClass = nil viewClass = require(\"client.src.app.views.layer.other.PopWait\") elseif (msgType == VIEW_LIST.QUERY_DIALOG_LAYER) then mediatorClass = nil viewClass = require(\"client.src.app.views.layer.other.QueryDialog\") elseif (msgType == VIEW_LIST.SELECT_SYSTEM_HEAD_LAYER) then mediatorClass = require(\"client.src.view.mediator.SelectSystemHeadMediator\") viewClass = require(\"client.src.plaza.views.layer.plaza.SelectSystemHeadLayer\") elseif (msgType == VIEW_LIST.SHARE_LAYER) then mediatorClass = nil viewClass = require(\"client.src.plaza.views.layer.plaza.PromoterInputLayer\") elseif (msgType == VIEW_LIST.GAME_LAYER) then mediatorClass = nil assert(msgData.viewClassPath ~= nil, \"viewClassPath is nil please check game path\") viewClass = require(msgData.viewClassPath) elseif (msgType == VIEW_LIST.ACTIVITY_LAYER) then mediatorClass = nil viewClass = require(\"client.src.plaza.views.layer.plaza.ActivityLayer\") elseif (msgType == VIEW_LIST.ACTIVITY_IOS_LAYER) then mediatorClass = nil viewClass = require(\"client.src.plaza.views.layer.plaza.ActivityLayerIOS\") elseif (msgType == VIEW_LIST.MODIFY_ACCOUNT_PASS_LAYER) then mediatorClass = nil viewClass = require(\"client.src.plaza.views.layer.plaza.ModifyAccountPasswdLayer\") elseif (msgType == VIEW_LIST.MODIFY_BANK_PASS_LAYER) then mediatorClass = nil viewClass = require(\"client.src.plaza.views.layer.plaza.ModifyBankPasswdLayer\") elseif (msgType == VIEW_LIST.TASKLAYER) then mediatorClass = nil viewClass = require(\"client.src.plaza.views.layer.plaza.TaskLayer\") elseif (msgType == VIEW_LIST.BANK_LAYER) then mediatorClass = require(\"client.src.view.mediator.BankMediator\") viewClass = require(\"client.src.plaza.views.layer.plaza.BankLayer\") elseif (msgType == VIEW_LIST.BANK_OPEN_LAYER) then mediatorClass = require(\"client.src.view.mediator.BankOpenMediator\") viewClass = require(\"client.src.plaza.views.layer.plaza.BankOpenLayer\") elseif (msgType == VIEW_LIST.BANK_MODIFY_LAYER) then mediatorClass = require(\"client.src.view.mediator.BankModifyMediator\") viewClass = require(\"client.src.plaza.views.layer.plaza.BankModifyLayer\") elseif (msgType == VIEW_LIST.GAME_WAIT_LAYER) then mediatorClass = nil viewClass = require(\"client.src.app.views.layer.other.PopGameWait\") elseif (msgType == VIEW_LIST.SETTING_LAYER) then mediatorClass = nil viewClass = require(\"client.src.plaza.views.layer.other.OptionLayer\") elseif (msgType == VIEW_LIST.SHOP_LAYER) then mediatorClass = require(\"client.src.view.mediator.ShopMediator\") viewClass = require(\"client.src.plaza.views.layer.plaza.ShopLayer\") elseif (msgType == VIEW_LIST.SHOP_APPSTORE_LAYER) then mediatorClass = require(\"client.src.view.mediator.ShopMediator\") viewClass = require(\"client.src.plaza.views.layer.plaza.ShopAppstoreLayer\") elseif (msgType == VIEW_LIST.EARN_LAYER) then mediatorClass = require(\"client.src.view.mediator.ShopMediator\") --require(\"client.src.view.mediator.EarnMediator\") viewClass = require(\"client.src.plaza.views.layer.plaza.EarnLayer\") elseif (msgType == VIEW_LIST.EARN_MONEY) then mediatorClass = require(\"client.src.view.mediator.ShopMediator\") --require(\"client.src.view.mediator.EarnMediator\") viewClass = require(\"client.src.plaza.views.layer.plaza.EarnMoney\") elseif (msgType == VIEW_LIST.VISITOR_BIND_LAYER) then mediatorClass = nil --require(\"client.src.view.mediator.EarnMediator\") viewClass = require(\"client.src.plaza.views.layer.plaza.VisitorBindLayer\") elseif (msgType == VIEW_LIST.AGENT_RECHARGE_LAYER) then mediatorClass = nil --require(\"client.src.view.mediator.EarnMediator\") viewClass = require(\"client.src.plaza.views.layer.plaza.AgentRechargeLayer\") elseif (msgType == VIEW_LIST.REGISTER_AGREATMENT) then mediatorClass = nil --require(\"client.src.view.mediator.EarnMediator\") viewClass = require(\"client.src.plaza.views.layer.logon.Agreatment\") elseif (msgType == VIEW_LIST.ACCOUNT_REGISTER_LAYER) then mediatorClass = nil --require(\"client.src.view.mediator.EarnMediator\") viewClass = require(\"client.src.plaza.views.layer.logon.AccountRegisterView\") elseif (msgType == VIEW_LIST.SHOW_POP_TIPS) then mediatorClass = nil viewClass = require(\"client.src.app.views.layer.other.PopTips\") elseif (msgType == VIEW_LIST.SHOP_SHENGQING_DAILI) then mediatorClass = nil --require(\"client.src.view.mediator.EarnMediator\") viewClass = require(\"client.src.plaza.views.layer.plaza.AgentShengQingLayer\") elseif (msgType == VIEW_LIST.SHOP_SHENGQING_DAILI_COMFIRM) then mediatorClass = nil --require(\"client.src.view.mediator.EarnMediator\") viewClass = require(\"client.src.plaza.views.layer.plaza.AgentShengQingConfirmLayer\") elseif (msgType == VIEW_LIST.SHOP_TOUSU_DAILI) then mediatorClass = require(\"client.src.view.mediator.AgentTouSuMediator\") viewClass = require(\"client.src.plaza.views.layer.plaza.AgentTouSuLayer\") elseif (msgType == VIEW_LIST.AGENT_AGREATMENT) then mediatorClass = nil viewClass = require(\"client.src.plaza.views.layer.plaza.AgentAgreatment\") elseif (msgType == VIEW_LIST.GAME_RULE) then mediatorClass = nil viewClass = require(\"client.src.plaza.views.layer.plaza.GameRule\") elseif (msgType == VIEW_LIST.RECHARGE_RIGHT_NOW) then mediatorClass = nil viewClass = require(\"client.src.plaza.views.layer.plaza.RechargeRightNow\") elseif (msgType == VIEW_LIST.ROATEWAIT_LAYER) then mediatorClass = nil viewClass = require(\"client.src.view.component.PopRoateWait\") elseif (msgType == VIEW_LIST.SELECT_LINK_LAYER) then mediatorClass = nil viewClass = require(\"client.src.plaza.views.layer.plaza.SelectLinkLayer\") elseif (msgType == VIEW_LIST.HALL_MESSAGE_LAYER) then mediatorClass = nil viewClass = require(\"client.src.plaza.views.layer.plaza.HallMessageLayer\") else assert(false, \"not support view type\") end local genid = guid() self:sendNotification( GAME_COMMAMD.LOAD_VIEW, &#123;id = genid, viewClass = viewClass, mediatorClass = mediatorClass, parm = msgData&#125;, msgType ) elseif (msgName == GAME_COMMAMD.POP_VIEW) then if (msgData ~= nil) then -- load context nData self:sendNotification(GAME_COMMAMD.UNLOAD_VIEW, msgData) else self:sendNotification(GAME_COMMAMD.UNLOAD_VIEW) end elseif (msgName == GAME_COMMAMD.PLAY_ONE_EFFECT) then --只播放一次的 音效 local musicPath = msgType assert(type(msgType) == \"string\") --获取音乐播放配置 local musicProxy = AppFacade:getInstance():retrieveProxy(\"MusicRecordProxy\") local refCount = musicProxy:addRef(musicPath) if (refCount == 1) then AudioEngine.playEffect(cc.FileUtils:getInstance():fullPathForFilename(musicPath), false) end elseif (msgName == GAME_COMMAMD.PLAY_EFFECT) then local musicPath = msgType assert(type(msgType) == \"string\") --获取音乐播放配置 AudioEngine.playEffect(cc.FileUtils:getInstance():fullPathForFilename(musicPath), false) else assert(false, \"Command not support now!\") endend StartupCommand:executefunction StartupCommand:execute(note) self.super.execute(self, note) --@parm1 消息命令 --@parm2 合并到 context.data 中，作为状态被传递到 Mediator 使用，使用 context.data 在场景之间传递信息非常方便 --@parm3 消息命令附带信息 ? 这个信息是发到哪里去了？ self:sendNotification(GAME_COMMAMD.PUSH_VIEW, &#123;&#125;, VIEW_LIST.WELLCOME_SCENE) --self:sendNotification(GAME_COMMAMD.PUSH_VIEW, &#123;&#125;, VIEW_LIST.WELLCOME_SCENE)end 最终，当我们的调用 self:sendNotification(GAME_COMMAMD.PUSH_VIEW, {}, VIEW_LIST.WELLCOME_SCENE)，将会由 ViewMediator:handleNotification(notification) 处理： if (msgName == GAME_COMMAMD.PUSH_VIEW) then --self:sendNotification(GAME_COMMAMD.LOAD_VIEW, ) --local context = Context.new() or contextProxy:findContextByName(msgType) -- load context nData --[[ if (type(msgData) == \"table\") then for k, v in pairs(msgData) do context.data[k] = v end end--]] assert(msgType ~= nil, \"PushView Name expected not nil\") local mediatorClass = nil local viewClass = nil --创建上下文环境 if (msgType == VIEW_LIST.WELLCOME_SCENE) then mediatorClass = nil viewClass = require(\"client.src.view.component.WelcomeScene\") .......... local genid = guid() self:sendNotification( GAME_COMMAMD.LOAD_VIEW, &#123;id = genid, viewClass = viewClass, mediatorClass = mediatorClass, parm = msgData&#125;, msgType ) LOAD_VIEW 事件此事件在 Facade 中注册： self:registerCommand(GAME_COMMAMD.LOAD_VIEW, LoadViewCommand) function LoadViewCommand:execute(note) local msgData = note:getBody() local msgType = note:getType() --总视图上下文环境栈 local contextProxy = AppFacade:getInstance():retrieveProxy(\"ContextProxy\") --[[ --查找要添加的视图 local willAddContext = msgData.context if (willAddContext:getParent() ~= nil) then assert(false, \"this context already has parent context\") end --]] --suspend、running、dead、normal local eventCoroutine = nil eventCoroutine = coroutine.create(function() local willAddContext = nil local Context = require(\"client.src.model.base.Context\") if (msgData.parm.canrepeat == false) then willAddContext = contextProxy:findContextByName(msgType) or Context.new() else willAddContext = Context.new() end --判断是否为新创建的 Context 界面 if (willAddContext:getParent() == nil) then willAddContext:setName(msgType) willAddContext:setViewClass(msgData.viewClass) willAddContext:setMediatorClass(msgData.mediatorClass) end --附加数据重新赋值 if (type(msgData.parm) == \"table\") then willAddContext.data = &#123;&#125; for k, v in pairs(msgData.parm) do willAddContext.data[k] = v end end --引用次数 +1 local refCount = willAddContext:retain() --printf(\"PUSH_VIEW %d\", debug.getinfo(1).currentline) if (willAddContext.data.canrepeat == false) then if (refCount &gt; 1) then printf(\"PUSH_VIEW FAILED,the view is find, attribute is not repeat!\", debug.getinfo(1).currentline) else --上下文环境入栈 --printf(\"PUSH_VIEW %d\", debug.getinfo(1).currentline) self:recursiveAddView(willAddContext, function (context) if (context == willAddContext) then if (willAddContext.data.viewcallback ~= nil) then willAddContext.data.viewcallback(context:getView(), \"enter\") end end end, eventCoroutine) --printf(\"PUSH_VIEW %d\", debug.getinfo(1).currentline) coroutine.yield() end else --上下文环境入栈 --printf(\"PUSH_VIEW %d\", debug.getinfo(1).currentline) self:recursiveAddView(willAddContext, function (context) if (context == willAddContext) then if (willAddContext.data.viewcallback ~= nil) then willAddContext.data.viewcallback(context:getView(), \"enter\") end end end, eventCoroutine) coroutine.yield() end --printf(\"PUSH_VIEW %d\", debug.getinfo(1).currentline) local frontEventCoroutine = contextProxy:frontEvent() if (frontEventCoroutine) then --printf(\"PUSH_VIEW %d\", debug.getinfo(1).currentline) if (frontEventCoroutine ~= eventCoroutine) then --printf(\"PUSH_VIEW %d\", debug.getinfo(1).currentline) local result, msg = coroutine.resume(frontEventCoroutine) assert(result, msg) else --printf(\"PUSH_VIEW %d\", debug.getinfo(1).currentline) contextProxy:popFrontEvent() local nxtEventCoroutine = contextProxy:frontEvent() if (nxtEventCoroutine) then --printf(\"PUSH_VIEW %d\", debug.getinfo(1).currentline) local result, msg = coroutine.resume(nxtEventCoroutine) assert(result, msg) end end end end) local frontCoroutine = contextProxy:frontEvent() contextProxy:pushBackEvent(eventCoroutine) --printf(\"PUSH_VIEW %d\", debug.getinfo(1).currentline) if (frontCoroutine == nil) then --printf(\"PUSH_VIEW %d\", debug.getinfo(1).currentline) local result, msg = coroutine.resume(eventCoroutine) assert(result, msg) endend 通过上下文来操作这个问题比较复杂，有空再解释。","categories":[{"name":"Cocos2d-X","slug":"Cocos2d-X","permalink":"https://gowa2017.github.io/categories/Cocos2d-X/"}],"tags":[{"name":"Lua","slug":"Lua","permalink":"https://gowa2017.github.io/tags/Lua/"},{"name":"Cocos2d-X","slug":"Cocos2d-X","permalink":"https://gowa2017.github.io/tags/Cocos2d-X/"}],"keywords":[{"name":"Cocos2d-X","slug":"Cocos2d-X","permalink":"https://gowa2017.github.io/categories/Cocos2d-X/"}]},{"title":"JS原型继承的深入理解","slug":"JS原型继承的深入理解","date":"2019-01-16T22:28:10.000Z","updated":"2019-01-16T22:28:10.000Z","comments":true,"path":"JavaScript/JS原型继承的深入理解.html","link":"","permalink":"https://gowa2017.github.io/JavaScript/JS原型继承的深入理解.html","excerpt":"JS 的继承是通过原型来实现的。每个对象都有一个原型属性 __proto__ ，然后，我们可以也多种方法来构造对象。但这中间有一些细节很值得我们深入了解。","text":"JS 的继承是通过原型来实现的。每个对象都有一个原型属性 __proto__ ，然后，我们可以也多种方法来构造对象。但这中间有一些细节很值得我们深入了解。 文前首先我们需要理解和区别，对象的原型属性(__proto__属性，或者通过 Object.getPrototypeOf()来获取) 与 函数的 prototype（此属性只有函数才有。prototype 属性的 constructor 指向函数本身）。 我们可以把 __proto__ 称为对象的原型，而把 prototype 称为函数的原型。 构造函数一般来说，构造函数的首字母会大写，以此来与其他一般的函数进行区分。 我们定义一个构造函数： function Person(first, last, age, gender, interests) &#123; this.name = &#123; first, last &#125;; this.age = age; this.gender = gender; this.interests = interests;&#125;; 函数，也是一个对象，其是一个 Function 的实例: console.log(typeof Person);// \"function\"。 函数，也有一个原型，我们这里并没有对他的原型做什么操作，所以其是默认的原生代码： Object.getPrototypeOf(Person)//ƒ () &#123; [native code] &#125; 可以看出，其原型是一个用原生代码编写的函数。 与 Object 的原型显示一样。 我们可以调用 Person.valueOf() 这样的函数，正是因为这是从 Object 原型继承的。 每一个函数对象，都有一个 prototype 属性（同时只有函数对象才有）。 因为：prototype 是定义在 Fuction 对象下的属性。 构造函数的 prototype 属性的构造方法（constructor），指向函数本身。 Person === Person.prototype.constructor。 我们可以进行验证： Person.prototype//&#123;constructor: ƒ&#125;// constructor: ƒ Person(first, last, age, gender,interests)//__proto__: ObjectPerson === Person.prototype.constructor// true 构造对象我们可以用 new 关键词来建立一个对象。 当我们输入类似var person1=new Person(…)来构造对象时，JavaScript实际上参考的是Person.prototype指向的对象来生成person1。 其基本流程是： 建立一个空对象。 将构造函数的执行环境绑定到此对象。(this 绑定，相当于调用 call(), apply())这样。 执行构造函数。 p1 = new Person(); 我们可以更详细的看一下 p1 的内容： Person &#123;name: &#123;…&#125;, age: undefined, gender: undefined, interests: undefined&#125;age: undefinedgender: undefinedinterests: undefinedname: &#123;first: undefined, last: undefined&#125;__proto__: constructor: ƒ Person(first, last, age, gender, interests) __proto__: Object p1 对象的原型，实际上指向的是构造函数的 prototype 属性： Object.getPrototypeOf(p1) === Person.prototype// true Object.create()我们可以把一个对象作为原型来建立对象，而不使用构造函数： p2 = Object.create(p1); 我们可以验证， p2 的原型就是 p1: Object.getPrototypeOf(p2) === p1//true 我们也可以看到 p2, p1 是不同的： p2//Person &#123;&#125;__proto__: Personage: undefinedgender: undefinedinterests: undefinedname: &#123;first: undefined, last: undefined&#125;// __proto__: Objectp1//Person &#123;name: &#123;…&#125;, age: undefined, gender: undefined, interests: undefined&#125;// age: undefined// gender: undefined// interests: undefined// name: &#123;first: undefined, last: undefined&#125;// __proto__: Object p2 本身没有任何属性，只有一个 _proto_ 属性 指明其原型。其实就是指向 p1 的意思。 我们改变 p1 的值， p2 也会变化： p1.age = 20;p2.age//20 classECMAScript6 引入了一套新的关键字用来实现 class。使用基于类语言的开发人员会对这些结构感到熟悉，但它们是不同的。JavaScript 仍然基于原型。这些新的关键字包括 class, constructor，static，extends 和 super。 \"use strict\";class Polygon &#123; constructor(height, width) &#123; this.height = height; this.width = width; &#125;&#125;class Square extends Polygon &#123; constructor(sideLength) &#123; super(sideLength, sideLength); &#125; get area() &#123; return this.height * this.width; &#125; set sideLength(newLength) &#123; this.height = newLength; this.width = newLength; &#125;&#125;var square = new Square(2);","categories":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://gowa2017.github.io/categories/JavaScript/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://gowa2017.github.io/tags/JavaScript/"}],"keywords":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://gowa2017.github.io/categories/JavaScript/"}]},{"title":"JS中的变量基础","slug":"JS中的变量基础","date":"2019-01-16T22:03:47.000Z","updated":"2019-01-16T22:03:47.000Z","comments":true,"path":"JavaScript/JS中的变量基础.html","link":"","permalink":"https://gowa2017.github.io/JavaScript/JS中的变量基础.html","excerpt":"了解一下基础知识，虽然 JS 很简单，但是经常会造成误解。","text":"了解一下基础知识，虽然 JS 很简单，但是经常会造成误解。 变量声明有三种方式： var let 块作用域变量 const 块作用域常量。 其中 块作用域 是在 ECMA 2015 才提出的。之前只有全局作用域和本地作用域两个概念。 变量提升let/const 在 ECMA6 中不会提升到代码顶部。所以在声明前引用，将会出错。 值的传递JS 中的变量的引用是引用的形式传递的。一个比较典型的例子就是在闭包中引用全局变量。先看一下全局变量作为参数的例子： var g = 'GLOBAL';function test(g)&#123; return function()&#123; console.log(g)&#125;;&#125;let fun1 = test(g);g = 'global';fun1(); 输出会是什么？答案是 GLOBAL。 再来看下一个例子： var g = 'GLOBAL';function test2()&#123; return function()&#123; console.log(g)&#125;;&#125;let fun2 = test2();g = 'global';fun2(); 输出是什么？答案是什么 global。 从后面一个例子看出，全局变量的变化其实会影响到所有其他引用它的地方。 之所以第一个例子输出的是 GLOBAL 而不是 global 是因为：当把 g 作为参数传递给 test 的时候，test 的本地作用域内会建立一个本地的变量 g，这个时候，引用的就不是全局变量了。所以你改变全局变量的值不会影响它。","categories":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://gowa2017.github.io/categories/JavaScript/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://gowa2017.github.io/tags/JavaScript/"}],"keywords":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://gowa2017.github.io/categories/JavaScript/"}]},{"title":"安卓9.0应用内升级失败的一种情况解决","slug":"安卓9.0应用内升级失败的一种情况解决","date":"2019-01-16T05:16:35.000Z","updated":"2019-01-16T05:16:35.000Z","comments":true,"path":"Android/安卓9.0应用内升级失败的一种情况解决.html","link":"","permalink":"https://gowa2017.github.io/Android/安卓9.0应用内升级失败的一种情况解决.html","excerpt":"本来应用内升级一切工作良好。但是在换了新设备，安卓9.0，华为机型后，突然就出现了死活更新不了的问题。首先的问题是总是提示更新失败请重试。通过调试代码发现问题所在。","text":"本来应用内升级一切工作良好。但是在换了新设备，安卓9.0，华为机型后，突然就出现了死活更新不了的问题。首先的问题是总是提示更新失败请重试。通过调试代码发现问题所在。 错误代码onError: android.util.AndroidRuntimeException: Calling startActivity() from outside of an Activity context requires the FLAG_ACTIVITY_NEW_TASK flag. Is this really what you want? 意思就是 如果是在 Activity 上下文中调用 startActivity() 方法的话，需要设置 FLAG_ACTIVITY_NEW_TASK 标志。 追踪一下我们的代码，启动安装新 apk 包的地方。 private void startInstallApk() &#123; myBinder.cancelDownload(); //apk文件的本地路径 File apkfile = new File(filePath); //会根据用户的数据类型打开android系统相应的Activity。 Intent intent = new Intent(Intent.ACTION_VIEW); //设置intent的数据类型是应用程序application //判读版本是否在7.0以上 if (Build.VERSION.SDK_INT &gt;= 24) &#123; Uri apkUri = FileProvider.getUriForFile(this, getPackageName() + \".fileprovider\", apkfile); intent.addFlags(Intent.FLAG_GRANT_READ_URI_PERMISSION); intent.setDataAndType(apkUri, \"application/vnd.android.package-archive\"); &#125; else &#123; //为这个新apk开启一个新的activity栈 intent.setFlags(Intent.FLAG_ACTIVITY_NEW_TASK); intent.setDataAndType(Uri.parse(\"file://\" + apkfile.toString()), \"application/vnd.android.package-archive\"); &#125; //开始安装 startActivity(intent); //关闭旧版本的应用程序的进程 android.os.Process.killProcess(android.os.Process.myPid());&#125; 代码中只有在 24 以下才添加了这个标志。OK，那么我们把这个标志加上。 为什么在我小米的 8.1 系统上正常？ intent.addFlags(Intent.FLAG_ACTIVITY_NEW_TASK); 继续编译看看是否能够更新了，此时我的 小米8.1 运行也正常，但是依然还不可以： Writing exception to parcel java.lang.SecurityException: Permission Denial: reading android.support.v4.content.FileProvider uri content://cn.nanming.smart.fileprovider/root_path/storage/emulated/0/Android/data/cn.nanming.smartenterprise/cache/smartEnterprise_4.4.114.apk from pid=27641, uid=10054 requires the provider be exported, or grantUriPermission() 这下读取我们下载包的请求又被拒绝了。这怎么破？ 根据 官方文档，我们需要临时进行授权，StackOverFlow 上也有这个问题的解答： grantUriPermission(getPackageName(),apkUri,Intent.FLAG_GRANT_READ_URI_PERMISSION); 最终：发觉我们的下载路径，并不是放在 provider 里面的，采用 Uri.fromFile 的形式能够正常执行升级了。 为什么后面又没有出现第二个问题了？这个问题很苦恼啊。","categories":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/tags/Java/"},{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"}],"keywords":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}]},{"title":"Retrofit统一进行错误处理的实现","slug":"Retrofit统一进行错误处理的实现","date":"2019-01-15T13:03:09.000Z","updated":"2019-01-15T13:03:09.000Z","comments":true,"path":"Android/Retrofit统一进行错误处理的实现.html","link":"","permalink":"https://gowa2017.github.io/Android/Retrofit统一进行错误处理的实现.html","excerpt":"在前的一篇文章中 建立一个可持续发展的安卓Client 。介绍了使用 Retrofit 来建立 Client 的一个方式。但后面在使用中遇到，如果每次调用接口请求都要处理 Response 的话，很多代码是重复的，而且不方便进行维护。所以有了这个文章。","text":"在前的一篇文章中 建立一个可持续发展的安卓Client 。介绍了使用 Retrofit 来建立 Client 的一个方式。但后面在使用中遇到，如果每次调用接口请求都要处理 Response 的话，很多代码是重复的，而且不方便进行维护。所以有了这个文章。 Retrofit 基本使用。Retrofit 的基本使用就是用一个接口来定义我们网络请求的行为，Retrofit 会根据这个定义行为的接口来构造对应的 Client， Client 拥有了我们接口定义的各种方法。 IApis net = ServiceGenerator.createServices(IApis.class);Call&lt;SrvResult&gt; cb = net.getQqPhone(\"hahaha\");cb.enqueue(new NetCallback() &#123; @Override public void onSuccessful(SrvResult response) &#123; System.out.println(response.getData()); &#125;&#125;); 我们调用 ServiceGenarator.createServices(IApis.class) 来建立一个 Client。 调用 Client 的方法，得到一个 Call。 将这个 Call 放入队列。 调用回调函数，响应我们的 Call。 在异步调用的时候(cb.enqueue()) 的时候，我们的回调实现了 Call 接口。 public interface Callback&lt;T&gt; &#123; void onResponse(Call&lt;T&gt; var1, Response&lt;T&gt; var2); void onFailure(Call&lt;T&gt; var1, Throwable var2);&#125; 当请求成功，或失败的时候就会回调对应的方法。 在此，我想到的是使用一个实现了 Callback 接口的的类，在其中进行统一的处理。但是，有可能我们针对不同的返回结果，又需要进行不同的数据操作的时候，这又不足。 所以准备用抽象类来完成这个活。 NetCallback由于我们的服务端返回的数据格式都是一致的： public class SrvResult &#123; private int state; private Object data; public int getState() &#123; return state; &#125; public void setState(int state) &#123; this.state = state; &#125; public Object getData() &#123; return data; &#125; public void setData(Object data) &#123; this.data = data; &#125;&#125; 所以我们可以统一解析为一致的格式。 对于出现失败的情况有两种： HTTP 协议级别的异常失败 应用返回表示此次请求数据逻辑不合法等等的失败 public abstract class NetCallback implements Callback&lt;SrvResult&gt; &#123; private static final String TAG = \"NetCallback\"; public abstract void onSuccessfull(SrvResult data); @Override public void onResponse(Call&lt;SrvResult&gt; call, Response&lt;SrvResult&gt; response) &#123; Response&lt;SrvResult&gt; res = response; SrvResult data = response.body(); // 请求成功，http 协议返回代码 200-300 if (res.isSuccessful()) &#123; if (data.getState() != 200) &#123; if (data.getData() == null || TextUtils.isEmpty(data.getData().toString())) &#123; if (!TextUtils.isEmpty(CodeConfig.getCodeTip(data.getState()))) &#123; onFail(CodeConfig.getCodeTip(data.getState())); &#125; else &#123; onFail(\"请求失败，请重试\"); &#125; &#125; else &#123; onFail(data.getData().toString()); &#125; return; &#125; onSuccessfull(data); &#125; else &#123; onFail(res.message()); &#125; &#125; @Override public void onFailure(Call&lt;SrvResult&gt; call, Throwable t) &#123; Toast.makeText(SSVApplication.getInstance(), t.getMessage(), Toast.LENGTH_SHORT).show(); &#125; /** * 错误提示 */ protected void onFail(String s) &#123; Toast.makeText(SSVApplication.getInstance(), s, Toast.LENGTH_SHORT).show(); &#125;&#125; Retrofit 默认会成功时调用 onResponse 失败调用 onFailure。 所以我们只需要定义一个我们需要在数据响应成功时的方法就OK了。 注意：isSuccessful 返回的状态码是 200 -300 public boolean isSuccessful() &#123; return this.code &gt;= 200 &amp;&amp; this.code &lt; 300;&#125; HTTP 状态码 STATUE 说明 1xx 代表请求已被接受，需要继续处理 (临时响应) 2xx 代表请求已成功被服务器接收、理解、并接受 3xx 代表需要客户端采取进一步的操作才能完成请求 4xx 代表了客户端看起来可能发生了错误，妨碍了服务器的处理 5xx 表示服务器无法完成明显有效的请求","categories":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"},{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/tags/Java/"},{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"},{"name":"Retrofit","slug":"Retrofit","permalink":"https://gowa2017.github.io/tags/Retrofit/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"},{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}]},{"title":"关于接口与对象的一些思考","slug":"关于接口与对象的一些思考","date":"2019-01-15T12:49:08.000Z","updated":"2019-01-15T12:49:08.000Z","comments":true,"path":"Java/关于接口与对象的一些思考.html","link":"","permalink":"https://gowa2017.github.io/Java/关于接口与对象的一些思考.html","excerpt":"关于 Java 的接口与对象，很相似，但又有所不同，网络上的文章大多是介绍两者有什么地方不同。但很少有解释这两者产生的背景，及其真实的意义及作用到底是什么。我是最近忽然看到 ECS 的概念的时候产生的这种想法。","text":"关于 Java 的接口与对象，很相似，但又有所不同，网络上的文章大多是介绍两者有什么地方不同。但很少有解释这两者产生的背景，及其真实的意义及作用到底是什么。我是最近忽然看到 ECS 的概念的时候产生的这种想法。 先说不同官方的 Tutorial 上对两者的不同有介绍： 抽象类与接口很相似。我们不能初始化它，他们可能会声明一些有实现也可能没有实现的方法。然而，使用抽象类，我们可以声明非 static, final 的字段，定义 public, protected, private 的方法。使用接口，所有的字段自动变成 public, static, final，所有定义的方法都是 public的。我们只能 extend 一个类，但是我们可以实现多个接口。 从这里来看，根本的区别就是：抽象类可以对字段进行修饰，而接口的字段和方法都是 public 的。 下面的情况考虑使用抽象类： 在几个关联很密切的类间共享代码。 希望继承抽象类的类有一些公共的方法和字段，或需要一些非 public 的修饰。 需要定义 非 static, 非 final 的字段。 下面的情况就考虑使用接口： 不相关的类都能实现接口。比如接口 Comparable 和 Cloneable 就被很多不相关的类实现。 我们想指定一个特定数据类型的行为，但并不关心谁来实现它的行为。 希望使用多重继承。 个人的理解我更愿意用 ECS 中的观念去理解接口。用组合而非继承的方式去实现复杂的功能。 ECS 认为，总有抽象的类会复杂到不想用的地步，或者一开始这个类就抽象得不怎么样，你再怎么扩展都是很坑的。 同时，类 是为某一对象创建定义的原型或者蓝图，或者说是对某些性质的抽象。而接口，是对行为的定义。这应该据两者根本的不同。","categories":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/tags/Java/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}]},{"title":"谷歌的todo-mvp-dagger例子探究","slug":"谷歌的todo-mvp-dagger例子探究","date":"2019-01-15T09:22:26.000Z","updated":"2019-01-15T09:22:26.000Z","comments":true,"path":"Java/谷歌的todo-mvp-dagger例子探究.html","link":"","permalink":"https://gowa2017.github.io/Java/谷歌的todo-mvp-dagger例子探究.html","excerpt":"根据 Dagger 在官方文档上介绍的在安卓中使用 Dagger 的方式，想看一下谷歌的例子是怎么做的。但是发现，这和其文档上说明的并不一致，所以来深入的看一下。 官方文档 中文版","text":"根据 Dagger 在官方文档上介绍的在安卓中使用 Dagger 的方式，想看一下谷歌的例子是怎么做的。但是发现，这和其文档上说明的并不一致，所以来深入的看一下。 官方文档 中文版 Activty 注入按照官方文档的说明，当我们在 Activity 的 onCreate 函数内调用 AndroidInjection.inject() 时，我们可以从 Application 处获得一个 DispatchingAndroidInjector&lt;Activity&gt;，并将调用 Activity 作为参数传递来调用 inject(Activity)。 DispatchingAndroidInjector 会查找 我们传递的 Activity 类的 AndroidInjector.Factory（实际上就是我们自己定义的 YourActivitySubcomponent.Builder），并用它来建立 AndroidInjector（实际就是 YourActivitySubcomponent），最终调用 inject(YourActivity)。 DaggerAppCompatActivity这个类，签名为 public abstract class DaggerAppCompatActivity extends AppCompatActivity implements HasFragmentInjector, HasSupportFragmentInjector &#123;&#125; 我们所有的 Activity 都继承自它。在它的 onCreate() 方法中，确实调用了 AndroidInjection.inject(this);方法。 按照上面介绍的工作流程。我们来理一理。 AndroidInjection.inject(this);这个类，这个方法，都是由 Dagger 已经实现的： public static void inject(Activity activity) &#123; checkNotNull(activity, \"activity\"); Application application = activity.getApplication(); if (!(application instanceof HasActivityInjector)) &#123; throw new RuntimeException( String.format( \"%s does not implement %s\", application.getClass().getCanonicalName(), HasActivityInjector.class.getCanonicalName())); &#125; AndroidInjector&lt;Activity&gt; activityInjector = ((HasActivityInjector) application).activityInjector(); checkNotNull(activityInjector, \"%s.activityInjector() returned null\", application.getClass()); activityInjector.inject(activity);&#125; 其基本的过程就是：通过 Activity 获取到 应用级别的上下文 Application。然后通过 应用上下文 实现的接口 HasActivityInjector 的方法 activityInjector() 来获取一个 activityInjector。 @Overridepublic DispatchingAndroidInjector&lt;Activity&gt; activityInjector() &#123; return activityInjector;&#125; 关于 activityInjector 是如何初始化的，我们下一节看。 injectIfNecessaryDaggerApplication 在应用启动的时候，会尝试是否需要注入的检查，如果需要注入，那么就初始化相应的内容. public void onCreate() &#123; super.onCreate(); injectIfNecessary();&#125; private void injecAtIfNecessary() &#123; if (needToInject) &#123; synchronized (this) &#123; if (needToInject) &#123; @SuppressWarnings(\"unchecked\") AndroidInjector&lt;DaggerApplication&gt; applicationInjector = (AndroidInjector&lt;DaggerApplication&gt;) applicationInjector(); applicationInjector.inject(this); if (needToInject) &#123; throw new IllegalStateException( \"The AndroidInjector returned from applicationInjector() did not inject the \" + \"DaggerApplication\"); &#125; &#125; &#125; &#125;&#125; 哈，也是通过 Application 来注入自身。AndroidInjector&lt;DaggerApplication&gt; applicationInjector = (AndroidInjector&lt;DaggerApplication&gt;) applicationInjector(); 是一个抽象方法，是我们的 Application 进行实现的： @Overrideprotected AndroidInjector&lt;? extends DaggerApplication&gt; applicationInjector() &#123; return DaggerAppComponent.builder().application(this).build();&#125; 这个就很明了。 @Inject DispatchingAndroidInjector&lt;Activity&gt; activityInjector;@Inject DispatchingAndroidInjector&lt;BroadcastReceiver&gt; broadcastReceiverInjector;@Inject DispatchingAndroidInjector&lt;Fragment&gt; fragmentInjector;@Inject DispatchingAndroidInjector&lt;Service&gt; serviceInjector;@Inject DispatchingAndroidInjector&lt;ContentProvider&gt; contentProviderInjector; 在 DaggerAppliction 内是定义了这些几大类型的注入器，这些，都是需要我们自己实现的 应用级别的注入器来实现的。 那么，必然，他会在 AppComponent 内定义这些注入的实现方式。 AppComponent@Singleton@Component(modules = &#123;TasksRepositoryModule.class, ApplicationModule.class, ActivityBindingModule.class, AndroidSupportInjectionModule.class&#125;)public interface AppComponent extends AndroidInjector&lt;ToDoApplication&gt; &#123; TasksRepository getTasksRepository(); // Gives us syntactic sugar. we can then do DaggerAppComponent.builder().application(this).build().inject(this); // never having to instantiate any modules or say which module we are passing the application to. // Application will just be provided into our app graph now. @Component.Builder interface Builder &#123; @BindsInstance AppComponent.Builder application(Application application); AppComponent build(); &#125;&#125; 其中，用到的模块 AndroidInjectionModule 这个是由 Dagger 来实现的。目的就是为了注入 Application 上下文保存的那些 关于 Activty 等五大类型的注入分发器。注入分发器就是为了根据类型来寻找指定的注入器。 @Beta@Modulepublic abstract class AndroidInjectionModule &#123; @Multibinds abstract Map&lt;Class&lt;? extends Activity&gt;, AndroidInjector.Factory&lt;? extends Activity&gt;&gt; activityInjectorFactories(); @Multibinds abstract Map&lt;Class&lt;? extends Fragment&gt;, AndroidInjector.Factory&lt;? extends Fragment&gt;&gt; fragmentInjectorFactories(); @Multibinds abstract Map&lt;Class&lt;? extends Service&gt;, AndroidInjector.Factory&lt;? extends Service&gt;&gt; serviceInjectorFactories(); @Multibinds abstract Map&lt; Class&lt;? extends BroadcastReceiver&gt;, AndroidInjector.Factory&lt;? extends BroadcastReceiver&gt;&gt; broadcastReceiverInjectorFactories(); @Multibinds abstract Map&lt; Class&lt;? extends ContentProvider&gt;, AndroidInjector.Factory&lt;? extends ContentProvider&gt;&gt; contentProviderInjectorFactories(); private AndroidInjectionModule() &#123;&#125;&#125; 此模块是采取的 @MultiBinds 的方式来注解方法的。其实到一步，我们都不必关心了，都是由 Dagger 来实现了。 总结 我们只需要定义一个 Component （应用级别的），将我们需要要使用的 Module 传递给它。同时，还要加上 Dagger 自己实现的模块 AndroidSupportInjectionModule。 Dagger 会根据我们传递的 Module 自己组织相关需要的注解分发器。而后根据对应的参数就能进行注入了。 深入关于在 AppComponent 中使用的 Module 还有讲究哦。比如我们就以 ActivityBindingModule.class 为例来看看。 /**我们希望 dagger.android ActivityBindingModule 所在的父组件（在我们的例子中是 AppComponent） 中建立一个子组件。这样做的美妙之处在于，我们不需要告诉 AppComponent 所有的字组件，也不需要这些子组件 AppComponent 存在。我们也告诉 Dagger.android 生成的子组件应该包括对应的 Module，同时要注意到注解 @ActivityScoped。当 Dagger.android 注解处理器工作的时候，其会产生 4 个子组件。@ContributesAndroidInjector 注解：为方法返回的类型产生一个 AndroidInjector。injector 用 dagger.SubComponent 实现，其将会是 dagger.Modlue 组件的子组件。此注解必须在一个 Module 内的 抽象方法上，此抽象方法返回一个具体的安卓框架类型。方法也没有参数。@ActivityScoped 在 Dagger 中，没有范围的组件不能依赖于有范围的组件。因为 AppComponent 是一个有范围的组件，(Singleton），所以我们建立一个范围来给所有的 Fragment 使用。一个有范围的组件，其子组件不能拥有相同的范围。*/@Modulepublic abstract class ActivityBindingModule &#123; @ActivityScoped @ContributesAndroidInjector(modules = TasksModule.class) abstract TasksActivity tasksActivity(); @ActivityScoped @ContributesAndroidInjector(modules = AddEditTaskModule.class) abstract AddEditTaskActivity addEditTaskActivity(); @ActivityScoped @ContributesAndroidInjector(modules = StatisticsModule.class) abstract StatisticsActivity statisticsActivity(); @ActivityScoped @ContributesAndroidInjector(modules = TaskDetailPresenterModule.class) abstract TaskDetailActivity taskDetailActivity();&#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/tags/Java/"},{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"},{"name":"Dagger","slug":"Dagger","permalink":"https://gowa2017.github.io/tags/Dagger/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}]},{"title":"Vim的自动命令-au与augroup","slug":"Vim的自动命令-au与augroup","date":"2019-01-14T13:50:02.000Z","updated":"2019-01-14T13:50:02.000Z","comments":true,"path":"Vim/Vim的自动命令-au与augroup.html","link":"","permalink":"https://gowa2017.github.io/Vim/Vim的自动命令-au与augroup.html","excerpt":"还是在把 Vim 配置为 Go 的开发环境的时候看到使用了 augroup/autocmd 命令的。但是当时没有深究，后来在很多地方看到了，所以就想要看一下其到底有什么用的。","text":"还是在把 Vim 配置为 Go 的开发环境的时候看到使用了 augroup/autocmd 命令的。但是当时没有深究，后来在很多地方看到了，所以就想要看一下其到底有什么用的。 简介可以在读、写文件，进入或离开缓冲区，或者退出 Vim 的时候自动执行一些命令。命令的基本格式是： :au[tocmd] [group] &#123;event&#125; &#123;pat&#125; [nested] &#123;cmd&#125; 其基本意思就是：把 {cmd} 命令添加到 Vim 在一个文件匹配 {pat} 并遇到 {event} 事件时会自动执行的命令列表中。 Vim总是在已存在的自动命令后添加 {cmd}。 {event}可以在 Vim 中用命令 :help event 来查看事件。 augroup {name}为后面的 autocmd 命令定义一个自动命令组。augroup END|end 选择默认的自动命令组。为了避免混淆， {name} 应该与已经存在 {event} 相区别开来。 augroup! {name} 会删除一个组。在尚有 autocmd 命令使用要这个组时，不要这样干，不然会出错。 在组内定义自动命令的基本过程是: 用命令 :autogroup {name} 选择组 用命令 :au! 删除所有老的命令 定义新的命令 :au 回到默认组 :augroup END 例子： :augroup uncompress: au!: au BufEnter *.gz %!gunzip:augroup END 这会防止自动命令被执行两次。（如 source .vimrc 两次或多次）。 augroup goaugroup go autocmd! \" 不在设置全局绑定 autocmd FileType go nmap &lt;C-g&gt; :GoDeclsDir&lt;cr&gt; autocmd FileType go imap &lt;C-g&gt; &lt;esc&gt;:&lt;C-u&gt;GoDeclsDir&lt;cr&gt; \" Show by default 4 spaces for a tab autocmd BufNewFile,BufRead *.go setlocal noexpandtab tabstop=4 shiftwidth=4 \" :GoBuild and :GoTestCompile autocmd FileType go nmap &lt;leader&gt;b :&lt;C-u&gt;call &lt;SID&gt;build_go_files()&lt;CR&gt; \" :GoTest autocmd FileType go nmap &lt;leader&gt;t &lt;Plug&gt;(go-test) \" :GoRun autocmd FileType go nmap &lt;leader&gt;r &lt;Plug&gt;(go-run) \" :GoDoc autocmd FileType go nmap &lt;Leader&gt;d &lt;Plug&gt;(go-doc) \" :GoCoverageToggle autocmd FileType go nmap &lt;Leader&gt;c &lt;Plug&gt;(go-coverage-toggle) \" :GoInfo autocmd FileType go nmap &lt;Leader&gt;i &lt;Plug&gt;(go-info) \" :GoMetaLinter autocmd FileType go nmap &lt;Leader&gt;l &lt;Plug&gt;(go-metalinter) \" :GoDef but opens in a vertical split autocmd FileType go nmap &lt;Leader&gt;v &lt;Plug&gt;(go-def-vertical) \" :GoDef but opens in a horizontal split autocmd FileType go nmap &lt;Leader&gt;s &lt;Plug&gt;(go-def-split) \" :GoAlternate commands :A, :AV, :AS and :AT autocmd Filetype go command! -bang A call go#alternate#Switch(&lt;bang&gt;0, 'edit') autocmd Filetype go command! -bang AV call go#alternate#Switch(&lt;bang&gt;0, 'vsplit') autocmd Filetype go command! -bang AS call go#alternate#Switch(&lt;bang&gt;0, 'split') autocmd Filetype go command! -bang AT call go#alternate#Switch(&lt;bang&gt;0, 'tabe')augroup END 上面就是一个不错的例子了","categories":[{"name":"Vim","slug":"Vim","permalink":"https://gowa2017.github.io/categories/Vim/"}],"tags":[{"name":"Vim","slug":"Vim","permalink":"https://gowa2017.github.io/tags/Vim/"}],"keywords":[{"name":"Vim","slug":"Vim","permalink":"https://gowa2017.github.io/categories/Vim/"}]},{"title":"Java中final语义","slug":"Java中final语义","date":"2019-01-09T06:07:09.000Z","updated":"2019-01-09T06:07:09.000Z","comments":true,"path":"Java/Java中final语义.html","link":"","permalink":"https://gowa2017.github.io/Java/Java中final语义.html","excerpt":"使用场景是我在安卓组件的点击事件回调中不准备修改 Activity 中的一个 Map 的内容，但是开始的时候，提示我在内部类中访问外部变量必须声明为 final。","text":"使用场景是我在安卓组件的点击事件回调中不准备修改 Activity 中的一个 Map 的内容，但是开始的时候，提示我在内部类中访问外部变量必须声明为 final。 重现问题protected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); setContentView(R.layout.activity_com_register_multi_cert_global_freight_srv); ButterKnife.bind(this); addCheckBoxToGl(cargoClassArr, cargoClassMap, glCargoClass);&#125;private void addCheckBoxToGl(String[] data, final Map&lt;String, String&gt; dataMap, GridLayout gl) &#123; for (int i = 0; i &lt; data.length; i++) &#123; String s = data[i]; AppCompatCheckBox cb = new AppCompatCheckBox(this); cb.setText(s); cb.setOnCheckedChangeListener(new CompoundButton.OnCheckedChangeListener() &#123; @Override public void onCheckedChanged(CompoundButton buttonView, boolean isChecked) &#123; if (isChecked) &#123; dataMap.put(buttonView.getText().toString(), buttonView.getText().toString()); &#125; else &#123; dataMap.remove(buttonView.getText().toString()); &#125; Log.d(TAG, \"onViewClicked: \" + new Gson().toJson(cargoClassMap)); &#125; &#125;); gl.addView(cb); &#125;&#125; 错误提示：变量 dataMap 从内部类中进行访问，需要声明为 final 我当时以为，final 是不可改变的意思。但事实证明这是错误的。在进行 final 声明后，依然改变了 dataMap 的值。 最后查阅官方文档才发现：https://docs.oracle.com/javase/tutorial/java/javaOO/classvars.html The final modifier indicates that the value of this field cannot change.final 修饰符只是表明，字段的值不能被改变 对于一个引用字段，其值并不是一个对象，而是一个引用。所以改变对象，其引用依然不变，所以可以改变对象的值。","categories":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/tags/Java/"},{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}]},{"title":"Dagger注解说明","slug":"Dagger注解说明","date":"2019-01-08T15:04:28.000Z","updated":"2019-01-08T15:04:28.000Z","comments":true,"path":"Java/Dagger注解说明.html","link":"","permalink":"https://gowa2017.github.io/Java/Dagger注解说明.html","excerpt":"把工作流程搞清楚以后，我就准备来看一下注解的使用与不同之处了。我们最常用的 @Provides, @Component 这个自不用说，但是还有些也是很有用的感觉没有用到的东西。","text":"把工作流程搞清楚以后，我就准备来看一下注解的使用与不同之处了。我们最常用的 @Provides, @Component 这个自不用说，但是还有些也是很有用的感觉没有用到的东西。 @Provides注解一个方法，用来提供依赖。如果方法声明为 static 那么这就和 @Binds 语义一样，只能有一个参数。 @Binds注解一个抽象类的，抽象方法。方法只能有一个参数。这样注解的模块和方法不会实例化 @Module(includes, subcomponents)注解一个 module，可用 includes 来包含其他 module。module 内包含的是一些 @Provides 方法 或 @Binds 方法。 subcomponets 可以包含子组件。 @Component(modules, dependencies)指定要使用的模块，然后生成对应的 Dagger 类。 @Component.Builder类似 Builder 模式。注解的方法会在 Builder 里面可以调用。 @BindsInstance在我们构建组件的时候，可能我们已经是有数据可用了的。这个时候，加入我们想把已有的数据，绑定到 Component 里面去，就会用到这个注解：@BindsInstance。 下面的例子把命令行参绑定一个字符串到@Component(modules = AppModule.class)interface AppComponent &#123; App app(); @Component.Builder interface Builder &#123; @BindsInstance Builder userName(@UserName String userName); AppComponent build(); &#125;&#125; 上面的 @BindsInstance 会把 参数绑定到 Builder 内的字段 userName。 @BindsOptionalOf如果想在某些依赖没有绑定到组件的情况下依然工作，可以在 module 内添加此注解。 @BindsOptionalOf abstract CoffeeCozy optionalCozy(); @Reusable某些时候想要限制一个 @inject 注解构造器的类被实例化的次数，或一个 @Provides 方法被调用的次数，但你并不需要在组件或子组件的生命周期内使用相同的实例。这在安卓这样的环境上非常有用，因为分配内存是昂贵的。 @Reusable 范围绑定，和其他范围不一样，并不与任何一个特定的组件关联相反，实际使用这个绑定的任何组件都会缓存和绑定返回的或实例化的对象。 这意味着，如果你使用 @Reusable 将一个 module 装在 Component 内，但是只有一个 Subcomponent 使用这个绑定，那么只有 Subcomponent 会缓存绑定的对象。两个 Subcomponent 祖先不同，但都使用这个绑定，那么他们会分别缓存自己的对象。如果组件的祖先已经缓存了此对象，那么Subcomponent 会直接使用。 保证 Component 只调用绑定一次，所以 @Reusable 应用到返回可变对象的绑定，或者对于引用同一实例很重要的对象是非常危险的。如果我们不关心不关心对象被分配了多少次话，对于我们不进行范围限制不可变对象使用 @Reusable 是安全的。 @Reusable // It doesn't matter how many scoopers we use, but don't waste them.class CoffeeScooper &#123; @Inject CoffeeScooper() &#123;&#125;&#125;@Moduleclass CashRegisterModule &#123; @Provides @Reusable // DON'T DO THIS! You do care which register you put your cash in. // Use a specific scope instead. static CashRegister badIdeaCashRegister() &#123; return new CashRegister(); &#125;&#125;@Reusable // DON'T DO THIS! You really do want a new filter each time, so this // should be unscoped.class CoffeeFilter &#123; @Inject CoffeeFilter() &#123;&#125;&#125; @Subcomponent(modules)子组件从父组件那继承和扩展对象图。可以使用他们来将应用的对象图进行分区，要么用来封装应用的不同部分，或者想在一个组件上使用不同的 scope。 绑定在子组件上的对象可以依赖任何绑定在父组件及更高层级组件上的对象，当然，绑定在其他 module 的对象也是可以依赖的。相反，绑定在父组件上的对象却不能依赖子组件上的绑定对象；绑定在一个子组件中的对象也不能依赖于兄弟子组件中绑定的对象。 使用方式类似 @Component @Subcomponent.Builder注解一些构建 @Subcomponent 需要的模块。 添加到父组件这是一个子组件： @Subcomponent(modules = RequestModule.class)interface RequestComponent &#123; RequestHandler requestHandler(); @Subcomponent.Builder interface Builder &#123; Builder requestModule(RequestModule module); RequestComponent build(); &#125;&#125; 添加方法：在父组件使用的 module 内，引用这个子组件： @Module(subcomponents = RequestComponent.class)class ServerModule &#123;&#125;@Singleton@Component(modules = ServerModule.class)interface ServerComponent &#123; RequestRouter requestRouter();&#125;@Singletonclass RequestRouter &#123; @Inject RequestRouter( Provider&lt;RequestComponent.Builder&gt; requestComponentProvider) &#123;&#125; void dataReceived(Data data) &#123; RequestComponent requestComponent = requestComponentProvider.get() .data(data) .build(); requestComponent.requestHandler() .writeResponse(200, \"hello, world\"); &#125;&#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/tags/Java/"},{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"},{"name":"Dagger","slug":"Dagger","permalink":"https://gowa2017.github.io/tags/Dagger/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}]},{"title":"Dagger例子的使用解析","slug":"Dagger例子的使用解析","date":"2019-01-08T13:06:23.000Z","updated":"2019-01-08T13:06:23.000Z","comments":true,"path":"Java/Dagger例子的使用解析.html","link":"","permalink":"https://gowa2017.github.io/Java/Dagger例子的使用解析.html","excerpt":"关于 Dagger 的例子，看起来非常的迷糊，看了一下用户文档也不怎么的。还是来看一下例子具体的解析比较好。","text":"关于 Dagger 的例子，看起来非常的迷糊，看了一下用户文档也不怎么的。还是来看一下例子具体的解析比较好。 开始比较迷糊的地方应该是，这个例子是面向接口的，只通过接口进行调用，而不与具体的类相关联。 其首先虚拟了几个过程： 咖啡店 CoffeeShop 咖啡机 CoffeeMaker 咖啡机会进行 加热 Heater ，抽水 Pump 两个过程。 这几者都是用接口来进行定义。注入的时候提供接口实现的实例。 我们要做的就是在咖啡店中，让咖啡机给我们弄一杯咖啡。 几个接口的定义都是非常简单的： 接口定义CoffeeShoppackage coffee;public interface CoffeeShop &#123; CoffeeMaker maker();&#125; CoffeeMakerpublic class CoffeeMaker &#123; private final Lazy&lt;Heater&gt; heater; private final Pump pump; @Inject public CoffeeMaker(Lazy&lt;Heater&gt; heater, Pump pump) &#123; this.heater = heater; this.pump = pump; &#125; public void brew()&#123; heater.get().on(); pump.pump(); System.out.println(\" [_]P coffee! [_]P \"); heater.get().off(); &#125; public Lazy&lt;Heater&gt; getHeater() &#123; return heater; &#125; public Pump getPump() &#123; return pump; &#125;&#125; 在这里， CoffeeMaker 依赖 Heater, Pump 两个对象来进行操作。 Heaterpackage coffee;public interface Heater &#123; void on(); void off(); boolean isHot();&#125; Pumppackage coffee;public interface Pump &#123; void pump();&#125; 调用例子最终，我们要实现的是这样的调用： public class CoffeeApp &#123; public static void main(String[] args) &#123; CoffeeShop coffeeShop = DaggerCoffeeShop.builder().build(); coffeeShop.maker().brew(); &#125;&#125; 但是，我们发现，CoffeeShop 其实是没有实现的，只是定义了一个接口，这个实现是由 Dagger 来完成。通过对我们的 CoffeeShop 接口加上 @Component 注解，Dagger 会自动生成此接口的一个实现。 Component@Singleton@Component(modules = &#123;DripCoffeeModule.class&#125;)public interface CoffeeShop &#123; CoffeeMaker maker();&#125; 不过，在我们查看生成的 DaggerCoffeeShop 类的时候，却发现一些不一样的地方。 DaggerCoffeeShopBut, 为什么会有这么多东西？从哪里来的？ // implements 说明，确实是一个 CoffeeShop 的实现。public final class DaggerCoffeeShop implements CoffeeShop &#123; private Provider&lt;Heater&gt; provideHeaterProvider; // 构造器 private DaggerCoffeeShop(Builder builder) &#123; initialize(builder); &#125; // 采用 Builder 模式 public static Builder builder() &#123; return new Builder(); &#125; // 默认的一个方法 public static CoffeeShop create() &#123; return new Builder().build(); &#125; //这个暂且不提 private Thermosiphon getThermosiphon() &#123; return new Thermosiphon(provideHeaterProvider.get()); &#125; //初始化 @SuppressWarnings(\"unchecked\") private void initialize(final Builder builder) &#123; this.provideHeaterProvider = DoubleCheck.provider( DripCoffeeModule_ProvideHeaterFactory.create(builder.dripCoffeeModule)); &#125; @Override public CoffeeMaker maker() &#123; return new CoffeeMaker(DoubleCheck.lazy(provideHeaterProvider), getThermosiphon()); &#125; public static final class Builder &#123; private DripCoffeeModule dripCoffeeModule; private Builder() &#123;&#125; public CoffeeShop build() &#123; if (dripCoffeeModule == null) &#123; this.dripCoffeeModule = new DripCoffeeModule(); &#125; return new DaggerCoffeeShop(this); &#125; public Builder dripCoffeeModule(DripCoffeeModule dripCoffeeModule) &#123; this.dripCoffeeModule = Preconditions.checkNotNull(dripCoffeeModule); return this; &#125; &#125;&#125; 我们可以来看看，我们执行 builder().build()的时候都发生了什么。 builder() 会返回一个内部的 Builder对象，当此对象执行 build()的时候，纠结做了些什么呢。 .build()private DripCoffeeModule dripCoffeeModule;private Builder() &#123;&#125;public CoffeeShop build() &#123; if (dripCoffeeModule == null) &#123; this.dripCoffeeModule = new DripCoffeeModule(); &#125; return new DaggerCoffeeShop(this);&#125; 初始化了一个 module，然后将 Builder 自身传递给 DaggerCoffeeShop进行构建 CoffeeShop 实例。 这实际上执行的是 CoffeeShop 的 initialize() 方法. initialize（）private void initialize(final Builder builder) &#123; this.provideHeaterProvider = DoubleCheck.provider( DripCoffeeModule_ProvideHeaterFactory.create(builder.dripCoffeeModule));&#125; initialize 也只是把所需要的 provider 进行了初始化。 其中 DripCoffeeModule_ProvideHeaterFactory.create(builder.dripCoffeeModule)); 根据模块，建立一个工厂类。 DoubleCheck.provider() 使用工厂类来实现一个 provider。 public static &lt;P extends Provider&lt;T&gt;, T&gt; Provider&lt;T&gt; provider(P delegate) &#123; Preconditions.checkNotNull(delegate); return (Provider)(delegate instanceof DoubleCheck ? delegate : new DoubleCheck(delegate));&#125; 事实上可以这么理解，就是对于每个 provider 都会生成了一个工厂类。 maker()public CoffeeMaker maker() &#123; return new CoffeeMaker(provideHeaterProvider.get(), getThermosiphon());&#125; 这个就比较常规了，就是 new 一个对象出来，其依赖的话，是通过 provider 来获取的。我们在上面说道， provider 其实就工厂类。 我们调用其 get() 方法。 ProviderFactory 工厂类public final class DripCoffeeModule_ProvideHeaterFactory implements Factory&lt;Heater&gt; &#123; private final DripCoffeeModule module; public DripCoffeeModule_ProvideHeaterFactory(DripCoffeeModule module) &#123; this.module = module; &#125; @Override public Heater get() &#123; return provideInstance(module); &#125; public static Heater provideInstance(DripCoffeeModule module) &#123; return proxyProvideHeater(module); &#125; public static DripCoffeeModule_ProvideHeaterFactory create(DripCoffeeModule module) &#123; return new DripCoffeeModule_ProvideHeaterFactory(module); &#125; public static Heater proxyProvideHeater(DripCoffeeModule instance) &#123; return Preconditions.checkNotNull( instance.provideHeater(), \"Cannot return null from a non-@Nullable @Provides method\"); &#125;&#125; 我们可以看到，其最终，是调用了我们接口对应定义的 provideHeater() 方法了。 工作流程工作流程就可以总结下来了。 Dagger 生成类实现 @Component 注解的接口，并将注解中的 modules 参数指定的模块进行实例化。 为 modules 中定义的 provide 方法生成工厂类。 用工厂类建立 provider ，并作为 Dagger 生成类的字段。 调用 provider 获取依赖实例（实际上工厂类是作为代理调用了我们定义的 module 中的 provider 方法。） 有什么不同？先前我们就注意到，为什么 Pump 与 Heater 在生成类中似乎并不一样，其好像并没有 provider 字段。而是一个 getter 函数。 private Thermosiphon getThermosiphon() &#123; return new Thermosiphon(provideHeaterProvider.get());&#125; 而且也不是以接口的形式定义 module ，而是以抽象类的形式： @Moduleabstract class PumpModule &#123; @Binds abstract Pump providerPump(Thermosiphon pump);&#125; 这就是 @Provides 与 @Binds 的区别了。 @Provides 是实例方法，需要实例化 module 后进行使用。 @Binds 的不会实例化 module，也不会调用 module 中的 provide 方法，而是会直接用 provide 方法参数中用 @inject 注解的方法。 在官方文档的FAQ 上对此做了说明。 @Binds 与 @Provides 不同@Provides 是我们最常用的注解，提供了三个功能： 声明提供了什么类型————方法的返回类型 声明依赖————方法的参数 提供了一个返回类型的实例是如何实现的————方法体 前两项每个 @Provides 方法都有，但第三种情况有时候可能重复性的或很冗长的。所以当 @Provides 的实现很简单，或者 Dagger 可以推测出来的时候，就可以将其声明为一个没有方法体的方法（抽象方法）。 但是，如果说我们应该像 @Binds 那样对待 @Provides 的话，那么 @Provides 的规范基本上就是两个有条件逻辑的规范。例如，@Provides 可以拥有任何类型，任意数量的参数，但是 @Binds 只能拥有一个参数，其类型可以分配给返回类型。分开这两个规范更容易推测出正确的结果，因为注解决定了约束。 为什么 @Binds 与 @Provides 不能在一个 Module因为 @Binds 只是一个方法声明，被表示为 abstract 方法————不会有实现，也不会被调用。相反，@Provides 会被实现，同时也会被调用。 @Binds 不会被实现，也不会有对应的类实例化来实现这些方法。然而，实例化 @Provides 方法需要一个具体的类来构建一个能调用此方法的实例。 替代方法最简单的方法就是让 @Provides 方法声明为 static 。除了兼容 @Binds，性能会更好些。 如果方法 必须 是一个实例方法（例如，从一个字段返回值），最简单的方法就是将两种方法进行分开，然后从其中一个 module 包括另外一个。下面就是一个例子： @Module(includes = Declarations.class)final class HttpServletRequestModule &#123; @Module interface Declarations &#123; @Binds ServletRequest bindServletRequest(HttpServletRequest httpRequest); &#125; private final HttpServletRequest httpRequest; HttpServletRequestModule(HttpServletRequest httpRequest) &#123; this.httpRequest = httpRequest; &#125;&#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/tags/Java/"},{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"},{"name":"Dagger","slug":"Dagger","permalink":"https://gowa2017.github.io/tags/Dagger/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}]},{"title":"Cocos Creator热更新例子的研究","slug":"Cocos Creator热更新例子的研究","date":"2019-01-05T14:18:43.000Z","updated":"2019-01-05T14:18:43.000Z","comments":true,"path":"Cocos-Creator/Cocos Creator热更新例子的研究.html","link":"","permalink":"https://gowa2017.github.io/Cocos-Creator/Cocos Creator热更新例子的研究.html","excerpt":"来源于官方的例子，主要是看一下是怎么实现的。官方文档有一定的描述，但很科幻，也没有集成在插件内。官方的文档描述地址：热更新范例教程","text":"来源于官方的例子，主要是看一下是怎么实现的。官方文档有一定的描述，但很科幻，也没有集成在插件内。官方的文档描述地址：热更新范例教程 基本原理对于不同版本的文件级差异，AssetsManager 中使用 Manifest 文件来进行版本比对。本地和远端的 Manifest 文件分别标示了本地和远端的当前版本包含的文件列表和文件版本，这样就可以通过比对每个文件的版本来确定需要更新的文件列表。 Manifest 文件中包含以下几个重要信息： 远程资源包的根路径 远程 Manifest 文件地址 远程 Version 文件地址（非必需） 主版本号 文件列表：以文件路径来索引，包含文件版本信息，一般推荐用文件的 md5 校验码来作为版本号 搜索路径列表 其中 Version 文件内容是 Manifest 文件内容的一部分，不包含文件列表。由于 Manifest 文件可能比较大，每次检查更新的时候都完整下载的话可能影响体验，所以开发者可以额外提供一个非常小的 Version 文件。AssetsManager 会首先检查 Version 文件提供的主版本号来判断是否需要继续下载 Manifest 文件并更新。 例子实现scripts/module/HotUpdate.js 是实现逻辑的组件，其挂在了 Canvas 上。组件拥有的属性如下： properties: &#123; panel: UpdatePanel, // 进度条 manifestUrl: &#123; // 版本库文件 type: cc.Asset, default: null &#125;, updateUI: cc.Node, //更新窗口 _updating: false, _canRetry: false, _storagePath: ''&#125; 界面基本如下： AssetsManager事实上热更新就是因为 AssetsManager 支持而实现的了。关于这个资源管理器的接口，是绑定到 jsb 的，文档上我没看到，但是官方有提示源代码有能看到：AssetsManagerEx.h 初始化在 onLoad 函数里面完成： 在这个初始化中，先得出一个存储路径 this_storagePath，一个版本比较函数 this_versionCompareHandle，然后就初始化了 AssetsManager，初始化的时候，将 manifest 路径设置为空。 接着，为 AssetsManager 设置了一个回调 setVerifyCallback。 onLoad: function () &#123; // Hot update is only available in Native build if (!cc.sys.isNative) &#123; return; &#125; this._storagePath = ((jsb.fileUtils ? jsb.fileUtils.getWritablePath() : '/') + 'blackjack-remote-asset'); cc.log('Storage path for remote asset : ' + this._storagePath); // Setup your own version compare handler, versionA and B is versions in string // if the return value greater than 0, versionA is greater than B, // if the return value equals 0, versionA equals to B, // if the return value smaller than 0, versionA is smaller than B. this.versionCompareHandle = function (versionA, versionB) &#123; cc.log(\"JS Custom Version Compare: version A is \" + versionA + ', version B is ' + versionB); var vA = versionA.split('.'); var vB = versionB.split('.'); for (var i = 0; i &lt; vA.length; ++i) &#123; var a = parseInt(vA[i]); var b = parseInt(vB[i] || 0); if (a === b) &#123; continue; &#125; else &#123; return a - b; &#125; &#125; if (vB.length &gt; vA.length) &#123; return -1; &#125; else &#123; return 0; &#125; &#125;; // Init with empty manifest url for testing custom manifest this._am = new jsb.AssetsManager('', this._storagePath, this.versionCompareHandle); var panel = this.panel; // Setup the verification callback, but we don't have md5 check function yet, so only print some message // Return true if the verification passed, otherwise return false this._am.setVerifyCallback(function (path, asset) &#123; // When asset is compressed, we don't need to check its md5, because zip file have been deleted. var compressed = asset.compressed; // Retrieve the correct md5 value. var expectedMD5 = asset.md5; // asset.path is relative path and path is absolute. var relativePath = asset.path; // The size of asset file, but this value could be absent. var size = asset.size; if (compressed) &#123; panel.info.string = \"Verification passed : \" + relativePath; return true; &#125; else &#123; panel.info.string = \"Verification passed : \" + relativePath + ' (' + expectedMD5 + ')'; return true; &#125; &#125;); this.panel.info.string = 'Hot update is ready, please check or directly update.'; if (cc.sys.os === cc.sys.OS_ANDROID) &#123; // Some Android device may slow down the download process when concurrent tasks is too much. // The value may not be accurate, please do more test and find what's most suitable for your game. this._am.setMaxConcurrentTask(2); this.panel.info.string = \"Max concurrent tasks count have been limited to 2\"; &#125; this.panel.fileProgress.progress = 0; this.panel.byteProgress.progress = 0;&#125;, 当我们点击检查更新的时候，就会调用对应的事件响应函数： 函数中，先是载入了本地 manifest 文件，接着，就开始检查更新，更新完毕，会回调 我们的 checkCb() 回调。 checkUpdate: function () &#123; if (this._updating) &#123; this.panel.info.string = 'Checking or updating ...'; return; &#125; if (this._am.getState() === jsb.AssetsManager.State.UNINITED) &#123; // Resolve md5 url var url = this.manifestUrl.nativeUrl; if (cc.loader.md5Pipe) &#123; url = cc.loader.md5Pipe.transformURL(url); &#125; this._am.loadLocalManifest(url); &#125; if (!this._am.getLocalManifest() || !this._am.getLocalManifest().isLoaded()) &#123; this.panel.info.string = 'Failed to load local manifest ...'; return; &#125; this._am.setEventCallback(this.checkCb.bind(this)); this._am.checkUpdate(); this._updating = true;&#125;, OK，在回调中就可以根据检测的结果，来确定是否需要进行更新了： checkCb: function (event) &#123; cc.log('Code: ' + event.getEventCode()); switch (event.getEventCode()) &#123; case jsb.EventAssetsManager.ERROR_NO_LOCAL_MANIFEST: this.panel.info.string = \"No local manifest file found, hot update skipped.\"; break; case jsb.EventAssetsManager.ERROR_DOWNLOAD_MANIFEST: case jsb.EventAssetsManager.ERROR_PARSE_MANIFEST: this.panel.info.string = \"Fail to download manifest file, hot update skipped.\"; break; case jsb.EventAssetsManager.ALREADY_UP_TO_DATE: this.panel.info.string = \"Already up to date with the latest remote version.\"; break; case jsb.EventAssetsManager.NEW_VERSION_FOUND: this.panel.info.string = 'New version found, please try to update.'; this.panel.checkBtn.active = false; this.panel.fileProgress.progress = 0; this.panel.byteProgress.progress = 0; break; default: return; &#125; this._am.setEventCallback(null); this._checkListener = null; this._updating = false;&#125;, 接着我们就可以点击更新按钮进行更新了，具体的代码，其实都在里面了。 hotUpdate: function () &#123; if (this._am &amp;&amp; !this._updating) &#123; this._am.setEventCallback(this.updateCb.bind(this)); if (this._am.getState() === jsb.AssetsManager.State.UNINITED) &#123; // Resolve md5 url var url = this.manifestUrl.nativeUrl; if (cc.loader.md5Pipe) &#123; url = cc.loader.md5Pipe.transformURL(url); &#125; this._am.loadLocalManifest(url); &#125; this._failCount = 0; this._am.update(); this.panel.updateBtn.active = false; this._updating = true; &#125;&#125;,","categories":[{"name":"Cocos Creator","slug":"Cocos-Creator","permalink":"https://gowa2017.github.io/categories/Cocos-Creator/"}],"tags":[{"name":"Cocos Creator","slug":"Cocos-Creator","permalink":"https://gowa2017.github.io/tags/Cocos-Creator/"}],"keywords":[{"name":"Cocos Creator","slug":"Cocos-Creator","permalink":"https://gowa2017.github.io/categories/Cocos-Creator/"}]},{"title":"Vim常用插件清单","slug":"Vim常用插件清单","date":"2019-01-03T12:05:49.000Z","updated":"2019-01-03T12:05:49.000Z","comments":true,"path":"Vim/Vim常用插件清单.html","link":"","permalink":"https://gowa2017.github.io/Vim/Vim常用插件清单.html","excerpt":"个人所有，最近需要用 js 来干一些活，但是用 ide 感觉太重量级了。webStorm 或者 vs code 也好，感觉启动起来都慢慢的，直接用 vim 怕不是要好点哦。所以把我常用的配置都整理了一下。","text":"个人所有，最近需要用 js 来干一些活，但是用 ide 感觉太重量级了。webStorm 或者 vs code 也好，感觉启动起来都慢慢的，直接用 vim 怕不是要好点哦。所以把我常用的配置都整理了一下。 常规插件 Vundle 插件管理。 molokai主题 ctrlp.vim 路径模糊搜索 NERDTree 文件夹浏览器 Vim Markdown Vim MarkDown 支持 AndrewRadev/splitjoin.vim 在单行语句和多行语句间变换 UltiSnips 代码片段插件 vim-airline 状态栏加强 tagbar 文件结构，标签浏览 vim-easygrep 多个文件间查找和替换 tabular 文本过滤与对齐 vim-syntastic/syntastic 语法检查 YouCompleteMe 用来进行补全的，效果不错，非常强大 Go fatih/vim-go Go语言的Vim 支持插件 JavaScript pangloss/vim-javascript JavaScript 缩进与语法支持 maksimr/vim-jsbeautify 格式化 js/json/html/css/jsx 等 tern_for_vim 补全 JS 用 关于如何启用，使用 Vundle 作为插件管理，然后添加 YouCompleteMe 和 tern_for_vim ，然后 :PluginInstall。 接着，进入 YouCompleteMe 目录，执行 ./install.py --tern-completer 最后，在 $HOME 目录下，建立一个 .tern_project 文件： &#123; \"ecmaVersion\": 6, \"libs\": [ \"browser\", \"underscore\", \"jquery\" ], \"plugins\": &#123; \"node\": &#123;&#125; &#125;&#125; 接着就可以享受很多了。 Pythonsproto vim-sproto sproto 支持","categories":[{"name":"Vim","slug":"Vim","permalink":"https://gowa2017.github.io/categories/Vim/"}],"tags":[{"name":"Vim","slug":"Vim","permalink":"https://gowa2017.github.io/tags/Vim/"}],"keywords":[{"name":"Vim","slug":"Vim","permalink":"https://gowa2017.github.io/categories/Vim/"}]},{"title":"关于JavaScript执行环境和Scope","slug":"关于JavaScript执行环境和Scope","date":"2019-01-02T01:46:23.000Z","updated":"2019-01-02T01:46:23.000Z","comments":true,"path":"JavaScript/关于JavaScript执行环境和Scope.html","link":"","permalink":"https://gowa2017.github.io/JavaScript/关于JavaScript执行环境和Scope.html","excerpt":"此文章来源于 medium 上作者的系列文章，做个翻译和记录，感觉讲得比较直观易解。javascript-demystified","text":"此文章来源于 medium 上作者的系列文章，做个翻译和记录，感觉讲得比较直观易解。javascript-demystified 变量提升其开篇几以一个非常简单的例子来问大家： console.log('x is', x)var xconsole.log('x is', x)x = 5console.log('x is', x) 三个 console.log 的输出是什么。结果是： x is undefinedx is undefinedx is 5 为什么会是这个结果而不是其他的？ 因为： JavaScript 的解释器会在解释（编译） js 脚本的时候，类似于把所有的变量的声明提升到最前，所以，你可以在看起来变量声明之前使用它，不过得到的是一个 undefined 的值。 undefined 是一个正常值，我把它理解为和 null, Nan 差不多这样。 函数提升第一个例子： sayHello()function sayHello () &#123; function hello () &#123; console.log('Hello!') &#125; hello() function hello () &#123; console.log('Hey!') &#125;&#125; 输出是什么？ 第二个例子： sayHello()function sayHello () &#123; function hello () &#123; console.log('Hello!') &#125; hello() var hello = function () &#123; console.log('Hey!') &#125;&#125; 这个的输出又是什么。 第三个例子： sayHello()var sayHello = function () &#123; function hello () &#123; console.log('Hello!') &#125; hello() function hello () &#123; console.log('Hey!') &#125;&#125; 结果： 第一个例子输出是 Hey! 第二个例子输出是 Hello! 第三个例子输出是 TypeError。 为什么？ 同变量提升一样，对于函数声明，也会进行提升。所以可以在函数定义之前使用它。这也就是第一个例子和第二个例子都可以正常输出的原因。第一个例子输出 Hey，是因为重复定义了，后一个生效。 第二个例子输出是 Hello ，是因为首先定义一个叫 hello 的函数，再次用 var 声明变量的时候已经存在叫 hello 的变量了；只有在运行时，对 hello 重新进行赋值为函数表达式了。 第三个例子一样不用说了，因为其是变量，在执行 sayHello() 的时候，var sayHello 的值是 undefined ，所以肯定会报错了。 对于第三个例子： var sayHello = function () &#123; function hello () &#123; console.log('Hello!') &#125; hello() function hello () &#123; console.log('Hey!') &#125;&#125; 叫做函数表达式，是不会进行提升的。 Scopevar greet = 'Hello!'function sayHi () &#123; console.log('2: ', greet) var greet = 'Ciao!' console.log('3: ', greet)&#125;console.log('1: ', greet)sayHi()console.log('4: ', greet) 输出的结果是： 1: Hello!2: undefined3: Ciao!4: Hello! 作者在这里的提醒是： 作用域 和 执行环境 非常的相近，但并不一样。 作用域作用域定义了你所处代码位置，能访问的变量和函数。 var greet = 'Hello!'function sayHi () &#123; console.log('1: ', greet)&#125;sayHi()console.log('2: ', greet)// 1: Hello!// 2: Hello! function sayHi () &#123; var greet = 'Hello!' console.log('1: ', greet)&#125;sayHi()console.log('2: ', greet)// 1: Hello!// ReferenceError: greet is not defined 为什么第二个例子的输出会是 引用错误？ 第一个和第二个例子的不同再于：greet 定义的位置不同，一个位于 sayHi 函数内，一个在 sayHi 函数外。我们可以在函数内访问函数外定义的 greet，相反则不能。这是因为，在函数外第一的变量 greet 具有全局作用域，而在 sayHi 内定义的只有本地作用域。 那么 全局作用域和本地作用域又是什么？ 全局作用域默认作用域，引擎在执行代码前就已经定义了。一般情况下我们只有一个全局作用域，我们打开 chrome，直接在 console 里面输入 this 就能查看我们当前的全局作用域。 全局作用域的变量，也叫全局变量，可以在其他任何地方访问和修改。 本地作用域本地作用域是在全局作用域内建立的作用域。每当声明一个新的函数的时候，即建立了一个本地作用域，在函数内声明的变量就属于这个刚建立的作用域。 在执行环节，本地变量只能在其声明的作用域内被访问和修改。当函数执行完毕的时候，就返回到全局作用域，就会丢失在本地作用域内的变量。 这就是为什么上面的例子2中会报错的原因。 另外，在全局作用域中可能有多个本地作用域，本地作用域间互不影响，相互隔离。 执行环境(Execution context- EC)前面我们说到，执行环境EC与作用域关联非常密切，但并不一样。经常，这两个概念会被不适当的理解同时进行交换使用，这可能会导致一些危险。 EC != SCOPE我们现在只需要记住，在 JavaScript 引擎开始阅读我们代码的时候，会发生下面的几件事情： 全局执行环境在任何代码被执行之前建立 当 执行 一个函数的时候，会建立一个新的执行环境。 每个执行环境都提供 this 关键字，其指向当前代码在其内执行的一个对象。 现在我们来看一下下面的代码： var globalThis = thisfunction myFunc () &#123; console.log('globalThis: ', globalThis) console.log('this inside: ', this) console.log(globalThis === this)&#125;myFunc()// globalThis: Window &#123;...&#125;// this inside: Window &#123;...&#125;// true 你可能会有疑问，为什么 globalThis 与 myFunc 内的 this 指向同一个对象呢，虽然，我们是在一个不同的作用域内访问了 this。 这就是我们之前重复的：作用域与执行环境并不一样。但是，作用域在执行环境的定义上，扮演了一个非常关键的角色。 那么，到底什么是执行环境？ EC定义在 JavaScript 中，执行环境，执行上下文是一个非常抽象的概念，其维护了当前代码执行的环境信息。 注意： JavaScript 在任何代码开始执行之前就建立了全局执行环境。接着，每当执行一个函数的时候就会建立一个新的执行环境。事实上，全局执行环境也没有什么特别的。只不过其是在任何代码执行之前建立罢了。 内存建立环节当一个新的函数被调用的时候， JavaScript 需要花一点点时间来进行配置执行环境。这个环节很重要。 在这个环节会发生下面的事情： 建立作用域 建立作用域链 确定 this 的值。 作用域 Scope每个执行环境需要了解其自身的作用域————换句话说，其需要知道其自己能访问哪些变量和函数。Hoisting 就在这个环节发生，JavaScript 会扫描所有的代码，然后把变量和函数声明放到内存中去。 作用域链 Scope Chain除了自身的作用域，每个执行环境还有一个对其外部作用域的引用（可能的话），最终会引用到全局作用域。我们把这一系列的引用就叫做作用域链。 一个执行环境的作用域链并不包含任何关于其兄弟作用域的信息（即使是在相同的外部函数内），或者其子作用域。这就是为什么 a) 你为什么可以从本地作用域访问全局变量，反之则不行； b) 你不能从其他本地作用域访问当前作用域变量。 下面的例子就显示了上面说的内容： console.log(one) // undefinedconsole.log(two) // ReferenceError: two is not definedconsole.log(three) // ReferenceError: three is not definedvar one = 1function myFunc () &#123; console.log(one) // 1 console.log(two) // undefined console.log(three) // ReferenceError: three is not defined var two = 2 console.log(two) // 2&#125;function myOtherFunc () &#123; console.log(one) // 1 console.log(two) // ReferenceError: two is not defined console.log(three) // undefined var three = 3 console.log(three) // 3&#125;myFunc()myOtherFunc() this 的值每个执行环境都有一个特殊的变量 this。this 指向代表了当前代码在其内执行的那个对象。。 在下面的例子中，全局执行环境中 this 的值是 window。而在 myFunc 函数内 this 的值也是 window。 var globalThis = thisfunction myFunc () &#123; console.log('globalThis: ', globalThis) console.log('this inside: ', this) console.log(globalThis === this)&#125;myFunc()// globalThis: Window &#123;...&#125;// this inside: Window &#123;...&#125;// true 但是，怎么解释下面这个例子： var globalThis = thisvar myObj = &#123; myMethod: function () &#123; console.log('globalThis: ', globalThis) console.log('this inside: ', this) console.log(globalThis === this) console.log(myObj === this) &#125;&#125;myObj.myMethod()// globalThis: Window &#123; ... &#125;// this inside: &#123; myMethod: f &#125;// false// true 这是因为 this 在有一个执行对象的时候，就指向那个执行对象； 如果没有一个执行对象，那么它就指向全局环境。 执行对象在上面的例子中，当 myMethod() 在第12行执行的时候，其前面有一个对 myObj 的引用————这就是它的执行对象。这样，在 myMethod() 的执行环境中，this 就指向了 myObj。 那么，你能知道下面例子中的 this 输出是什么么： var myObj = &#123; myMethod: function () &#123; console.log(this) &#125;&#125;var myFunc = myObj.myMethodmyFunc() 输出会是 Window，而不是 myObj ， 为什么？因为 this 只是在执行的时候才会被设置为执行对象。 那么下一个的输出呢？ var myObj = &#123; myMethod: function () &#123; myFunc() function myFunc () &#123; console.log(this) &#125; &#125;&#125;myObj.myMethod() 还是 Window。 this 与 self看起来我们不能对 this 有什么有用的操作，真的是这样么？当在嵌套的函数中的时候，如果 this 指向一个全局对象是很不好的事情，因为调用是在一个对象内进行的。 常规的方法是把 this 赋值给一个变量： var myObj = &#123; myMethod: function () &#123; var self = this myFunc() function myFunc () &#123; console.log('this: ', this) console.log('self: ', self) &#125; &#125;&#125;myObj.myMethod()// this: Window &#123; ... &#125;// self: &#123; myMethod: f &#125; bind(), call(), apply()另外一种来操作 this 值的方式是调用内建的方法： call(), bind(), apply()。任何一个 JavaScript 函数都可以调用这三个方法。所有他们三个做的事情都一样————以一个对象作为参数，把这个对象作为执行环境的父对象————只有轻微的不同。 bind() 返回一个函数，不过其 this 也被设置 call(), apply()：执行调用。 var greet = 'Hello!'function showGreet () &#123; console.log(this.greet)&#125;var casualGreet = &#123; greet: 'Hey!' &#125;showGreet() // Hello!showGreet.bind(casualGreet)() // Hey!showGreet.call(casualGreet) // Hey!showGreet.apply(casualGreet) // Hey! 执行栈一个简单的规则，调用函数，就会建立执行环境。 那么接下来呢？ 假如你的代码中有两个函数。你事实上拥有三个执行环境（包括全局执行环境）。我们需要更深入的了解一下执行栈 每当一个新执行环境建立的时候，其被放在前一个执行环境之上。这就是为什么我们把他们叫做执行栈的意思。 有一个需要了解的地方就是，JavaScript 只能在一个环境执行。 当开始执行代码的时候，是在全局执行环境执行的。 当调用一个函数的时候，将会进入执行环境 a，所有在全局环境内的事件都会暂停，直到 JavaScript 引擎退出 a。 当在 a 中又进行函数调用的话，那么就会进入一个环境 b。此时，会将 a 暂停。 …. 上面这个过程就是为什么 JS 被称作是单线程的原因。 闭包下面的例子会打印出什么。 var name = 'John'function greet (name) &#123; return (function () &#123; console.log('Hello ' + name) &#125;)&#125;var sayHello = greet(name)name = 'Sam'sayHello() 答案是：Hello John。 即使我们在调用 sayHello() 之前改变了 name 的值，输出不会变化。就好像 name 的值，以前在其改变前被捕捉了。 这就是 闭包了。 Scope Chain 在一个执行环境中，包含了一个作用域链，保留了对其外部作用域的引用，直到全局作用域。但事实上我们并不知道作用域链是怎么样建立的。我们需要介绍一个新的角色了————函数的[[scope]]属性。 [[scope]] Property每个函数，在建立的时候，就被谁知了一个内部的属性 [[scope]]，属性的值就是当前执行环境的作用域链。 当函数被调用的时候，会建立一个新的执行环境，同时新的执行环境的作用域链，此作用域链引用了所有的本地作用域变量。这个作用域链还会以一个单独的属性来继承 [[scope]] 的值。这就是一个作用域链怎么样引用外部作用域的了。 需要记住的是， [[scope]] 属性是在函数被建立的时候设置的，而不是在其被调用或运行的时候。当函数运行的时候，新的执行环境的作用域链中的变量引用了这个 [[scope]]。 // scope chain: &#123; a: undefined &#125;var a = 'global'// scope chain: &#123; a: 'global' &#125;function outer () &#123; // [[scope]]: &#123; a: 'global' &#125; // scope chain: &#123; b: undefined, outerScope: [[scope]] &#125; var b = 'outer' // scope chain: &#123; b: 'outer', outerScope: [[scope]] &#125; function inner () &#123; // [[scope]]: &#123; // b: 'outer', // outerScope: &#123; a: 'global' &#125; // &#125; // scope chain: &#123; c: undefined, outerScope: [[scope]] &#125; var c = 'inner' // scope chain: &#123; c: 'inner', outerScope: [[scope]] &#125; console.log('a:', a) console.log('b:', b) console.log('c:', c) &#125; inner()&#125;outer()// a: global// b: outer// c: inner 闭包在上面的例子中，我们来想一下这样的场景：我想在将来的某个时刻执行 inner() 函数，而不是立刻在 outer 内调用？那么在 inner() 的 console.log() 会打印出什么来？ var a = 'global'function outer () &#123; var b = 'outer' return function inner () &#123; var c = 'inner' console.log('a:', a) console.log('b:', b) console.log('c:', c) &#125;&#125;var innerFunc = outer()innerFunc()// a: global// b: outer// c: inner 事实上，对外部变量的引用： 在函数建立时创建 即使在外部执行环境移除后依然可用。 这就叫做闭包。 通过引用，而不是值需要注意，一个闭包捕捉对外部变量的引用，而不是他们的值。其记住的是，在哪里去找到变量，这些变量在不同的时间不同的地方可以代表不同的值。 换句话说，闭包内变量的值可以被修改。 var a = 'global'function outer () &#123; var b = 'outer' return function inner () &#123; var c = 'inner' console.log('a:', a) console.log('b:', b) console.log('c:', c) &#125;&#125;var innerFunc = outer()a = 'GLOBAL'innerFunc()// a: GLOBAL// b: outer// c: inner 你可能会有疑问，为什么本节开头的那个例子输出的却是 John，而不是 Sam。 这就有所不同了，因为我们的 name 是作为参数传递给 sayHello() 的，其实已经是本地作用域内的变量了，所以你再改变全局变量的值已经不会影响它了。","categories":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://gowa2017.github.io/categories/JavaScript/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://gowa2017.github.io/tags/JavaScript/"}],"keywords":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://gowa2017.github.io/categories/JavaScript/"}]},{"title":"Pomelo的启动流程","slug":"Pomelo的启动流程","date":"2018-12-31T13:45:53.000Z","updated":"2018-12-31T13:45:53.000Z","comments":true,"path":"JavaScript/Pomelo的启动流程.html","link":"","permalink":"https://gowa2017.github.io/JavaScript/Pomelo的启动流程.html","excerpt":"了解一下吧，不然用起来总是会出现疑问不是？这是我一贯的习惯了。查看我们每个 pomelo 项目的 game-server 下的 app.js ，从头开始抓其流程吧。就以lordofpomelo 为例来看。","text":"了解一下吧，不然用起来总是会出现疑问不是？这是我一贯的习惯了。查看我们每个 pomelo 项目的 game-server 下的 app.js ，从头开始抓其流程吧。就以lordofpomelo 为例来看。 前言我更想把 pomelo 当做是一个 ECS 系统进行理解。 App 就是一个载体，承载了各个组件，各组件的协同运作，提供了一个 server。当然，我们也可以把它叫做一个上下文来理解。 需要明确一点的就是，App 并不提供任何服务，其加载的组件才是真正提供了各项功能的所在。 ApplicationPomelo 有一个叫做 Application 的东西，在里面挂了很多的内容（加载了很多组件，配置）。我们也可以把他简称为 app，这是我们项目，游戏运行的一个全局上下文，很多内容可以从里面获取。 在程序的入口文件 app.js 中，我们会对每种类型的服务器，或者所有的服务器进行配置。包括 connector 的选择，组件的加载，甚至是自定义的插件等的加载。 //app.jsvar app = pomelo.createApp();app.set('name', 'lord of pomelo');// configure for globalapp.configure('production|development', function() &#123; app.before(pomelo.filters.toobusy()); app.enable('systemMonitor'); require('./app/util/httpServer'); //var sceneInfo = require('./app/modules/sceneInfo'); var onlineUser = require('./app/modules/onlineUser'); if(typeof app.registerAdmin === 'function')&#123; //app.registerAdmin(sceneInfo, &#123;app: app&#125;); app.registerAdmin(onlineUser, &#123;app: app&#125;); &#125; //Set areasIdMap, a map from area id to serverId. if (app.serverType !== 'master') &#123; var areas = app.get('servers').area; var areaIdMap = &#123;&#125;; for(var id in areas)&#123; areaIdMap[areas[id].area] = areas[id].id; &#125; app.set('areaIdMap', areaIdMap); &#125; // proxy configures app.set('proxyConfig', &#123; cacheMsg: true, interval: 30, lazyConnection: true // enableRpcLog: true &#125;); // remote configures app.set('remoteConfig', &#123; cacheMsg: true, interval: 30 &#125;); // route configures app.route('area', routeUtil.area); app.route('connector', routeUtil.connector); app.loadConfig('mysql', app.getBase() + '/../shared/config/mysql.json'); app.filter(pomelo.filters.timeout()); /* // master high availability app.use(masterhaPlugin, &#123; zookeeper: &#123; server: '127.0.0.1:2181', path: '/pomelo/master' &#125; &#125;); */&#125;);// Configure for auth serverapp.configure('production|development', 'auth', function() &#123; // load session congfigures app.set('session', require('./config/session.json'));&#125;);// Configure for area serverapp.configure('production|development', 'area', function()&#123; app.filter(pomelo.filters.serial()); app.before(playerFilter()); //Load scene server and instance server var server = app.curServer; if(server.instance)&#123; instancePool.init(require('./config/instance.json')); app.areaManager = instancePool; &#125;else&#123; scene.init(dataApi.area.findById(server.area)); app.areaManager = scene; /* kill -SIGUSR2 &lt;pid&gt; http://localhost:3272/inspector.html?host=localhost:9999&amp;page=0 */ /* // disable webkit-devtools-agent var areaId = parseInt(server.area); if(areaId === 3) &#123; // area-server-3 require('webkit-devtools-agent'); var express = require('express'); var expressSvr = express.createServer(); expressSvr.use(express.static(__dirname + '/devtools_agent_page')); var tmpPort = 3270 + areaId - 1; expressSvr.listen(tmpPort); &#125; */ &#125; //Init areaService areaService.init();&#125;);app.configure('production|development', 'manager', function()&#123; var events = pomelo.events; app.event.on(events.ADD_SERVERS, instanceManager.addServers); app.event.on(events.REMOVE_SERVERS, instanceManager.removeServers);&#125;);// Configure databaseapp.configure('production|development', 'area|auth|connector|master', function() &#123; var dbclient = require('./app/dao/mysql/mysql').init(app); app.set('dbclient', dbclient); // app.load(pomelo.sync, &#123;path:__dirname + '/app/dao/mapping', dbclient: dbclient&#125;); app.use(sync, &#123;sync: &#123;path:__dirname + '/app/dao/mapping', dbclient: dbclient&#125;&#125;);&#125;);app.configure('production|development', 'connector', function()&#123; var dictionary = app.components['__dictionary__']; var dict = null; if(!!dictionary)&#123; dict = dictionary.getDict(); &#125; app.set('connectorConfig', &#123; connector : pomelo.connectors.hybridconnector, heartbeat : 30, useDict : true, useProtobuf : true, handshake : function(msg, cb)&#123; cb(null, &#123;&#125;); &#125; &#125;);&#125;);app.configure('production|development', 'gate', function()&#123; app.set('connectorConfig', &#123; connector : pomelo.connectors.hybridconnector, useProtobuf : true &#125;);&#125;);// Configure for chat serverapp.configure('production|development', 'chat', function() &#123; app.set('chatService', new ChatService(app));&#125;);//startapp.start();// Uncaught exception handlerprocess.on('uncaughtException', function(err) &#123; console.error(' Caught exception: ' + err.stack);&#125;); 可以看到，先是建立一个 app ，然后调用 app.configure 配置了很多选项，还有，用 app.set 设置了一些键值。更多的细节我们后面再看。 配置文件我们的服务启动都会进行很多的配置，配置文件的分布如下：这些定义在 pomelo 的 constants.js 文件内。 // utils/constans.js FILEPATH: &#123; MASTER: '/config/master.json', SERVER: '/config/servers.json', CRON: '/config/crons.json', LOG: '/config/log4js.json', SERVER_PROTOS: '/config/serverProtos.json', CLIENT_PROTOS: '/config/clientProtos.json', MASTER_HA: '/config/masterha.json', LIFECYCLE: '/lifecycle.js', SERVER_DIR: '/app/servers/', CONFIG_DIR: '/config' &#125;, Pomelo.createApp()Pomelo.createApp = function (opts) &#123; var app = application; app.init(opts); self.app = app; return app;&#125;; Application.init()Application.init = function(opts) &#123; opts = opts || &#123;&#125;; this.loaded = []; // loaded component list this.components = &#123;&#125;; // name -&gt; component map this.settings = &#123;&#125;; // collection keep set/get var base = opts.base || path.dirname(require.main.filename); // base path this.set(Constants.RESERVED.BASE, base, true); this.event = new EventEmitter(); // event object to sub/pub events // current server info this.serverId = null; // current server id this.serverType = null; // current server type this.curServer = null; // current server info this.startTime = null; // current server start time // global server infos this.master = null; // master server info this.servers = &#123;&#125;; // current global server info maps, id -&gt; info this.serverTypeMaps = &#123;&#125;; // current global type maps, type -&gt; [info] this.serverTypes = []; // current global server type list this.lifecycleCbs = &#123;&#125;; // current server custom lifecycle callbacks this.clusterSeq = &#123;&#125;; // cluster id seqence appUtil.defaultConfiguration(this); this.state = STATE_INITED; logger.info('application inited: %j', this.getServerId());&#125;; 其他都暂时不用看，我们关注后面的 appUtil.defaultConfiguration(this); 以上会对服务器进行默认的设置。 appUtil.defaultConfiguration(this);module.exports.defaultConfiguration = function(app) &#123; var args = parseArgs(process.argv); setupEnv(app, args); loadMaster(app); loadServers(app); processArgs(app, args); configLogger(app); loadLifecycle(app);&#125;; 根据其方法名称，可以得出其可能干了些什么。 解析命令行参数 设置环境 加载 Master 加载 Servers 解析参数 设置 Logger 加载生命周期parseArgs(process.argv) 此方法将命令行参数解析为一个map。 将 -- 指定识别为选项 将 key=value 指定的识别为参数。 var parseArgs = function(args) &#123; var argsMap = &#123;&#125;; var mainPos = 1; while (args[mainPos].indexOf('--') &gt; 0) &#123; mainPos++; &#125; argsMap.main = args[mainPos]; for (var i = (mainPos + 1); i &lt; args.length; i++) &#123; var arg = args[i]; var sep = arg.indexOf('='); var key = arg.slice(0, sep); var value = arg.slice(sep + 1); if (!isNaN(Number(value)) &amp;&amp; (value.indexOf('.') &lt; 0)) &#123; value = Number(value); &#125; argsMap[key] = value; &#125; return argsMap;&#125;; loadMaster/loadServers这两个函数，只是加载我们的配置文件。 var loadMaster = function(app) &#123; app.loadConfigBaseApp(Constants.RESERVED.MASTER, Constants.FILEPATH.MASTER); app.master = app.get(Constants.RESERVED.MASTER);&#125;; 让 app 全局上下文去加载配置文件 /config/master.json’ 内的内容。 var loadServers = function(app) &#123; app.loadConfigBaseApp(Constants.RESERVED.SERVERS, Constants.FILEPATH.SERVER); var servers = app.get(Constants.RESERVED.SERVERS); var serverMap = &#123;&#125;, slist, i, l, server; for (var serverType in servers) &#123; slist = servers[serverType]; for (i = 0, l = slist.length; i &lt; l; i++) &#123; server = slist[i]; server.serverType = serverType; if(server[Constants.RESERVED.CLUSTER_COUNT]) &#123; utils.loadCluster(app, server, serverMap); continue; &#125; serverMap[server.id] = server; if (server.wsPort) &#123; logger.warn('wsPort is deprecated, use clientPort in frontend server instead, server: %j', server); &#125; &#125; &#125; app.set(Constants.KEYWORDS.SERVER_MAP, serverMap);&#125;; 加载 /config/servers.json 的内容。 我们可以看到，这其实都是做了一些加载配置类的工作。 真正启动我们程序的，还是 app.start() 这个方法。 processArgs这个函数所做的就是解析我们的命令行参数，来启动对应的服务。 当我们使用 pomelo start 不带任何命令行参数启动的时候，其实启动的是 master 服务器。后续，再由 master 服务器来启动其他服务。当然，事实上都是以 node app.js args.... 这样的形式来启动的。 我们可以通过 ps -e | grep node 命令来证实这一点： 45941 ttys000 0:00.51 node /usr/local/bin/pomelo start45942 ttys000 0:00.86 /usr/local/Cellar/node/11.3.0_1/bin/node /Users/wodediannao/gitrepo/mygame/game-server/app.js env=development type=all45943 ttys000 0:01.01 /usr/local/Cellar/node/11.3.0_1/bin/node /Users/wodediannao/gitrepo/mygame/game-server/app.js env=development id=connector-server-1 host=127.0.0.1 port=3150 clientPort=3010 frontend=true serverType=connector45944 ttys000 0:01.04 /usr/local/Cellar/node/11.3.0_1/bin/node /Users/wodediannao/gitrepo/mygame/game-server/app.js env=development id=connector-server-2 host=127.0.0.1 port=3151 clientPort=3011 frontend=true serverType=connector45945 ttys000 0:00.89 /usr/local/Cellar/node/11.3.0_1/bin/node /Users/wodediannao/gitrepo/mygame/game-server/app.js env=development id=chat-server-1 host=127.0.0.1 port=3450 serverType=chat45946 ttys000 0:00.90 /usr/local/Cellar/node/11.3.0_1/bin/node /Users/wodediannao/gitrepo/mygame/game-server/app.js env=development id=auth-server-1 host=127.0.0.1 port=3650 serverType=auth45947 ttys000 0:01.00 /usr/local/Cellar/node/11.3.0_1/bin/node /Users/wodediannao/gitrepo/mygame/game-server/app.js env=development id=gate-server-1 host=127.0.0.1 clientPort=3014 frontend=true serverType=gate var processArgs = function(app, args) &#123; var serverType = args.serverType || Constants.RESERVED.MASTER; // 默认当我们的命令行不包括任何参数的时候，启动 master 服务器 var serverId = args.id || app.getMaster().id; // ID 默认的也是 master 的ID var mode = args.mode || Constants.RESERVED.CLUSTER; var masterha = args.masterha || 'false'; var type = args.type || Constants.RESERVED.ALL; // master 服务器会有一个 type 为 all 的东西 var startId = args.startId; app.set(Constants.RESERVED.MAIN, args.main, true); // args.main 实际上是由 -- 选项进行指定 app.set(Constants.RESERVED.SERVER_TYPE, serverType, true); app.set(Constants.RESERVED.SERVER_ID, serverId, true); app.set(Constants.RESERVED.MODE, mode, true); app.set(Constants.RESERVED.TYPE, type, true); if(!!startId) &#123; app.set(Constants.RESERVED.STARTID, startId, true); &#125; if (masterha === 'true') &#123; app.master = args; app.set(Constants.RESERVED.CURRENT_SERVER, args, true); &#125; else if (serverType !== Constants.RESERVED.MASTER) &#123; app.set(Constants.RESERVED.CURRENT_SERVER, args, true); &#125; else &#123; app.set(Constants.RESERVED.CURRENT_SERVER, app.getMaster(), true); &#125;&#125;; Application.start()服务的启动，其实就分为两步： 加载各组件 启动各组件 Application.start = function(cb) &#123; this.startTime = Date.now(); if(this.state &gt; STATE_INITED) &#123; utils.invokeCallback(cb, new Error('application has already start.')); return; &#125; var self = this; appUtil.startByType(self, function() &#123; appUtil.loadDefaultComponents(self); var startUp = function() &#123; appUtil.optComponents(self.loaded, Constants.RESERVED.START, function(err) &#123; self.state = STATE_START; if(err) &#123; utils.invokeCallback(cb, err); &#125; else &#123; logger.info('%j enter after start...', self.getServerId()); self.afterStart(cb); &#125; &#125;); &#125;; var beforeFun = self.lifecycleCbs[Constants.LIFECYCLE.BEFORE_STARTUP]; if(!!beforeFun) &#123; beforeFun.call(null, self, startUp); &#125; else &#123; startUp(); &#125; &#125;);&#125;; appUtil.startByType()module.exports.startByType = function(app, cb) &#123; if(!!app.startId) &#123; if(app.startId === Constants.RESERVED.MASTER) &#123; utils.invokeCallback(cb); &#125; else &#123; starter.runServers(app); &#125; &#125; else &#123; if(!!app.type &amp;&amp; app.type !== Constants.RESERVED.ALL &amp;&amp; app.type !== Constants.RESERVED.MASTER) &#123; starter.runServers(app); &#125; else &#123; utils.invokeCallback(cb); &#125; &#125;&#125;; 这个函数会根据是否是 master 服务器来执行不同的启动流程。在这里，我们默认使用 pomelo start 的情况下，会执行到第一个 utils.invokeCallback(cb);。 starter.runServers ()MASTER 服务器会启动其他所有的服务器。通过 starter.js 来执行的。 判断是不是本地服务。 本地服务通过 spanProcess 来执行 不是本地服务通过 ssh 命令来启动 // lib/master/starter.js starter.runServers = function(app) &#123; var server, servers; var condition = app.startId || app.type; switch(condition) &#123; case Constants.RESERVED.MASTER: break; case Constants.RESERVED.ALL: servers = app.getServersFromConfig(); for (var serverId in servers) &#123; this.run(app, servers[serverId]); &#125; break; default: server = app.getServerFromConfig(condition); if(!!server) &#123; this.run(app, server); &#125; else &#123; servers = app.get(Constants.RESERVED.SERVERS)[condition]; for(var i=0; i&lt;servers.length; i++) &#123; this.run(app, servers[i]); &#125; &#125; &#125;&#125;;starter.localrun = function (cmd, host, options, callback) &#123; logger.info('Executing ' + cmd + ' ' + options + ' locally'); spawnProcess(cmd, host, options, callback);&#125;; 在这个函数中，如果是 master 就不再进行什么逻辑操作了。 接下来，就会从 配置文件中（在 loadConfigBaseApp 中我们已经加载内容）加载所有的服务器，然后进行 run 操作。最终，会派生出新再进程，来启动我们定义的服务器。 appUtil.loadDefaultComponents()当我们执行完毕 startByServerType 后就会进行这个回调。 顾名思义，加载默认的组件到 app 内来。 module.exports.loadDefaultComponents = function(app) &#123; var pomelo = require('../pomelo'); // load system default components if (app.serverType === Constants.RESERVED.MASTER) &#123; app.load(pomelo.master, app.get('masterConfig')); &#125; else &#123; app.load(pomelo.proxy, app.get('proxyConfig')); if (app.getCurServer().port) &#123; app.load(pomelo.remote, app.get('remoteConfig')); &#125; if (app.isFrontend()) &#123; app.load(pomelo.connection, app.get('connectionConfig')); app.load(pomelo.connector, app.get('connectorConfig')); app.load(pomelo.session, app.get('sessionConfig')); // compatible for schedulerConfig if(app.get('schedulerConfig')) &#123; app.load(pomelo.pushScheduler, app.get('schedulerConfig')); &#125; else &#123; app.load(pomelo.pushScheduler, app.get('pushSchedulerConfig')); &#125; &#125; app.load(pomelo.backendSession, app.get('backendSessionConfig')); app.load(pomelo.channel, app.get('channelConfig')); app.load(pomelo.server, app.get('serverConfig')); &#125; app.load(pomelo.monitor, app.get('monitorConfig'));&#125;; 这些很多地方就会很明了了 Master 服务器只会加载 masterConfig 配置 （/config/master.json）。 其他所有服务器都会加载 proxy,channel,server, backendSession 组件。 有监听端口的服务器会加载 remote 组件 所有的前端服务器会加载 connection, connector, session；还有可能会加载 pushScheduler 组件。 所有都会加载 Monitor 组件。 app.load()我们以加载的 connector 组件为例来看。 connector 定义在 pomelo 模块内： Pomelo.connectors = &#123;&#125;;Pomelo.connectors.__defineGetter__('sioconnector', load.bind(null, './connectors/sioconnector'));Pomelo.connectors.__defineGetter__('hybridconnector', load.bind(null, './connectors/hybridconnector'));Pomelo.connectors.__defineGetter__('udpconnector', load.bind(null, './connectors/udpconnector'));Pomelo.connectors.__defineGetter__('mqttconnector', load.bind(null, './connectors/mqttconnector')); 定义了四种方式。 socket.io, hybrid, udp, mqtt。 我们在 app.js 内定义了： app.configure('production|development', 'connector', function()&#123; var dictionary = app.components['__dictionary__']; var dict = null; if(!!dictionary)&#123; dict = dictionary.getDict(); &#125; app.set('connectorConfig', &#123; connector : pomelo.connectors.hybridconnector, heartbeat : 30, useDict : true, useProtobuf : true, handshake : function(msg, cb)&#123; cb(null, &#123;&#125;); &#125; &#125;);&#125;); 当执行 app.load(pomelo.connector, app.get(&#39;connectorConfig&#39;)); 时，就会很明了 // app.load(&#123;&#125;, &#123;&#125;);Application.load = function(name, component, opts) &#123; if(typeof name !== 'string') &#123; opts = component; component = name; name = null; if(typeof component.name === 'string') &#123; name = component.name; &#125; &#125; if(typeof component === 'function') &#123; component = component(this, opts); &#125; if(!name &amp;&amp; typeof component.name === 'string') &#123; name = component.name; &#125; if(name &amp;&amp; this.components[name]) &#123; // ignore duplicat component logger.warn('ignore duplicate component: %j', name); return; &#125; this.loaded.push(component); if(name) &#123; // components with a name would get by name throught app.components later. this.components[name] = component; &#125; return this;&#125;; startUp在线我们把组件都加载完毕了，就开始启动这些组件了。 var startUp = function() &#123; appUtil.optComponents(self.loaded, Constants.RESERVED.START, function(err) &#123; self.state = STATE_START; if(err) &#123; utils.invokeCallback(cb, err); &#125; else &#123; logger.info('%j enter after start...', self.getServerId()); self.afterStart(cb); &#125; &#125;);&#125;;var beforeFun = self.lifecycleCbs[Constants.LIFECYCLE.BEFORE_STARTUP];if(!!beforeFun) &#123; beforeFun.call(null, self, startUp);&#125; else &#123; startUp();&#125; 如果有 beforeFun 函数，则会先执行，执行完毕后，还会调用 afterStart 函数。 appUtil.optComponents这个函数，是将所有的组件进行启动，其中， method 传递的是 start 函数。 comps 就是已加载的组件列表。 module.exports.optComponents = function(comps, method, cb) &#123; var i = 0; async.forEachSeries(comps, function(comp, done) &#123; i++; if (typeof comp[method] === 'function') &#123; comp[method](done); &#125; else &#123; done(); &#125; &#125;, function(err) &#123; if (err) &#123; if(typeof err === 'string') &#123; logger.error('fail to operate component, method: %s, err: %j', method, err); &#125; else &#123; logger.error('fail to operate component, method: %s, err: %j', method, err.stack); &#125; &#125; utils.invokeCallback(cb, err); &#125;);&#125;; async.forEachSeries([], (), cb)。这个函数的意思是，对 [] 列表中的每个 item，的应用 () 定义的函数。cb 回调是可选的。 在我们的例子中，会对每个组件应用我们一个异步函数 function(comp, done) ， done 是回调函数。 以我们的 connector 中的 hybridconnector.js 为例： Connector.prototype.start = function(cb) &#123; var app = require('../pomelo').app; var self = this; var gensocket = function(socket) &#123; var hybridsocket = new HybridSocket(curId++, socket); hybridsocket.on('handshake', self.handshake.handle.bind(self.handshake, hybridsocket)); hybridsocket.on('heartbeat', self.heartbeat.handle.bind(self.heartbeat, hybridsocket)); hybridsocket.on('disconnect', self.heartbeat.clear.bind(self.heartbeat, hybridsocket.id)); hybridsocket.on('closing', Kick.handle.bind(null, hybridsocket)); self.emit('connection', hybridsocket); &#125;; // 从 app 处获取加载的组件 this.connector = app.components.__connector__.connector; this.dictionary = app.components.__dictionary__; this.protobuf = app.components.__protobuf__; this.decodeIO_protobuf = app.components.__decodeIO__protobuf__; if(!this.ssl) &#123; this.listeningServer = net.createServer(); &#125; else &#123; this.listeningServer = tls.createServer(this.ssl); &#125; this.switcher = new Switcher(this.listeningServer, self.opts); this.switcher.on('connection', function(socket) &#123; gensocket(socket); &#125;); if(!!this.distinctHost) &#123; this.listeningServer.listen(this.port, this.host); &#125; else &#123; this.listeningServer.listen(this.port); &#125; process.nextTick(cb);&#125;; 这样的话，一个组件就启动起来了，当然这个组件里面其实有更多的细节，但那不是本文关注的重点了。","categories":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://gowa2017.github.io/categories/JavaScript/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://gowa2017.github.io/tags/JavaScript/"},{"name":"Pomelo","slug":"Pomelo","permalink":"https://gowa2017.github.io/tags/Pomelo/"}],"keywords":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://gowa2017.github.io/categories/JavaScript/"}]},{"title":"Pomelo中登录流程","slug":"Pomelo中登录流程","date":"2018-12-31T12:53:59.000Z","updated":"2018-12-31T12:53:59.000Z","comments":true,"path":"JavaScript/Pomelo中登录流程.html","link":"","permalink":"https://gowa2017.github.io/JavaScript/Pomelo中登录流程.html","excerpt":"Pomelo做棋牌和小游戏确实是不错的，所以来了解一下其登录流程。客户端连接的建立是由 connector 组件完成的，在我们配置的 servers.json 中，只有前端服务器 frontend:true 才会加载这个组件（一般来说，我们只会设置 game, connector 为前端服务器）。同时这个组件会依赖 session 组件来维护连接信息。","text":"Pomelo做棋牌和小游戏确实是不错的，所以来了解一下其登录流程。客户端连接的建立是由 connector 组件完成的，在我们配置的 servers.json 中，只有前端服务器 frontend:true 才会加载这个组件（一般来说，我们只会设置 game, connector 为前端服务器）。同时这个组件会依赖 session 组件来维护连接信息。 客户端一般来说，我们会和 gate 建立连接，请求一个可以接入服务器的 connector。 之后我们就会和对应的 connector 建立连接。我们以 网易 demo中的 lordofpomelo 来看。 // web-server/public/js/ui/clientManager.js $.post(httpHost + 'login', &#123;username: username, password: pwd&#125;, function(data) &#123; if (data.code === 501) &#123; alert('Username or password is invalid!'); loading = false; return; &#125; if (data.code !== 200) &#123; alert('Username is not exists!'); loading = false; return; &#125; authEntry(data.uid, data.token, function() &#123; loading = false; &#125;); localStorage.setItem('username', username); &#125;); 有点意外哈，其是用 post 的方式在当前网页上进行登录的。我们看一下登录的过程： // web-server/app.jsapp.post('/login', function(req, res) &#123; var msg = req.body; var username = msg.username; var pwd = msg.password; if (!username || !pwd) &#123; res.send(&#123;code: 500&#125;); return; &#125; userDao.getUserByName(username, function(err, user) &#123; if (err || !user) &#123; console.log('username not exist!'); res.send(&#123;code: 500&#125;); return; &#125; if (pwd !== user.password) &#123; // TODO code // password is wrong console.log('password incorrect!'); res.send(&#123;code: 501&#125;); return; &#125; console.log(username + ' login!'); res.send(&#123;code: 200, token: Token.create(user.id, Date.now(), secret), uid: user.id&#125;); &#125;);&#125;); 简单的验证了一下账号密码后，通过 user.id，和当前时间生成一个 token 进行返回。 从第一部分我们知道，在登录成功后，其调用了 authEntry() 方法。 function authEntry(uid, token, callback) &#123; queryEntry(uid, function(host, port) &#123; entry(host, port, token, callback); &#125;);&#125;function queryEntry(uid, callback) &#123; pomelo.init(&#123;host: config.GATE_HOST, port: config.GATE_PORT, log: true&#125;, function() &#123; pomelo.request('gate.gateHandler.queryEntry', &#123; uid: uid&#125;, function(data) &#123; pomelo.disconnect(); if(data.code === 2001) &#123; alert('Servers error!'); return; &#125; callback(data.host, data.port); &#125;); &#125;); function entry(host, port, token, callback) &#123; // init socketClient // TODO for development if(host === '127.0.0.1') &#123; host = config.GATE_HOST; &#125; pomelo.init(&#123;host: host, port: port, log: true&#125;, function() &#123; pomelo.request('connector.entryHandler.entry', &#123;token: token&#125;, function(data) &#123; var player = data.player; if (callback) &#123; callback(data.code); &#125; if (data.code == 1001) &#123; alert('Login fail!'); return; &#125; else if (data.code == 1003) &#123; alert('Username not exists!'); return; &#125; if (data.code != 200) &#123; alert('Login Fail!'); return; &#125; // init handler loginMsgHandler.init(); gameMsgHandler.init(); if (!player || player.id &lt;= 0) &#123; switchManager.selectView(\"heroSelectPanel\"); &#125; else &#123; afterLogin(data); &#125; &#125;); &#125;);&#125; 其基本经历了，与 game建立连接，获取 connector， 与 connector 建立连接，进行进入请求的过程。接下来到客户端我们的处理。 服务端客户端最终发送了一个 pomelo.request(&#39;connector.entryHandler.entry&#39;, {token: token}, function(data) {} 的请求，这个请求根据其路由回由 connector.entryHandler.entry 处理，一目了然。 pro.entry = function(msg, session, next) &#123; var token = msg.token, self = this; if(!token) &#123; next(new Error('invalid entry request: empty token'), &#123;code: Code.FAIL&#125;); return; &#125; var uid, players, player; async.waterfall([ function(cb) &#123; // auth token 根据 token 来计算机出 user self.app.rpc.auth.authRemote.auth(session, token, cb); &#125;, function(code, user, cb) &#123; // query player info by user id if(code !== Code.OK) &#123; next(null, &#123;code: code&#125;); return; &#125; if(!user) &#123; next(null, &#123;code: Code.ENTRY.FA_USER_NOT_EXIST&#125;); return; &#125; uid = user.id; userDao.getPlayersByUid(user.id, cb); &#125;, function(res, cb) &#123; // generate session and register chat status players = res; self.app.get('sessionService').kick(uid, cb); &#125;, function(cb) &#123; // 将 serssion 与 uid 相绑定。 session.bind(uid, cb); &#125;, function(cb) &#123; if(!players || players.length === 0) &#123; next(null, &#123;code: Code.OK&#125;); return; &#125; player = players[0]; // 设置一些信息到 session 中 session.set('serverId', self.app.get('areaIdMap')[player.areaId]); session.set('playername', player.name); session.set('playerId', player.id); session.on('closed', onUserLeave.bind(null, self.app)); session.pushAll(cb); &#125;, function(cb) &#123; // 加入频道 self.app.rpc.chat.chatRemote.add(session, player.userId, player.name, channelUtil.getGlobalChannelName(), cb); &#125; ], function(err) &#123; if(err) &#123; next(err, &#123;code: Code.FAIL&#125;); return; &#125; next(null, &#123;code: Code.OK, player: players ? players[0] : null&#125;); &#125;);&#125;; 看起来很简单，先是验证了一下 token 是否有效，接着就调用了一系列的函数。这里不禁就要问一下 waterfall 是什么意思。根据 官方定义。 waterfall 是序列化的执行一个数组内的异步函数，每个函数的输出作为下一函数的输入；如果有任何函数出错，那么就会立刻执行最后的那个回调函数。同时异步函数的形式的最后一个回调函数形入 function cb(err, results….)。 其执行过程是： 验证 token（是否过期，用户是否有效），成功则返回一个用户。 获取用户角色列表。 从session里面踢掉以前登录的这个用户，或者生成一个新的session。 绑定当前登录的用户到 session 设置 session 的一些键值 在全局频道内添加此用户 返回。 我在这里有一个疑问就是，session 是在哪里建立的？是 connector 服务器（前端服务器） 加载的 connector组件， session 组件在连接建立的时候创建的。所以能传递给 entry 函数。","categories":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://gowa2017.github.io/categories/JavaScript/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://gowa2017.github.io/tags/JavaScript/"},{"name":"Pomelo","slug":"Pomelo","permalink":"https://gowa2017.github.io/tags/Pomelo/"}],"keywords":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://gowa2017.github.io/categories/JavaScript/"}]},{"title":"Pomelo内建组件及游戏需要实现的一些东西","slug":"Pomelo内建组件及游戏需要实现的一些东西","date":"2018-12-29T08:56:19.000Z","updated":"2018-12-29T08:56:19.000Z","comments":true,"path":"JavaScript/Pomelo内建组件及游戏需要实现的一些东西.html","link":"","permalink":"https://gowa2017.github.io/JavaScript/Pomelo内建组件及游戏需要实现的一些东西.html","excerpt":"","text":"先从用户接入游戏说起。 游戏运行connector负责 管理客户端的连接 ，创建端口监听，绑定事件响应。依赖 session, server, pushSchedule, connection 组件。 当有客户连接，请求 session 组件，获取当前连接的 session；若当前连接不存在 session，那么 session 组件会建立新的 session，并维护连接。 然后 connector 组件还会向 connection 组件上报连接信息，供统计使用。 最后，将拿到的 session 以及客户端的请求，一起抛给 server 组件，由 server 组件进行请求处理 当 server 组件处理完请求后，又会通过 connector 组件将响应返回给客户端。在返回响应给客户端的时候， connector 组件做了一个缓存选择，这个缓存实现依赖于 pushScheduler 组件，也就是说 connector 组件并不是直接将响应发给客户端，而是将响应给 pushScheduler 组件。 pushScheduler 组件根据相应调度策略，可能不缓存直接通过 session 组件维护的连接，将响应发出去，也可能进行缓存，并按时 flush 。这是可以配置的。 支持的配置 connector: 底层使用的通信 connector，不配置的话，会默认使用sioconnector; useProtobuf: 目前仅仅支持 connector 配置使用hybridconnector 的情况，配置其为 true ，将开启消息的 protobuf 功能； useDict： 目前仅仅支持 connector 配置使用 hybridconnector 的情况，配置其为 true 时，将会开启基于字典的路由消息压缩； useCrypto： 目前仅仅支持 connector 配置为 hybridconnector 的情况，配置其为 true 时，将会启用通信时的数字签名； encode/decode： 消息的编码解码方式，如果不配置的话，将会默认使用 connector 配置中，底层 connector 提供的相应的编码解码函数。 transports：这个配置选项是用于 sioconnector 的，因为 socket.io 的通信方式可能会有多种，如 websocket，xhr-polling 等等。通过这个配置选项可以选择需要的方式。 通过类似代码配置： app.set('connectorConfig', opts); session session 组件跟 connector 相关，也是仅仅被前端服务器加载，为 sessionService 提供一个组件包装, 加载 session 组件后，会在app的上下文中增加 sessionService ，可以通过app.get(&#39;sessionService&#39;)获取。 主要用来维护客户端的连接信息，以及生成 session 并维护 session 。 一个连接与一个 session 对应，同时 session 组件还维护具体登录用户与 session 的绑定信息。一个用户可以有多个客户端登录，对应于多个 session 。当需要给客户端推送消息或者给客户端返回响应的话，必须通过 session 组件拿到具体的客户端连接来进行。 支持的配置singleSession： 如果这个配置项配置为true的话，那么将将不允许一个用户同时绑定到多个session，在绑定用户一次后，后面的绑定将会失败。 配置 session 组件，通过调用如下方式进行: app.set('sessionConfig', opts); connectionconnection 组件是一个功能相对简单的组件，也是仅仅被前端服务器加载,为 connectionService 提供一个组件包装,他主要进行连接信息的统计, connector 组件接收到客户端连接请求以及有客户端离线时，以及用户登录下线等等情况，都会向其汇报。 connection 组件无配置项。 serverserver 组件也是一个功能比较复杂的组件，它被除 master 外的服务器加载。server 组件会加载并维护自身的 Filter 信息和 Handler 信息。server 组件会从 connector 组件的回调里获得到相应的客户端请求或者通知，然后会使用自己的 before filters 对其消息进行过滤，再次调用自己的相应 Handler进行请求的逻辑处理，然后将响应通过回调的方式发给 connector 处理。最后调用after filters 进行一些清理处理。 当然，如果客户请求的服务本来就是前端服务器提供的话，会是上面的那种处理流程。 如果客户请求的服务是后端服务器提供的服务的话，则将不是上面的那种处理流程，此时会出现 sys rpc 调用。 前面那种前端服务器自己处理的情况具体调用为 doHandle ，而发起rpc调用的情况则为 doForward 。 这两种处理流程的不同点是，对于自身的请求，调用自己的filter-handler链进行处理，对于不是前端服务器自己提供的服务，则是发起一个sys rpc，然后将 rpc 调用的结果作为响应，发给 connector 进行处理。关于这个 rpc 调用则是 pomelo 内建的 msgRemote 实现的。 对于后端服务器来说，其客户请求不是直接来源于真实的客户端，而是来源于前端服务器对其发起的sys rpc调用，这个rpc调用的实现就是 pomelo 内建的msgRemote。在msgRemote的实现里，会将来自前端服务器的 sys rpc 调用请求派发给后端服务器的 server 组件，然后后端服务器会启用filter-handler 链对其进行处理，最后通过rpc调用的返回将具体的响应返回给前端服务器。 在前端服务器将客户端请求向后端服务器分派时，由于同类型的后端服务器往往有很多，因此需要一个路由策略 router ，一般情况下用户通过Application.route 调用为后端服务器配置router。 server 组件无配置项。 pushSchedulerpushScheduler 组件也是一个功能较为简单的组件，它仅仅被前端服务器加载，与 connector 组件的关系密切。 当 connector 组件收到 server 组件的对客户端请求的响应后，connector 并不直接将此响应返回给客户端，而是将这个给客户端发送响应的操作调度给 scheduler 组件。 pushScheduler 组件完成最后通过 session 组件拿到具体的客户端连接并将请求的响应发送给客户端的任务。因此，通过pushScheduler 组件可以对发给用户的响应进行缓冲，从而提高通信效率。pomelo 实现了两种调度策略，一种是不进行任何缓冲，直接将响应发送给客户端，一种是进行缓冲，并定时地将已缓冲的响应发送给对应的客户端。 配置项scheduler： scheduler 组件的具体调度策略配置，默认的是直接将响应发给客户端，同时pomelo还提供了有缓冲并且定时刷新的调度策略。用户也可以自定义自己的调度策略。 配置pushScheduler组件，通过调用如下: app.set('pushSchedulerConfig', opts); 如果要启用使用缓冲的scheduler的话，可以在app.js中增加: app.set('pushSchedulerConfig', &#123;scheduler: pomelo.pushSchedulers.buffer, flushInterval: 20&#125;); flushInterval是刷新周期，默认为20毫秒。 channelchannel 组件维护 channel 信息，可以被除了master之外的服务器加载。 channel组件可以看作是channelService的组件包装,加载该组件后，会在app上下文中加入channelService，可以通过app.get(‘channelService’)获取。 可以认为一个channel就是一个用户的集合，每一个用户大致对应于前端服务器中的一个session，用户可以通过channel组件向一个channel里面的所有用户推送消息。当然，由于后端服务器并不与客户端直接相连，故后端服务器会发起一个sys rpc来表示向客户端推送消息，接受这个远程调用的是pomelo已经实现的 ChannelRemote。 channel组件的配置项： broadcastFilter， broadcast的过滤函数。会在执行channel的broadcast的时候，在前端服务器上，在消息发送给每个session之前，进行一个过滤。其函数签名为 broadcastFilter(session, msg, filterParam) 其中filterParam参数由在channelService的broadcast调用时传入，如下: channelService.broadcast(type, route, &#123;filterParam: param&#125;, cb); 可以通过如下方式对Channel组件进行配置： app.set('channelConfig', opts) proxyproxy 组件是一个重量级的组件，它被除 master 外的所有服务器加载。 proxy 组件会扫描具体应用服务器的目录，抽取其中的 remote 部分，由于javascript语言的动态性，可以很轻易地获得到 remote 中的关于远程调用的元信息，生成stub，并将这些调用都挂到app.rpc 下面。 当用户发起rpc调用时，proxy 组件会查看其扫描到的stub信息，以此决定此远程调用是否合法。同时，proxy又会创建一个 RpcClient，当发起远程调用时，负责与远端的remote进行通信，并得到远程调用的结果供调用者使用。当进行远程调用时，由于同类型的远程服务器可能有多个，所以这里同样需要配置相应的router。 配置项proxy的配置项： cacheMsg, 配置cacheMsg为true的话，将开启rpc调用时的对消息的缓冲，而不是直接一旦有rpc请求就发出。 interval, 与配置参数cacheMsg配合使用，设置flush缓存的周期 mailBoxFactory, rpc底层实现需要的，用户可以定义自己的mailBoxFactory,我们将在rpc原理里面详述。 另外，可以开启rpc的调用日志，通过如下的调用: app.enable('rpcDebugLog'); 配置proxy使用： app.set('proxyConfig', opts); remoteremote 组件是与 proxy 组件对等的组件，它用来提供rpc调用服务。rpc 组件完成对当前服务器的 remote 的加载，并开启监听端口，等待rpc客户端的连接及相应的rpc调用。当接收到具体的调用请求时，会根据调用请求中描述的调用请求信息，调用相应的 remote 中的相应方法。然后再将具体的处理结果返回给rpc客户端。rpc服务端还支持对调用请求的filter，也就是说跟server组件处理客户端请求一样，rpc服务端处理具体请求时也会使用filter-remote链进行处理。 remote组件配置项: cacheMsg, 与proxy组件的含义相同 interval， 与proxy组件的含义相同 acceptorFactory, rpc底层实现需要的,可以认为跟proxy配置中的mailBoxFactory是对等的，我们将在rpc原理里面详述。跟proxy组件一样，用户可以开启rpcDebugLog来得到所有的rpc调用过程的日志。 配置remote组件使用： app.set('remoteConfig', opts); dictionarydictionary组件是一个可选组件，不会被默认加载，只有当 connector组件的配置中开启了 useDict 的时候，此组件才会被加载。此组件会遍历所有 handler 的 route 字符串，还会从config/dictionary.json 中读取客户端的route字符串，然后对这些字符串进行编码，给予每一个路由赋予一个唯一的小整数，实现route信息压缩，当客户端与前端服务器通信时需要路由信息时，将不会再使用很长的那个字符串，而仅仅使用一个小整数。 dictionary的配置项: dict, 客户端路由字符串文件的位置，默认使用的是config/dictionary.json 配置dictionary组件使用: app.set('dictionaryConfig', opts); protobufprotobuf组件也是一个可选组件，不会被默认加载，只有当connector组件的配置中开启了useProtobuf的时候，此组件才会被加载。此组件会加载对应的proto文件，并完成消息的基于protobuf的编解码。默认的proto文件的配置信息在config/serverProtos.json和config/clientProtos.json中。具体会在详细介绍pomelo-protobuf中详细介绍。 protobuf组件无配置项。 backendSessionBackendSession组件可以看作是BackendSessionService的组件包装，加载该组件后，会在app的上下文中加入backendSessionService，可以通过app.get(&#39;backendSessionService&#39;)调用获取。可以被除了master之外的服务器加载。它主要为后端服务器提供BackendSession信息，并通过远程过程调用完成一些比如对原始session绑定uid等操作。 backendSession组件无配置项。 服务器管理mastermaster组件仅仅由master服务器加载，它主要的功能包括启动所有的应用服务器、管理和监控所有的应用服务器和接受管理客户端的请求与响应。 在master组件的start方法里，会根据用户提供的服务器配置信息，启动用户配置的所有的具体应用服务器。 当master组件start结束后，他将开启一个socket监听端口，接受应用服务器和监控客户端的连接和注册，收集应用服务器上报的监控信息，给应用服务器推送一些消息，并对管理客户端发出的管理请求给予响应。管理客户端如pomelo-cli可能发出的请求包括查看某个服务器进程状态，增加一个服务器，停掉一个服务器等。以增加一个服务器为例，当管理客户端发出增加服务器请求时，会提供相应的服务器参数，如服务器类型，主机ip，开启的端口等。此时，master组件接受后，会启动相应的服务器，并将新增加的服务器信息广播通知给其他已经启动的服务器。 master组件无配置项。 monitormonitor组件由所有的包括master服务器在内的服务器都会加载，它的主要功能就是与master建立连接进行通信，从而对整个应用服务器群进行管理和监控。master服务器本身也会加载monitor服务器，因为master服务器也会收集其本身自己的监控信息。 可以认为monitor服务器与master服务器是对等组件，monitor会通过master接受一些命令，比如关闭整个服务器等。对于一些周期性监控的信息，pomelo提供了两种收集方式，即pull方式和push方式。pull方式要求master周期地去与monitor通信，拉取相应的监控信息；push方式，则是由monitor周期地主动地向master报告其监控信息。 monitor组件无配置项。","categories":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://gowa2017.github.io/categories/JavaScript/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://gowa2017.github.io/tags/JavaScript/"},{"name":"Pomelo","slug":"Pomelo","permalink":"https://gowa2017.github.io/tags/Pomelo/"}],"keywords":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://gowa2017.github.io/categories/JavaScript/"}]},{"title":"偶尔遇到MySQL几个BUG似的地方","slug":"偶尔遇到MySQL几个BUG似的地方","date":"2018-12-26T08:08:25.000Z","updated":"2018-12-26T08:08:25.000Z","comments":true,"path":"MySQL/偶尔遇到MySQL几个BUG似的地方.html","link":"","permalink":"https://gowa2017.github.io/MySQL/偶尔遇到MySQL几个BUG似的地方.html","excerpt":"今天在删除和查询数据的时候，发现了几个以前没有注意的地方。我有一列值，里面有 NULL，有字符值。然后我用 != 字符这样的情况去居然过滤不出来。","text":"今天在删除和查询数据的时候，发现了几个以前没有注意的地方。我有一列值，里面有 NULL，有字符值。然后我用 != 字符这样的情况去居然过滤不出来。 字符比较CREATE TABLE a(a INT AUTO_INCREMENT, b CHAR(20) DEFAULT NULL, PRIMARY KEY (`a`));INSERT INTO a(`b`) VALUES ('and'),('or'),('but'),(NULL);select * from a where b != 'and'; NULL 值的行居然没有出来，这是为什么？ 官方文档说明：NULL意味着 一个不存在的，未知的值，所以和其他值有所不同。 需要用 IS NULL 或者 IS NOT NULL 来测试 。任何数学上的比较都没有效比如： mysql&gt; SELECT 1 = NULL, 1 &lt;&gt; NULL, 1 &lt; NULL, 1 &gt; NULL;+----------+-----------+----------+----------+| 1 = NULL | 1 &lt;&gt; NULL | 1 &lt; NULL | 1 &gt; NULL |+----------+-----------+----------+----------+| NULL | NULL | NULL | NULL |+----------+-----------+----------+----------+ 其返回值，都是NULL。 0 和 NULL 意味着 false，其他值都表示 true。对一个布尔操作默认 trueth 值是 1。 应该说，字符比较也返回 NULL。 mysql&gt; SELECT '1' = NULL, 1 &lt;&gt; NULL, 1 &lt; NULL, 1 &gt; NULL;+----------+-----------+----------+----------+| 1 = NULL | 1 &lt;&gt; NULL | 1 &lt; NULL | 1 &gt; NULL |+----------+-----------+----------+----------+| NULL | NULL | NULL | NULL |+----------+-----------+----------+----------+ 多表删除另外一个问题是我用类似 delete a from t1 a, t2 b where a.id = b.id; 这个语句会报错，表示找不到 表 a 。 这就是一个问题： 在多表删除中，我们删除表只能使用 别名， 而不能用我们引用的表的名称。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://gowa2017.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://gowa2017.github.io/tags/MySQL/"}],"keywords":[{"name":"MySQL","slug":"MySQL","permalink":"https://gowa2017.github.io/categories/MySQL/"}]},{"title":"Cocos Creator接入支付实现","slug":"Cocos Creator接入支付实现","date":"2018-12-22T13:25:18.000Z","updated":"2018-12-22T13:25:18.000Z","comments":true,"path":"Cocos-Creator/Cocos Creator接入支付实现.html","link":"","permalink":"https://gowa2017.github.io/Cocos-Creator/Cocos Creator接入支付实现.html","excerpt":"","text":"最近搞了个小游戏，需要接入第三方支付。本来在 H5 上是可以用 uri 直接拉起 app 的，但是原生的不行，所以需要手动在代码内接入一下。 思考根据一般支付的流程，不外乎在下单后从服务器拿到一个支付相关的 ID， 把这个 ID 传递给手机上的支付 APP，其在支付成功后回调我们定义的函数就OK了。 但这有几个问题，Cocos Creator 是使用 JS 开发的，其可以通过反射的形式调用原生 JAVA 的代码 JAVA 原生反射机制。理想的情况是，支付成功后， APP 调用我们的原生代码，原生代码再调用 我们定义的 JS 函数，来进行通知。 但我仔细思考了一下就会有个很明显的问题，如果在支付场景，出现意外情况，比如说断线，进行了操作后重至一个新场景的话，比如我们要拉起通知框会不会拉不起来？ 最终我选择了一个比较简单的方法。 JS -&gt; 原生代码 -&gt; 支付APP -&gt; 原生代码改变支付状态 -&gt; JS 轮询获取结果。 原生代码设计我们设计一个给 JS 调用的方法，设计一个是否完成支付的代码，及最终支付结果状态的代码。 private static int payResult; // 表示支付结果，0 失败， 1成功 private static boolean isPay; // 表示是否开始支付 // 给JS调用已知道是否支付成功 public static boolean isPaySuccess()&#123; Log.d(TAG, \"isPaySuccess: \" + isPay); return isPay; &#125;// JS 调用查看是否完成支付 public static int getPayResult()&#123; Log.d(TAG, \"getPayResult: \" + payResult); return payResult; &#125; // 给JS调用，拉起支付APP public static void doMolPay(String uri)&#123; payResult = 0; isPay = false; PayParamsV0 paramsV0 = PayParamsV0.builder() .uri(uri) .build(); Log.d(TAG, \"doMolPay: \" + paramsV0.toString()); MolPay.builder() .setParams(paramsV0) .setContext(getContext()) .setOnPayListener(new OnPayListener() &#123; @Override public void onStart() &#123; Log.d(TAG, \"onStart: \"); &#125; @Override public void onSuccess() &#123; payResult = 1; Log.d(TAG, \"onSuccess: \"); &#125; @Override public void onError(int i) &#123; payResult = 0; Log.d(TAG, \"onError: \" + i); &#125; @Override public void onComplete() &#123; Log.d(TAG, \"onComplete: \"); isPay = true; &#125; &#125;) .start(); &#125; &#125; 上面的代码逻辑很简单，支付成功 设置 isPay = 1， 支付错误 设置 isPay = 0， 完成的话，表示 isPay 支付逻辑完成。 JS 内的代码实现：var s = this;// 开始调用原生代码支付jsb.reflection.callStaticMethod(\"org/cocos2dx/javascript/AppActivity\", \"doMolPay\", \"(Ljava/lang/String;)V\", uri);// 开始定时任务，0.5秒查询一下是否支付完成s.schedule(function()&#123; var isPay = jsb.reflection.callStaticMethod(\"org/cocos2dx/javascript/AppActivity\", \"isPaySuccess\",\"()Z\"); // 支付完成获取结果 if(isPay)&#123; s.unscheduleAllCallbacks(); var payResult = jsb.reflection.callStaticMethod(\"org/cocos2dx/javascript/AppActivity\",\"getPayResult\",\"()I\"); if (payResult === 1)&#123; // 这些代码自定义的一些代码，来显示提示框 s.com_MessageBox.active = !0, s.bg_Black.active = !0, s.com_MessageBox.getChildByName(\"lb_Tips\").getComponent(\"cc.Label\").string = \"支付成功\" s.netWork.socket.emit(\"getCoin\"); &#125; else &#123; s.com_MessageBox.active = !0, s.bg_Black.active = !0, s.com_MessageBox.getChildByName(\"lb_Tips\").getComponent(\"cc.Label\").string = \"支付失败\" &#125; &#125;&#125;,0.5)","categories":[{"name":"Cocos Creator","slug":"Cocos-Creator","permalink":"https://gowa2017.github.io/categories/Cocos-Creator/"}],"tags":[{"name":"Cocos Creator","slug":"Cocos-Creator","permalink":"https://gowa2017.github.io/tags/Cocos-Creator/"}],"keywords":[{"name":"Cocos Creator","slug":"Cocos-Creator","permalink":"https://gowa2017.github.io/categories/Cocos-Creator/"}]},{"title":"MySQL主从复制会出现的问题","slug":"MySQL主从复制会出现的问题","date":"2018-12-17T02:30:20.000Z","updated":"2018-12-17T02:30:20.000Z","comments":true,"path":"MySQL/MySQL主从复制会出现的问题.html","link":"","permalink":"https://gowa2017.github.io/MySQL/MySQL主从复制会出现的问题.html","excerpt":"公司本来业务量不大，但是为了备份，或者是因为很多视图上的查询有很多锁的问题，导致很多时候连登录都登录不上，就准备做一下读写分里，通过主从复制来实现。","text":"公司本来业务量不大，但是为了备份，或者是因为很多视图上的查询有很多锁的问题，导致很多时候连登录都登录不上，就准备做一下读写分里，通过主从复制来实现。 行与语句基于行的复制会复制变更的每一行，但是如果在类似与 update … set date=now() 这样的语句就会很坑爹。 基于语句的复制，会被执行更新操作的语句进行重放。但是有时候这个重放的顺序可能不一致，同样，，update … set date = now() 这样的情况下，有可能主从服务器时间不一致呢？ 所以呢默认的情况下，MySQL 自己使用了一种 mixed 的方式来混合，一种出现问题的时候就使用另外一种来进行。 配置配置 主从复制是非常简单的。原理就是，主机把变更事件写入二进制日志，从机获取日志，然后重放日志。 直接贴配置了。懒得讲了： Master[mysqld]datadir=/data/mysql/datasocket=/data/mysql/mysql.sockcharacter_set_server=utf8mb4lower_case_table_names = 1max_connections=2000group_concat_max_len = 5120log-bin = mysql_bin_logserver-id = 1innodb_flush_log_at_trx_commit=1 # 事务日志的同步设置。为0，每秒写入日志并同步到磁盘； 1 默认值，事务提交刷新到磁盘；为2时，事务提交就写到日志，但刷新到磁盘每秒一次。sync_binlog=1 # 当事务提交时，由 MySQL刷新到 bin_log 设置为0，由 内核来执行。为 N(N&gt;1)时，有 N个提交后进行刷新。slow_query_log = 1long_query_time = 3slow_query_log_file=/data/mysql/log/slow_query.logmax_allowed_packet=20Mexpire_logs_days=15sql_mode = strict_trans_tables,no_zero_in_date,no_zero_date,error_for_division_by_zero,no_auto_create_user,no_engine_substitutionevent_scheduler = ONsymbolic-links=0log-error=/var/log/mysqld.logpid-file=/var/run/mysqld/mysqld.pid[client]default-character-set=utf8mb4socket=/data/mysql/mysql.sock[mysql]default-character-set=utf8mb4socket=/data/mysql/mysql.sock Slave多加几句就行： server-id = 2 # 此参数一定不能和主配置文件中的相同skip-slave-start=true # 手动启动同步线程read_only=ON #开启的只读模式relay-log=relay-bin #中继日志命名relay-log-index=relay-bin.index 中继日志索引文件# 我们不只同步我们关注的业务库。replicate_wild_ignore_table =sys.%replicate_wild_ignore_table =mysql.%replicate_wild_ignore_table =performance_schema.%replicate_wild_ignore_table =information_schema.%","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://gowa2017.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://gowa2017.github.io/tags/MySQL/"}],"keywords":[{"name":"MySQL","slug":"MySQL","permalink":"https://gowa2017.github.io/categories/MySQL/"}]},{"title":"JavaScript的原型继承与原型链","slug":"JavaScript的原型","date":"2018-12-15T07:33:45.000Z","updated":"2018-12-15T07:33:45.000Z","comments":true,"path":"JavaScript/JavaScript的原型.html","link":"","permalink":"https://gowa2017.github.io/JavaScript/JavaScript的原型.html","excerpt":"Prototyes，原型，是 JavaScript 中一个对象从另外一个对象继承特性的方法。本文中来解释 原型链是怎么样工作的，还介绍一下怎么样对已存的构造器通过原型属性来添加方法。ES2015 添加了一个 class 关键词，但其实也是使用的基于原型来实现的类机制。","text":"Prototyes，原型，是 JavaScript 中一个对象从另外一个对象继承特性的方法。本文中来解释 原型链是怎么样工作的，还介绍一下怎么样对已存的构造器通过原型属性来添加方法。ES2015 添加了一个 class 关键词，但其实也是使用的基于原型来实现的类机制。 基于原型的语言？JavaScript 经常被描述为基于原型的语言 ————为了提供继承，对象可以有一个 原型对象，可以从这个原型对象继承方法和属性。原型对象也可能拥有一个原型对象。就可以被称做一个原型链了，这就解释了为什么某个对象可以拥有在其他对象内定义的属性和方法。几乎所有对象都是 Object 的一个实例。 更准确一点，一个对象的属性和方法是在对象的构造方法上的prototype属性定义的，而不是在对象实例自身。 在 JavaScript 中，在对象实例和其原型（proto属性，此属性从构造器的 prototype 属性衍生）间有一个链接，那么通过遍历对象的原型链就能获取所有的属性和方法了。 注意：要理解在对象的原型（通过 Object.getPrototypeOf(obj)获取，或通过已经过时的 proto属性）和构造函数的 prototype 属性的区别。proto 是每个实例的属性，后面一个是构造器的属性。这也就是说：Object.getPrototypeOf(new Foobar()) 和 Foobar.prototype 引用同样一个对象。 理解原型对象定义一个构造函数： function Person(first, last, age, gender, interests) &#123; this.name = &#123; 'first': first, 'last' : last &#125;; this.age = age; this.gender = gender; this.interests = interests; this.bio = function() &#123; // First define a string, and make it equal to the part of // the bio that we know will always be the same. var string = this.name.first + ' ' + this.name.last + ' is ' + this.age + ' years old. '; // define a variable that will contain the pronoun part of // the second sentence var pronoun; // check what the value of gender is, and set pronoun // to an appropriate value in each case if(this.gender === 'male' || this.gender === 'Male' || this.gender === 'm' || this.gender === 'M') &#123; pronoun = 'He likes '; &#125; else if(this.gender === 'female' || this.gender === 'Female' || this.gender === 'f' || this.gender === 'F') &#123; pronoun = 'She likes '; &#125; else &#123; pronoun = 'They like '; &#125; // add the pronoun string on to the end of the main string string += pronoun; // use another conditional to structure the last part of the // second sentence depending on whether the number of interests // is 1, 2, or 3 if(this.interests.length === 1) &#123; string += this.interests[0] + '.'; &#125; else if(this.interests.length === 2) &#123; string += this.interests[0] + ' and ' + this.interests[1] + '.'; &#125; else &#123; // if there are more than 2 interests, we loop through them // all, adding each one to the main string followed by a comma, // except for the last one, which needs an and &amp; a full stop for(var i = 0; i &lt; this.interests.length; i++) &#123; if(i === this.interests.length - 1) &#123; string += 'and ' + this.interests[i] + '.'; &#125; else &#123; string += this.interests[i] + ', '; &#125; &#125; &#125; // finally, with the string built, we alert() it alert(string); &#125;; this.greeting = function() &#123; alert('Hi! I\\'m ' + this.name.first + '.'); &#125;;&#125;; 用此构造函数构造实例： var person1 = new Person('Bob', 'Smith', 32, 'male', ['music', 'skiing']); 在我们的 Chrome ，打开 Developer Tools ，进入 console 。执行上面的代码后，前敲入 ： person1。你会看到如下结果： 但如果我们输入 person1. 的话，我们会看到更多的提示内容： 这提示了更多的属性和方法。比如 watch, valueOf 等。这些不是由 Person() 定义的，而是由 Object 对象定义的。 当我们调用类似 person1.valueOf 的时候发生了什么：？ JS 引擎会检查 person1 及其构造函数 Person() 是否有这么一个 valueOf() 方法。 如果都没有，检查 Person() 构造函数的原型对象（这里是 Object ，且有一个 valueOf 方法），然后进行执行。 在这里，方法和属性不会从一个对象复制到另外一个，而只是通过原型链来访问。 没有一个官方的，用来直接访问对象原型对象方式。根据 ECMAScript 的规范，我们把他叫做 [[prototype]]。现代浏览器很多都有一个 proto 参数来包含构造器的原型对象。自 ECMA2015 可以通过 Object.getPrototypeOf(obj) 来获取原型。 prototype :定义继承属性的地方Object 对象有很多的属性和方法，但是我们的 person1 继承来的不多，这是为什么？ 上面提到，我们继承的属性，是原型对象定义在 prototype 属性内的。也就是说以 Object.prototype 开头，而不是 Object. 开头的属性。 prototype 属性的值是一个对象，用来存放我们希望可以被其他对象继承的属性和方法。 这听起来可能有点奇怪，怎么样在一个构造器内定义函数？事实上，函数也是一个对象，不相信的话可以查看 Function() 我们可以检查我们现在对象的 prototype 属性来看看。 Person.prototype&#123;constructor: ƒ&#125;constructor: ƒ Person(first, last, age, gender, interests)__proto__: Object Object.prototype&#123;constructor: ƒ, __defineGetter__: ƒ, __defineSetter__: ƒ, hasOwnProperty: ƒ, __lookupGetter__: ƒ, …&#125;constructor: ƒ Object()hasOwnProperty: ƒ hasOwnProperty()isPrototypeOf: ƒ isPrototypeOf()propertyIsEnumerable: ƒ propertyIsEnumerable()toLocaleString: ƒ toLocaleString()toString: ƒ toString()valueOf: ƒ valueOf()__defineGetter__: ƒ __defineGetter__()__defineSetter__: ƒ __defineSetter__()__lookupGetter__: ƒ __lookupGetter__()__lookupSetter__: ƒ __lookupSetter__()get __proto__: ƒ __proto__()set __proto__: ƒ __proto__() 我们会发现一个问题，就是对于构造器函数 Person()，其 prototype 属性包含一个属性:constructor，其值就是构造函数本身。所以定义在构造函数内的所有属性，都能被构造出来的对象继承。 回顾 create()我们通过另外一种方式来实例化对象： var person2 = Object.create(person1); create() 做的事情就是从一个原型对象建立一个新对象。在这里，person2 使用 person1 作为原型对象。我们可以证明，确实是这样： person2.__proto__Person &#123;name: &#123;…&#125;, age: 32, gender: \"male\", interests: Array(2), bio: ƒ, …&#125;age: 32bio: ƒ ()gender: \"male\"greeting: ƒ ()interests: (2) [\"music\", \"skiing\"]name: &#123;first: \"Bob\", last: \"Smith\"&#125;__proto__: Object 这似乎和 person1.proto 有所不同： person1.__proto__&#123;constructor: ƒ&#125;constructor: ƒ Person(first, last, age, gender, interests)__proto__: Object 但其实也表明了， person1 是通过 构造器函数建立的，而 person2 是通过对象建立的。 constructor 属性每个实例对象都从原型中继承了一个constructor属性，该属性指向了用于构造此实例对象的构造函数。 person1.constructorperson2.constructor 返回的都是 Person() 构造器。可以在 constructor 末尾添加 () 来调用构造器，构造一个新的实例。 var person3 = new person1.constructor('Karen', 'Stephenson', 26, 'female', ['playing drums', 'mountain climbing']);person3 正常工作。通常你不会去用这种方法创建新的实例；但如果你刚好因为某些原因没有原始构造器的引用，那么这种方法就很有用了。 此外，constructor 属性还有其他用途。比如，想要获得某个对象实例的构造器的名字，可以这么用： person1.constructor.name 修改原型 prototype我们为上面的构造器函数 Person() 添加一个新的方法： Person.prototype.farewell = function() &#123; alert(this.name.first + ' has left the building. Bye for now!');&#125; 接着我们调用这个方法看一下： person1.farewell(); 事实上，一种极其常见的对象定义模式是，在构造器（函数体）中定义属性、在 prototype 属性上定义方法。如此，构造器只包含属性定义，而方法则分装在不同的代码块，代码更具可读性。例如： // 构造器及其属性定义function Test(a,b,c,d) &#123; // 属性定义&#125;;// 定义第一个方法Test.prototype.x = function () &#123; ... &#125;// 定义第二个方法Test.prototype.y = function () &#123; ... &#125;// 等等……","categories":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://gowa2017.github.io/categories/JavaScript/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://gowa2017.github.io/tags/JavaScript/"}],"keywords":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://gowa2017.github.io/categories/JavaScript/"}]},{"title":"Nodes.js中的事件调度","slug":"Nodes.js中的事件调度","date":"2018-12-14T12:45:02.000Z","updated":"2018-12-14T12:45:02.000Z","comments":true,"path":"JavaScript/Nodes.js中的事件调度.html","link":"","permalink":"https://gowa2017.github.io/JavaScript/Nodes.js中的事件调度.html","excerpt":"Node.js 正是因为其 Event Loop 事件调度器的设计让其拥有了进行非阻塞操作的能力————尽管 JavaScript 是单线程的———— 这通过在可能的时候，从内核处把任务卸载下来达到。","text":"Node.js 正是因为其 Event Loop 事件调度器的设计让其拥有了进行非阻塞操作的能力————尽管 JavaScript 是单线程的———— 这通过在可能的时候，从内核处把任务卸载下来达到。 事件调度解释当 Node.js 启动时，会初始化 Event Loop，处理输入的脚本文件。我们在脚本中我们可能会做 异步的 API 调用，定时器调度，或者调用 process.nextTick()，然后再开始处理 Event Loop。 下面就是 Event Loop 的运行处理流程： 在上面的图中，每个方框内的，Node.js 官方文档把它叫做 Phase，我把它叫做环节这样理解。 每个环节都有一个 FIFO 的回调函数队列需要执行。通常，每个环节都有其特别的地方，所以当 Event Loop 每进入一个环节的时候，都会进行本环节特定的操作，然后执行环节内的回调队列，直到：队列清空或已达到最大可执行数量。当队列为空或者达到执行数量限制就会进入下一环节。 因为任何一个操作都可能调度更多的操作，且在 POLL 环节处理的新事件是由内核排队的，poll事件可以在正在处理 poll 事件的时候 的时候就排队。由此，长时间运行的回调允许 Poll 环境运行的时间比 timer 环节更长。 环节概览 timer 执行由 setTimeOut() 和 setInterval() 调度的回调。 pending callbacks: 执行上一循环未执行完的I/O回调。 idle, prepare 内部使用 poll 获取新的 I/O 事件；执行 I/O 相关的回调（除了 closed 回调，这个回调是由 timers 和 setImmediate() 调度的）；node 可能会在这个环节阻塞。 check: setImmediate() 回调被调用。 close callbacks：一些关闭回调。比如 socket.on(&#39;close&#39;, ...)。 在每个事件循环间，Node.js 会检查是否需要等待异步I/O 或者定事器，如果没有的话，就会干净的关闭。 细节timers定时器。此个环节的回调会尽可能快的执行。然而，因为系统调度的问题，有可能会慢于我们指定的时间。 技术上来说，Poll 环节控制了合适执行定时器回调。 举例说明，我们希望调度一个 100ms 后的任务，然后我们的脚本却开始异步读一个文件，花了 95 ms。 const fs = require('fs');function someAsyncOperation(callback) &#123; // Assume this takes 95ms to complete fs.readFile('/path/to/file', callback);&#125;const timeoutScheduled = Date.now();setTimeout(() =&gt; &#123; const delay = Date.now() - timeoutScheduled; console.log(`$&#123;delay&#125;ms have passed since I was scheduled`);&#125;, 100);// do someAsyncOperation which takes 95 ms to completesomeAsyncOperation(() =&gt; &#123; const startCallback = Date.now(); // do something that will take 10ms... while (Date.now() - startCallback &lt; 10) &#123; // do nothing &#125;&#125;); 当事件循环进入 poll 环节，其队列是空的 (fs.readFile并没有完成），所以会一直等待，直到某个定时器到期。然而，在等待了 95ms 后，fs.readFile 完成了，其回调函数被添加到了 poll 环节的回调队列内，这个回调函数会执行 10ms。当回调结束后，队列为空，因为定时器已经到期咯，所以会立马执行定事器的回调。在这个例子中，可以看到事实上定时器花了 105ms 才执行。 pending callbacks这个环节会执行某些操作系统的回调，比如说 tcp 的错误。当一个 tcp 套接字收到一个 ECONNREFUSED 错误的时候，某些 *nix 系统会报告这个错误。这些些回调就放在这个环节的队列中。 poll此环节有两个主要的功能： 计算其会阻塞多久，然后 poll I/O。 处理队列中的回调。 当 循环进入这个环节，其没有定时器调度的话，会有下面这一的事件发生： 如果 poll 回调队列不为空。那么就会遍历回调队列，同步执行，直到队列执行完，或者到达系统的硬限制。 如果 poll 回调队列为空。就会发生更多的事情了：如果有 setImmediate() 调度，那么就结束 poll 环节，进入 check 环节。如果没有 setImmediate() 调度， 一旦 poll 的队列为空，那么事件循环就会检查有没有定时器到期，如果有的话，那么就立马开始执行相应的回调。 check这个环节允许我们在 poll 环节完成后立马执行回调。如果 poll 环节完成，同时有回调被 setImmediate() 调度，那么这些回调会立马执行。 setImmediate() 是一个特殊的定时器，其在事件循环的单独环节内运行。它使用了一个libuv的API来调度回调在 Poll 环节后立刻执行。 通常，当代码被执行，事件循环会经常性的遇到 poll 环节等待一个进入连接，请求等等的情况。然而，如果有回调被 setImmediate() 调度，poll 变得 idle，那么就会结束 poll，进入这么一个环节。 close callback如果一个 socket 或者 handle 突然关闭， close 事件就会在此环节产生。否则的话，就会调用 process.nextTick()。 setImmediate() VS setTimeout()这两个函数很类似，但是因为在何时调用而显得行为不同。 setImmediate() 是为了能在 poll 环节完成后立刻执行 setTimeOut() 是为了在一个指定的 ms 后执行。 这两个函数的执行顺序会因为其被调用的上下文而不同。如果两者都是在 main 模块内调用，那么这个由进程的性能决定。 例如，如果我们在一 I/O 循环外调度这两个函数，这两个函数执行的顺序是不定的，因为这由进程的性能决定。 // timeout_vs_immediate.jssetTimeout(() =&gt; &#123; console.log('timeout');&#125;, 0);setImmediate(() =&gt; &#123; console.log('immediate');&#125;); $ node timeout_vs_immediate.jstimeoutimmediate$ node timeout_vs_immediate.jsimmediatetimeout 然而，如果我们在一个 I/O 周期内调度这两个函数，那么 setImmediate() 总是会先执行： // timeout_vs_immediate.jsconst fs = require('fs');fs.readFile(__filename, () =&gt; &#123; setTimeout(() =&gt; &#123; console.log('timeout'); &#125;, 0); setImmediate(() =&gt; &#123; console.log('immediate'); &#125;);&#125;); $ node timeout_vs_immediate.jsimmediatetimeout$ node timeout_vs_immediate.jsimmediatetimeout 使用 setImmediate() 的优势是：如果是在 I/O 周期内，那么它永远会比 setTimeOut() 调度的回调先执行。 process.nextTick()在前面的图表中我们并没有出现 process.netTick()，即使其是异步API的一部分。这是因为，技术上来说，process.nextTick() 并不是事件循环的一部分。相反，当前操作完成后，nextTickQueue 将会被处理，而不管当前处于事件循环的哪个环节。 回去看我们的图表，每当我们在任何一个环节调用 process.nextTick() 的时候，所有传递给 process.nextTick() 的回调都会在事件循环继续前优先解决。 这可能会产生一些比较坏的情况，因为我们可以通过递归调用 process.nextTick() 来饿死我们的 I/O ，这样事件循环永远到不了 poll 环节。 为什么会允许这样？这就是设计上的统一了：一个API即使不需要是异步的也要设计成异步。例如： function apiCall(arg, callback) &#123; if (typeof arg !== 'string') return process.nextTick(callback, new TypeError('argument should be string')); &#125; 上面的代码做一个参数检查，如果不对，把错误传递给回调。最近更新的API允许将参数传递给process.nextTick（），允许它将回调后传递的任何参数作为参数传播到回调，因此您不必嵌套函数。 我们做的事情是：将一个错误返回给用户，但这只是在我们允许后面的代码被执行的情况下。通过使用 process.nextTick()，我们保证 apiCall 总是在后续的用户代码后，事件循环继续前执行。为了达到这个目的，JS 的回调栈允许回绕，且立刻执行提供的回调函数，此回调允许用户递归调用 process.nextTick() 而不会达到一个 RangeError: Maximum call stack size exceeded from v8 的错误。 这个设计可能会有一些潜在的问题出现。例如： let bar;// this has an asynchronous signature, but calls callback synchronouslyfunction someAsyncApiCall(callback) &#123; callback(); &#125;// the callback is called before `someAsyncApiCall` completes.someAsyncApiCall(() =&gt; &#123; // since someAsyncApiCall has completed, bar hasn't been assigned any value console.log('bar', bar); // undefined&#125;);bar = 1; 用户定义 someAsyncApiCall() 有一个异步签名，但实际上却是同步的。当其被调用时，回调函数会立刻执行。在回调中，其试图访问 bar 变量，但此时其作用域内并没有这个，因为还没有运行到后面的代码。 现在我们把这个回调放在 process.nextTick()内，那么脚本现在有了执行到最后的能力。但其也有不允许事件循环继续的能力。 let bar;function someAsyncApiCall(callback) &#123; process.nextTick(callback);&#125;someAsyncApiCall(() =&gt; &#123; console.log('bar', bar); // 1&#125;);bar = 1; 这是现实世界的一个例子： const server = net.createServer(() =&gt; &#123;&#125;).listen(8080);server.on('listening', () =&gt; &#123;&#125;); process.nextTick() vs setImmediate()我们现在有了两个相似的调用，但他们的名字有点迷惑： process.nextTick() 会在当前环节立刻执行 setImmediate() 在事件循环的下一环节。 事实上，这两个名称应该反过来才对。process.nextTick() 更迫切的需要执行，不过这是历史因素了。 推荐使用 setImmediate() ，这更易理解和更兼容。 为什么使用 process.netTick()？两个原因： 允许用户处理错误，清理不需要资源，或者在事件循环继续前重新请求。 在回调栈解绑后，事件循环继续前有必要允许一个回调执行的时候。 const server = net.createServer();server.on('connection', (conn) =&gt; &#123; &#125;);server.listen(8080);server.on('listening', () =&gt; &#123; &#125;); listen() 在事件循环的开始执行，但是 listening 的回调被放在了 setImmediate()。如果不传递一个域名，那么绑定到端口会立刻执行。对于事件循环来说，其必须马上到达 poll 环节，因为有可能在 listenting 事件前已经有连接进来了。","categories":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://gowa2017.github.io/categories/JavaScript/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://gowa2017.github.io/tags/JavaScript/"},{"name":"Node","slug":"Node","permalink":"https://gowa2017.github.io/tags/Node/"}],"keywords":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://gowa2017.github.io/categories/JavaScript/"}]},{"title":"Promise的使用及API","slug":"Promise的使用及API","date":"2018-12-11T16:52:05.000Z","updated":"2018-12-11T16:52:05.000Z","comments":true,"path":"JavaScript/Promise的使用及API.html","link":"","permalink":"https://gowa2017.github.io/JavaScript/Promise的使用及API.html","excerpt":"完全是闲的，工作暂时用不到，但是看书偶尔看到了，不了解一下心里就根猫抓的一样。 Promise 对象，代表的是一个异步操作的最终完成（或失败）及其返回值。原文地址","text":"完全是闲的，工作暂时用不到，但是看书偶尔看到了，不了解一下心里就根猫抓的一样。 Promise 对象，代表的是一个异步操作的最终完成（或失败）及其返回值。原文地址 例子开篇就是一个例子： var promise1 = new Promise(function(resolve, reject) &#123; setTimeout(function() &#123; resolve('foo'); &#125;, 300);&#125;);promise1.then(function(value) &#123; console.log(value); // expected output: \"foo\"&#125;);console.log(promise1);// expected output: [object Promise] 执行脚本的输出是： &gt; [object Promise]&gt; \"foo\" 语法new Promise( /* executor */ function(resolve, reject) &#123; ... &#125; ); 参数：executor。 一个以 resolve, reject 为参数的函数，我们就叫它 executor 函数吧。executor 函数会被 Promise 的实现立即执行（这个函数会在 Promise 构造器返回创建好的对象前执行），参数 resolve, reject 都是函数哦。调用 resolve, reject 分别表示 解决或拒绝了此次 Promise。executor 函数通常会执行一些异步操作，一旦完成成，就会调用 resolve 来解决或在有错误时调用reject 来拒绝。如果 executor 抛出一个错误，那么本次 Promise 被拒绝，返回值被忽略。 描述Promise 是一个值的代理，但在这个 promise 创建的时候并不需要知道。这允许我们把异步操作的最终完成或失败与事件处理器相关联。这让异步方法像同步方法一样返回值：asynchronous 方法能立即返回一个将来可能用到的 promise，而不是立即返回最终值。 一个 Promise 有几种状态： pending 初始状态 fulfilled 操作已成功 rejected 操作失败 pending 状态的 Promise 可以用一个值来 fulfilled ，或用一个原因（错误）来 rejected。当前面两个操作中的任意一个发生时，通过 promise 的 then() 函数排队的相关事件处理器就会被调用。（如果在事件处理器排队的时候 Promise 已经 fulfieed 或 rejected，此处理器会被立即调用。所以在异步操作完成与设置处理器间没有竞争条件） Promise.prototype.then()，Promise.prototype.catch() 都返回的是 promise，所以可以链式调用。 fulfilled, rejected 状态的 Promise 都可以被叫做 settled。 属性 Promise.length 总是为 1。 代表构造器参数。 Promise.prototype Promise构造器的原型。 方法 Promise.all(iterable) 在所有的 iterable 参数中的所有 promises 都满足的情况下返回一个 fulfilled 的 promise，或者，一旦 iterable 中有一个 Promise 出现错误就返回一个 rejected 的 promise。也就是说，如果返回的 Promise 是 fulfilled 的，那么返回值是一个数组，其中的是值于 iterable 中的 promise。如果返回的是 rejected的，那么就是第一个被拒绝的 promise。这个类似于多个文件描述符的 select/epoll 这样。 Promise.race(iterable) iterable中有有一个 Promise 完成（fulfill or rejectd），就返回。 Promise.reject(reason) 返回一个被给定的 reason 拒绝的 Promise。 Promise.resolve(value) 返回一个被给的值 resolve 的Promise。如果这个值是 可then 的（也就是有一个 then()方法），返回的 Promise 就会执行 then()方法，获取最终状态；不然的话就用 value 来 fulfill 返回的 Promise。通常，如果您不知道某个值是否为promise，则Promise.resolve（value）代替它并将返回值作为promise。 原型属性Promise.prototype.constructor 返回创建了一个 Promise 实例的原型。默认情况下就是 Promise() 函数。 方法 Promise.prototype.catch(onRejected) 给 Promise 一个拒绝回调函数。只处理 reject 的情况。其行为和调用 Promise.prototype.then(undefined, onRejected)相似，（实际上，调用 Obj.catch(onRejected)内部调用的是 obj.(undefined, onRejected)。这意味着，即使是你想得到一个 undefined 值的情况下，你也要提供这个 onRejected函数。 Promise.prototype.then(onFulfilled, onRejected) 两种情况下的回调函数。 Promise.prototype.finally(onFinally) 这个函数会 settled 的时候被调用。无论是 fulfilled 或 rejected。","categories":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://gowa2017.github.io/categories/JavaScript/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://gowa2017.github.io/tags/JavaScript/"},{"name":"Promise","slug":"Promise","permalink":"https://gowa2017.github.io/tags/Promise/"}],"keywords":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://gowa2017.github.io/categories/JavaScript/"}]},{"title":"将当前的git版本库内容提交到svn","slug":"将当前的git版本库内容提交到svn","date":"2018-12-11T06:35:17.000Z","updated":"2018-12-11T06:35:17.000Z","comments":true,"path":"Git/将当前的git版本库内容提交到svn.html","link":"","permalink":"https://gowa2017.github.io/Git/将当前的git版本库内容提交到svn.html","excerpt":"由于自己本地一直都使用的是 git ，很多凌乱的脚本准备归一下类，方便维护。所以就建立了一个 svn 版本库来存储。但我不想简单的只是把内容提交上去，还要保留我本地的 git 历史记录，所以要进行手动处理一下。参考地址","text":"由于自己本地一直都使用的是 git ，很多凌乱的脚本准备归一下类，方便维护。所以就建立了一个 svn 版本库来存储。但我不想简单的只是把内容提交上去，还要保留我本地的 git 历史记录，所以要进行手动处理一下。参考地址 手动指定 svn 库地址在配置文件内添加： vim .git/config[svn-remote \"svn\"] url = http://svn.example.com/foo/trunk fetch = :refs/remotes/git-svn 我们可以用 git config --local -l 来验证一下我们的配置： git config --local -l`svn-remote.svn.url=svn://guan.isum.cn/smart/shellssvn-remote.svn.fetch=:refs/remotes/git-svn 这里，请不要被 “svn” 这个所误导，只是我们指定的一个远程版本仓库的名称而已，你可以叫任何其他的名字。 这个配置也就是指定了一个远程 svn 版本库的意思。 拉取远程分支git svn fetch svn 将 svn 版本库获取之后，我们可以将内容检出到本地来。 git co -b svn git-svn 将原程分支 git-svn 给检出到本地了。 分支合并这个时候，我们就可以用 merge 命令将我们本地 git 分支上的内容合并过来了。 git merge master --allow-unrelated-histories 推送到 svn 远程库： git svn dcommit 回到主分支git co mastergit rebase svngit branch -d svn","categories":[{"name":"Git","slug":"Git","permalink":"https://gowa2017.github.io/categories/Git/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://gowa2017.github.io/tags/Git/"},{"name":"SVN","slug":"SVN","permalink":"https://gowa2017.github.io/tags/SVN/"}],"keywords":[{"name":"Git","slug":"Git","permalink":"https://gowa2017.github.io/categories/Git/"}]},{"title":"利用NFS及LVM进行存储动态扩容","slug":"利用NFS及LVM进行存储动态扩容","date":"2018-12-10T05:42:05.000Z","updated":"2018-12-10T05:42:05.000Z","comments":true,"path":"Linux/利用NFS及LVM进行存储动态扩容.html","link":"","permalink":"https://gowa2017.github.io/Linux/利用NFS及LVM进行存储动态扩容.html","excerpt":"业务需要，以前的磁盘不够用了。而且涉及到多个接口机存储数据的问题。所以用 NFS 来进行文件共享，LVM 实现磁盘的动态扩容， Lsyncd 实现备份。","text":"业务需要，以前的磁盘不够用了。而且涉及到多个接口机存储数据的问题。所以用 NFS 来进行文件共享，LVM 实现磁盘的动态扩容， Lsyncd 实现备份。 LVM 磁盘建立PVpvcreate /dev/vdc /dev/vdd /dev/vde VGvgcreate -v -d VolGp /dev/vdc /dev/vdd /dev/vde LVlvcreate VolGp -L 4T 创建文件系统mkfs -t ext3 /dev/VolGp/lvol0 本机挂载mkdir /datamount /dev/VolGp/lvol0 /data NFS 服务开启 Servernfs 服务安装yum install nfs-utils nfs-utils-lib rpcbindchkconfig rpcbind onchkconfig nfs onchkconfig nfslock onservice rpcbind startservice nfs startservice nfslock start 导出资源vi /etc/exports/data 10.11.49.131(rw,sync,no_root_squash,no_subtree_check) exportfs -a NFS Clientyum install nfs-utils nfs-utils-lib rpcbindchkconfig rpcbind onchkconfig nfslock onservice rpcbind startservice nfslock start mount 10.11.49.138:/data /data 同步服务 lsyncdyum install lsyncd 配置settings &#123; logfile = \"/var/log/lsyncd.log\", statusFile = \"/var/log/lsyncd-status.log\", statusInterval = 20 &#125; sync &#123; default.rsyncssh, source=\"/data\", host=\"10.11.49.139\", targetdir=\"/data\", rsync = &#123; archive = true, compress = false, whole_file = false &#125;, ssh = &#123; port = 22 &#125; &#125; 同步服务设置好存储机到备份机的公私钥登陆方式略","categories":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/tags/Linux/"},{"name":"LVM","slug":"LVM","permalink":"https://gowa2017.github.io/tags/LVM/"},{"name":"NFS","slug":"NFS","permalink":"https://gowa2017.github.io/tags/NFS/"}],"keywords":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}]},{"title":"pandas类似于SQL一样的使用操作","slug":"pandas类似于SQL一样的使用操作","date":"2018-12-04T12:37:46.000Z","updated":"2018-12-04T12:37:46.000Z","comments":true,"path":"Python/pandas类似于SQL一样的使用操作.html","link":"","permalink":"https://gowa2017.github.io/Python/pandas类似于SQL一样的使用操作.html","excerpt":"主要是企业为了对接数据，结构并不一致，感觉使用 SQL 实现起来是有点类的。有点为难 MySQL 了。还是准备打算用 Python 来使用。","text":"主要是企业为了对接数据，结构并不一致，感觉使用 SQL 实现起来是有点类的。有点为难 MySQL 了。还是准备打算用 Python 来使用。 Python 连接 MySQL我们可以使用包 pymysql。 先安装 pymysql: pip install -U pymysql 在 py 脚本内使用 import pymysqlimport pandas as pdpymysql.install_as_MySQLdb()import MySQLdb 执行 pymysql.install_as_MySQLdb() 后，使用 MySQLdb 的地方会不知不觉的使用 pymysql 了。 将我们 MySQL 的配置写在一个字典内： dbconf = &#123; 'host': 'sunny-catalyst-130304.asia-east2.mysql', 'user': 'google', 'password': 'fajdlbudadf', 'db': 'game', 'port': 3306&#125;db = MySQLdb.connect(**dbconf) 这样我们就可以连接我们的 MySQL 了。连接后返回的其实是一个 pymysql.connections 类的实例。我们就可以用他其中的很多方法了。 其实现在的模块好像都有这样做法，或者说类。就是在实例内会有字段保存我们获取的结果等，通过方法来获取这样。 Connection 实例使用。query()本来我是看到返回的 db 有 query 方法的，我们也可以进行使用。但是又看到这个方面上的注释： # The following methods are INTERNAL USE ONLY (called from Cursor)def query(self, sql, unbuffered=False): # if DEBUG: # print(\"DEBUG: sending query:\", sql) if isinstance(sql, text_type) and not (JYTHON or IRONPYTHON): if PY2: sql = sql.encode(self.encoding) else: sql = sql.encode(self.encoding, 'surrogateescape') self._execute_command(COMMAND.COM_QUERY, sql) self._affected_rows = self._read_query_result(unbuffered=unbuffered) return self._affected_rows 嗷，这个方法是给 Cursor 来使用的。一般我们都是得到一个 Cursor 实例来执行查询的。 cursor()def cursor(self, cursor=None): \"\"\" Create a new cursor to execute queries with. :param cursor: The type of cursor to create; one of :py:class:`Cursor`, :py:class:`SSCursor`, :py:class:`DictCursor`, or :py:class:`SSDictCursor`. None means use Cursor. \"\"\" if cursor: return cursor(self) return self.cursorclass(self) 然后才是我们调用 cursor 的方法来进行查询的： cur = db.cursor()cur.execute('select sysdate() from dual')cur.fetchone() 注意：调用来 fetchone(), fetchall(), fetchmany() 这些方法后结果就会减少哦。 pd.read_sql(sql, db, index_col=)pandas 就更给力了，可以直接从 sql 进行查询获取得到结果的哦。 df = pd.read_sql('select * from information_schema.TABLES',db)print(df) 这样我们就可以随便的像处理其他数据一样处理了。 列拆分我们构造一个一个字段逗号分隔存储多个值的情况： df = pd.DataFrame(&#123;'id':['A','B','C'],'item':['1,2,3','3,4,5,6,7','101,102,103']&#125;)df = df.set_index('id')id itemA 1,2,3B 3,4,5,6,7C 101,102,103 我们把 A 列当做字符串按 , 拆分的话，得到的是一个数组，我们可以提供一个额外参数 expand=True 来拆分结果也变成列： df.item.str.split(',', expand=True)id 0 1 2 3 4 A 1 2 3 None NoneB 3 4 5 6 7C 101 102 103 None None pd.stack() 函数这个函数，将列堆叠到指定索引级别。 返回一个重新整形后的，具有一个多级索引的 帧 或 列，与当前的帧相比较，多级索引的内层索引级别最高。这通过旋转最当前帧的列来建立最内层的级别。 如果当前列只有一个级别，那么输出就是一个系列 如果当前列有多个级别，那么就通过我们指定的级别来转换。 参数 level int, str, list, default -1 从列轴堆到索引轴的级别。定义为一个索引或者标签，或者一个标签列表等。 dropna 继续上面的例子： df.item.str.split(',',expand=True).stack()id A 0 1 1 2 2 3B 0 3 1 4 2 5 3 6 4 7C 0 101 1 102 2 103dtype: object 这样的情况下，我们就是一个具有两级索引的系列了，但我们不需要那个二级索引，所以要丢掉： df.item.str.split(',',expand=True).stack().reset_index(level=1, drop=True)idA 1A 2A 3B 3B 4B 5B 6B 7C 101C 102C 103dtype: object pd.reset_index(level= , drop=True) 的意思是把对应级别的索引丢弃，drop=True的意思，是不要把丢弃的索引给插为新列。 结果是一个系列，我们可以把列命名一下。 series.reset_index(level=None, drop=False, inplace=False) 方法会重新生成一个帧，把以前的索引变成一列。 level, drop 参数的意思，同上一个reset_index()方法。","categories":[{"name":"Python","slug":"Python","permalink":"https://gowa2017.github.io/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://gowa2017.github.io/tags/Python/"},{"name":"SQL","slug":"SQL","permalink":"https://gowa2017.github.io/tags/SQL/"}],"keywords":[{"name":"Python","slug":"Python","permalink":"https://gowa2017.github.io/categories/Python/"}]},{"title":"MySQL将单列拆分为多个行","slug":"MySQL将单列拆分为多个行","date":"2018-12-04T04:05:38.000Z","updated":"2018-12-04T04:05:38.000Z","comments":true,"path":"MySQL/MySQL将单列拆分为多个行.html","link":"","permalink":"https://gowa2017.github.io/MySQL/MySQL将单列拆分为多个行.html","excerpt":"事情的起因是业务表内存储的各检查项目的ID，是用 、 分隔存储在了一个字段，而现在需要获得每个字段的具体内容。所以想要把字段分开来，join 查询另外的内容表。","text":"事情的起因是业务表内存储的各检查项目的ID，是用 、 分隔存储在了一个字段，而现在需要获得每个字段的具体内容。所以想要把字段分开来，join 查询另外的内容表。 拆分MySQL 有一个 replace 函数可以替换字符串内容。思路是将一列拆分为多个值，然后插入到中间表。 原来数据create table t1(uuid varchar(64),itemlist varchar(200));insert into t1 (`uuid`, `itemlist`) values(replace(uuid(),'-',''),'*1.2,*1.3,*2.1,*2.2,*3.2,*3.3,*3.4,*3.5'); 想要得到的表结构是： create table t2(uuid varchar(64),item varchar(64)) 分析我们的数据字段 itemlist 是以 , 来进行分隔的，有几个逗号，我们就要拆分成逗号数量 + 1个字段。我们可以将数据重复那么多次，然后把其中的内容给替换掉就行了。 对于要拆成的字段数的计算方法，我们可以这样操作： length(itemlist) - length(replace(itemlist, ',', '')) + 1 基本原理就是把逗号替换为空后的字符会比原来的字符少掉逗号个字符，再加上最开始的一个。 select length(itemlist) - length(replace(itemlist, ',', '')) + 1 from t1;结果是 8 然后我们可以用一个只有数字的表来进行 join 只显示 8 行。 光是生成一个序列表其实有点麻烦。mysql。我们用视图的形式先生成一个 16 个数字的 view： CREATE OR REPLACE VIEW generator_16AS SELECT 0 n UNION ALL SELECT 1 UNION ALL SELECT 2 UNION ALL SELECT 3 UNION ALL SELECT 4 UNION ALL SELECT 5 UNION ALL SELECT 6 UNION ALL SELECT 7 UNION ALL SELECT 8 UNION ALL SELECT 9 UNION ALL SELECT 10 UNION ALL SELECT 11 UNION ALL SELECT 12 UNION ALL SELECT 13 UNION ALL SELECT 14 UNION ALL SELECT 15; 接着我们就可以利用 join 会增加您行数的这么一个事实来显示更多的记录： CREATE OR REPLACE VIEW generator_256AS SELECT ( ( hi.n &lt;&lt; 4 ) | lo.n ) AS n FROM generator_16 lo, generator_16 hi; 下面我们就可以干活了： join 序列表select * from t1 a join generator_256 b ON b.n &lt; (length(a.itemlist) - length(replace(a.itemlist, ',', ''))+1);c9e5cdc8f77a11e88966525400aa5cdc *1.2,*1.3,*2.1,*2.2,*3.2,*3.3,*3.4,*3.5 0c9e5cdc8f77a11e88966525400aa5cdc *1.2,*1.3,*2.1,*2.2,*3.2,*3.3,*3.4,*3.5 1c9e5cdc8f77a11e88966525400aa5cdc *1.2,*1.3,*2.1,*2.2,*3.2,*3.3,*3.4,*3.5 2c9e5cdc8f77a11e88966525400aa5cdc *1.2,*1.3,*2.1,*2.2,*3.2,*3.3,*3.4,*3.5 3c9e5cdc8f77a11e88966525400aa5cdc *1.2,*1.3,*2.1,*2.2,*3.2,*3.3,*3.4,*3.5 4c9e5cdc8f77a11e88966525400aa5cdc *1.2,*1.3,*2.1,*2.2,*3.2,*3.3,*3.4,*3.5 5c9e5cdc8f77a11e88966525400aa5cdc *1.2,*1.3,*2.1,*2.2,*3.2,*3.3,*3.4,*3.5 6c9e5cdc8f77a11e88966525400aa5cdc *1.2,*1.3,*2.1,*2.2,*3.2,*3.3,*3.4,*3.5 7 然后我们把其中的 itemlist 进行替换。 substring_index(str, char, n) 函数会找到我们指定的字符出现的地方就停止。 n 表示第几次出现的位置。如果 n 是负值，表明从右向左去找。 SELECT a.uuid, substring_index(a.itemlist, ',', b.n+1)FROM t1 aJOIN generator_256 b ON b.n &lt; (length(a.itemlist) - length(replace(a.itemlist, ',', ''))+1);c9e5cdc8f77a11e88966525400aa5cdc *1.2c9e5cdc8f77a11e88966525400aa5cdc *1.2,*1.3c9e5cdc8f77a11e88966525400aa5cdc *1.2,*1.3,*2.1c9e5cdc8f77a11e88966525400aa5cdc *1.2,*1.3,*2.1,*2.2c9e5cdc8f77a11e88966525400aa5cdc *1.2,*1.3,*2.1,*2.2,*3.2c9e5cdc8f77a11e88966525400aa5cdc *1.2,*1.3,*2.1,*2.2,*3.2,*3.3c9e5cdc8f77a11e88966525400aa5cdc *1.2,*1.3,*2.1,*2.2,*3.2,*3.3,*3.4c9e5cdc8f77a11e88966525400aa5cdc *1.2,*1.3,*2.1,*2.2,*3.2,*3.3,*3.4,*3.5 这不是我们想要的，我们还需要把顺序在后面的记录中的值给挑选出来。是不是就是从右往左的第一个。 SELECT a.uuid, substring_index(substring_index(a.itemlist, ',', b.n+1), ',', -1)FROM t1 aJOIN generator_256 b ON b.n &lt; (length(a.itemlist) - length(replace(a.itemlist, ',', ''))+1);c9e5cdc8f77a11e88966525400aa5cdc *1.2c9e5cdc8f77a11e88966525400aa5cdc *1.3c9e5cdc8f77a11e88966525400aa5cdc *2.1c9e5cdc8f77a11e88966525400aa5cdc *2.2c9e5cdc8f77a11e88966525400aa5cdc *3.2c9e5cdc8f77a11e88966525400aa5cdc *3.3c9e5cdc8f77a11e88966525400aa5cdc *3.4c9e5cdc8f77a11e88966525400aa5cdc *3.5 OK，大功告成。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://gowa2017.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://gowa2017.github.io/tags/MySQL/"}],"keywords":[{"name":"MySQL","slug":"MySQL","permalink":"https://gowa2017.github.io/categories/MySQL/"}]},{"title":"adblockplus的匹配规则-PAC用到","slug":"adblockplus的匹配规则-PAC用到","date":"2018-12-03T01:11:02.000Z","updated":"2018-12-03T01:11:02.000Z","comments":true,"path":"Network/adblockplus的匹配规则-PAC用到.html","link":"","permalink":"https://gowa2017.github.io/Network/adblockplus的匹配规则-PAC用到.html","excerpt":"自定义 PAC 规则会用到呢。 原文地址","text":"自定义 PAC 规则会用到呢。 原文地址 例子通过部分地址匹配 Verbatim text 这部分必须出现在地址内 Wildcard charcter 通配符部分 Separator 分隔符。要么是一个分隔符，或者是地址的结束 上面的图片会匹配以下地址： http://example.com/banner/foo/img http://example.com/banner/foo/bar/img?param http://example.com/banner//img/foo 不会匹配以下地址： http://example.com/banner/img http://example.com/banner/foo/imgraph http://example.com/banner/foo/img.gif 通过域名匹配 Domain name anchor 域名锚点。这后面的必须是域名 Verbatim text 。 地址中必须出现的域名 Separtor 分隔符。表示域名的结束 ^ 上图会匹配以下： http://ads.example.com/foo.gif http://server1.ads.example.com/foo.gif https://ads.example.com:8000/ 不会匹配下面的地址： http://ads.example.com.ua/foo.gif http://example.com/redirect/http://ads.example.com/ 匹配确切的地址 锚点开始符号 | 必须出现的部分 锚点结束 | 这会匹配： http://example.com/ 而不会匹配： http://example.com/foo.gif http://example.info/redirect/http://example.com/ 匹配规则中的选项匹配规则中有很多选项来改变他们的行为。 Address to be blocked 要匹配的地址 Option Selector 可选分隔符。指名后面跟随的是过滤选项。 Type Option 类型选项 定义了要匹配的类型。通常是 script/images 表示只有这两种类型才匹配。 ~ 表示非的意思。 Domain Option 域名选项。 限制过滤只在指定的域名上。可以使用 ~ 来取反。 上面的图片在满足下面的情况下匹配了 http://ads.example.com/foo.gif 地址被加载为 script 或者 image 从域名 example.com 加载（或者子域名），且不是从 foo.example.com 加载。 例外规则例外规则的用处是及时匹配上了我们要屏蔽的内容，也可以允许其通过。 特定请求的例外 Exception rule。以 @@ 开始。 Address to be allowed 这和以上规则是一样的。不过是允许例外而已。 Type option 类型选项。 上面的规则的意思是，对于 ads.example.com/notbanner 非 script 不进行过滤。 整个站点例外 只需要把 类型指定为 document 即可。 注释以 ! 开头的注释","categories":[{"name":"Network","slug":"Network","permalink":"https://gowa2017.github.io/categories/Network/"}],"tags":[{"name":"Network","slug":"Network","permalink":"https://gowa2017.github.io/tags/Network/"},{"name":"PAC","slug":"PAC","permalink":"https://gowa2017.github.io/tags/PAC/"}],"keywords":[{"name":"Network","slug":"Network","permalink":"https://gowa2017.github.io/categories/Network/"}]},{"title":"Poi中添加Anchor图片到Docx文档","slug":"Poi中添加Anchor图片到Docx文档","date":"2018-11-28T05:54:11.000Z","updated":"2018-11-28T05:54:11.000Z","comments":true,"path":"Java/Poi中添加Anchor图片到Docx文档.html","link":"","permalink":"https://gowa2017.github.io/Java/Poi中添加Anchor图片到Docx文档.html","excerpt":"做文书的时候，需要把印章放在相关的文字上面。事实上这个问题拖了很久了都没有去处理。因为 POI 对于这种要把图片盖在文字上面的做法很蛋疼，其提供的API并不好用。使用了底层的，直接写 xml 的方式来插入进去的。 参考了 stackoverflow.com/ 的做法后完成","text":"做文书的时候，需要把印章放在相关的文字上面。事实上这个问题拖了很久了都没有去处理。因为 POI 对于这种要把图片盖在文字上面的做法很蛋疼，其提供的API并不好用。使用了底层的，直接写 xml 的方式来插入进去的。 参考了 stackoverflow.com/ 的做法后完成 Inline这种方式添加图片是非常的简单。只需要一句代码就可以了。 run.addPicture(java.io.InputStream pictureData, int pictureType, java.lang.String filename, int width, int height) 指定 输入流，图片类型，文件名，宽，高即可。注意这里的宽高是 EMU 为单位的。 关于这个方法的API解释，地址在这里：http://poi.apache.org/apidocs/dev/index.html 添加之后我们可以查看我们 run 的 xml 代码是什么： System.out.println(run.getCTR()); &lt;xml-fragment w:rsidRPr=\"00924CAC\" xmlns:cx=\"http://schemas.microsoft.com/office/drawing/2014/chartex\" xmlns:cx1=\"http://schemas.microsoft.com/office/drawing/2015/9/8/chartex\" xmlns:m=\"http://schemas.openxmlformats.org/officeDocument/2006/math\" xmlns:mc=\"http://schemas.openxmlformats.org/markup-compatibility/2006\" xmlns:o=\"urn:schemas-microsoft-com:office:office\" xmlns:r=\"http://schemas.openxmlformats.org/officeDocument/2006/relationships\" xmlns:v=\"urn:schemas-microsoft-com:vml\" xmlns:w=\"http://schemas.openxmlformats.org/wordprocessingml/2006/main\" xmlns:w10=\"urn:schemas-microsoft-com:office:word\" xmlns:w14=\"http://schemas.microsoft.com/office/word/2010/wordml\" xmlns:w15=\"http://schemas.microsoft.com/office/word/2012/wordml\" xmlns:w16se=\"http://schemas.microsoft.com/office/word/2015/wordml/symex\" xmlns:wne=\"http://schemas.microsoft.com/office/word/2006/wordml\" xmlns:wp=\"http://schemas.openxmlformats.org/drawingml/2006/wordprocessingDrawing\" xmlns:wp14=\"http://schemas.microsoft.com/office/word/2010/wordprocessingDrawing\" xmlns:wpc=\"http://schemas.microsoft.com/office/word/2010/wordprocessingCanvas\" xmlns:wpg=\"http://schemas.microsoft.com/office/word/2010/wordprocessingGroup\" xmlns:wpi=\"http://schemas.microsoft.com/office/word/2010/wordprocessingInk\" xmlns:wps=\"http://schemas.microsoft.com/office/word/2010/wordprocessingShape\"&gt; &lt;w:rPr&gt; &lt;w:rFonts w:ascii=\"仿宋_GB2312\" w:eastAsia=\"仿宋_GB2312\" w:hAnsi=\"Times New Roman\"/&gt; &lt;w:kern w:val=\"2\"/&gt; &lt;w:sz w:val=\"32\"/&gt; &lt;w:szCs w:val=\"32\"/&gt; &lt;/w:rPr&gt; &lt;w:t/&gt; &lt;w:drawing&gt; &lt;wp:inline distT=\"0\" distR=\"0\" distB=\"0\" distL=\"0\"&gt; &lt;wp:extent cx=\"1440000\" cy=\"1440000\"/&gt; &lt;wp:docPr id=\"0\" name=\"Drawing 0\" descr=\"stamp\"/&gt; &lt;a:graphic xmlns:a=\"http://schemas.openxmlformats.org/drawingml/2006/main\"&gt; &lt;a:graphicData uri=\"http://schemas.openxmlformats.org/drawingml/2006/picture\"&gt; &lt;pic:pic xmlns:pic=\"http://schemas.openxmlformats.org/drawingml/2006/picture\"&gt; &lt;pic:nvPicPr&gt; &lt;pic:cNvPr id=\"0\" name=\"Picture 0\" descr=\"stamp\"/&gt; &lt;pic:cNvPicPr&gt; &lt;a:picLocks noChangeAspect=\"true\"/&gt; &lt;/pic:cNvPicPr&gt; &lt;/pic:nvPicPr&gt; &lt;pic:blipFill&gt; &lt;a:blip r:embed=\"rId6\"/&gt; &lt;a:stretch&gt; &lt;a:fillRect/&gt; &lt;/a:stretch&gt; &lt;/pic:blipFill&gt; &lt;pic:spPr&gt; &lt;a:xfrm&gt; &lt;a:off x=\"0\" y=\"0\"/&gt; &lt;a:ext cx=\"1440000\" cy=\"1440000\"/&gt; &lt;/a:xfrm&gt; &lt;a:prstGeom prst=\"rect\"&gt; &lt;a:avLst/&gt; &lt;/a:prstGeom&gt; &lt;/pic:spPr&gt; &lt;/pic:pic&gt; &lt;/a:graphicData&gt; &lt;/a:graphic&gt; &lt;/wp:inline&gt; &lt;/w:drawing&gt;&lt;/xml-fragment&gt; 很一目了然，在 run -&gt; drawing -&gt; inline -&gt; graphic -&gt; …. 由于图片的代码是一样的，其实我们只需要把 inline 元素这里进行变更就好了。 但是，事实上，POI 上并没有提供 Anchor 的 API，所以只能用比较底层的方式来进行了。 Anchor我们先定义一个 Anchor 节点。 String anchorXML = \"&lt;wp:anchor xmlns:wp=\\\"http://schemas.openxmlformats.org/drawingml/2006/wordprocessingDrawing\\\" \" + \"simplePos=\\\"0\\\" relativeHeight=\\\"0\\\" behindDoc=\\\"0\\\" locked=\\\"0\\\" layoutInCell=\\\"1\\\" allowOverlap=\\\"1\\\"&gt;\" + \"&lt;wp:simplePos x=\\\"0\\\" y=\\\"0\\\"/&gt;\" + \"&lt;wp:positionH relativeFrom=\\\"\" + relativeFrom +\"\\\"&gt;\"// + \"&lt;wp:align&gt;\" + relativeFrom + \"&lt;/wp:align&gt;\" + \"&lt;wp:posOffset&gt;\" + hOffset + \"&lt;/wp:posOffset&gt;\" +\"&lt;/wp:positionH&gt;\"// + \"&lt;wp:positionH relativeFrom=\\\"column\\\"&gt;&lt;wp:align&gt;left&lt;/wp:align&gt;&lt;/wp:positionH&gt;\" + \"&lt;wp:positionV relativeFrom=\\\"paragraph\\\"&gt;&lt;wp:align&gt;center&lt;/wp:align&gt;&lt;/wp:positionV&gt;\" + \"&lt;wp:extent cx=\\\"\" + width + \"\\\" cy=\\\"\" + height + \"\\\"/&gt;\" + \"&lt;wp:effectExtent l=\\\"0\\\" t=\\\"0\\\" r=\\\"0\\\" b=\\\"0\\\"/&gt;\" + \"&lt;wp:wrapNone/&gt;\" + \"&lt;wp:docPr id=\\\"1\\\" name=\\\"Drawing 0\\\" descr=\\\"\" + drawingDescr + \"\\\"/&gt;&lt;wp:cNvGraphicFramePr/&gt;\" + \"&lt;/wp:anchor&gt;\"; 确定图片在哪里的元素就在 positionH、positionV 上。这两者都有一个属性 relativeFrom 决定相对与哪个地方来计算位置，这个属性的取值可参考文章：Java/openoffice-XML-生成word中的图片.html#anchor。我一般选用 margin 就行了。主要原因就是，很多取值 我需要用 openoffice 转的时候，不支持。 但是 positionH、positionV 的子元素中 align 与 posOffset 只能有一个，两者共存文档就会损坏。 现在我们用代码来进行操作，根据我们的输入参数来返回 Anchor： /** * * @param graphicalobject 图片数据 * @param drawingDescr 图片描述 * @param width 宽 * @param height 高 * @param hOffset 水平偏移 * @param vOffset 垂直偏移 * @param relativeFrom 相对位置 * @return * @throws Exception */ private static CTAnchor getAnchorWithGraphic(CTGraphicalObject graphicalobject, String drawingDescr, int width, int height, int hOffset, int vOffset, String relativeFrom) throws Exception &#123; String anchorXML = \"&lt;wp:anchor xmlns:wp=\\\"http://schemas.openxmlformats.org/drawingml/2006/wordprocessingDrawing\\\" \" + \"simplePos=\\\"0\\\" relativeHeight=\\\"0\\\" behindDoc=\\\"0\\\" locked=\\\"0\\\" layoutInCell=\\\"1\\\" allowOverlap=\\\"1\\\"&gt;\" + \"&lt;wp:simplePos x=\\\"0\\\" y=\\\"0\\\"/&gt;\" + \"&lt;wp:positionH relativeFrom=\\\"\" + relativeFrom +\"\\\"&gt;\"// + \"&lt;wp:align&gt;\" + relativeFrom + \"&lt;/wp:align&gt;\" + \"&lt;wp:posOffset&gt;\" + hOffset + \"&lt;/wp:posOffset&gt;\" +\"&lt;/wp:positionH&gt;\"// + \"&lt;wp:positionH relativeFrom=\\\"column\\\"&gt;&lt;wp:align&gt;left&lt;/wp:align&gt;&lt;/wp:positionH&gt;\" + \"&lt;wp:positionV relativeFrom=\\\"paragraph\\\"&gt;&lt;wp:align&gt;center&lt;/wp:align&gt;&lt;/wp:positionV&gt;\" + \"&lt;wp:extent cx=\\\"\" + width + \"\\\" cy=\\\"\" + height + \"\\\"/&gt;\" + \"&lt;wp:effectExtent l=\\\"0\\\" t=\\\"0\\\" r=\\\"0\\\" b=\\\"0\\\"/&gt;\" + \"&lt;wp:wrapNone/&gt;\" + \"&lt;wp:docPr id=\\\"1\\\" name=\\\"Drawing 0\\\" descr=\\\"\" + drawingDescr + \"\\\"/&gt;&lt;wp:cNvGraphicFramePr/&gt;\" + \"&lt;/wp:anchor&gt;\"; CTDrawing drawing = CTDrawing.Factory.parse(anchorXML); CTAnchor anchor = drawing.getAnchorArray(0); anchor.setGraphic(graphicalobject); return anchor; &#125; graphicalobject 从哪里来？我们为了简单，不要手动添加。我们通过 我们刚开始就介绍的添加到 inline 里面的方法来添加。然后获取了以后，我们就把 inline 给删除就OK。 XWPFDocument document = new XWPFDocument(); XWPFParagraph paragraph = document.createParagraph(); XWPFRun run = paragraph.createRun(); // 添加 inline 图片 这里有个问题，就是openOffice识别的时候，必须要图片数据的宽高和后面我们设置的宽高一致run.setText(\"行内图片: \"); InputStream in = new FileInputStream(\"/Users/wodediannao/sample.png\"); run.addPicture(in, Document.PICTURE_TYPE_JPEG, \"/Users/wodediannao/sample.png\", Units.toEMU(100), Units.toEMU(30)); in.close(); // 添加浮动图片 // 1. 先添加一个行内图片 run = paragraph.createRun(); in = new FileInputStream(\"/Users/wodediannao/sample.png\"); run.addPicture(in, Document.PICTURE_TYPE_JPEG, \"/Users/wodediannao/sample.png\", Units.toEMU(100), Units.toEMU(30)); in.close(); // 2. 获取到图片数据 CTDrawing drawing = run.getCTR().getDrawingArray(0); CTGraphicalObject graphicalobject = drawing.getInlineArray(0).getGraphic(); // 3. 加入 Anchor 并删除 Inline 的图片 CTAnchor anchor = getAnchorWithGraphic(graphicalobject, \"/Users/wodediannao/sample.png\", Units.toEMU(100), Units.toEMU(30), Units.toEMU(0), Units.toEMU(0),\"\"); drawing.setAnchorArray(new CTAnchor[]&#123;anchor&#125;); drawing.removeInline(0); // 4. 写出文件 document.write(new FileOutputStream(\"WordInsertPictures.docx\")); document.close();","categories":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/tags/Java/"},{"name":"Word","slug":"Word","permalink":"https://gowa2017.github.io/tags/Word/"},{"name":"Poi","slug":"Poi","permalink":"https://gowa2017.github.io/tags/Poi/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}]},{"title":"TensorFlow中的LSTM了解","slug":"TensorFlow中的LSTM了解","date":"2018-11-26T15:59:20.000Z","updated":"2018-11-26T15:59:20.000Z","comments":true,"path":"TensorFlow/TensorFlow中的LSTM了解.html","link":"","permalink":"https://gowa2017.github.io/TensorFlow/TensorFlow中的LSTM了解.html","excerpt":"LSTM（长短期记忆）是最常用的 RNN （递归神经网络了）。经常用于序列数据。关于它的详细介绍可以看这个 权威博客。本文章原文位于：这里","text":"LSTM（长短期记忆）是最常用的 RNN （递归神经网络了）。经常用于序列数据。关于它的详细介绍可以看这个 权威博客。本文章原文位于：这里 MNIST 数据集MNIST 是一个手写数字识别的数据集。可以用代码来下载使用： from tensorflow.examples.tutorials.mnist import input_datamnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True) 数据分割为三个部分： mnist.train 55000 个图片数据 mnist.test 10000 的测试图片数据。 mnist.validation 5000 个有效的图片数据。 数据形状让我们讨论关于MNIST数据集的训练数据的形状。所有三个部分数据的形状是相同的。 训练数据，55000 张图片，每张图片 28 X 28 pixels。这 784 个像素点放在一个维度是 784 的向量中。所以呢，训练数据的形状就是 (55000,784)，可通过 mnist.train.images 进行引用。 55000 个训练图片中，每个都有一个对应的标签，表示了图片所数的类（是哪个数字）。这里有 10 个（ 0,1,2….）。类标签以一种热编码形式表示。 标签在 numpy 数组中的形式为 (55000,10)，通过 mnist.train.lables。 实现写代码前先画出一个概要，这有助于我们的代码更直观。 vanilla RNN把一个 RNN 进行展开的话，就是如下这样： 在这里： X_t 引用在 t 时刻的输入。 S_t 引用在 t 时刻的隐藏状态。可以把它想象成我们网络的 记忆。 O_t 引用 t 时刻的输出。 U, V, W 表示在所有的时刻中共享的参数。使用同样参数的意义在于，我们的模型在每个时刻做的任务是一样的，只是输入不同。 通过把 RNN 展开，我们达到了一个目的：在任何时刻，我们都会考虑前一时刻的输入，所以可以想象它是一个 前馈网络（由时刻之间的联系表示） 两个要点我们的实施将取决于两个主要概念，这些概念将使我们对实施感到满意： TensorFlow 中对于 LSTM 神经元的解释。 传递数据给 TensorFlow RNN 前把数据格式化。 TensorFlow 中的 LSTM 神经元我们可以很简单的在 TensorFlow 中声明一个 LSTM 神经元： tf.contrib.rnn.BasicLSTMCell(num_units) num_units 代表了 LSTM 神经元中的单元数。num_units 可以类比于前馈神经网络的隐藏层。在一个前馈神经网络中隐藏层的节点数等于这个网络中每个时刻 LSTM 神经元内 LSTM 中的单元数。下面的图片可能会减少我们的疑惑。 num_units 的任何一个 LSTM 单元可以被看作是一个标准的 LSTM 单元： 格式化输入TensorFlow 中最简单的 RNN 就是 static_rnn 了。 tf.static_rnn(cell,inputs) 其拥有很多参数，但现在我们只关注这两个。 inputs 参数接受一个张量列表，形状为 (batch_size, input_size) 。列表的长度，就是这个网络展开的时刻数。就是说，在我们的网络中，一个输入就对应了一个时刻。 就我们的 MNIST 图片数据而言，我们的图片大小是 28 X 28。可以把图片看成是 28 行，每行有 28 pixels。我们会把我们的网络展开成 28 个时刻，这样，每个时刻我们就可以输入一行数据了（28 pixels, input_size，输入张量的维度），一个图片就会走完 28 个时刻。 如果我们提供了 batch_size 个图片数据，每个时刻都会提供 batch_size 条数据。下面的图片看得更清楚： static_rnn 的输入是一个张量列表，形状 (batch_size, num_units)。列表的长度，就是网络展开的长度。在此实现中，我们将仅关注最终时间步的输出，因为当将图像的所有行提供给RNN时将生成预测结果，也就是最后一个时刻。 现在我们已经完成了所有繁重的工作，我们已经准备好编写代码。一旦上述概念清楚，编码部分就非常直接了。 代码开始，让我们导入必要的依赖项，数据集并声明一些常量。我们将使用batch_size = 128 和 num_units = 128。 import tensorflow as tffrom tensorflow.contrib import rnn#import mnist datasetfrom tensorflow.examples.tutorials.mnist import input_datamnist=input_data.read_data_sets(\"/tmp/data/\",one_hot=True)#define constants#unrolled through 28 time stepstime_steps=28#hidden LSTM unitsnum_units=128#rows of 28 pixelsn_input=28#learning rate for adamlearning_rate=0.001#mnist is meant to be classified in 10 classes(0-9).n_classes=10#size of batchbatch_size=128 现在让我们声明占位符和权重以及偏差变量，这些变量将用于将shape [batch_size，num_units]的输出转换为[batch_size，n_classes]，以便可以预测正确的类。 #weights and biases of appropriate shape to accomplish above taskout_weights=tf.Variable(tf.random_normal([num_units,n_classes]))out_bias=tf.Variable(tf.random_normal([n_classes]))#defining placeholders#input image placeholder# [None, time_steps, n_input] 代表了 批量数，网络展开时刻数，每个时刻输入数据的大小x=tf.placeholder(\"float\",[None,time_steps,n_input])#input label placeholdery=tf.placeholder(\"float\",[None,n_classes]) 现在我们正在接收 shape [batch_size，time_steps，n_input] 的输入，我们需要将其转换为长度为 time_steps 的shape [batch_size，n_inputs]的张量列表，以便可以将其输入static_rnn。 #processing the input tensor from [batch_size,n_steps,n_input] to \"time_steps\" number of [batch_size,n_input] tensors# 将 [batch_size,n_steps,n_input] 沿 time_steps 展开后，结果就是 [batch_size,n_input] 列表，大小是 time_steps。列表中每个元素都会被每个时刻当做输入。input=tf.unstack(x ,time_steps,1) 现在我们已经准备好定义我们的网络。我们将使用一层BasicLSTMCell并使用我们的static_rnn网络。 #defining the networklstm_layer=rnn.BasicLSTMCell(num_units,forget_bias=1)outputs,_=rnn.static_rnn(lstm_layer,input,dtype=\"float32\") 由于我们只考虑上一次时间步的输入，我们将从中生成我们的预测: #converting last output of dimension [batch_size,num_units] to [batch_size,n_classes] by out_weight multiplicationprediction=tf.matmul(outputs[-1],out_weights)+out_bias 定义损失，优化器和准确性。 #loss_functionloss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction,labels=y))#optimizationopt=tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)#model evaluationcorrect_prediction=tf.equal(tf.argmax(prediction,1),tf.argmax(y,1))accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32)) 现在我们已经定义了图表，我们可以运行它。 #initialize variablesinit=tf.global_variables_initializer()with tf.Session() as sess: sess.run(init) iter=1 while iter&lt;800: batch_x,batch_y=mnist.train.next_batch(batch_size=batch_size) batch_x=batch_x.reshape((batch_size,time_steps,n_input)) sess.run(opt, feed_dict=&#123;x: batch_x, y: batch_y&#125;) if iter %10==0: acc=sess.run(accuracy,feed_dict=&#123;x:batch_x,y:batch_y&#125;) los=sess.run(loss,feed_dict=&#123;x:batch_x,y:batch_y&#125;) print(\"For iter \",iter) print(\"Accuracy \",acc) print(\"Loss \",los) print(\"__________________\") iter=iter+1 这里需要注意的一件重要事情是，我们的图像基本上被展平为一个维度784的矢量。函数next_batch（batch_size）必然返回这些784维向量的batch_size批量。因此，它们被重新整形为[batch_size，time_steps，n_input]，以便我们的占位符可以接受它们。 我们还可以计算出我们模型的测试精度 - #calculating test accuracytest_data = mnist.test.images[:128].reshape((-1, time_steps, n_input))test_label = mnist.test.labels[:128]print(\"Testing Accuracy:\", sess.run(accuracy, feed_dict=&#123;x: test_data, y: test_label&#125;)) 在运行时，模型运行的测试精度为99.21％。","categories":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://gowa2017.github.io/categories/TensorFlow/"}],"tags":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://gowa2017.github.io/tags/TensorFlow/"}],"keywords":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://gowa2017.github.io/categories/TensorFlow/"}]},{"title":"Dagger与安卓","slug":"Dagger与安卓","date":"2018-11-25T06:09:01.000Z","updated":"2018-11-25T06:09:01.000Z","comments":true,"path":"Java/Dagger与安卓.html","link":"","permalink":"https://gowa2017.github.io/Java/Dagger与安卓.html","excerpt":"Dagger相比其他依赖注入框架的优势是其严格生成的实现。这意味着可以在安卓内使用。然而，在安卓里面使用时也有很多需要考虑的地方。","text":"Dagger相比其他依赖注入框架的优势是其严格生成的实现。这意味着可以在安卓内使用。然而，在安卓里面使用时也有很多需要考虑的地方。 原理尽管安卓上的应用代码用 Java 来写，但往往风格差异巨大。通常，存在这样的差异以适应移动平台的独特性能考虑。 但是，通常应用于Android代码的许多模式与应用于其他Java代码的模式相反。甚至 Effective Java 中的大部分建议都被认为不适合Android。 为了达到写出通用和可移植的代码，Dagger依靠ProGuard对已编译的字节码进行后处理。这允许Dagger在服务器和Android上发出看起来和感觉自然的源，同时使用不同的工具链来生成在两个环境中有效执行的字节码。此外，Dagger有一个明确的目标，即确保它生成的Java源始终与ProGuard优化兼容。 当然，并非所有问题都能以这种方式解决，但它是提供Android特定兼容性的主要机制。 Dagger假设Android上的用户将使用ProGuard。 推荐的 ProGuard 设置观看此空间以获取与使用Dagger的应用程序相关的ProGuard设置。 dagger.android在安卓应用中使用 Dagger 的一个主要难处是很多安卓框架的类都是由 OS 自身初始化的，例如 Activity 和 Fragment，但在 Dagger 能建立所有注入对象的话会工作得很好。否则，您必须在生命周期方法中执行成员注入。这意味着许多类最终看起来像： public class FrombulationActivity extends Activity &#123; @Inject Frombulator frombulator; @Override public void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); // DO THIS FIRST. Otherwise frombulator might be null! ((SomeApplicationBaseType) getContext().getApplicationContext()) .getApplicationComponent() .newActivityComponentBuilder() .activity(this) .build() .inject(this); // ... now you can write the exciting code &#125;&#125; 这会有几个问题： 复制-粘贴的代码在后面来难以重构。越来越多的程序员复制代码，但是没几个人知道其真正干了什么。 更基本点，它需要请求注入的类型（FrombulationActivity）来了解其注入器。尽管这是通过接口而不是通过具体的类型来完成，但这打破了依赖注入的一个原则：一个类不应该知道其应该是怎么注入的。 dagger.android中的类提供了一种简化此模式的方法。 注入 Activity 对象 在应用级别的组件 (Component) 中安装 AndroidInjectionModule ，以此来确保所有 dagger.android 框架中的类都可用。 通过书写一个实现了 AndroidInjector 的 @Subcomponent 和一个 扩展了 AndroidInjector.Builder 的 @Subcomponent.Builder 开始： @Subcomponent(modules = ...)public interface YourActivitySubcomponent extends AndroidInjector&lt;YourActivity&gt; &#123; @Subcomponent.Builder public abstract class Builder extends AndroidInjector.Builder&lt;YourActivity&gt; &#123;&#125;&#125; 3.定义了子组件后，把这个子组件添加到组件层级中。具体做法是：定义一个绑定了子组件 builder 的 module，然后把这个 module 添加到注入 Application 的 组件中。 @Module(subcomponents = YourActivitySubcomponent.class)abstract class YourActivityModule &#123; @Binds @IntoMap @ClassKey(YourActivity.class) abstract AndroidInjector.Factory&lt;?&gt; bindYourActivityInjectorFactory(YourActivitySubcomponent.Builder builder);&#125;@Component(modules = &#123;..., YourActivityModule.class&#125;)interface YourApplicationComponent &#123;&#125; 提示：如果子组件和它的 builder 没有除了 步骤2 中提到的其他方法或者超类，那么可使用 @ContributesAndroidInjector 来生成他们。步骤2，3就不需要了，添加一个 abstract 模块方法来返回你的 Activity，用 @ContributesAndroidInjector, 来注解，然后指定需要安装在子组件中的模块。如果 子组件需要范围，给这个方法也加上范围注解。 @ActivityScope@ContributesAndroidInjector(modules = &#123; /* modules to install into the subcomponent */ &#125;)abstract YourActivity contributeYourActivityInjector(); 4.接下来，让我们的 Application 实现 HasActivityInjector 并 @Inject 一个 DispatchingAndroidInjector 来从 activityInjector() 方法返回： public class YourApplication extends Application implements HasActivityInjector &#123; @Inject DispatchingAndroidInjector&lt;Activity&gt; dispatchingActivityInjector; @Override public void onCreate() &#123; super.onCreate(); DaggerYourApplicationComponent.create() .inject(this); &#125; @Override public AndroidInjector&lt;Activity&gt; activityInjector() &#123; return dispatchingActivityInjector; &#125;&#125; 5.在我们的 Activity 的 onCreate() 方法，在调用 super.onCreate() 前调用 AndroidInjection.inject(this)。 public class YourActivity extends Activity &#123; public void onCreate(Bundle savedInstanceState) &#123; AndroidInjection.inject(this); super.onCreate(savedInstanceState); &#125;&#125; 6.完毕。 怎么工作的？AndroidInjection.inject() 从 Application获取一个 DispatchingAndroidInjector&lt;Activity&gt;，然后把我们自己的 Activity 传递给 inject(Activity)。 DispatchingAndroidInjector 为我们的 Activity的类寻找 AndroidInjector.Factory（这里是 YourActivitySubcomponent.Builder），建立 AndroidInjector（这出是 YourActivitySubcomponent），把我们的 Activity 传递到 inject(YourActivity)。 注入 Fragment 对象这就和注入到 Activity 差不多。按同样的方式定义子组件，用 HasFragmentInjector 替换 HasActivityInjector。 同样，我们不是在 onCreate() 中注入，而是在 onAttach() 中注入。 不像 Activitys 中定义的模块那样，我们有一个机会来选择在何处为 Fragment 安装模块。可以把我们的 Fragment 组件 当作另外一个Fragment 的子组件，或者是 Activity 组件的，或 Application 的———— 这取决于你的 Fragment 需要哪些其他相关绑定。就决定了 组件位置后，让对应的类型实现 HasFragmentInjector。例如，如果你的 Fragment 需要 YourActivitySubcomponent 中的绑定，代码可能会是下面这样： public class YourActivity extends Activity implements HasFragmentInjector &#123; @Inject DispatchingAndroidInjector&lt;Fragment&gt; fragmentInjector; @Override public void onCreate(Bundle savedInstanceState) &#123; AndroidInjection.inject(this); super.onCreate(savedInstanceState); // ... &#125; @Override public AndroidInjector&lt;Fragment&gt; fragmentInjector() &#123; return fragmentInjector; &#125;&#125;public class YourFragment extends Fragment &#123; @Inject SomeDependency someDep; @Override public void onAttach(Activity activity) &#123; AndroidInjection.inject(this); super.onAttach(activity); // ... &#125;&#125;@Subcomponent(modules = ...)public interface YourFragmentSubcomponent extends AndroidInjector&lt;YourFragment&gt; &#123; @Subcomponent.Builder public abstract class Builder extends AndroidInjector.Builder&lt;YourFragment&gt; &#123;&#125;&#125;@Module(subcomponents = YourFragmentSubcomponent.class)abstract class YourFragmentModule &#123; @Binds @IntoMap @ClassKey(YourFragment.class) abstract AndroidInjector.Factory&lt;?&gt; bindYourFragmentInjectorFactory(YourFragmentSubcomponent.Builder builder);&#125;@Subcomponent(modules = &#123; YourFragmentModule.class, ... &#125;public interface YourActivityOrYourApplicationComponent &#123; ... &#125; 基本框架类型支持库dependencies &#123; compile 'com.google.dagger:dagger-android:2.x' compile 'com.google.dagger:dagger-android-support:2.x' // if you use the support libraries annotationProcessor 'com.google.dagger:dagger-android-processor:2.x'&#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/tags/Java/"},{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"},{"name":"Dagger","slug":"Dagger","permalink":"https://gowa2017.github.io/tags/Dagger/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}]},{"title":"Dagger用户指南","slug":"dagger用户指南","date":"2018-11-23T14:27:15.000Z","updated":"2018-11-23T14:27:15.000Z","comments":true,"path":"Java/dagger用户指南.html","link":"","permalink":"https://gowa2017.github.io/Java/dagger用户指南.html","excerpt":"只是一个对于官方简单说明指南的翻译。光看不用没有办法，正好有个应用使用到了这些东西，自己就来看一下是否果然如传说中的那么神奇。官方地址","text":"只是一个对于官方简单说明指南的翻译。光看不用没有办法，正好有个应用使用到了这些东西，自己就来看一下是否果然如传说中的那么神奇。官方地址 每个应用中最好的类就是那些真正做事情的类：比如 BarcodeDecoder，KoopaPhysicsEngine，AudioStreamer。这些类会有依赖；可能是 BarcodeCameraFinder，DefaultPhysicsEngine 和HttpStreamer。（保持简单，只保留干事的类） 相反，最垃圾的类就是那些占了很大空间，但是却只做一小点事情的类：BarcodeDecoderFactory，CameraServiceLoader，MutableContextWrapper。这些类就像笨拙的脚带一下把我们感兴趣的类给联系起来。（占用空间虽大，其实真正其作用的就是把我们感兴趣的联系起来，很多内容是不需要的） Dagger 就是这种 FactoryFactory 工厂类的替代，其实现了 依赖注入 设计模式，但我们不用去书写样板。这允许我们把注意力集中在我们感兴趣的类上。只需要 声明依赖，指定怎么样满足依赖，然后自然而然的传输给应用。 通过建立在标准的 javax.inject 注解（ JSR 330 ），每个类都 易于测试。您不需要写一堆样板，目的仅仅是为了将RpcCreditCardService换成FakeCreditCardService。 依赖注入不仅仅为了测试。其也会使我们易于建立 可重用的，通用的模块。比如我们可以在整个 app 中使用同样的 AuthenticationModule。我们可以在开发环境中运行 DevLoggingModule 而在生产环境中运行 ProdLoggingModule 来获得每种场景下的正确行为。 Dagger 2有何不同？依赖注入 框架已经存在很多年了，并且配置和注入都有了一大堆的可用 API 。所以，为什么要重新造轮子？Dagger 2是第一个实现了 生成代码的完整栈。这个原则是为了通过产生代码了减少我们需要手写的代码，以此来保证 依赖注入的 尽可能简单，可追踪和更好的性能。 使用 Dagger我们通过构建一个咖啡制造机来演示依赖注入和 Dagger。完整的例子见 这里 声明依赖Dagger 构建应用中的类实例并满足他们的依赖。其使用 javax.inject.Inject 注解来分辨哪些构造器或者字段是其感兴趣的。 使用 @Inject 来注解一个 Dagger 应该用来创建一个类实例的构造器。但需要一个新实例的时候，Dagger 会获取需要的参数值，然后调用这个构造器。 class Thermosiphon implements Pump &#123; private final Heater heater; @Inject Thermosiphon(Heater heater) &#123; this.heater = heater; &#125; ...&#125; Dagger 可以直接注入字段。在下面的例子中，Dagger 会为 header 字段获取一个 Heater 实例，为 pump 字段获取一个 Pump 实例。 class CoffeeMaker &#123; @Inject Heater heater; @Inject Pump pump; ...&#125; 如果我们的类有 @Inject 注解的字段，但是没有 @Inject 注解的构造器，Dagger 会在需要的时候注入这个字段，但不会建立一个新实例。那么，为一个 无参数的 构造器添加 @Inject 来告诉 Dagger 也应该建立新实例。 Dagger 也支持方法注入，尽管构造器或字段注入是最典型的。 没有 @Inject 注解的类不会被 Dagger 构建。 满足依赖默认情况下，Dagger 通过为每个需要的类型构造一个新的实例来满足依赖。 当我们需要一个 CoffeeMaker 的时候，其会通过调用 new CoffeeMaker() 并设置其中可注入的字段来获得。 但是 @Inject 并不是可以在任何地方工作： 接口 不能 被构建 第三方类 不能 被注解 可配置的类必须被配置好 这样的情况下使用 @Inject 就比较尴尬了，我们使用 @Provider 注解方法来满足一个依赖。 这个方法的返回类型定义了其满足的是哪个依赖。 例如，当需要一个 Heater 的时候，就会调用 provideHeater()。 @Provides static Heater provideHeater() &#123; return new ElectricHeater();&#125; @Provides 注解的方法有依赖也是可能的，比如下面这个例子，当需要一个 Pump 的时候，会返回 Thermosiphon。因为在上面的代码中，Thermosiphon 继承了 Pump 。 @Provides static Pump providePump(Thermosiphon pump) &#123; return pump;&#125; 所有 @Providers 方法必须属于一个模块。这个模块也就只是一个拥有 @Module 注解的类而已。 @Moduleclass DripCoffeeModule &#123; @Provides static Heater provideHeater() &#123; return new ElectricHeater(); &#125; @Provides static Pump providePump(Thermosiphon pump) &#123; return pump; &#125;&#125; 作为一个约定，@Provides 方法以提供前缀命名，模块类以 Module 后缀命名。 构建图@Inject 和 @Provides 注解的类形成了一个对象图，相互之间通过依赖关系连接。调用类似于应用的 main() 方法或者 安卓的 Application，在其中通过一个明确定义的根集合来访问图。 在 Dagger 2 中，这个集合通过一个包含一些返回我们期待类型的无参数方法。通过给这样一个接口加上 @Component注解，并给 此注解的 module 参数传递一个 Module 类型，然后 Dagger 2会完成生成这样一个约束的实现。 @Component(modules = DripCoffeeModule.class)interface CoffeeShop &#123; CoffeeMaker maker();&#125; 这个实现和接口的名称相同，不过加上了一个 Dagger 前缀。通过这个实现的 builder() 方法来获取一个实例，使用 builder() 返回的 builder 来设置依赖和 build() 一个新实例。 CoffeeShop coffeeShop = DaggerCoffeeShop.builder() .dripCoffeeModule(new DripCoffeeModule()) .build(); 注意，如果我们的 @Component 不是一个顶层的类型，所产生的类的名字略有不同。比如： class Foo &#123; static class Bar &#123; @Component interface BazComponent &#123;&#125; &#125;&#125; 产生的组件名称为 DaggerFoo_Bar_BazComponent。 任何具有可访问的默认构造函数的模块都可以省略，因为如果没有设置，构建器将自动构造实例。对于任何@Provides方法都是静态的模块，实现根本不需要实例。如果可以在没有用户创建依赖项实例的情况下构造所有依赖项，那么生成的实现也将具有create（）方法，该方法可用于获取新实例而无需处理构建器。 CoffeeShop coffeeShop = DaggerCoffeeShop.create(); 现在，我们的CoffeeApp可以简单地使用Dagger生成的CoffeeShop实现来获得完全注入的CoffeeMaker。 public class CoffeeApp &#123; public static void main(String[] args) &#123; CoffeeShop coffeeShop = DaggerCoffeeShop.create(); coffeeShop.maker().brew(); &#125;&#125; 现在构建了图形并注入了入口点，我们运行了我们的咖啡机应用程序。 $ java -cp ... coffee.CoffeeApp~ ~ ~ heating ~ ~ ~=&gt; =&gt; pumping =&gt; =&gt; [_]P coffee! [_]P 图中的绑定 上面的示例显示了如何使用一些更典型的绑定构造组件，但是有多种机制可以为图形提供绑定。 以下可用作依赖项，可用于生成格式良好的组件： Those declared by @Provides methods within a @Module referenced directly by @Component.modules or transitively via @Module.includes Any type with an @Inject constructor that is unscoped or has a @Scope annotation that matches one of the component’s scopes The component provision methods of the component dependencies The component itself Unqualified builders for any included subcomponent Provider or Lazy wrappers for any of the above bindings A Provider of a Lazy of any of the above bindings (e.g., Provider","categories":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/tags/Java/"},{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"},{"name":"Dagger","slug":"Dagger","permalink":"https://gowa2017.github.io/tags/Dagger/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}]},{"title":"在macOS上安装apache与php环境","slug":"在macOS上安装apache与php环境","date":"2018-11-19T05:41:38.000Z","updated":"2018-11-19T05:41:38.000Z","comments":true,"path":"macOS/在macOS上安装apache与php环境.html","link":"","permalink":"https://gowa2017.github.io/macOS/在macOS上安装apache与php环境.html","excerpt":"为了测试而用。 macOS High Sierra 已经预装了 php7 我们只需要把他进行启用就行了。 修改配置文件sudo vim /etc/apache2/httpd.conf 去掉这一行前的注释： #LoadModule php7_module libexec/apache2/libphp7.so 启动命令","text":"为了测试而用。 macOS High Sierra 已经预装了 php7 我们只需要把他进行启用就行了。 修改配置文件sudo vim /etc/apache2/httpd.conf 去掉这一行前的注释： #LoadModule php7_module libexec/apache2/libphp7.so 启动命令 sudo apachectl restart 完整版： Usage: /usr/sbin/httpd [-D name] [-d directory] [-f file] [-C \"directive\"] [-c \"directive\"] [-k start|restart|graceful|graceful-stop|stop] [-v] [-V] [-h] [-l] [-L] [-t] [-T] [-S] [-X]Options: -D name : define a name for use in &lt;IfDefine name&gt; directives -d directory : specify an alternate initial ServerRoot -f file : specify an alternate ServerConfigFile -C \"directive\" : process directive before reading config files -c \"directive\" : process directive after reading config files -e level : show startup errors of level (see LogLevel) -E file : log startup errors to file -v : show version number -V : show compile settings -h : list available command line options (this page) -l : list compiled in modules -L : list available configuration directives -t -D DUMP_VHOSTS : show parsed vhost settings -t -D DUMP_RUN_CFG : show parsed run settings -S : a synonym for -t -D DUMP_VHOSTS -D DUMP_RUN_CFG -t -D DUMP_MODULES : show all loaded modules -M : a synonym for -t -D DUMP_MODULES -t -D DUMP_INCLUDES: show all included configuration files -t : run syntax check for config files -T : start without DocumentRoot(s) check -X : debug mode (only one worker, do not detach) 更改网站目录打开 /etc/apache2/httpd.conf 文件，然后修改 DocumentRoot &quot;/Library/WebServer/Documents&quot;&lt;Directory &quot;/Library/WebServer/Documents&quot;&gt; 把这个替换为我们自己的目录： DocumentRoot &quot;/usr/local/var/www&quot;&lt;Directory &quot;usr/local/var/www&quot;&gt; 在我们的目录下建立新文件 index.php &lt;?phpinfo();?&gt; 重启sudo apachectl restart","categories":[{"name":"macOS","slug":"macOS","permalink":"https://gowa2017.github.io/categories/macOS/"}],"tags":[{"name":"macOS","slug":"macOS","permalink":"https://gowa2017.github.io/tags/macOS/"},{"name":"php","slug":"php","permalink":"https://gowa2017.github.io/tags/php/"},{"name":"apache","slug":"apache","permalink":"https://gowa2017.github.io/tags/apache/"}],"keywords":[{"name":"macOS","slug":"macOS","permalink":"https://gowa2017.github.io/categories/macOS/"}]},{"title":"Android-Studio将一个项目以Module形式的引入及遇到的坑","slug":"Android-Studio将一个项目以Module形式的引入及遇到的坑","date":"2018-11-15T14:05:58.000Z","updated":"2018-11-15T14:05:58.000Z","comments":true,"path":"Android/Android-Studio将一个项目以Module形式的引入及遇到的坑.html","link":"","permalink":"https://gowa2017.github.io/Android/Android-Studio将一个项目以Module形式的引入及遇到的坑.html","excerpt":"公司买了蓝牙指纹设备，需要在APP上集成，设备方提供了一个测试的APP及相关的代码。想着手动集成有点类，要是能把整个项目直接以Module形式或者是以Jar包的形式来处理的话，那就完毕了。","text":"公司买了蓝牙指纹设备，需要在APP上集成，设备方提供了一个测试的APP及相关的代码。想着手动集成有点类，要是能把整个项目直接以Module形式或者是以Jar包的形式来处理的话，那就完毕了。搜索了一下，还真有。但需要一步步来。 导入Module在 Android Studio 上点击 File -&gt; New -&gt; Import Module 现在我们要导入的项目 APP文件夹 路径。我的项目我把新的Module 名称叫做 fgtitReader。 导入Module build.gralde 修改修改应用插件将 apply plugin: &#39;com.android.application&#39;改为apply plugin: &#39;com.android.library&#39; 删除 applicationId在我们导入的 fgtitReader 的 build.gradle 内，删除调 applicationId 设备。 AndroidManifest.xml修改将这个文件中的登录 Activity 改为普通的 Activity。 &lt;intent-filter&gt; &lt;action android:name=\"android.intent.action.MAIN\" /&gt; &lt;category android:name=\"android.intent.category.LAUNCHER\" /&gt;&lt;/intent-filter&gt; 把这几行去掉。 遇到的问题编译出错编译的时候出错了： Constant expression required Resource IDs cannot be used in a switch statement in Android library modules less... (⌘F1) Validates using resource IDs in a switch statement in Android library module. Resource IDs are non final in the library projects since SDK tools r14, means that the library code cannot treat these IDs as constants 哎哟，属于 library 库内的资源 ID 是不是 final 的，无法作为 switch 的 case 比较，而主模块中的就可以。 那么，以 if ... else ... 来替换吧。 把鼠标放在 case 语句上的时候，会出现一个感叹号，点击一下，就会出现一个替换语句。 编译以命令 ./gradlew fgtitReader:assemble 会打包出来一个 aar 文件。","categories":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"}],"keywords":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}]},{"title":"TensorFlow中的反向传播","slug":"TensorFlow中的反向传播","date":"2018-11-14T16:59:24.000Z","updated":"2018-11-14T16:59:24.000Z","comments":true,"path":"TensorFlow/TensorFlow中的反向传播.html","link":"","permalink":"https://gowa2017.github.io/TensorFlow/TensorFlow中的反向传播.html","excerpt":"反向传播算法对于快速训练大型神经网络来说至关重要。本文将介绍该算法的工作原理。来源于谷歌对神经网络的一个简单展示。原文地址：反向传播算法","text":"反向传播算法对于快速训练大型神经网络来说至关重要。本文将介绍该算法的工作原理。来源于谷歌对神经网络的一个简单展示。原文地址：反向传播算法 简单的神经网络在上边，您会看到一个神经网络，其中包含一个输入节点、一个输出节点，以及两个隐藏层（分别有两个节点）。 相邻的层中的节点通过权重 𝑤_{𝑖𝑗} 相关联，这些权重是网络参数。 激活函数每个节点都有一个总输入 𝑥、一个激活函数 𝑓(𝑥) 以及一个输出 𝑦=𝑓(𝑥)。 𝑓(𝑥) 必须是非线性函数，否则神经网络就只能学习线性模型。 常用的激活函数是 S 型函数：f(\\color{input}x\\color{black}) = \\frac{1}{1+e^{-\\color{input}x}} 误差函数 目标是根据数据自动学习网络的权重，以便让所有输入 x_{input} 的预测输出 y_{output} 接近目标 y_{target}。 为了衡量与该目标的差距，我们使用了一个误差函数 𝐸。 常用的误差函数是 E(\\color{output}y_{output}\\color{black},\\color{output}y_{target}\\color{black}) = \\frac{1}{2}(\\color{output}y_{output}\\color{black} - \\color{output}y_{target}\\color{black})^2 正向传播首先，我们取一个输入样本 (\\color{input}x_{input}\\color{black},\\color{output}y_{target}\\color{black})，并更新网络的输入层。 为了保持一致性，我们将输入视为与其他任何节点相同，但不具有激活函数，以便让其输出与输入相等，即\\color{output}y_1 \\color{black} = \\color{input} x_{input}。 更新隐藏层 现在，我们更新第一个隐藏层。我们取上一层节点的输出 \\color{output}y，并使用权重来计算下一层节点的输入 \\color{input}x。 \\color{input} x_j \\color{black} = \\sum_{i\\in in(j)} w_{ij}\\color{output} y_i\\color{black} +b_j 然后，我们更新第一个隐藏层中节点的输出。为此，我们使用激活函数 f(x)。 \\color{output} y \\color{black} = f(\\color{input} x \\color{black}) 使用这两个公式，我们可以传播到网络的其余内容，并获得网络的最终输出。 \\color{output} y \\color{black} = f(\\color{input} x \\color{black})\\color{input} x_j \\color{black} = \\sum_{i\\in in(j)} w_{ij}\\color{output} y_i \\color{black} + b_j误差导数 反向传播算法会对特定样本的预测输出和理想输出进行比较，然后确定网络的每个权重的更新幅度。 为此，我们需要计算误差相对于每个权重\\frac{dE}{dw_{ij}} 的变化情况。 获得误差导数后，我们可以使用一种简单的更新法则来更新权重： w_{ij} = w_{ij} - \\alpha \\frac{dE}{dw_{ij}}其中，𝛼 是一个正常量，称为“学习速率”，我们需要根据经验对该常量进行微调。 [注意] 该更新法则非常简单：如果在权重提高后误差降低了(\\frac{dE}{dw_{ij}} < 0)，则提高权重；否则，如果在权重提高后误差也提高了 (\\frac{dE}{dw_{ij}} > 0)，则降低权重。 其他导数 为了帮助计算 \\frac{dE}{dw_{ij}}，我们还为每个节点分别存储了另外两个导数，即误差随以下两项的变化情况： 节点 \\frac{dE}{dx} 的总输入，以及 \\frac{dE}{dy} 的输出 反向传播 我们开始反向传播误差导数。 由于我们拥有此特定输入样本的预测输出，因此我们可以计算误差随该输出的变化情况。 E = \\frac{1}{2}(\\color{output}y_{output}\\color{black} - \\color{output}y_{target}\\color{black})^2我们可以得出： \\frac{\\partial E}{\\partial y_{output}} = y_{output} - y_{target} 现在我们获得了\\frac{dE}{dy}，接下来便可以根据链式法则得出 \\frac{dE}{dx}。 \\frac{\\partial E}{\\partial x} = \\frac{dy}{dx}\\frac{\\partial E}{\\partial y} = \\frac{d}{dx}f(x)\\frac{\\partial E}{\\partial y}其中，当 f(\\color{input}x\\color{black})是 S 型激活函数时，\\frac{d}{dx}f(\\color{input}x\\color{black}) = f(\\color{input}x\\color{black})(1 - f(\\color{input}x\\color{black})) 一旦得出相对于某节点的总输入的误差导数，我们便可以得出相对于进入该节点的权重的误差导数。 \\frac{\\partial E}{\\partial w_{ij}} = \\frac{\\partial x_j}{\\partial w_{ij}} \\frac{\\partial E}{\\partial x_j} = y_i \\frac{\\partial E}{\\partial x_j} 根据链式法则，我们还可以根据上一层得出 \\frac{dE}{dy}。此时，我们形成了一个完整的循环。 \\frac{\\partial E}{\\partial y_i} = \\sum_{j\\in out(i)} \\frac{\\partial x_j}{\\partial y_i} \\frac{\\partial E}{\\partial x_j} = \\sum_{j\\in out(i)} w_{ij} \\frac{\\partial E}{\\partial x_j}接下来，只需重复前面的 3 个公式，直到计算出所有误差导数即可。 BPTTBPTT 是 Backpropagation through time 的缩写。在 RNN 中这是对传统 反向传播BP的一个扩展。 因为在 RNN 中，我们无法直接应用 反向传播算法，因为在计算图中 RNN 网络是循环的。所以我们就会将 RNN 进行展开。 这样，RNN 就可以看作是一个前馈网络，我们就可以使用 BP 了。 但是，因为有 梯度消失/梯度爆炸的情况，想要将梯度传播到多个层后非常的困难。此外，展开RNN并为一个非常长的序列传播梯度的计算要求非常大。 所以才出现了 BPTT，他背后的基本思想是：每次处理一个时间步长的序列，每处理 K1 步长，然后运行 BTPP K2 个步长。 反向传播的截短通过设计，递归神经网络（RNN）的输出取决于任意远距离的输入。不幸的是，这使得反向传播计算变得困难。为了使学习过程易于处理，通常的做法是创建网络的“展开”版本，其中包含固定数量（num_steps）的LSTM输入和输出。然后在RNN的这种有限近似上训练该模型。这可以通过一次馈送长度输入num_steps并在每个这样的输入块之后执行反向传递来实现。 这是一个简化的代码块，用于创建执行截断反向传播的图形： # Placeholder for the inputs in a given iteration.words = tf.placeholder(tf.int32, [batch_size, num_steps])lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)# Initial state of the LSTM memory.initial_state = state = lstm.zero_state(batch_size, dtype=tf.float32)for i in range(num_steps): # The value of state is updated after processing each batch of words. output, state = lstm(words[:, i], state) # The rest of the code. # ...final_state = state 在所有数据集上实现迭代： # A numpy array holding the state of LSTM after each batch of words.numpy_state = initial_state.eval()total_loss = 0.0for current_batch_of_words in words_in_dataset: numpy_state, current_loss = session.run([final_state, loss], # Initialize the LSTM state from the previous iteration. feed_dict=&#123;initial_state: numpy_state, words: current_batch_of_words&#125;) total_loss += current_loss","categories":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://gowa2017.github.io/categories/TensorFlow/"}],"tags":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://gowa2017.github.io/tags/TensorFlow/"}],"keywords":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://gowa2017.github.io/categories/TensorFlow/"}]},{"title":"TensorFlow模型建立过程","slug":"TensorFlow模型建立过程","date":"2018-11-14T13:50:38.000Z","updated":"2018-11-14T13:50:38.000Z","comments":true,"path":"TensorFlow/TensorFlow模型建立过程.html","link":"","permalink":"https://gowa2017.github.io/TensorFlow/TensorFlow模型建立过程.html","excerpt":"简单的总结一下 TensorFlow 建立模型进行使用的过程。嗯，到现在为止，一直想要研究一下怎么样整一个神经网络来预测二进制的序列，一直感觉看得如天书一般 ，不知道是如何进行的，所以还是从头开始来。","text":"简单的总结一下 TensorFlow 建立模型进行使用的过程。嗯，到现在为止，一直想要研究一下怎么样整一个神经网络来预测二进制的序列，一直感觉看得如天书一般 ，不知道是如何进行的，所以还是从头开始来。 概括简单来说，我们建立一个模型。然后给出一定的带标签的样本数据，传递给模型。模型在训练过程中会计算出每次训练的损失，然后逐渐的改变我们模型中的权重参数，最终达到让我们的损失到达一个期望值。就可以说模型收敛了。 神经网络中的几个概念 epoch 对所有训练数据的一次 前向传递 和 反向传递。 batch size 在一次 前向/反向 传递中训练样本数。此值越大，需要的内存就越大。 iterations 数量 = 传递次数。每次传递使用 [batch size] 个样本。更清晰一点说明 一次传递 = 一次反向传递 + 一次前向传递。 比如： 如果有 1000 个样本， batch size 是500， 那么就会需要 2 次遍历来完成 1 次 epoch。 例子以一个线性回归的例子来进行解析说明。 '''A linear regression learning algorithm example using TensorFlow library.Author: Aymeric DamienProject: https://github.com/aymericdamien/TensorFlow-Examples/'''from __future__ import print_functionimport tensorflow as tfimport numpyimport matplotlib.pyplot as pltrng = numpy.random# 训练参数learning_rate = 0.01 # 学习速率，梯度下降是用来选择下一个点training_epochs = 1000 # 训练次数display_step = 50 # 训练中显示的步长# Training Datatrain_X = numpy.asarray([3.3,4.4,5.5,6.71,6.93,4.168,9.779,6.182,7.59,2.167, 7.042,10.791,5.313,7.997,5.654,9.27,3.1]) # 样本train_Y = numpy.asarray([1.7,2.76,2.09,3.19,1.694,1.573,3.366,2.596,2.53,1.221, 2.827,3.465,1.65,2.904,2.42,2.94,1.3]) # 标签n_samples = train_X.shape[0] # 样本数量# tf Graph InputX = tf.placeholder(\"float\")Y = tf.placeholder(\"float\")# Set model weightsW = tf.Variable(rng.randn(), name=\"weight\")b = tf.Variable(rng.randn(), name=\"bias\")# Construct a linear model# 类似于输出为 y = wx + bpred = tf.add(tf.multiply(X, W), b)# Mean squared error 均方差cost = tf.reduce_sum(tf.pow(pred-Y, 2))/(2*n_samples)# Gradient descent 梯度下降# 这里 minimize() 知道需要修改 W and b ，因为默认情况下变量是可训练的。optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)# Initialize the variables (i.e. assign their default value)init = tf.global_variables_initializer()# Start trainingwith tf.Session() as sess: # Run the initializer sess.run(init) # Fit all training data for epoch in range(training_epochs): for (x, y) in zip(train_X, train_Y): sess.run(optimizer, feed_dict=&#123;X: x, Y: y&#125;) # Display logs per epoch step if (epoch+1) % display_step == 0: c = sess.run(cost, feed_dict=&#123;X: train_X, Y:train_Y&#125;) print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"&#123;:.9f&#125;\".format(c), \\ \"W=\", sess.run(W), \"b=\", sess.run(b)) print(\"Optimization Finished!\") training_cost = sess.run(cost, feed_dict=&#123;X: train_X, Y: train_Y&#125;) print(\"Training cost=\", training_cost, \"W=\", sess.run(W), \"b=\", sess.run(b), '\\n') # Graphic display plt.plot(train_X, train_Y, 'ro', label='Original data') plt.plot(train_X, sess.run(W) * train_X + sess.run(b), label='Fitted line') plt.legend() plt.show() # Testing example, as requested (Issue #2) test_X = numpy.asarray([6.83, 4.668, 8.9, 7.91, 5.7, 8.7, 3.1, 2.1]) test_Y = numpy.asarray([1.84, 2.273, 3.2, 2.831, 2.92, 3.24, 1.35, 1.03]) print(\"Testing... (Mean square loss Comparison)\") testing_cost = sess.run( tf.reduce_sum(tf.pow(pred - Y, 2)) / (2 * test_X.shape[0]), feed_dict=&#123;X: test_X, Y: test_Y&#125;) # same function as cost above print(\"Testing cost=\", testing_cost) print(\"Absolute mean square loss difference:\", abs( training_cost - testing_cost)) plt.plot(test_X, test_Y, 'bo', label='Testing data') plt.plot(train_X, sess.run(W) * train_X + sess.run(b), label='Fitted line') plt.legend() plt.show() 总结基本过程如下： 准备我们的样本数据（带标签的） 建立模型 选择损失函数 训练","categories":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://gowa2017.github.io/categories/TensorFlow/"}],"tags":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://gowa2017.github.io/tags/TensorFlow/"}],"keywords":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://gowa2017.github.io/categories/TensorFlow/"}]},{"title":"Android-Application启动流程分析","slug":"Android-Application启动流程分析","date":"2018-11-13T19:18:35.000Z","updated":"2018-11-13T19:18:35.000Z","comments":true,"path":"Android/Android-Application启动流程分析.html","link":"","permalink":"https://gowa2017.github.io/Android/Android-Application启动流程分析.html","excerpt":"来自于国外博客的译文，原文地址：Android-Application启动流程分析","text":"来自于国外博客的译文，原文地址：Android-Application启动流程分析 基础理论 每个Android App都在一个独立空间里, 意味着其运行在一个单独的进程中, 拥有自己的VM, 被系统分配一个唯一的user ID. Android App由很多不同组件组成, 这些组件还可以启动其他App的组件. 因此, Android App并没有一个类似程序入口的main()方法. 四大组件： Activities: 前台界面, 直接面向User, 提供UI和操作. Services: 后台任务. Broadcast Receivers: 广播接收者. Contexnt Providers: 数据提供者. Android进程与Linux进程一样. 默认情况下, 每个apk运行在自己的Linux进程中. 另外, 默认一个进程里面只有一个线程—-主线程. 这个主线程中有一个Looper实例, 通过调用Looper.loop()从Message队列里面取出Message来做相应的处理. 系统启动过程首先, 让我们快速看下 Android 启动流程. 与众多基于 Linux 内核的系统类似, 启动系统时, bootloader 启动内核和 init 进程. init 进程分裂出更多名为”daemons(守护进程)”的底层的 Linux 进程, 诸如android debug deamon, USB deamon等. 这些守护进程处理底层硬件相关的接口. 随后, init进程会启动一个非常有意思的进程—-“Zygote“. 顾名思义, 这是一个Android平台的非常基础的进程. 这个进程初始化了第一个VM, 并且预加载了framework和众多App所需要的通用资源. 然后它开启一个Socket接口来监听请求, 根据请求孵化出新的VM来管理新的App进程. 一旦收到新的请求, Zygote会基于自身预先加载的VM来孵化出一个新的VM创建一个新的进程. 启动Zygote之后, init进程会启动runtime进程. Zygote会孵化出一个超级管理进程—-System Server. SystemServer会启动所有系统核心服务, 例如Activity Manager Service, 硬件相关的Service等. 到此, 系统准备好启动它的第一个App进程—-Home进程了. APP启动过程 Click事件会调用startActivity(Intent), 会通过Binder IPC机制, 最终调用到ActivityManagerService. 该Service会执行如下操作: 第一步通过PackageManager的resolveIntent()收集这个intent对象的指向信息.指向信息被存储在一个intent对象中. 下面重要的一步是通过grantUriPermissionLocked()方法来验证用户是否有足够的权限去调用该intent对象指向的Activity. 如果有权限, ActivityManagerService会检查并在新的task中启动目标activity. 现在, 是时候检查这个进程的ProcessRecord是否存在了. 如果ProcessRecord是null, ActivityManagerService会创建新的进程来实例化目标activity. 进程创建ActivityManagerService调用startProcessLocked()方法来创建新的进程, 该方法会通过前面讲到的socket通道传递参数给Zygote进程. Zygote孵化自身, 并调用ZygoteInit.main()方法来实例化ActivityThread对象并最终返回新进程的pid. ActivityThread随后依次调用Looper.prepareLoop()和Looper.loop()来开启消息循环. 绑定Application接下来要做的就是将进程和指定的Application绑定起来. 这个是通过上节的ActivityThread对象中调用bindApplication()方法完成的. 该方法发送一个BIND_APPLICATION的消息到消息队列中, 最终通过handleBindApplication()方法处理该消息. 然后调用makeApplication()方法来加载App的classes到内存中. 启动Activity经过前两个步骤之后, 系统已经拥有了该application的进程. 后面的调用顺序就是普通的从一个已经存在的进程中启动一个新进程的activity了. 实际调用方法是realStartActivity(), 它会调用application线程对象中的sheduleLaunchActivity()发送一个LAUNCH_ACTIVITY消息到消息队列中, 通过 handleLaunchActivity()来处理该消息.","categories":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"},{"name":"Application","slug":"Application","permalink":"https://gowa2017.github.io/tags/Application/"}],"keywords":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}]},{"title":"Android的文件系统探究","slug":"Android的文件系统探究","date":"2018-11-13T14:50:05.000Z","updated":"2018-11-13T14:50:05.000Z","comments":true,"path":"Android/Android的文件系统探究.html","link":"","permalink":"https://gowa2017.github.io/Android/Android的文件系统探究.html","excerpt":"嗯，虽说官方文档上对于安卓的文件系统分为内部和外部两个部分，但是还是需要自己来看一下具体到底是怎么样的才比较放心。当然，其实只是做开发的话已经足够了，参考官方文档：https://developer.android.com/guide/topics/data/data-storage","text":"嗯，虽说官方文档上对于安卓的文件系统分为内部和外部两个部分，但是还是需要自己来看一下具体到底是怎么样的才比较放心。当然，其实只是做开发的话已经足够了，参考官方文档：https://developer.android.com/guide/topics/data/data-storage 前言Android 的底层其实是 Linux 内核，所以我们可以从这里着手来看。先把我们的设备用 adb 连上。 adb shell mount | sort -k 3 | awk &apos;&#123;print $3,$5,$1,$6&#125; &apos;/ rootfs rootfs (ro,seclabel)/acct cgroup none (rw,relatime,cpuacct)/bt_firmware vfat /dev/block/mmcblk0p38 (ro,context=u:object_r:bt_firmware_file:s0,relatime,uid=1002,gid=3002,fmask=0337,dmask=0227,codepage=437,iocharset=iso8859-1,shortname=lower,errors=remount-ro)/cache ext4 /dev/block/mmcblk0p60 (rw,seclabel,nosuid,nodev,noatime,data=ordered)/config configfs none (rw,relatime)/cust ext4 /dev/block/mmcblk0p63 (ro,seclabel,nosuid,nodev,relatime,data=ordered)/data ext4 /dev/block/dm-2 (rw,lazytime,seclabel,nosuid,nodev,noatime,nobarrier,noauto_da_alloc,resgid=1065,errors=panic,data=ordered)/dev tmpfs tmpfs (rw,seclabel,nosuid,relatime,size=1383624k,nr_inodes=345906,mode=755)/dev/blkio cgroup none (rw,relatime,blkio)/dev/cpuctl cgroup none (rw,relatime,cpu)/dev/cpuset cgroup none (rw,relatime,cpuset,noprefix,release_agent=/sbin/cpuset_release_agent)/dev/memcg cgroup none (rw,relatime,memory)/dev/pts devpts devpts (rw,seclabel,relatime,mode=600)/dev/stune cgroup none (rw,relatime,schedtune)/dev/usb-ffs/adb functionfs adb (rw,relatime)/dsp ext4 /dev/block/mmcblk0p48 (ro,seclabel,nosuid,nodev,relatime,data=ordered)/firmware vfat /dev/block/mmcblk0p56 (ro,context=u:object_r:firmware_file:s0,relatime,uid=1000,gid=1000,fmask=0337,dmask=0227,codepage=437,iocharset=iso8859-1,shortname=lower,errors=remount-ro)/mnt tmpfs tmpfs (rw,seclabel,relatime,size=1383624k,nr_inodes=345906,mode=755,gid=1000)/mnt/runtime/default/emulated sdcardfs /data/media (rw,nosuid,nodev,noexec,noatime,fsuid=1023,fsgid=1023,gid=1015,multiuser,mask=6,derive_gid)/mnt/runtime/read/emulated sdcardfs /data/media (rw,nosuid,nodev,noexec,noatime,fsuid=1023,fsgid=1023,gid=9997,multiuser,mask=23,derive_gid)/mnt/runtime/write/emulated sdcardfs /data/media (rw,nosuid,nodev,noexec,noatime,fsuid=1023,fsgid=1023,gid=9997,multiuser,mask=7,derive_gid)/persist ext4 /dev/block/mmcblk0p53 (rw,seclabel,nosuid,nodev,noatime,data=ordered)/persistbak ext4 /dev/block/mmcblk0p54 (rw,seclabel,nosuid,nodev,noatime,data=ordered)/proc proc proc (rw,relatime,gid=3009,hidepid=2)/storage tmpfs tmpfs (rw,seclabel,relatime,size=1383624k,nr_inodes=345906,mode=755,gid=1000)/storage/emulated sdcardfs /data/media (rw,nosuid,nodev,noexec,noatime,fsuid=1023,fsgid=1023,gid=1015,multiuser,mask=6,derive_gid)/sys sysfs sysfs (rw,seclabel,relatime)/sys/fs/cgroup tmpfs none (rw,seclabel,relatime,size=1383624k,nr_inodes=345906,mode=750,gid=1000)/sys/fs/cgroup/freezer cgroup none (rw,relatime,freezer)/sys/fs/cgroup/memory cgroup none (rw,relatime,memory)/sys/fs/pstore pstore pstore (rw,seclabel,relatime)/sys/fs/selinux selinuxfs selinuxfs (rw,relatime)/sys/kernel/debug debugfs debugfs (rw,seclabel,relatime)/sys/kernel/debug/tracing tracefs tracefs (rw,seclabel,relatime)/system ext4 /dev/block/dm-0 (ro,seclabel,relatime,discard,data=ordered)/vendor ext4 /dev/block/dm-1 (ro,seclabel,relatime,discard,data=ordered) 由左至右分别是挂载目录，文件系统类型，设备，挂载信息。这个其实很多文件系统属于内存文件系统等等。我们可以用另外一种方式来查看。 adb shell df -h 1 ↵Filesystem Size Used Avail Use% Mounted ontmpfs 1.3G 760K 1.3G 1% /dev/dev/block/dm-0 2.8G 2.4G 356M 88% /system/dev/block/dm-1 1.9G 727M 1.1G 38% /vendortmpfs 1.3G 0 1.3G 0% /mntnone 1.3G 0 1.3G 0% /sys/fs/cgroup/dev/block/mmcblk0p63 806M 318M 472M 41% /cust/dev/block/mmcblk0p56 192M 105M 87M 55% /firmware/dev/block/mmcblk0p38 64M 480K 63M 1% /bt_firmware/dev/block/mmcblk0p48 12M 7.3M 4.1M 64% /dsp/dev/block/mmcblk0p60 232M 16M 208M 8% /cache/dev/block/mmcblk0p53 27M 656K 26M 3% /persist/dev/block/dm-2 22G 13G 9.0G 59% /data/data/media 22G 13G 9.0G 59% /storage/emulated 我们重点看看 /dev/block/dm-N 类似的设备。我这个手机中有三个这样的设备。 /dev/block/dm-0 2.8G 2.4G 356M 88% /system/dev/block/dm-1 1.9G 727M 1.1G 38% /vendor/dev/block/dm-2 22G 13G 9.0G 59% /data/data/media 22G 13G 9.0G 59% /storage/emulated/ 可以看到，这三个设备都挂载到了对应的目录。 system, vendor, data 分别是我们的系统相关目录，厂商相关目录及数据相关目录。 dm设备，即是 Device Mapper 的意思。利用这种机制， Linux 内核可以将块设备（我们的磁盘存储）映射到虚拟块设备的意思。比如 LVM。就是利用这个机制，将多个物理盘（PV），组合成一个 卷组（VG），然后，在卷组上开辟多个逻辑分区（LV）的实现。 名称不重要，我们可以这样理解的就是，我们的手机上有一个物理存储设备，然后在这个物理设备上虚拟出了几个虚拟的块设备的样子。然后分别把这些块设备挂载到我们的目录上。 内部存储与外部存储早期的安卓系统，把存储设备分为内部和外部。需要共享的数据放在外部，而只有自己的应用可以使用的数据则可以放到内部存储。早期的设备内部存储都很小，多数都是以 sdcard 的形式来扩充外部存储。 而到了后期的话我们基本都不用内存卡了啊，全部都是手机自带的存储了。可能是为了兼容，依然在我们的存储设备上划分出了内部与外部两个区域。 sdcard 目录通过观察，我发现，在根目录下的 /sdcard 目录，其实是一个软链接。 ls -l /sdcard -&gt; /storage/self/primaryls -l /storage/self/primarylrwxrwxrwx 1 root root 19 1970-08-14 13:50 /storage/self/primary -&gt; /mnt/user/0/primaryls -l /mnt/user/0/primarylrwxrwxrwx 1 root root 19 2018-11-13 21:25 /mnt/user/0/primary -&gt; /storage/emulated/0 其最终其实是指向了 /storage/emulated/0 目录。而我们可以从上面的叙述中知道，此目录，实际上挂载的是 /data/media 设备。 因为实际上是以 符号链接的形式指向了 /storage/emulated/0 所以在我们获取外部存储目录的时候，得到的是 /storage/emulated/0 这个结果。 可以理解为，外部存储现在是用模拟的方式，以链接形式实现到了我们的手机存储设备上。最终，我们访问的都是 /dev/block/dm-2 这个设备 内部存储其实就是我们的 /data 目录。 ls /dataFTM_AP bootchart lct_diag nfc system adb cache local nvt_test system_ce anr connectivity lost+found ota system_de app dalvik-cache media ota_package time app-asec data mediadrm property tombstones app-ephemeral dpm misc resource-cache user app-lib drm misc_ce sdcard user_de app-private fota misc_de shared vendor backup hostapd mqsas ss 其中，app 下面是一些安装的软件。data 目录存储各软件私有的文件。 APIEnvironment通常，很多时候，我们可以看到，获取存储目录都是使用的 Environment 这个类。其提供了一些公共的方法来获取相关的信息。 我们从其常量的定义可以看出了一点线索： private static final String TAG = \"Environment\";private static final String ENV_EXTERNAL_STORAGE = \"EXTERNAL_STORAGE\";private static final String ENV_ANDROID_ROOT = \"ANDROID_ROOT\";private static final String ENV_ANDROID_DATA = \"ANDROID_DATA\";private static final String ENV_ANDROID_EXPAND = \"ANDROID_EXPAND\";private static final String ENV_ANDROID_STORAGE = \"ANDROID_STORAGE\";private static final String ENV_DOWNLOAD_CACHE = \"DOWNLOAD_CACHE\";private static final String ENV_OEM_ROOT = \"OEM_ROOT\";private static final String ENV_ODM_ROOT = \"ODM_ROOT\";private static final String ENV_VENDOR_ROOT = \"VENDOR_ROOT\";/** &#123;@hide&#125; */public static final String DIR_ANDROID = \"Android\";private static final String DIR_DATA = \"data\";private static final String DIR_MEDIA = \"media\";private static final String DIR_OBB = \"obb\";private static final String DIR_FILES = \"files\";private static final String DIR_CACHE = \"cache\";/** &#123;@hide&#125; */@Deprecatedpublic static final String DIRECTORY_ANDROID = DIR_ANDROID;private static final File DIR_ANDROID_ROOT = getDirectory(ENV_ANDROID_ROOT, \"/system\");private static final File DIR_ANDROID_DATA = getDirectory(ENV_ANDROID_DATA, \"/data\");private static final File DIR_ANDROID_EXPAND = getDirectory(ENV_ANDROID_EXPAND, \"/mnt/expand\");private static final File DIR_ANDROID_STORAGE = getDirectory(ENV_ANDROID_STORAGE, \"/storage\");private static final File DIR_DOWNLOAD_CACHE = getDirectory(ENV_DOWNLOAD_CACHE, \"/cache\");private static final File DIR_OEM_ROOT = getDirectory(ENV_OEM_ROOT, \"/oem\");private static final File DIR_ODM_ROOT = getDirectory(ENV_ODM_ROOT, \"/odm\");private static final File DIR_VENDOR_ROOT = getDirectory(ENV_VENDOR_ROOT, \"/vendor\"); 当我们系统在启动的时候，没有初始化 ENV_ 开头的那些环境变量的时候，其会在后面的 DIR_ 定义时获得一个默认值。比如我们的数据目录： private static final File DIR_ANDROID_DATA = getDirectory(ENV_ANDROID_DATA, \"/data\");private static final File DIR_ANDROID_STORAGE = getDirectory(ENV_ANDROID_STORAGE, \"/storage\"); 当我们调用 getExternalStorageDirectory() 时，其返回的实际上是第一个外部存储设备。 public static File getExternalStorageDirectory() &#123; throwIfUserRequired(); return sCurrentUser.getExternalDirs()[0];&#125; 其中有一个类 StorageManager 用来专门实现对我们的存储设备卷的管理功能。 public File[] getExternalDirs() &#123; final StorageVolume[] volumes = StorageManager.getVolumeList(mUserId, StorageManager.FLAG_FOR_WRITE); final File[] files = new File[volumes.length]; for (int i = 0; i &lt; volumes.length; i++) &#123; files[i] = volumes[i].getPathFile(); &#125; return files;&#125; 其会查询当前用户下的所有存储卷，然后返回第一个。 ContextContext是一个很重要的概念，但是我们可能一直不知道这个到底从哪里来。 安卓系统会为每个APP自动的新建一个 Application 类，这个类继承自 Context。但其构造出来的时候，其实是还没有上下文信息的。 public Application() &#123; super(null);&#125; 根据网络上的资料，其之后会调用 父类的 attachBaseContext() 方法，base 应该是由系统进行实现的： protected void attachBaseContext(Context base) &#123; if (mBase != null) &#123; throw new IllegalStateException(&quot;Base context already set&quot;); &#125; mBase = base;&#125; 最后才会调用自己的 onCreate() 方法。 外部存储当我在 Activity 中调用 getApplicationContext().getExternalMediaDirs()时，发现最终调用的是，ContextImpl 类中的方法： @Overridepublic File[] getExternalMediaDirs() &#123; synchronized (mSync) &#123; File[] dirs = Environment.buildExternalStorageAppMediaDirs(getPackageName()); return ensureExternalDirsExistOrFilter(dirs); &#125;&#125; 可以看到其也是通过 Environment 类来实现的。 而我调用 getApplicationContext().getFilesDir() 的时候，其却是通过另外一种方法来获取的： @Overridepublic File getDataDir() &#123; if (mPackageInfo != null) &#123; File res = null; if (isCredentialProtectedStorage()) &#123; res = mPackageInfo.getCredentialProtectedDataDirFile(); &#125; else if (isDeviceProtectedStorage()) &#123; res = mPackageInfo.getDeviceProtectedDataDirFile(); &#125; else &#123; res = mPackageInfo.getDataDirFile(); &#125; if (res != null) &#123; if (!res.exists() &amp;&amp; android.os.Process.myUid() == android.os.Process.SYSTEM_UID) &#123; Log.wtf(TAG, \"Data directory doesn't exist for package \" + getPackageName(), new Throwable()); &#125; return res; &#125; else &#123; throw new RuntimeException( \"No data directory found for package \" + getPackageName()); &#125; &#125; else &#123; throw new RuntimeException( \"No package details found for package \" + getPackageName()); &#125;&#125; 通过更多追踪发现，其是通过 LoadedApk 中的 getDataDirFile() 方法实现。 而继续追查下去，这其中的数据信息是在 ActivityThread.handleBindApplication 方法内构造时来的。 启动过程 安卓系统的 Zygote 进程 fork 一下自己。并调用ZygoteInit.main()方法来实例化ActivityThread对象。 返回进程 P。 ActivityThread调用bindApplication()方法，发送一个信息给本进程的 Looper。 ActivityThread调用handleBindApplication()进行绑定进程与APP的操作。这其中就会把app相关的信息存LoadedApk中。","categories":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"}],"keywords":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}]},{"title":"macOS的networksetup命令来管理网络","slug":"macOS的networksetup命令来管理网络","date":"2018-11-12T14:31:12.000Z","updated":"2018-11-12T14:31:12.000Z","comments":true,"path":"macOS/macOS的networksetup命令来管理网络.html","link":"","permalink":"https://gowa2017.github.io/macOS/macOS的networksetup命令来管理网络.html","excerpt":"主要的原因是需要在电脑上同时连接内外网的时候，每次都需要在我所使用的 Wi-Fi 网卡上附加一个我们内网的 IP：172.28.20.1/16 之后再加上一个路由。但是每次重启电脑后都得重新添加。当然，我们可以以脚本的形式在登录时进行执行，或者用 automator 建立一个小程序，给用户进行 LoginItems 内弄上。但这觉得都不是根本的解决办法。","text":"主要的原因是需要在电脑上同时连接内外网的时候，每次都需要在我所使用的 Wi-Fi 网卡上附加一个我们内网的 IP：172.28.20.1/16 之后再加上一个路由。但是每次重启电脑后都得重新添加。当然，我们可以以脚本的形式在登录时进行执行，或者用 automator 建立一个小程序，给用户进行 LoginItems 内弄上。但这觉得都不是根本的解决办法。 一句话介绍networksetup 是在系统偏好设置中对网络设定进行配置的工具。 networksetup 命令最少需要 admin 权限。 大多数的配置命令都需要 root 权限。 在任何需要密码的地方，可以用 - 代替，表示从标准输入读入密码。 概要networksetup [-listnetworkserviceorder] [-listallnetworkservices] [-listallhardwareports] [-detectnewhardware] [-getmacaddress hardwareport] [-getcomputername] [-setcomputername computername] [-getinfo networkservice] [-setmanual networkservice ip subnet router] [-setdhcp networkservice [clientid]] [-setbootp networkservice] [-setmanualwithdhcprouter networkservice ip] [-getadditionalroutes networkservice] [-setadditionalroutes networkservice [dest1 mask1 gate1] [dest2 mask2 gate2] ... [destN maskN gateN]] [-setv4off networkservice] [-setv6off networkservice] [-setv6automatic networkservice] [-setv6linklocal networkservice] [-setv6manual networkservice address prefixLength router] [-getv6additionalroutes networkservice] [-setv6additionalroutes networkservice [dest1 prefixlength1 gate1] [dest2 prefixlength2 gate2] ... [destN prefixlengthN gateN]] [-getdnsservers networkservice] [-setdnsservers networkservice dns1 [dns2] [...]] [-getsearchdomains networkservice] [-setsearchdomains networkservice domain1 [domain2] [...]] [-create6to4service networkservicename] [-set6to4automatic networkservice] [-set6to4manual networkservice relayAddress] [-getftpproxy networkservice] [-setftpproxy networkservice domain portnumber authenticated username password] [-setftpproxystate networkservice on | off] [-getwebproxy networkservice] [-setwebproxy networkservice domain portnumber authenticated username password] [-setwebproxystate networkservice on | off] [-getsecurewebproxy networkservice] [-setsecurewebproxy networkservice domain portnumber authenticated username password] [-setsecurewebproxystate networkservice on | off] [-getstreamingproxy networkservice] [-setstreamingproxy networkservice domain portnumber authenticated username password] [-setstreamingproxystate networkservice on | off] [-getgopherproxy networkservice] [-setgopherproxy networkservice domain portnumber authenticated username password] [-setgopherproxystate networkservice on | off] [-getsocksfirewallproxy networkservice] [-setsocksfirewallproxy networkservice domain portnumber authenticated username password] [-setsocksfirewallproxystate networkservice on | off] [-getproxybypassdomains networkservice] [-setproxybypassdomains networkservice domain1 [domain2] [...]] [-getproxyautodiscovery networkservice] [-setproxyautodiscovery networkservice on | off] [-getpassiveftp networkservice] [-setpassiveftp networkservice on | off] [-getairportnetwork device] [-setairportnetwork device network [password]] [-getairportpower device] [-setairportpower device on | off] [-listpreferredwirelessnetworks hardwareport] [-addpreferredwirelessnetworkatindex hardwareport network index securitytype [password]] [-removepreferredwirelessnetwork hardwareport network] [-removeallpreferredwirelessnetworks hardwareport] [-getnetworkserviceenabled networkservice] [-setnetworkserviceenabled networkservice on | off] [-createnetworkservice networkservicename hardwareport] [-renamenetworkservice networkservice newnetworkservicename] [-duplicatenetworkservice networkservice newnetworkservicename] [-removenetworkservice networkservice] [-ordernetworkservices service1 [service2] [service3] [...]] [-getMTU hardwareport] [-setMTU hardwarePort value] [-listvalidMTUrange hardwareport] [-getmedia hardwareport] [-setmedia hardwareport subtype [option1] [option2] [...]] [-listvalidmedia hardwareport] [-createVLAN name parentdevice tag] [-deleteVLAN name parentdevice tag] [-listVLANs] [-listdevicesthatsupportVLAN] [-isBondSupported device] [-createBond name [device1] [device2] [...]] [-deleteBond bond] [-addDeviceToBond device bond] [-removeDeviceFromBond device bond] [-listBonds] [-showBondStatus bond] [-listpppoeservices] [-showpppoestatus name] [-createpppoeservice device name account password [pppoeName]] [-deletepppoeservice service] [-setpppoeaccountname service account] [-setpppoepassword service password] [-connectpppoeservice service] [-disconnectpppoeservice service] [-listlocations] [-getcurrentlocation] [-createlocation location [populate]] [-deletelocation location] [-switchtolocation location] [-listalluserprofiles] [-listloginprofiles service] [-enablesystemprofile service on | off] [-enableloginprofile service profile on | off] [-enableuserprofile profile on | off] [-import8021xProfiles service path] [-export8021xProfiles service path yes | no] [-export8021xUserProfiles path yes | no] [-export8021xLoginProfiles service path yes | no] [-export8021xSystemProfile service path yes | no] [-settlsidentityonsystemprofile service path passphrase] [-settlsidentityonuserprofile profile path passphrase] [-deletesystemprofile service] [-deleteloginprofile service profile] [-deleteuserprofile profile] [-version] [-help] [-printcommands] 下面是所有的 flags 列表及他们的描述： 网络服务-listnetworkserviceorder按照与一个连接的相关性列出网络服务及其对应的 Port 。含有 * 说明这个服务不可用。如： networksetup -listnetworkserviceorderAn asterisk (*) denotes that a network service is disabled.(1) Wi-Fi(Hardware Port: Wi-Fi, Device: en0)(2) iPhone USB(Hardware Port: iPhone USB, Device: en4)(3) Bluetooth PAN(Hardware Port: Bluetooth PAN, Device: en2)(4) Thunderbolt Bridge(Hardware Port: Thunderbolt Bridge, Device: bridge0) -listallnetworkservices这个只是简单的列出网络服务名称而已。 networksetup -listallnetworkservices An asterisk (*) denotes that a network service is disabled.Wi-FiiPhone USBBluetooth PANThunderbolt Bridge -listallhardwareports这个会列出所有硬件端口，包含对应的设备名称及地址。 networksetup -listallhardwareports Hardware Port: Wi-FiDevice: en0Ethernet Address: 34:36:3b:17:ac:beHardware Port: Bluetooth PANDevice: en2Ethernet Address: 34:36:3b:17:ac:bfHardware Port: Thunderbolt 1Device: en1Ethernet Address: 32:00:17:5f:00:00Hardware Port: Thunderbolt BridgeDevice: bridge0Ethernet Address: 32:00:17:5f:00:00VLAN Configurations=================== -detectnewhardware检测网络硬件，并为这个硬件建立一个默认的网络服务。 -getmacaddress hardwareport获取硬件接口的网卡地址。比如以太网或者是 Wi-Fi。 networksetup -getmacaddress &apos;Wi-Fi&apos; 130 ↵Ethernet Address: 34:36:3b:17:ac:be (Hardware Port: Wi-Fi) -getcomputername获取计算机名称 networksetup -getcomputername 我的电脑的MacBook Air -setcomputername设置计算机名称 networksetup -setcomputername &quot;Angel&apos;s MacBook Air&quot; -getinfo netwokservice获取网络服务的信息。IP 地址，子网掩码，下一跳路由，硬件地址 networksetup -getinfo &quot;Wi-Fi&quot; DHCP ConfigurationIP address: 192.168.0.8Subnet mask: 255.255.255.0Router: 192.168.0.1Client ID: IPv6: AutomaticIPv6 IP address: noneIPv6 Router: noneWi-Fi ID: 34:36:3b:17:ac:be -setmanual networkservice ip subnet router设置网络服务的 IP， 子网， 下一跳路由。 -setdhcp networkservice [clientid]设置使用 DHCP 自动获取IP地址，。 clientid 是可选的，可以将其设置为 Empty 来清空已设置的 clientid。 -setbootp networkservice设置网络服务使用 bootp -setmanualwithdhcprouter networkservice ip手动指定一个 dhcp 池内的地址。 -getadditionalroutes networkservice获取附加的路由。 -setadditionalroutes networkservice [dest1 mask1 gate1] [dest2 mask2 gate2] … [destN maskN gateN]设置附加的路由。 networksetup -setadditionalroutes &quot;Wi-Fi&quot; 172.230.1.1 255.255.0.0 172.28.20.1 -setv{4 | 6}off networkservice用来关闭 IPv4 或者 IPv6 协议。 -setv6automatic networkservice自动设置 IPv6 地址。 -setv6linklocal networkservice设置 IPv6 只使用本地链路地址。 -setv6manual ip prefixlength router设置 IPv6 地址。包括 IP, 前缀, 及路由 -getv6additionalroutes networkservice获取 IPv6 附加路由。 -setv6additionalroutes networkservice [dest1 prefixlength1 gate1] [dest2 prefixlength2 gate2] … [destN prefixlengthN gateN]设置 IPv6 附加路由 -getdnsservers networkservice获取 DNS 服务器。 -setdnsservers networkservice dns1 [dns2] […]设置 DNS 服务器。 networksetup -setdnsservers &quot;Wi-Fi&quot; 8.8.8.8 114.114.114.114 -getsearchdomains networkservice为指定的网络服务显示出域名。这个我们本机一般不会用到。 -setsearchdomains networkservice domain1 [domain2] […]对网络服务指定域名。可设置多个呢。如果要清除的话，指定为 aemptya。 -create6to4service -建立一个 IPv6 -&gt; IPv4 的网络服务。 -set6to4automatic --set6to4manual - --getftpproxy networkservice获取 ftp 代理情况。 Enabled: NoServer: Port: 0Authenticated Proxy Enabled: 0 -setftpproxy networkservice domain portnumber authenticated username password设置 ftp 代理信息。authenticated 可以是 [ on | off ]。如果设置为 on，那么需要输入后面的账户和密码。 -setftpproxystate networkservice on | off开/关 ftp 代理。 -getwebproxy networkservice获取 web 代理信息。 -setwebproxy networkservice domain portnumber authenticated username password设置 web 代理。 -setwebproxystate networkservice on | off开关 web 代理。 -getsecurewebproxy networkservice-setsecurewebproxy networkservice domain portnumber authenticated username password-setsecurewebproxystate networkservice on | off-getstreamingproxy networkservice-setstreamingproxy networkservice domain portnumber authenticated username password-setstreamingproxystate networkservice on | off-getgopherproxy networkservice-setgopherproxy networkservice domain portnumber authenticated username password-setgopherproxystate networkservice on | off-getsocksfirewallproxy networkservice-setsocksfirewallproxy networkservice domain portnumber authenticated username password-setsocksfirewallproxystate networkservice on | off-getproxybypassdomains networkservice-setproxybypassdomains networkservice domain1 [domain2] […]-getproxyautodiscovery networkservice-setproxyautodiscovery networkservice on | off-getpassiveftp networkserviceFTP 被动模式是否开启。 -setpassiveftp networkservice {on | off}设置被动 FTP 模式。 -setautoproxyurl networkservice url设置自动代理配置的url。 -getautoproxyurl networkservice获取上面配置的信息。 networksetup -getautoproxyurl &quot;Wi-Fi&quot;URL: http://127.0.0.1:1089/proxy.pacEnabled: Yes -setsocksfirewallproxystate networkservice on | off设置是否开启 SOCKS 防火墙代理。 -getairportnetwork hardwareport显示当前的 Wi-Fi 网络。 networksetup -getairportnetwork en0 Current Wi-Fi Network: 360WiFi-8471A7-5G -setairportnetwork hardwareport network [password]连接一个 Wi-Fi 热点的意思。 -getairportpower hardwareport看一下 Wi-Fi 是开还是关。 -setairportpower hardwareport on | off开关 Wi-Fi。 -listpreferredwirelessnetworks hardwareport列出首选的 Wi-Fi 网络热点信息。 networksetup -listpreferredwirelessnetworks en0 | headPreferred networks on en0: 360WiFi-8471A7 real_602 nmj602_5G nmj504 HUAWEI-E5Mini-5FF7 iPhone D-GuiYang 360WiFi-DD0658 Wo4G-G7DQ -addpreferredwirelessnetworkatindex hardwareport network index securitytype [password]添加 Wi-Fi 网络信息。 -removepreferredwirelessnetwork hardwareport network移除 Wi-Fi 网络。 -removeallpreferredwirelessnetworks hardwareport移除所有的 Wi-Fi 网络。 -getnetworkserviceenabled networkservice查看网络服务是否开启。 -setnetworkserviceenabled networkservice on | off开/关一个网络服务 -createnetworkservice networkservicename hardwareport在硬件端口 hadrwareport 上建立网络服务 networkservicename。 建立后默认会开启。 -renamenetworkservice networkservice newnetworkservicename重命名网络服务 -duplicatenetworkservice networkservice newnetworkservicename复制网络服务。 -removenetworkservice networkservice删除网络服务 -ordernetworkservices service1 [service2] [service3] […]排序网络服务。 -getMTU hardwareport获取 MTU 以太网 一般是1468 -setMTU hardwarePort value手动设置 MTU -listValidMTURange hardwareport查看有效的 MTU值。 networksetup -listValidMTURange en0Valid MTU Range: 1280-1500 -getMedia hardwareport获取当前媒介的设置及端口上的活跃媒介或设备。 -setMedia hardwareport subtype [option1] [option2] […]指定端口的媒介类型。 -listValidMedia hardwareport列出可用的媒介。 -createVLAN name parentdevice tag在父设备 parentdevice，创建 Vlan ，标签 tag。 -deleteVLAN name parentdevice tag删除 Vlan -listVLANs列出V Vlan -listdevicesthatsupportVLAN列出支持 Vlan 的设备。 -isBondSupported device设备是否支持 bond。 networksetup -isBondSupported &quot;Wi-Fi&quot;NO -createBond name [device1] [device2] […]建立聚合链路 -deleteBond bond删除链路聚合。 -addDeviceToBond device bond为链路添加设备 -listBonds列出聚合链路 -showBondStatus bond查看链路聚合状态 pppoe相关-listpppoeservices-showpppoestatus name-createpppoeservice device name account password [pppoeName]-deletepppoeservice service-setpppoeaccountname service account-setpppoepassword service password-connectpppoeservice service-disconnectpppoeservice service-listlocations位置列表 -getcurrentlocation当前位置 -createlocation location [populate]创建位置 -deletelocation location删除位置 -switchtolocation location切换位置。","categories":[{"name":"macOS","slug":"macOS","permalink":"https://gowa2017.github.io/categories/macOS/"}],"tags":[{"name":"macOS","slug":"macOS","permalink":"https://gowa2017.github.io/tags/macOS/"},{"name":"networksetup","slug":"networksetup","permalink":"https://gowa2017.github.io/tags/networksetup/"}],"keywords":[{"name":"macOS","slug":"macOS","permalink":"https://gowa2017.github.io/categories/macOS/"}]},{"title":"TensorFlow中的张量的stack与unstack","slug":"TensorFlow中张量的stack与unstack","date":"2018-11-02T14:12:25.000Z","updated":"2018-11-02T14:12:25.000Z","comments":true,"path":"TensorFlow/TensorFlow中张量的stack与unstack.html","link":"","permalink":"https://gowa2017.github.io/TensorFlow/TensorFlow中张量的stack与unstack.html","excerpt":"学习一个简单的例子，关于神经网络的，总是会看到关于 stack unstack 函数的使用。但这涉及到的东西实在是多，比如最基本的一个前提概念就是，Tensor 张量，非常难以理解这个东西。","text":"学习一个简单的例子，关于神经网络的，总是会看到关于 stack unstack 函数的使用。但这涉及到的东西实在是多，比如最基本的一个前提概念就是，Tensor 张量，非常难以理解这个东西。 张量张量 TensorFlow 定义 TensorFlow 框架涉及到两个重要的元素：张量 和 操作 。 按照定义，张量 是对矢量和矩阵向潜在更高维度的泛化。 我们在使用 TensorFlow 的时候，我们操作和传递的主要对象都是 张量，tf.Tensor。tf.Tensor 对象表示一个部分定义的计算，最终会产生一个值。TensorFlow 程序首先会构建一个 tf.Tensor 对象图，详细说明如何基于其他可用张量计算每个张量，然后运行该图的某些部分以获得期望的结果。 张量具有以下两个属性： 数据类型 形状 shape 张量中的每个元素具有相同的数据类型，且该数据类型一定是已知的。形状，即是张量的维数和每个维度的大小，可能只是部分已知。如果其输入的形状也完全已知，则大多数指令会生成形状完全已知的张量，但在某些情况下，只能在图的执行时间找到张量的形状。 以下是一些特殊的张量： tf.Variable tf.constant tf.placeholder tf.SparseTensor 除了 tf.Variable ，张量的值不变。因此，执行一个任务的时候，张量只有一个值。但重复评估同一张量可能会有不同的值。 阶张量 对象的 阶 是其本身的维数。其同义词包括：秩、等级或 n 维。 TensorFlow 中的阶与数学矩阵中的阶并不是同一概念。 TensorFlow中的每个阶都对应一个不同的数学实例。 张量的 形状 中元素数量与阶（维数）相等。 阶 数学实例 0 标量（只有大小） 1 矢量（大小和方向） 2 矩阵（数据表） 3 3阶张量（数据立体） n n阶张量（自行想象） 0 阶mammal = tf.Variable(\"Elephant\", tf.string)ignition = tf.Variable(451, tf.int16)floating = tf.Variable(3.14159265359, tf.float64)its_complicated = tf.Variable(12.3 - 4.85j, tf.complex64) 注意：字符串在 TensorFlow 中被视为单一项，而不是一连串字符串。TensorFlow 可以有标量字符串，字符串矢量，等等。 1 阶要建立 1 阶的 tf.Tensor 对象，可传递一个项目列表作为初值： mystr = tf.Variable([\"Hello\"], tf.string)cool_numbers = tf.Variable([3.14159, 2.71828], tf.float32)first_primes = tf.Variable([2, 3, 5, 7, 11], tf.int32)its_very_complicated = tf.Variable([12.3 - 4.85j, 7.5 - 6.23j], tf.complex64) 更高阶2 阶 tf.Tensor 对象至少包含一行和一列： mymat = tf.Variable([[7],[11]], tf.int16)myxor = tf.Variable([[False, True],[True, False]], tf.bool)linear_squares = tf.Variable([[4], [9], [16], [25]], tf.int32)squarish_squares = tf.Variable([ [4, 9], [16, 25] ], tf.int32)rank_of_squares = tf.rank(squarish_squares)mymatC = tf.Variable([[7],[11]], tf.int32) 同样，更高阶的张量由一个 n 维数组组成。例如，在图像处理过程中，会使用许多 4 阶张量，维度对应批次大小、图像宽度、图像高度和颜色通道。 my_image = tf.zeros([10, 299, 299, 3]) # batch x height x width x color 获取 tf.Tensor 对象的阶要确定 tf.Tensor 对象的阶，需调用 tf.rank 方法。例如，以下方法以编程方式确定上一章节中所定义的 tf.Tensor 的阶： r = tf.rank(my_image)# After the graph runs, r will hold the value 4. 引用 tf.Tensor 切片由于 tf.Tensor 是 n 维单元数组，要访问 tf.Tensor 中的某一单元，需要指定 n 个索引。 0 阶张量（标量）不需要索引，因为其本身便是单一数字。 对于 1 阶张量（矢量）来说，通过传递单一索引可以访问某个数字： my_scalar = my_vector[2] 请注意，如果想从矢量中动态地选择元素，那么在 [] 内传递的索引本身可以是一个标量 tf.Tensor。 对于 2 阶及以上的张量来说，情况更为有趣。对于 2 阶 tf.Tensor 来说，传递两个数字会如预期般返回一个标量： my_scalar = my_matrix[1, 2] 而传递一个数字则会返回一个矩阵子矢量，如下所示： my_row_vector = my_matrix[2]my_column_vector = my_matrix[:, 3] 符号 : 是 Python 切片语法，意味“不要触碰该维度”。这对更高阶的张量来说很有用，可以帮助访问其子矢量，子矩阵，甚至其他子张量。 形状张量的形状是每个维度中元素的数量。TensorFlow 在图的构建过程中自动推理形状。这些推理的形状可能具有已知或未知的阶。如果阶已知，则每个维度的大小可能已知或未知。 TensorFlow 文件编制中通过三种符号约定来描述张量维度：阶，形状和维数。下表阐述了三者如何相互关联： 阶 形状 维度 示例 0 [] 0-D 0维张量。标量 1 [D0] 1-D 形状为[5]的1维张量 2 [D0,D1] 2-D 形状为[3,4]的2维张量 3 [D0, D1, D2] 3-D 形状为[1,4,3]的3维张量 n [D0, D1, …. Dn-1] n维 形状为 [D0,D1,…Dn-1]的张量 形状包含了两个属性，dims, ndim tf.TensorShape此是形状在内部的实现。https://www.tensorflow.org/api_docs/python/tf/TensorShape tf.shape()tf.shape( input, name=None, out_type=tf.int32) 返回张量的形状。 这个操作会返回一个 1-D 整数张量，代表了 input 的形状。 例如： t = tf.constant([[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]])tf.shape(t) # [2, 2, 3] tf.concat()要了解 tf.stack() 就必须要了解 tf.concat()。这函数会沿某一维度拼接张量。 tf.concat( values, axis, name='concat') 沿 axis 维度连接 values 中的张量列表。如果 values[i].shape=[D0, D1, … Daxis(i), … Dn] 那么结果就是：[D0, D1, … Raxis, …Dn]其中Raxis = sum(Daxis(i)) 这也就是说，输入张量内的数据沿 axis 维度连接了。 输入张量的维数必匹配，除了 axis 外的维度必须相等。 例如： t1 = [[1, 2, 3], [4, 5, 6]]t2 = [[7, 8, 9], [10, 11, 12]]tf.concat([t1, t2], 0) # [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]]tf.concat([t1, t2], 1) # [[1, 2, 3, 7, 8, 9], [4, 5, 6, 10, 11, 12]]# tensor t3 with shape [2, 3]# tensor t4 with shape [2, 3]tf.shape(tf.concat([t3, t4], 0)) # [4, 3]tf.shape(tf.concat([t3, t4], 1)) # [2, 6] 而： tf.concat([tf.expand_dims(t, axis) for t in tensors], axis)tf.stack(tensors, axis=axis) 这两者是相等的。 tf.stack()官方定义 tf.stack( values, axis=0, name='stack') 把一个 R 阶的张量列表堆成一个 R+1 阶的张量。 通过沿 axis 方向，将 values 中的张量列表打包到一个比 values 中的任何一个张量高一阶的张量中。现在给定一个长度为 N 的列表，其中的张量形状为 (A, B, C)。 如果 axis == 0 ，输出张量的形状是 (N, A, B, C) 如果 axis == 1 ，输出张量的形状是 (A, N, B, C)…….……. 例如： x = tf.constant([1, 4])y = tf.constant([2, 5])z = tf.constant([3, 6])tf.stack([x, y, z]) # [[1, 4], [2, 5], [3, 6]] (Pack along first dim.)tf.stack([x, y, z], axis=1) # [[1, 2, 3], [4, 5, 6]] 理解的时候，我把 [x, y, z] 理解为一个张量了，而其实上，我不应该混淆，张量 与其在 Python 中的阵列实现混为一谈。这个时候，其只是作为一个 张量列表 传递给 stack() 函数的。 列表中的张量其形状都是 [2]， 列表长度为 3，那么，stack() 后的张量形状应该为 [3,2]。而当 axis = 1，的时候，就应该是 [2,3] 这与 unstack 是相反的操作。这与 ： tf.stack([x, y, z]) = np.stack([x, y, z]) 一致。 参数： values 具有相同形状和类型的张量对象列表 axis int 值。要压缩的轴方向。默认就是第一个。负值回绕，所以有效值就是 [-(R+1), R+1)。 name 操作名称 返回值： output 与 values 类型相同的压缩后的 张量 。 抛出： ValueError 如果 axis 超过了范围 [-(R+1), R+1) tf.unstack()tf.unstack( value, num=None, axis=0, name='unstack') 把 R 阶的张量解压为 R-1 阶。 通过沿 axis 方向解开，从 value 张量内解压出 num 个张量。如果没有指定 num（默认情况），这会从 value 的形状去推测出来。但如果 value.shape[axis] 是未知的，就会抛出 ValueError 错误。 比如给出一个形状为 (A, B, C, D)的张量： 如果 axis==0，那么 输出 的第 i 个张量就是切片 value[i, :, :, :]，且输出中的每个张量形状都是 (B, C, D)。注意，解压的轴消失了。这和 split 不一样。 如果 axis==1，那么 输出 的第 i 个张量就是切片 value[:, i, :, :]，且输出中的每个张量形状都是 (A, C, D)。注意，解压的轴消失了。这和 split 不一样。 参数： value: 一个 R &gt; 0 阶张量 num: 轴的长度。 axis: 解压的轴方向。 name: 操作名称（可选） 返回值： 一个从 value 解压出来的 张量列表。","categories":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://gowa2017.github.io/categories/TensorFlow/"}],"tags":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://gowa2017.github.io/tags/TensorFlow/"}],"keywords":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://gowa2017.github.io/categories/TensorFlow/"}]},{"title":"Android截图后相册没有立马到相册中","slug":"Android截图后相册没有立马到相册中","date":"2018-11-01T14:47:38.000Z","updated":"2018-11-01T14:47:38.000Z","comments":true,"path":"Android/Android截图后相册没有立马到相册中.html","link":"","permalink":"https://gowa2017.github.io/Android/Android截图后相册没有立马到相册中.html","excerpt":"问题是这样的，我们使用的第三方的视频SDK，截图后却不能马上在相册中显示，而有的时候又显示出来了。查看了一下截图的路径，确实是截图下来了的。问题就是没有放到相册进去的问题。","text":"问题是这样的，我们使用的第三方的视频SDK，截图后却不能马上在相册中显示，而有的时候又显示出来了。查看了一下截图的路径，确实是截图下来了的。问题就是没有放到相册进去的问题。 查看了一下 SDK 内截图的代码： public final static String IMAGE_PATH = Environment.getExternalStorageDirectory().getPath() + \"/snapshot/\"; public final static String IMGSTR = new SimpleDateFormat(\"yyyyMMddHHmmss\").format(new Date()) + \".jpg\"; private void captureBitmap() &#123; String path = IMAGE_PATH + IMGSTR; //先创建一个文件夹 File dir = new File(IMAGE_PATH); File file = new File(IMAGE_PATH, IMGSTR); if(!dir.exists()) &#123; dir.mkdir(); &#125; else &#123; if(file.exists()) &#123; file.delete(); &#125; &#125; int result = IPlaySDK.PLAYCatchPicEx(m_nPort, path, PicFormat_JPEG); Log.i(\"PLAYCatchPicEx\", String.valueOf(result)); if (result &gt; 0) &#123; showToast(R.string.capture_success); saveIntoMediaCore(); &#125; else &#123; showToast(R.string.capture_fail); &#125;&#125; private void saveIntoMediaCore() &#123; Intent intent = new Intent(Intent.ACTION_MEDIA_SCANNER_SCAN_FILE); Uri uri = Uri.parse(IMAGE_PATH + IMGSTR); intent.setData(uri); RealPlayActivity.this.setIntent(intent); &#125; 似乎截图之后，并没有把截图通知到系统，扫描对应的图片。而是调用了 setIntent(intent) 这个方法。 查看了官方关于 setIntent() 的定义后)，放才了解到，这个方法，只会设置 Activity 调用 getIntent() 所获取的 Intent。 窃以为其应该是在截图了之后，能够立马在当前查看而设置的这个。但其实这没有什么意义啊，截图了之后知道了路径本来就可以立马在当前的 Activity 打开的。 解决办法我来加上一个广播意图的操作看看。 private void saveIntoMediaCore() &#123; Intent intent = new Intent(Intent.ACTION_MEDIA_SCANNER_SCAN_FILE); Uri uri = Uri.parse(IMAGE_PATH + IMGSTR); intent.setData(uri); sendBroadcast(intent);&#125; 如果这样还不能解决的话，提供了一个更详细的解决办法：https://www.grokkingandroid.com/adding-files-to-androids-media-library-using-the-mediascanner/ 结果：在我的 MIUI 10 开发版中正常。但是在 华为系统，和小米的老版本系统上却无法进入相册，文件是已保存的。 解释通常情况下我们在向文件系统添加文件的时候，安卓的 MedaScanner 会自动的把文件给扫描出来。但不是一直都会进行这个扫描。 只有在重启或挂载 sdcard 的时候，安卓系统会做一个完整的媒体文件扫描。这一听起来会很糟糕————但我们应该仔细想一下。因为完整扫描就非常耗时的，你可能并不想这样的扫描随时随地发生，特别系统的负载比较高的情况下。 这就意味着，任何需要立刻在媒体库内可用的话，必须通过你手动的添加。我们有这个责任来保证这一点。扩展一点，新的设备可能会支持 MTP，那就意味做所有文件（不仅是媒体文件）必须可用。这个后面会说到。 想要让文件添加到媒体库，可以使用 MediaStore 内容提供者 或者 MediaScanner。 那篇文章只解释了 MediaScanner，在他的另外一篇文章就介绍了 MediaStore。 使用 broadcast最简单的方式： Intent intent = new Intent(Intent.ACTION_MEDIA_SCANNER_SCAN_FILE);intent.setData(Uri.fromFile(file));sendBroadcast(intent); 大多数时候，这个会工作得很好。不过如果想更好的控制的话，采用下面两种方式。 使用静态方法 scanFile()如果只是想简单的知道文件是什么时候被添加的，使用 MediaScannerConnection 的静态方法 scanFile() ，给他弄上一个监听回调函数 MediaScannerConnection.OnScanCompletedListener。 scanFile() 命名非常的坑爹，其会把一个路径数组进行添加————而不是像我们想的那样去工作。 下面是怎么使用这个方法： MediaScannerConnection.scanFile( getApplicationContext(), new String[]&#123;file.getAbsolutePath()&#125;, null, new OnScanCompletedListener() &#123; @Override public void onScanCompleted(String path, Uri uri) &#123; Log.v(\"grokkingandroid\", \"file \" + path + \" was scanned seccessfully: \" + uri); &#125; &#125;); 参数解释： context 应用程序上下文 paths 一个 String[] 数组，包含了我们要添加的路径 mimeTypes String[] 数组，包含了我们添加的文件类型。 callback MediaScannerConnection.OnScanCompletedListener 会在扫描完成后调用。 OnScanCompletedListener 必须实现 onScanCompleted() 方法。这个方法使用 文件名，MediaStore.Files 提供者传递的 Uri 作为参数。 建立MediaScannerConnection实例这是让我们的文件可见的一种最麻烦的一种方法。那这也可以让我们控制更多。我们需要实现 MediaScannerConnection.MediaScannerConnectionClient 来进行回调。 MediaScannerConnectionClient的实现不仅会在一次扫描完成后调用，而且会在连接开始通信时调用。因为这可能会花一点时间，下一节我们会描述，你可能会对这个回调感兴趣。构建API的方式实际上需要使用此回调方法来启动扫描。 下面是一个 MediaScannerConnectionClient 的实现例子： final class MyMediaScannerConnectionClient implements MediaScannerConnectionClient &#123; private String mFilename; private String mMimetype; private MediaScannerConnection mConn; public MyMediaScannerConnectionClient (Context ctx, File file, String mimetype) &#123; this.mFilename = file.getAbsolutePath(); mConn = new MediaScannerConnection(ctx, this); mConn.connect(); &#125; @Override public void onMediaScannerConnected() &#123; mConn.scanFile(mFilename, mMimetype); &#125; @Override public void onScanCompleted(String path, Uri uri) &#123; mConn.disconnect(); &#125; &#125; 在这个实现中，在构造器里面建立了 MediaScannerConnection，也调用了 connect() 方法。 然后在 onMediaScannerConnected() 方法中启动了扫描。 最简单的使用方法： MediaScannerConnectionClient client = new MyMediaScannerConnectionClient( getApplicationContext(), file, null); 通信的连接需要花一点时间请注意，连接不会立即建立。这就是为什么下面的片段会引起麻烦（这是我第一次注意到Mark Murphy特别推荐的书籍中有问题的代码） /////// Do not do this ! ///////MediaScannerConnection c = new MediaScannerConnection( getApplicationContext(), null);c.connect();c.scanFile(file.getAbsolutePath(), null);c.disconnect();/////// Do not do this ! /////// 这会抛出一个违例： IllegalStateException:java.lang.IllegalStateException: not connected to MediaScannerService 有的设备上花 20-40 ms 就建立起来了，但是有的设备可能会花上 100ms ，设置 1s。 不仅仅是媒体文件现在的设备使用了 MTP 而不仅仅是传统的 USB 存储协议， MediaScanner还用于通过MTP访问任意文件。因此，如果您将设备插入计算机，那么您未添加到MediaScanner的任何文件和文件夹在完全扫描之前是不可见的！ 随着Honeycomb的推出，谷歌开始推动MTP。即使不是所有的手机制造商都遵循谷歌的决定，有些人可能 - 而谷歌自己的Nexus系列肯定会这样做。 这意味着您还应将MediaScanner用于用户可能要下载到其计算机的任何文件。It could be anything, e.g. CSV backup files, PDF files and so on. If the user might want to use them on a traditional computer, you have to make these files known using the methods described above.中文(简体)它可以是任何东西，例如CSV备份文件，PDF文件等。如果用户可能希望在传统计算机上使用它们，则必须使用上述方法使这些文件已知。","categories":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"}],"keywords":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}]},{"title":"MySQL自己的定时任务使用","slug":"MySQL自己的定时任务使用","date":"2018-11-01T03:18:57.000Z","updated":"2018-11-01T03:18:57.000Z","comments":true,"path":"MySQL/MySQL自己的定时任务使用.html","link":"","permalink":"https://gowa2017.github.io/MySQL/MySQL自己的定时任务使用.html","excerpt":"我一直的定时任务都是通过 Linux 服务器上的 Crond 守护进程来实现的。还一直没有关注过 MySQL 其实自己也有定时任务。恰好我们的后台有用到了，就逼迫我来熟悉一下了。","text":"我一直的定时任务都是通过 Linux 服务器上的 Crond 守护进程来实现的。还一直没有关注过 MySQL 其实自己也有定时任务。恰好我们的后台有用到了，就逼迫我来熟悉一下了。 MySQL版本 ：5.1.73服务器环境： CentOS 6.8 MySQL 的事件调度器（Event Scheduler） 据说是在 5.1.6 版本添加的，可以精确到按秒来执行。 这种类型的计划任务有时也称为 “ 时间触发器 ”，暗示这些是由时间推移触发的对象。虽然这基本上是正确的，但我们更喜欢使用术语 事件来避免与第触发器混淆。事件应该更具体地不与“ 临时触发器 ”混淆。触发器是数据库对象，其语句是响应于在给定表上发生的特定类型的事件而执行的，（（已调度的）事件是响应于指定时间间隔的通过而执行其语句的对象。 主要特性MySQL Events具有以下主要特性和属性： 在MySQL中，事件由其名称和分配给它的模式唯一标识。 事件根据计划执行特定操作。此操作由一个SQL语句组成，BEGIN ... END如果需要，该语句可以是块中的复合语句 （请参见 第13.6节“复合语句语法”）。事件的时间可以是 一次性或 反复发作。一次性事件仅执行一次。周期性事件会定期重复其操作，并且可以为重复事件的计划分配特定的开始日期和时间，结束日期和时间，两者或两者都不。（默认情况下，定期事件的计划在创建后立即开始，并且无限期地继续，直到它被禁用或删除。） 如果重复事件未在其调度间隔内终止，则结果可能是事件同时执行的多个实例。如果这是不合需要的，您应该建立一个机制来防止同时发生。例如，您可以使用 GET_LOCK()函数，或行或表锁定。 用户可以使用用于这些目的的SQL语句创建，修改和删除预定事件。语法无效的事件创建和修改语句失败，并显示相应的错误消息。用户可以在事件的动作中包括需要用户实际上没有的特权的语句。事件创建或修改语句成功，但事件的操作失败。有关详细信息，请参见第20.4.6节“事件调度程序和MySQL权限”。 可以使用SQL语句设置或修改事件的许多属性。这些属性包括事件的名称，计时，持久性（即，是否在其计划到期后保留），状态（启用或禁用），要执行的操作以及分配给它的模式。请参见第13.1.2节“ALTER EVENT语法”。 事件的默认定义者是创建事件的用户，除非事件已被更改，在这种情况下，定义者是发出ALTER EVENT影响该事件的最后一个语句的用户 。任何具有EVENT定义事件的数据库特权的用户都可以修改 事件。请参见 第20.4.6节“事件调度程序和MySQL权限”。 事件的操作语句可能包括存储例程中允许的大多数SQL语句。有关限制，请参见 第C.1节“存储程序的限制”。 配置事件由特殊事件调度程序线程执行 ; 当我们引用Event Scheduler时，我们实际上是指这个线程。在运行时，具有PROCESS输出特权的用户可以看到事件调度程序线程及其当前状态SHOW PROCESSLIST，如下面的讨论所示。 全局event_scheduler系统变量确定是否在服务器上启用并运行事件调度程序。它具有以下3个值中的一个，它们会影响事件调度，如下所述： OFF 默认值。事件计划程序已停止。事件调度程序线程未运行 ON 事件调度程序已启动; 事件调度程序线程运行并执行所有计划事件。 DISABLED 此值使事件计划程序不可操作。当事件调度程序是 DISABLED，事件调度程序线程不运行。此外，无法在运行时更改事件计划程序状态。 如果事件调度程序状态尚未设置为 DISABLED，那么可以手动设置 event_scheduler 的值为 ON/OFF，也可以设置为 1/0。 -- 开启事件调度 SET GLOBAL event_scheduler = ON;SET @@GLOBAL.event_scheduler = ON;SET GLOBAL event_scheduler = 1;SET @@GLOBAL.event_scheduler = 1;-- 关闭事件调度SET GLOBAL event_scheduler = OFF;SET @@GLOBAL.event_scheduler = OFF;SET GLOBAL event_scheduler = 0;SET @@GLOBAL.event_scheduler = 0;-- 查看当前状态 select @@GLOBAL.event_scheduler; 请注意，尝试设置 event_scheduler而不将其指定为全局变量会导致错误： mysql&lt; SET @@event_scheduler = OFF;ERROR 1229 (HY000): Variable 'event_scheduler' is a GLOBALvariable and should be set with SET GLOBAL 要禁用事件调度程序，请使用以下两种方法之一： 命令行启动mysql时 --event-scheduler=DISABLED my.cnf 配置文件中 event_scheduler=DISABLED 相关语法 可以使用 Create Event 来创建事件 可以使用 ALter Event 来改变事件 可以使用 Drop Event 来删除事件。 查看所有的事件可以用如下办法： 查询 mysql.event 表 查询 INFORMATION_SCHEMA.events 表 SHOW CREATE EVENT 差看对应的事件创建过程。 show events 查看所有事件。 CREATE EVENTCREATE [DEFINER = &#123; user | CURRENT_USER &#125;] EVENT [IF NOT EXISTS] event_name ON SCHEDULE schedule [ON COMPLETION [NOT] PRESERVE] [ENABLE | DISABLE | DISABLE ON SLAVE] [COMMENT 'string'] DO event_body;schedule: AT timestamp [+ INTERVAL interval] ... | EVERY interval [STARTS timestamp [+ INTERVAL interval] ...] [ENDS timestamp [+ INTERVAL interval] ...]interval: quantity &#123;YEAR | QUARTER | MONTH | DAY | HOUR | MINUTE | WEEK | SECOND | YEAR_MONTH | DAY_HOUR | DAY_MINUTE | DAY_SECOND | HOUR_MINUTE | HOUR_SECOND | MINUTE_SECOND&#125; 大概可以认为有三个部分： 事件相关信息 调度信息 时间间隔 建立一个事件最少需要下面三个内容： CREATE EVENT 加上一个事件名字。 一个 ON SCHEDULE 语句，指出什么时候怎么执行事件。 DO语句，指明要执行的语句。 最简单的一个例子： CREATE EVENT myevent ON SCHEDULE AT CURRENT_TIMESTAMP + INTERVAL 1 HOUR DO UPDATE myschema.mytable SET mycol = mycol + 1; CREATE EVENT e_hourly ON SCHEDULE EVERY 1 HOUR COMMENT 'Clears out sessions table each hour.' DO DELETE FROM site_activity.sessions; ON SCHEDULE如果只执行一次的话，使用 at 来指定执行时间。 如果要重复执行的话，那么使用 every 来指定执行的时间间隔。在 every 后面可能会跟上一个 START 用来指定从什么时间开始执行。也有可能跟上一个 END 时间戳 来指定结束时间。 ON COMPLETION通常事件过期（指定结束日期的情况下）就会被 drop 掉。但是如果我们不想这样的话，可以用 ON COMPLETION PRESERVE 来保留这事件。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://gowa2017.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://gowa2017.github.io/tags/MySQL/"}],"keywords":[{"name":"MySQL","slug":"MySQL","permalink":"https://gowa2017.github.io/categories/MySQL/"}]},{"title":"TensorFlow的基本概念和原理","slug":"TensorFlow的基本概念和原理","date":"2018-10-31T14:31:19.000Z","updated":"2018-10-31T14:31:19.000Z","comments":true,"path":"TensorFlow/TensorFlow的基本概念和原理.html","link":"","permalink":"https://gowa2017.github.io/TensorFlow/TensorFlow的基本概念和原理.html","excerpt":"听起来很是高深的机器学习，但是我一点不懂。说实话这个框架不知道怎么拿来即用。但本着一直一来学习都是要了解原理的这种习惯，还是来看一下官方文档上的一些指导。","text":"听起来很是高深的机器学习，但是我一点不懂。说实话这个框架不知道怎么拿来即用。但本着一直一来学习都是要了解原理的这种习惯，还是来看一下官方文档上的一些指导。 数据流图TensorFlow 使用数据流图将计算表示为独立的指令之间的依赖关系。这可生成低级别的编程模型，在该模型中，您首先定义数据流图，然后创建 TensorFlow 会话，以便在一组本地和远程设备上运行图的各个部分。 初看这个图的时候是懵的，大概能模糊的知道一种数据流向的概念，但更多的就不清楚了。 数据流是一种用于并行计算的常用编程模型。在数据流图中，节点表示计算单元，边缘表示计算使用或产生的数据。例如，在 TensorFlow 图中，tf.matmul 操作对应单个节点，该节点具有两个传入边缘（要相乘的矩阵）和一个传出边缘（乘法结果）。 数据流图实际上是一个模板？一个数据流的描述？ 描述了操作对于数据流的依赖关系。 TensorFlow中的图我们实际上可以把 TensorFlow 看作两个相互独立的部分： 构建计算图（ tf.Graph） 运行计算图（ tf.Session()） 计算图是排列成一个图的一系列 TensorFlow 指令。图由两种类型的对象组成。 操作（简称“op”）：图的节点。操作描述了消耗和生成张量的计算。 张量：图的边。它们代表将流经图的值。大多数 TensorFlow 函数会返回 tf.Tensors。 操作Operation官方定义再此 操作 定义了一个在 张量 上进行计算的节点。 操作 是 TensorFlow 图中的一个节点，其将 0 个或 多个 张量 对象作为输入，然后产生 0 或者 多个 张量 对象作为输出。操作 类型的对象通过调用 Python 接口中的 操作符构造器来产生（如 tf.matmul 或者 tf.Graph.create_op。 例如，c = tf.matmul(a, b) 会创建一个 MatMul 类型的 操作 对象，其将 张量 a,b 作为输入，然后输出 c。 张量Tensor在 张量类的定义中 这样说明： 代表 操作 的一个输出。一个 张量 是一个 操作 一个输出的 符号句柄。 其并不保存那个操作输出的值，其只是在一个 TensorFlow 的 tf.Session 中提供一个计算这些值的方式。张量的定义有两个根本的目的： 一个张量（Tensor）可以当作输入传递给另外一个 操作。这在多个操作间建立数据流连接，以此来使 TensorFlow 能个执行完一个巨大，多步的计算的 图。 在这个图已经在会话中启动后， Tensor 的值可以通过把张量传递给 tf.Session.run 来计算。 t.eval() 是对 tf.get_default_session().run(t) 的简写。 构建图 tf.Graph大多数 TensorFlow 程序都以数据流图构建阶段开始。在此阶段，您会调用 TensorFlow API 函数，这些函数可构建新的 tf.Operation（节点）和 tf.Tensor（边缘）对象并将它们添加到 tf.Graph 实例中。TensorFlow 提供了一个默认图，此图是同一上下文中的所有 API 函数的明确参数。例如： 调用 tf.constant(42.0) 可创建单个 tf.Operation，该操作可以生成值 42.0，将该值添加到默认图中，并返回表示常量值的 tf.Tensor。 调用 tf.matmul(x, y) 可创建单个 tf.Operation，该操作会将 tf.Tensor 对象 x 和 y 的值相乘，将其添加到默认图中，并返回表示乘法运算结果的 tf.Tensor。 执行 v = tf.Variable(0)可向图添加一个 tf.Operation，该操作可以存储一个可写入的张量值，该值在多个 tf.Session.run 调用之间保持恒定。tf.Variable 对象会封装此操作，并可以像张量一样使用，即读取已存储的值的当前值。tf.Variable 对象也具有 assign 和 assign_add 等方法，这些方法可创建 tf.Operation 对象，这些对象在执行时将更新已存储的值。（请参阅变量了解关于变量的更多信息。） 调用 tf.train.Optimizer.minimize 可将操作和张量添加到计算梯度的默认图中，并返回一个 tf.Operation，该操作在运行时会将这些梯度应用到一组变量上。 大多数程序仅依赖于默认图。尽管如此，请参阅处理多个图了解更加高级的用例。高阶 API（比如 tf.estimator.Estimator API）可替您管理默认图，并且还具有其他功能，例如创建不同的图以用于训练和评估。 类似于张量的对象许多 TensorFlow 操作都会接受一个或多个 tf.Tensor 对象作为参数。例如，tf.matmul 接受两个 tf.Tensor 对象，tf.add_n 接受一个具有 n 个 tf.Tensor 对象的列表。为了方便起见，这些函数将接受类张量对象来取代 tf.Tensor，并将它明确转换为 tf.Tensor（通过 tf.convert_to_tensor 方法）。类张量对象包括以下类型的元素： tf.Tensor tf.Variable numpy.ndarray list（以及类似于张量的对象的列表） 标量 Python 类型：bool、float、int、str 您可以使用 tf.register_tensor_conversion_function注册其他类张量类型。 在以下会话中执行图：tf.SessionTensorFlow 使用 tf.Session 类来表示客户端程序（通常为 Python 程序，但也提供了其他语言的类似接口）与 C++ 运行时之间的连接。tf.Session 对象使我们能够访问本地机器中的设备和使用分布式 TensorFlow 运行时的远程设备。它还可缓存关于 tf.Graph 的信息，使您能够多次高效地运行同一计算。 创建 tf.Session如果您使用的是低阶 TensorFlow API，您可以为当前默认图创建一个 tf.Session，如下所示： # Create a default in-process session.with tf.Session() as sess: # ...# Create a remote session.with tf.Session(\"grpc://example.org:2222\"): # ... 由于 tf.Session 拥有物理资源（例如 GPU 和网络连接），因此通常（在 with 代码块中）用作上下文管理器，并在您退出代码块时自动关闭会话。您也可以在不使用 with 代码块的情况下创建会话，但应在完成会话时明确调用 tf.Session.close 以便释放资源。 tf.Session.init 接受三个可选参数： target。 如果将此参数留空（默认设置），会话将仅使用本地机器中的设备。但是，您也可以指定 grpc:// 网址，以便指定 TensorFlow 服务器的地址，这使得会话可以访问该服务器控制的机器上的所有设备。请参阅 tf.train.Server 详细了解如何创建 TensorFlow 服务器。例如，在常见的图间复制配置中，tf.Session 连接到 tf.train.Server 的流程与客户端相同。分布式 TensorFlow 部署指南介绍了其他常见情形。 graph。 默认情况下，新的 tf.Session 将绑定到当前的默认图，并且仅能够在当前的默认图中运行操作。如果您在程序中使用了多个图（更多详情请参阅使用多个图进行编程），则可以在构建会话时指定明确的 tf.Graph。 config。 此参数允许您指定一个控制会话行为的 tf.ConfigProto。例如，部分配置选项包括： allow_soft_placement。将此参数设置为 True 可启用“软”设备放置算法，该算法会忽略尝试将仅限 CPU 的操作分配到 GPU 设备上的 tf.device 注解，并将这些操作放置到 CPU 上。 cluster_def。使用分布式 TensorFlow 时，此选项允许您指定要在计算中使用的机器，并提供作业名称、任务索引和网络地址之间的映射。详情请参阅 tf.train.ClusterSpec.as_cluster_def。 graph_options.optimizer_options。在执行图之前使您能够控制 TensorFlow 对图实施的优化。 gpu_options.allow_growth。将此参数设置为 True 可更改 GPU 内存分配器，使该分配器逐渐增加分配的内存量，而不是在启动时分配掉大多数内存。 使用 tf.Session.run 执行操作tf.Session.run 方法是运行 tf.Operation 或评估 tf.Tensor 的主要机制。您可以将一个或多个 tf.Operation 或 tf.Tensor 对象传递到 tf.Session.run，TensorFlow 将执行计算结果所需的操作。 tf.Session.run 要求您指定一组 fetch，这些 fetch 可确定返回值，并且可能是 tf.Operation、tf.Tensor 或类张量类型，例如 tf.Variable。这些 fetch 决定了必须执行整体 tf.Graph 的哪些子图以生成结果：该子图包含 fetch 列表中指定的所有操作，以及其输出用于计算 fetch 值的所有操作。例如，以下代码段说明了 tf.Session.run 的不同参数如何导致执行不同的子图： x = tf.constant([[37.0, -23.0], [1.0, 4.0]])w = tf.Variable(tf.random_uniform([2, 2]))y = tf.matmul(x, w)output = tf.nn.softmax(y)init_op = w.initializerwith tf.Session() as sess: # Run the initializer on `w`. sess.run(init_op) # Evaluate `output`. `sess.run(output)` will return a NumPy array containing # the result of the computation. print(sess.run(output)) # Evaluate `y` and `output`. Note that `y` will only be computed once, and its # result used both to return `y_val` and as an input to the `tf.nn.softmax()` # op. Both `y_val` and `output_val` will be NumPy arrays. y_val, output_val = sess.run([y, output]) tf.Session.run 也可以选择接受 Feed 字典，该字典是从 tf.Tensor 对象（通常是 tf.placeholder 张量）到在执行时会被替换为这些张量的值（通常是 Python 标量、列表或 NumPy 数组）的映射。例如： # Define a placeholder that expects a vector of three floating-point values,# and a computation that depends on it.x = tf.placeholder(tf.float32, shape=[3])y = tf.square(x)with tf.Session() as sess: # Feeding a value changes the result that is returned when you evaluate `y`. print(sess.run(y, &#123;x: [1.0, 2.0, 3.0]&#125;)) # =&gt; \"[1.0, 4.0, 9.0]\" print(sess.run(y, &#123;x: [0.0, 0.0, 5.0]&#125;)) # =&gt; \"[0.0, 0.0, 25.0]\" # Raises &lt;a href=\"../api_docs/python/tf/errors/InvalidArgumentError\"&gt;&lt;code&gt;tf.errors.InvalidArgumentError&lt;/code&gt;&lt;/a&gt;, because you must feed a value for # a `tf.placeholder()` when evaluating a tensor that depends on it. sess.run(y) # Raises `ValueError`, because the shape of `37.0` does not match the shape # of placeholder `x`. sess.run(y, &#123;x: 37.0&#125;) tf.Session.run 也接受可选的 options 参数（允许您指定与调用有关的选项）和可选的 run_metadata 参数（允许您收集与执行有关的元数据）。例如，您可以同时使用这些选项来收集与执行有关的跟踪信息： y = tf.matmul([[37.0, -23.0], [1.0, 4.0]], tf.random_uniform([2, 2]))with tf.Session() as sess: # Define options for the `sess.run()` call. options = tf.RunOptions() options.output_partition_graphs = True options.trace_level = tf.RunOptions.FULL_TRACE # Define a container for the returned metadata. metadata = tf.RunMetadata() sess.run(y, options=options, run_metadata=metadata) # Print the subgraphs that executed on each device. print(metadata.partition_graphs) # Print the timings of each operation that executed. print(metadata.step_stats) 直观展示您的图TensorFlow 包含可帮助您理解图中的代码的工具。图可视化工具是 TensorBoard 的一个组件，可在浏览器中可视化图的结构。要创建可视化图表，最简单的方法是传递 tf.Graph（在创建 tf.summary.FileWriter 时）： # Build your graph.x = tf.constant([[37.0, -23.0], [1.0, 4.0]])w = tf.Variable(tf.random_uniform([2, 2]))y = tf.matmul(x, w)# ...loss = ...train_op = tf.train.AdagradOptimizer(0.01).minimize(loss)with tf.Session() as sess: # `sess.graph` provides access to the graph used in a &lt;a href=\"../api_docs/python/tf/Session\"&gt;&lt;code&gt;tf.Session&lt;/code&gt;&lt;/a&gt;. writer = tf.summary.FileWriter(\"/tmp/log/...\", sess.graph) # Perform your computation... for i in range(1000): sess.run(train_op) # ... writer.close() 随后，您可以在 tensorboard 中打开日志并转到“图”标签，查看图结构的概要可视化图表。请注意，典型的 TensorFlow 图（尤其是具有自动计算的梯度的训练图）包含的节点太多，无法一次性完成直观展示。图可视化工具使用名称范围来将相关指令分组到“超级”节点中。您可以点击任意超级节点上的橙色“+”按钮以展开内部的子图。","categories":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://gowa2017.github.io/categories/TensorFlow/"}],"tags":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://gowa2017.github.io/tags/TensorFlow/"},{"name":"Python","slug":"Python","permalink":"https://gowa2017.github.io/tags/Python/"}],"keywords":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://gowa2017.github.io/categories/TensorFlow/"}]},{"title":"如何在TensorFlow中建立一个神经网络-01","slug":"如何在TensorFlow中建立一个神经网络-01","date":"2018-10-30T11:58:30.000Z","updated":"2018-10-30T11:58:30.000Z","comments":true,"path":"TensorFlow/如何在TensorFlow中建立一个神经网络-01.html","link":"","permalink":"https://gowa2017.github.io/TensorFlow/如何在TensorFlow中建立一个神经网络-01.html","excerpt":"原文 https://medium.com/@erikhallstrm/hello-world-rnn-83cd7105b767系列文章介绍了如何在 TensorFlow 中间建立一个神经网络。 这是第一部分，覆盖了很多基本的概念和技术。它从 RNN 开始进行介绍。","text":"原文 https://medium.com/@erikhallstrm/hello-world-rnn-83cd7105b767系列文章介绍了如何在 TensorFlow 中间建立一个神经网络。 这是第一部分，覆盖了很多基本的概念和技术。它从 RNN 开始进行介绍。 RNN 是什么RNN 是 Recurrent Neural Network（循环神经网络） 的简写。基本上其就是一个可以在你的数据被当做序列来对待时使用的 神经网络，在这个序列中，数据点的顺序很重要。更重要的是，序列可以有 任意长度。 最直接的例子可能就是一系列的数字的时间序列了，在这个序列中的任务就是通过前面的数字来预测下一个数字。在 RNN 每个时间步长这的输入是 当前值 和一个 状态向量 ，这个状态向量代表了这个网络在这个步长前所”看到“内容。这个 状态向量 就是 RNN 的编码存储器，初始设置为0。 至今为止我所发现的最全面介绍 RNN 的文章在 这里。现在我们只需要了解一些基础的就行了，当我们在讲到 Modern RNN architectures 一节的时候，就需要阅读一下了。这个随后再说。 尽管这篇文章包含了一些解释，但我们只是聚焦怎么样使用它。不过建议还是更多的了解一下其理论，原理，那里面的解释更加的丰富。 反向传播反向传播算法对于快速训练大型神经网络来说至关重要。本文将介绍该算法的工作原理。谷歌有一个对此的演示。反向传播算法 其基本的含义是理解起来我是感觉有点恼火的。根据其进行演示的过程来看。 神经网络每训练一次就会更新网络中的权重参数。正向传播 而反向传播会根据误差确定每个网络的权重更新幅度。 设置我们来建立一个简单的 回显-RNN ，它会记住输入的数据，并在几个时间步长后进行回显。首先看一下我们需要的几个常量。 from __future__ import print_function, divisionimport numpy as npimport tensorflow as tfimport matplotlib.pyplot as pltnum_epochs = 100total_series_length = 50000truncated_backprop_length = 15state_size = 4num_classes = 2echo_step = 3batch_size = 5num_batches = total_series_length//batch_size//truncated_backprop_length 生成数据现在我们来生成需要的训练数据，输入是一个随机的二元向量。输出会是输入的往右移动了 echo_step 步的回显。 def generateData(): x = np.array(np.random.choice(2, total_series_length, p=[0.5, 0.5])) y = np.roll(x, echo_step) y[0:echo_step] = 0 x = x.reshape((batch_size, -1)) # The first index changing slowest, subseries as rows y = y.reshape((batch_size, -1)) return (x, y) 注意到我们使用 reshape 来把数据变换为一个 batch_size 行的矩阵。通过仅查看数据的一小部分（也称为小批量），逼近关于神经元权重的损失函数的梯度来训练神经网络。在这个问题中进一步阐述了这样做的理论原因。重新整形采用整个数据集并将其放入矩阵中，这个矩阵稍后将切成这些小批量。 重新形成的数据矩阵的示意图，箭头曲线显示了最终在不同行上的相邻时间步长。浅灰色矩形表示“零”，深灰色表示“一”。 构建计算图TensorFlow的工作原理是首先构建一个计算图，这个图指定将要执行的操作。该图的输入和输出通常是多维数组，也称为张量。然后，可以在会话中迭代地执行图形或其部分，这可以在CPU，GPU甚至远程服务器上的资源上完成。 变量和占位符将在此示例中使用的两个基本TensorFlow数据结构是占位符和变量。在每次运行中，批次数据被馈送到占位符，占位符是计算图的“起始节点”。此外，RNN状态也在一个占位符中提供，该占位符从前一次运行的输出中保存。 batchX_placeholder = tf.placeholder(tf.float32, [batch_size, truncated_backprop_length])batchY_placeholder = tf.placeholder(tf.int32, [batch_size, truncated_backprop_length])init_state = tf.placeholder(tf.float32, [batch_size, state_size]) 网络的权重和偏差被声明为TensorFlow 变量，这使得它们在运行期间持久化，并使它们能够以递增方式为每个批次进行更新。 W = tf.Variable(np.random.rand(state_size+1, state_size), dtype=tf.float32)b = tf.Variable(np.zeros((1,state_size)), dtype=tf.float32)W2 = tf.Variable(np.random.rand(state_size, num_classes),dtype=tf.float32)b2 = tf.Variable(np.zeros((1,num_classes)), dtype=tf.float32) 下图显示了输入数据矩阵，当前批次 batchX_placeholder 位于虚线矩形中。正如我们稍后将看到的，这个“批处理窗口” 在每次运行时向右滑动 truncated_backprop_length 步，沿着箭头走。在下面的例子中batch_size = 3，truncated_backprop_length = 3和total_series_length = 36。请注意，这些数字仅用于可视化目的，代码中的值不同。数据系列的索引在几个数据点中显示为数字。 开箱现在是时候构建类似于实际RNN计算的图形部分了，首先我们要将批处理数据分成相邻的时间步长。 ＃解压缩列inputs_series = tf.unstack（batchX_placeholder，axis = 1）labels_series = tf.unstack（batchY_placeholder，axis = 1） 补充一下：张量是一个概念，而 TensorFlow 中张量的实现用的是多维数组 unstack的结果，是将一个多维的张量降阶。如 [[ 0 1 2 3 4 5 6 7 8 9] [10 11 12 13 14 15 16 17 18 19] [20 21 22 23 24 25 26 27 28 29] [30 31 32 33 34 35 36 37 38 39] [40 41 42 43 44 45 46 47 48 49]]unstack后将是[array([ 0, 10, 20, 30, 40]), array([ 1, 11, 21, 31, 41]), array([ 2, 12, 22, 32, 42]), array([ 3, 13, 23, 33, 43]), array([ 4, 14, 24, 34, 44]), array([ 5, 15, 25, 35, 45]), array([ 6, 16, 26, 36, 46]), array([ 7, 17, 27, 37, 47]), array([ 8, 18, 28, 38, 48]), array([ 9, 19, 29, 39, 49])] 正如您在下图中所看到的那样，通过axis = 1将批处理的列（）解压缩到Python列表中来完成。RNN将同时对时间序列中的不同部分进行训练; 当前批次示例中的步骤4至6,16至18和28至30。使用变量名称的原因“plural”_”series”是为了强调该变量是一个列表，表示每个步骤中具有多个条目的时间序列。 在我们的时间序列中同时在三个地方进行训练的事实要求我们在向前传播时保存三个状态实例。已经考虑到了这一点，因为您看到init_state占位符有batch_size行。 转发接下来让我们构建执行实际RNN计算的图形部分。 # Forward passcurrent_state = init_statestates_series = []for current_input in inputs_series: current_input = tf.reshape(current_input, [batch_size, 1]) input_and_state_concatenated = tf.concat(1, [current_input, current_state]) # Increasing number of columns next_state = tf.tanh(tf.matmul(input_and_state_concatenated, W) + b) # Broadcasted addition states_series.append(next_state) current_state = next_state 注意第6行的连接，我们实际想要做的是计算下图中两个仿射变换的总和current_input Wa + current_state Wb。通过连接这两个张量，您将只使用一个矩阵乘法。加入偏置b的广播在该批次的所有样本。 您可能想知道变量名称truncated_backprop_length应该是什么意思。当训练RNN时，它实际上被视为深层神经网络，每层都有重复出现的权重。这些层将不会在开始时展开，这在计算上太昂贵，因此在有限数量的时间步骤中被截断。在上面的示例原理图中，错误在我们的批处理中反向传播了三个步骤。 计算损失这是图的最后一部分，从状态到输出的完全连接的softmax层将使类进行单热编码， 然后计算批量的损失。 logits_series = [tf.matmul(state, W2) + b2 for state in states_series] #Broadcasted additionpredictions_series = [tf.nn.softmax(logits) for logits in logits_series]losses = [tf.nn.sparse_softmax_cross_entropy_with_logits(logits, labels) for logits, labels in zip(logits_series,labels_series)]total_loss = tf.reduce_mean(losses)train_step = tf.train.AdagradOptimizer(0.3).minimize(total_loss) 最后一行是添加训练功能，TensorFlow将自动为我们执行反向传播 - 每个小批量执行一次计算图，并逐步更新网络权重。 注意API调用sparse_softmax_cross_entropy_with_logits，它会在内部自动计算softmax，然后计算交叉熵。在我们的示例中，类是互斥的（它们是零或一），这是使用“Sparse-softmax”的原因，您可以在API中阅读更多相关信息。用途是具有logits形状[batch_size, num_classes]和labels形状[batch_size]。 可视化训练有一个可视化功能，因此我们可以在训练时了解网络中正在发生的事情。它将绘制随时间的损失，显示训练输入，训练输出以及网络对训练批次中不同样本系列的当前预测。 def plot(loss_list, predictions_series, batchX, batchY): plt.subplot(2, 3, 1) plt.cla() plt.plot(loss_list) for batch_series_idx in range(5): one_hot_output_series = np.array(predictions_series)[:, batch_series_idx, :] single_output_series = np.array([(1 if out[0] &lt; 0.5 else 0) for out in one_hot_output_series]) plt.subplot(2, 3, batch_series_idx + 2) plt.cla() plt.axis([0, truncated_backprop_length, 0, 2]) left_offset = range(truncated_backprop_length) plt.bar(left_offset, batchX[batch_series_idx, :], width=1, color=\"blue\") plt.bar(left_offset, batchY[batch_series_idx, :] * 0.5, width=1, color=\"red\") plt.bar(left_offset, single_output_series * 0.3, width=1, color=\"green\") plt.draw() plt.pause(0.0001) 执行一个训练会话是时候结束并训练网络了，在TensorFlow中，图表在会话中执行。在每个时期生成新数据（不是通常的方式，但在这种情况下它可以工作，因为一切都是可预测的） with tf.Session() as sess: sess.run(tf.initialize_all_variables()) plt.ion() plt.figure() plt.show() loss_list = [] // 训练 num_epochs 批数据 for epoch_idx in range(num_epochs): x,y = generateData() _current_state = np.zeros((batch_size, state_size)) print(\"New data, epoch\", epoch_idx) #每批数据以小批量的形式进行训练 for batch_idx in range(num_batches): start_idx = batch_idx * truncated_backprop_length end_idx = start_idx + truncated_backprop_length batchX = x[:,start_idx:end_idx] batchY = y[:,start_idx:end_idx] _total_loss, _train_step, _current_state, _predictions_series = sess.run( [total_loss, train_step, current_state, predictions_series], feed_dict=&#123; batchX_placeholder:batchX, batchY_placeholder:batchY, init_state:_current_state &#125;) loss_list.append(_total_loss) if batch_idx%100 == 0: print(\"Step\",batch_idx, \"Loss\", _total_loss) plot(loss_list, _predictions_series, batchX, batchY)plt.ioff()plt.show() 你可以看到我们truncated_backprop_length在每次迭代时都在前进（第15-19行），但它可能有不同的步幅。该主题在进一步阐述了这篇文章。这样做的缺点是truncated_backprop_length需要明显大于时间依赖性（在我们的例子中是三个步骤）才能封装相关的训练数据。否则可能有很多“未命中”，如下图所示。 还要意识到这只是解释RNN如何工作的简单示例，只需几行代码即可轻松编写此功能。网络将能够准确地学习回声行为，因此不需要测试数据。 随着训练的进行，该计划将更新情节，如下图所示。蓝色条表示训练输入信号（二进制1），红色条表示训练输出中的回声，绿色条表示网络产生的回声。不同的条形图显示当前批次中的不同样品系列。 我们的算法可以很快地学习任务。左上角的图表显示了损失函数的输出，但为什么曲线中出现峰值？想一想，答案如下。 高峰的原因是我们正在开始一个新的时代，并产生新的数据。由于矩阵被重新整形，每行上的第一个元素与前一行中的最后一个元素相邻。所有行中的前几个元素（第一个除外）具有不包含在状态中的依赖项，因此网络将始终在第一批上执行不良。 完整代码from __future__ import print_function, divisionimport numpy as npimport tensorflow as tfimport matplotlib.pyplot as pltnum_epochs = 100total_series_length = 50000truncated_backprop_length = 15state_size = 4num_classes = 2echo_step = 3batch_size = 5num_batches = total_series_length//batch_size//truncated_backprop_lengthdef generateData(): x = np.array(np.random.choice(2, total_series_length, p=[0.5, 0.5])) y = np.roll(x, echo_step) y[0:echo_step] = 0 x = x.reshape((batch_size, -1)) # The first index changing slowest, subseries as rows y = y.reshape((batch_size, -1)) return (x, y)batchX_placeholder = tf.placeholder(tf.float32, [batch_size, truncated_backprop_length])batchY_placeholder = tf.placeholder(tf.int32, [batch_size, truncated_backprop_length])init_state = tf.placeholder(tf.float32, [batch_size, state_size])W = tf.Variable(np.random.rand(state_size+1, state_size), dtype=tf.float32)b = tf.Variable(np.zeros((1,state_size)), dtype=tf.float32)W2 = tf.Variable(np.random.rand(state_size, num_classes),dtype=tf.float32)b2 = tf.Variable(np.zeros((1,num_classes)), dtype=tf.float32)# Unpack columns# 我们的输入是 [batch_size, truncated_backprop_length] 也就是 [5, 15] 的矩阵# unstack后，就成为一个列表，列表内元素形状为[5]inputs_series = tf.unstack(batchX_placeholder, axis=1)labels_series = tf.unstack(batchY_placeholder, axis=1)# Forward passcurrent_state = init_statestates_series = []for current_input in inputs_series: current_input = tf.reshape(current_input, [batch_size, 1]) input_and_state_concatenated = tf.concat([current_input, current_state],1) # Increasing number of columns next_state = tf.tanh(tf.matmul(input_and_state_concatenated, W) + b) # Broadcasted addition states_series.append(next_state) current_state = next_statelogits_series = [tf.matmul(state, W2) + b2 for state in states_series] #Broadcasted additionpredictions_series = [tf.nn.softmax(logits) for logits in logits_series]losses = [tf.nn.sparse_softmax_cross_entropy_with_logits(logits, labels) for logits, labels in zip(logits_series,labels_series)]total_loss = tf.reduce_mean(losses)train_step = tf.train.AdagradOptimizer(0.3).minimize(total_loss)def plot(loss_list, predictions_series, batchX, batchY): plt.subplot(2, 3, 1) plt.cla() plt.plot(loss_list) for batch_series_idx in range(5): one_hot_output_series = np.array(predictions_series)[:, batch_series_idx, :] single_output_series = np.array([(1 if out[0] &lt; 0.5 else 0) for out in one_hot_output_series]) plt.subplot(2, 3, batch_series_idx + 2) plt.cla() plt.axis([0, truncated_backprop_length, 0, 2]) left_offset = range(truncated_backprop_length) plt.bar(left_offset, batchX[batch_series_idx, :], width=1, color=\"blue\") plt.bar(left_offset, batchY[batch_series_idx, :] * 0.5, width=1, color=\"red\") plt.bar(left_offset, single_output_series * 0.3, width=1, color=\"green\") plt.draw() plt.pause(0.0001)with tf.Session() as sess: sess.run(tf.initialize_all_variables()) plt.ion() plt.figure() plt.show() loss_list = [] for epoch_idx in range(num_epochs): x,y = generateData() _current_state = np.zeros((batch_size, state_size)) print(\"New data, epoch\", epoch_idx) for batch_idx in range(num_batches): start_idx = batch_idx * truncated_backprop_length end_idx = start_idx + truncated_backprop_length batchX = x[:,start_idx:end_idx] batchY = y[:,start_idx:end_idx] _total_loss, _train_step, _current_state, _predictions_series = sess.run( [total_loss, train_step, current_state, predictions_series], feed_dict=&#123; batchX_placeholder:batchX, batchY_placeholder:batchY, init_state:_current_state &#125;) loss_list.append(_total_loss) if batch_idx%100 == 0: print(\"Step\",batch_idx, \"Loss\", _total_loss) plot(loss_list, _predictions_series, batchX, batchY)plt.ioff()plt.show()","categories":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://gowa2017.github.io/categories/TensorFlow/"}],"tags":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://gowa2017.github.io/tags/TensorFlow/"},{"name":"Python","slug":"Python","permalink":"https://gowa2017.github.io/tags/Python/"}],"keywords":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://gowa2017.github.io/categories/TensorFlow/"}]},{"title":"去掉文件编码中的BOM标记","slug":"去掉文件编码中的BOM标记","date":"2018-10-26T15:21:10.000Z","updated":"2018-10-26T15:21:10.000Z","comments":true,"path":"Linux/去掉文件编码中的BOM标记.html","link":"","permalink":"https://gowa2017.github.io/Linux/去掉文件编码中的BOM标记.html","excerpt":"在编译一个 Demo 项目的时候，发现居然会出错。很奇怪，文件打开也正常。然后查找了一下关键字符就出来了。具体错误就是 非法字符: &#39;\\ufeff&#39; package com.dh.groupTree;","text":"在编译一个 Demo 项目的时候，发现居然会出错。很奇怪，文件打开也正常。然后查找了一下关键字符就出来了。具体错误就是 非法字符: &#39;\\ufeff&#39; package com.dh.groupTree; 原因原因是 微软下的 utf-8 编码加了 bom 标记。使用 file 命令来查看。 file *GroupListActivity.java: UTF-8 Unicode text, with CRLF line terminatorsGroupListAdapter.java: UTF-8 Unicode (with BOM) text, with CRLF line terminatorsGroupListGetTask.java: UTF-8 Unicode text, with CRLF line terminatorsGroupListManager.java: UTF-8 Unicode text, with CRLF line terminatorsSearchChannelsAdapter.java: UTF-8 Unicode (with BOM) text, with CRLF line terminators OK，然后在 https://unix.stackexchange.com/questions/381230/how-can-i-remove-the-bom-from-a-utf-8-file这里找到了好办法。 sed -i '1s/^\\xEF\\xBB\\xBF//' GroupListAdapter.java","categories":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/tags/Java/"},{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/tags/Linux/"}],"keywords":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}]},{"title":"macOS用HomeBrew安装Sqlplus","slug":"macOS用HomeBrew安装Sqlplus","date":"2018-10-26T05:17:43.000Z","updated":"2018-10-26T05:17:43.000Z","comments":true,"path":"Oracle/macOS用HomeBrew安装Sqlplus.html","link":"","permalink":"https://gowa2017.github.io/Oracle/macOS用HomeBrew安装Sqlplus.html","excerpt":"远程设备上用起来始终不太爽，调试起来麻烦，所以本地安装一个吧。原文","text":"远程设备上用起来始终不太爽，调试起来麻烦，所以本地安装一个吧。原文 下载http://www.oracle.com/technetwork/topics/intel-macsoft-096467.html. 从这网站下载两个文件这是必须的。因为甲骨文的授权问题。 instantclient-basic-macos.x64–11.2.0.4.0.zip instantclient-sqlplus-macos.x64–11.2.0.4.0.zip 把这两个文件放到 ~/Library/Caches/Homebrew 下 安装brew tap InstantClientTap/instantclientbrew install instantclient-basicbrew install instantclient-sqlplus 执行过程出了错照着改就是了： Error: The package file can not be downloaded automatically. Please sign inand accept the licence agreement on the Instant Client downloads page: http://www.oracle.com/technetwork/topics/intel-macsoft-096467.htmlThen manually download this file: http://download.oracle.com/otn/mac/instantclient/122010/instantclient-basic-macos.x64-12.2.0.1.0-2.zipTo this location (a specific filename in homebrew cache directory): /Users/wodediannao/Library/Caches/Homebrew/downloads/665aa2952dd4fcdbbe25f6a02ee3cc8cf5b39ab36c8001447b303fe567cc8354--instantclient-basic-macos.x64-12.2.0.1.0-2.zipAn example command to rename and move the file into the homebrew cache: $ cd /path/to/downloads &amp;&amp; mv instantclient-basic-macos.x64-12.2.0.1.0-2.zip /Users/wodediannao/Library/Caches/Homebrew/downloads/665aa2952dd4fcdbbe25f6a02ee3cc8cf5b39ab36c8001447b303fe567cc8354--instantclient-basic-macos.x64-12.2.0.1.0-2.zipInstead of renaming and moving you can create a symlink: $ cd /path/to/downloads &amp;&amp; ln -sf $(PWD)/instantclient-basic-macos.x64-12.2.0.1.0-2.zip /Users/wodediannao/Library/Caches/Homebrew/downloads/665aa2952dd4fcdbbe25f6a02ee3cc8cf5b39ab36c8001447b303fe567cc8354--instantclient-basic-macos.x64-12.2.0.1.0-2.zip 基本的原因就是必须要改成那种代码形式的文件名，放在download里面去。 brew tap这个命令经常在自定义下载的内容的时候用到。 选项参数： brew tap [--full] [--force-auto-update] user/repo [URL] 实际上就是指定一个我们要下载的项的源的意思。 如果我们没有指定 URL 参数，那么会使用 HTTPS 从 github 来获取。因为 github 上托管了很多的 tap，这其实是命令 brew tap user/repo https://github.com/user/homebrew-repo 的一个简写。 如果指定了 URL 的话，那么我们就可以从任何地方来获取资源了，使用只要 git 能处理的传输协议。我们可以诸如 SSH, GIT, HTTP, FTP(S), RSYNC 这些协议来获取资源。 默认情况下，资源会作为 shadow copy( depth = 1) 来克隆，但如果我们指定 -full 参数的话，就会进行完整克隆。想要将一个 shadow copy 转换为 full copy ，指定 -full 参数 重新获取资源。","categories":[{"name":"Oracle","slug":"Oracle","permalink":"https://gowa2017.github.io/categories/Oracle/"}],"tags":[{"name":"Oracle","slug":"Oracle","permalink":"https://gowa2017.github.io/tags/Oracle/"},{"name":"Sqlplus","slug":"Sqlplus","permalink":"https://gowa2017.github.io/tags/Sqlplus/"}],"keywords":[{"name":"Oracle","slug":"Oracle","permalink":"https://gowa2017.github.io/categories/Oracle/"}]},{"title":"Activiti数据库表结构","slug":"Activiti数据库表结构","date":"2018-10-24T15:46:11.000Z","updated":"2018-10-24T15:46:11.000Z","comments":true,"path":"Java/Activiti数据库表结构.html","link":"","permalink":"https://gowa2017.github.io/Java/Activiti数据库表结构.html","excerpt":"公司有用到这个来做工作流的任务，一直不清楚，但做维护的话不能不明白，所以就搜索了一下。现在做记录。原文地址：https://blog.csdn.net/muzi1314_/article/details/78649496https://blog.csdn.net/romantichjwhjwhjw/article/details/40650671","text":"公司有用到这个来做工作流的任务，一直不清楚，但做维护的话不能不明白，所以就搜索了一下。现在做记录。原文地址：https://blog.csdn.net/muzi1314_/article/details/78649496https://blog.csdn.net/romantichjwhjwhjw/article/details/40650671 Activiti-5.21数据字典 简介 # 前缀 描述 1 ACT\\_RE_ RE表示Repository资源库，保存流程定义，模型等设计阶段的数据。 2 ACT\\_RU_ RU表示Runtime运行时，保存流程实例，任务，变量等运行阶段的数据。 3 ACT\\_HI_ HI表示History历史，保存历史实例，历史任务等流程历史数据。 4 ACT\\_ID_ ID表示Identity身份，保存用户，群组，关系等组织机构相关数据。（Activiti中的组织机构过于简单，仅用于演示。） 5 ACT\\_GE_ GE表示General通用，属于一些通用配置。 6 其他 ACT\\_EVT_LOG和ACT\\_PROCDEF_INFO没有按照规则来，两者分别属于HI和RE。 ACT\\_RE_ ACT\\_RU_ ACT\\_HI_ 数据库 # 表名 描述 1 ACT\\_EVT_LOG 事件日志 2 ACT\\_GE_BYTEARRY xml, png等二进制内容 3 ACT\\_GE_PROPERTY 引擎版本信息 4 ACT\\_HI_ACTINST 历史节点 5 ACT\\_HI_ATTACHMENT 附件 6 ACT\\_HI_COMMENT 评论 7 ACT\\_HI_DETAIL 变更历史 8 ACT\\_HI_IDENTITYLINK 历史参与者 9 ACT\\_HI_PROCINST 历史流程实例 10 ACT\\_HI_TASKINST 历史任务 11 ACT\\_HI_VARINST 历史变量 12 ACT\\_ID_GROUP 群组 13 ACT\\_ID_INFO 用户的人员详细信息 14 ACT\\_ID_MEMBERSHIP 用户与群组关系 15 ACT\\_ID_USER 用户的基本信息 16 ACT\\_PROCDEF_INFO 流程定义的动态变更信息 17 ACT\\_RE_DEPLOYMENT 部署包 18 ACT\\_RE_MODEL 模型（用于Web Designer） 19 ACT\\_RE_PROCDEF 流程定义 20 ACT\\_RE_EVENT_SUBSCR 事件监听 21 ACT\\_RU_EXECUTION 流程实例与分支 22 ACT\\_RU_IDENTITYLINK 参与者 23 ACT\\_RU_JOB 异步作业 24 ACT\\_RU_TASK 任务 25 ACT\\_RU_VARIABLE 变量 ACT\\_EVT_LOG 事件日志，默认不开启。 # 字段名 字段类型 长度 空 默认 描述 主键 外键 1 LOG_NR_ BIGINT 19 &nbsp; &nbsp; 主键 自增 &nbsp; 2 TYPE_ VARCHAR 64 &nbsp; &nbsp; 类型 &nbsp; &nbsp; 3 PROC_DEF_ID_ VARCHAR 64 &nbsp; &nbsp; 流程定义 &nbsp; &nbsp; 4 PROC_INST_ID_ VARCHAR 64 &nbsp; &nbsp; 流程实例 &nbsp; &nbsp; 5 EXECUTION_ID_ VARCHAR 64 &nbsp; &nbsp; 执行 &nbsp; &nbsp; 6 TASK_ID_ VARCHAR 64 &nbsp; &nbsp; 任务 &nbsp; &nbsp; 7 TIME_STAMP_ TIMESTAMP 19 NOT NULL CURRENT_TIMESTAMP 时间 &nbsp; &nbsp; 8 USER_ID_ VARCHAR 255 &nbsp; &nbsp; 用户 &nbsp; &nbsp; 9 DATA_ LONGBLOB 2147483647 &nbsp; &nbsp; 内容 &nbsp; &nbsp; 10 LOCK_OWNER_ VARCHAR 255 &nbsp; &nbsp; 锁定节点 &nbsp; &nbsp; 11 LOCK_TIME_ TIMESTAMP 19 &nbsp; &nbsp; 锁定时间 &nbsp; &nbsp; 12 IS_PROCESSED_ TINYINT 3 &nbsp; 0 是否正在执行 &nbsp; &nbsp; ACT\\_GE_BYTEARRAY 所有二进制内容都会保存在这个表里，比如部署的process.bpmn20.xml, process.png, user.form, 附件，bean序列化为二进制的流程变量。 # 字段名 字段类型 长度 空 默认 描述 主键 外键 1 ID_ VARCHAR 64 &nbsp; &nbsp; 主键 &nbsp; &nbsp; 2 REV_ INT 10 &nbsp; &nbsp; 乐观锁 &nbsp; &nbsp; 3 NAME_ VARCHAR 255 &nbsp; &nbsp; 名称 &nbsp; &nbsp; 4 DEPLOYMENT_ID_ VARCHAR 64 &nbsp; &nbsp; 部署 &nbsp; ACT\\_RE_DEPLOYMENT 5 BYTES_ LONGBLOB 2147483647 &nbsp; &nbsp; 内容 &nbsp; &nbsp; 6 GENERATED_ TINYINT 3 &nbsp; &nbsp; 0为用户上传，1为系统自动生成，比如系统会自动根据xml生成png &nbsp; &nbsp; ACT\\_GE_PROPERTY 全局参数，默认三个参数next.dbid，IdGenerator区间，schema.history，自动执行sql历史，schema.version，当前sql版本。 # 字段名 字段类型 长度 空 默认 描述 主键 外键 1 NAME_ VARCHAR 64 &nbsp; &nbsp; 主键，参数名 &nbsp; &nbsp; 2 VALUE_ VARCHAR 300 &nbsp; &nbsp; 参数值 &nbsp; &nbsp; 3 REV_ INT 10 &nbsp; &nbsp; 乐观锁 &nbsp; &nbsp; ACT\\_HI_ACTINST 环节历史信息 # 字段名 字段类型 长度 空 默认 描述 主键 外键 1 ID_ VARCHAR 64 &nbsp; &nbsp; 主键 &nbsp; &nbsp; 2 PROC_DEF_ID_ VARCHAR 64 NOT NULL &nbsp; 流程定义 &nbsp; &nbsp; 3 PROC_INST_ID_ VARCHAR 64 NOT NULL &nbsp; 流程实例 &nbsp; &nbsp; 4 EXECUTION_ID_ VARCHAR 64 NOT NULL &nbsp; 执行 &nbsp; &nbsp; 5 ACT\\_ID_ VARCHAR 255 NOT NULL &nbsp; 环节ID &nbsp; &nbsp; 6 TASK_ID_ VARCHAR 64 &nbsp; &nbsp; 任务 &nbsp; &nbsp; 7 CALL_PROC_INST_ID_ VARCHAR 64 &nbsp; &nbsp; 父流程实例 &nbsp; &nbsp; 8 ACT\\_NAME_ VARCHAR 255 &nbsp; &nbsp; 环节名称 &nbsp; &nbsp; 9 ACT\\_TYPE_ VARCHAR 255 NOT NULL &nbsp; 环节类型 &nbsp; &nbsp; 10 ASSIGNEE_ VARCHAR 255 &nbsp; &nbsp; 负责人 &nbsp; &nbsp; 11 START_TIME_ DATETIME 19 NOT NULL &nbsp; 开始时间 &nbsp; &nbsp; 12 END_TIME_ DATETIME 19 &nbsp; &nbsp; 结束时间 &nbsp; &nbsp; 13 DURATION_ BIGINT 19 &nbsp; &nbsp; 持续时间 &nbsp; &nbsp; 14 TENANT_ID_ VARCHAR 255 &nbsp; &nbsp; 多租户 &nbsp; &nbsp; ACT\\_HI_ATTACHMENT 附件 # 字段名 字段类型 长度 空 默认 描述 主键 外键 1 ID_ VARCHAR 64 &nbsp; &nbsp; 主键 &nbsp; &nbsp; 2 REV_ INT 10 &nbsp; &nbsp; 乐观锁 &nbsp; &nbsp; 3 USER_ID_ VARCHAR 255 &nbsp; &nbsp; 用户 &nbsp; &nbsp; 4 NAME_ VARCHAR 255 &nbsp; &nbsp; 名称 &nbsp; &nbsp; 5 DESCRIPTION_ VARCHAR 4000 &nbsp; &nbsp; 描述 &nbsp; &nbsp; 6 TYPE_ VARCHAR 255 &nbsp; &nbsp; 类型 &nbsp; &nbsp; 7 TASK_ID_ VARCHAR 64 &nbsp; &nbsp; 任务 &nbsp; &nbsp; 8 PROC_INST_ID_ VARCHAR 64 &nbsp; &nbsp; 流程实例 &nbsp; &nbsp; 9 URL_ VARCHAR 4000 &nbsp; &nbsp; URL &nbsp; &nbsp; 10 CONTENT_ID_ VARCHAR 64 &nbsp; &nbsp; 内容 ACT\\_GE_BYTEARRAY &nbsp; &nbsp; 11 TIME_ DATETIME 19 &nbsp; &nbsp; 时间 &nbsp; &nbsp; ACT\\_HI_COMMENT 评论 # 字段名 字段类型 长度 空 默认 描述 主键 外键 1 ID_ VARCHAR 64 &nbsp; &nbsp; 主键 &nbsp; &nbsp; 2 TYPE_ VARCHAR 255 &nbsp; &nbsp; 类型，默认有event, comment理解成操作和评论。 &nbsp; &nbsp; 3 TIME_ DATETIME 19 NOT NULL &nbsp; 时间 &nbsp; &nbsp; 4 USER_ID_ VARCHAR 255 &nbsp; &nbsp; 用户 &nbsp; &nbsp; 5 TASK_ID_ VARCHAR 64 &nbsp; &nbsp; 任务 &nbsp; &nbsp; 6 PROC_INST_ID_ VARCHAR 64 &nbsp; &nbsp; 流程实例 &nbsp; &nbsp; 7 ACTION_ VARCHAR 255 &nbsp; &nbsp; 操作 &nbsp; &nbsp; 8 MESSAGE_ VARCHAR 4000 &nbsp; &nbsp; 消息 &nbsp; &nbsp; 9 FULL_MSG_ LONGBLOB 2147483647 &nbsp; &nbsp; 完整消息（字段更长） &nbsp; &nbsp; ACT\\_HI_DETAIL 历史详情信息。 # 字段名 字段类型 长度 空 默认 描述 主键 外键 1 ID_ VARCHAR 64 &nbsp; &nbsp; 主键 &nbsp; &nbsp; 2 TYPE_ VARCHAR 255 NOT NULL &nbsp; 类型 FormProperty, VariableUpdate &nbsp; &nbsp; 3 PROC_INST_ID_ VARCHAR 64 &nbsp; &nbsp; 流程实例 &nbsp; &nbsp; 4 EXECUTION_ID_ VARCHAR 64 &nbsp; &nbsp; 执行 &nbsp; &nbsp; 5 TASK_ID_ VARCHAR 64 &nbsp; &nbsp; 任务 &nbsp; &nbsp; 6 ACT\\_INST_ID_ VARCHAR 64 &nbsp; &nbsp; 环节ID &nbsp; &nbsp; 7 NAME_ VARCHAR 255 NOT NULL &nbsp; 名称 &nbsp; &nbsp; 8 VAR_TYPE_ VARCHAR 255 &nbsp; &nbsp; 变量类型 &nbsp; &nbsp; 9 REV_ INT 10 &nbsp; &nbsp; 乐观锁 &nbsp; &nbsp; 10 TIME_ DATETIME 19 NOT NULL &nbsp; 时间 &nbsp; &nbsp; 11 BYTEARRAY_ID_ VARCHAR 64 &nbsp; &nbsp; 内容 ACT\\_GE_BYTEARRAY &nbsp; &nbsp; 12 DOUBLE_ DOUBLE 22 &nbsp; &nbsp; 浮点值 &nbsp; &nbsp; 13 LONG_ BIGINT 19 &nbsp; &nbsp; 长整型值 &nbsp; &nbsp; 14 TEXT_ VARCHAR 4000 &nbsp; &nbsp; 文本值 &nbsp; &nbsp; 15 TEXT2_ VARCHAR 4000 &nbsp; &nbsp; jpa变量text存className,text2存id &nbsp; &nbsp; ACT\\_HI_IDENTITYLINK 参与者历史 # 字段名 字段类型 长度 空 默认 描述 主键 外键 1 ID_ VARCHAR 64 &nbsp; &nbsp; 主键 &nbsp; &nbsp; 2 GROUP_ID_ VARCHAR 255 &nbsp; &nbsp; 群组 &nbsp; &nbsp; 3 TYPE_ VARCHAR 255 &nbsp; &nbsp; 类型，assignee, candidate, owner, starter, participant &nbsp; &nbsp; 4 USER_ID_ VARCHAR 255 &nbsp; &nbsp; 用户 &nbsp; &nbsp; 5 TASK_ID_ VARCHAR 64 &nbsp; &nbsp; 任务 &nbsp; &nbsp; 6 PROC_INST_ID_ VARCHAR 64 &nbsp; &nbsp; 流程实例 &nbsp; &nbsp; ACT\\_HI_PROCINST 流程实例历史 # 字段名 字段类型 长度 空 默认 描述 主键 外键 1 ID_ VARCHAR 64 &nbsp; &nbsp; 主键 &nbsp; &nbsp; 2 PROC_INST_ID_ VARCHAR 64 NOT NULL &nbsp; 流程实例 &nbsp; &nbsp; 3 BUSINESS_KEY_ VARCHAR 255 &nbsp; &nbsp; 业务标识 &nbsp; &nbsp; 4 PROC_DEF_ID_ VARCHAR 64 NOT NULL &nbsp; 流程定义 &nbsp; &nbsp; 5 START_TIME_ DATETIME 19 NOT NULL &nbsp; 开始时间 &nbsp; &nbsp; 6 END_TIME_ DATETIME 19 &nbsp; &nbsp; 结束时间 &nbsp; &nbsp; 7 DURATION_ BIGINT 19 &nbsp; &nbsp; 持续时间 &nbsp; &nbsp; 8 START_USER_ID_ VARCHAR 255 &nbsp; &nbsp; 流程发起人 &nbsp; &nbsp; 9 START_ACT\\_ID_ VARCHAR 255 &nbsp; &nbsp; 开始环节ID &nbsp; &nbsp; 10 END_ACT\\_ID_ VARCHAR 255 &nbsp; &nbsp; 结束环节ID &nbsp; &nbsp; 11 SUPER_PROCESS_INSTANCE_ID_ VARCHAR 64 &nbsp; &nbsp; 父流程实例 &nbsp; &nbsp; 12 DELETE_REASON_ VARCHAR 4000 &nbsp; &nbsp; 删除原因 &nbsp; &nbsp; 13 TENANT_ID_ VARCHAR 255 &nbsp; &nbsp; 多租户 &nbsp; &nbsp; 14 NAME_ VARCHAR 255 &nbsp; &nbsp; 名称 &nbsp; &nbsp; ACT\\_HI_TASKINST 任务历史 # 字段名 字段类型 长度 空 默认 描述 主键 外键 1 ID_ VARCHAR 64 &nbsp; &nbsp; 主键 &nbsp; &nbsp; 2 PROC_DEF_ID_ VARCHAR 64 &nbsp; &nbsp; 流程定义 &nbsp; &nbsp; 3 TASK_DEF_KEY_ VARCHAR 255 &nbsp; &nbsp; 任务定义标识（环节ID） &nbsp; &nbsp; 4 PROC_INST_ID_ VARCHAR 64 &nbsp; &nbsp; 流程实例 &nbsp; &nbsp; 5 EXECUTION_ID_ VARCHAR 64 &nbsp; &nbsp; 执行 &nbsp; &nbsp; 6 NAME_ VARCHAR 255 &nbsp; &nbsp; 名称 &nbsp; &nbsp; 7 PARENT_TASK_ID_ VARCHAR 64 &nbsp; &nbsp; 父任务 &nbsp; &nbsp; 8 DESCRIPTION_ VARCHAR 4000 &nbsp; &nbsp; 描述 &nbsp; &nbsp; 9 OWNER_ VARCHAR 255 &nbsp; &nbsp; 被代理人 &nbsp; &nbsp; 10 ASSIGNEE_ VARCHAR 255 &nbsp; &nbsp; 负责人 &nbsp; &nbsp; 11 START_TIME_ DATETIME 19 NOT NULL &nbsp; 开始时间 &nbsp; &nbsp; 12 CLAIM_TIME_ DATETIME 19 &nbsp; &nbsp; 领取时间 &nbsp; &nbsp; 13 END_TIME_ DATETIME 19 &nbsp; &nbsp; 结束时间 &nbsp; &nbsp; 14 DURATION_ BIGINT 19 &nbsp; &nbsp; 持续时间 &nbsp; &nbsp; 15 DELETE_REASON_ VARCHAR 4000 &nbsp; &nbsp; 删除原因 &nbsp; &nbsp; 16 PRIORITY_ INT 10 &nbsp; &nbsp; 优先级 &nbsp; &nbsp; 17 DUE_DATE_ DATETIME 19 &nbsp; &nbsp; 截止时间 &nbsp; &nbsp; 18 FORM_KEY_ VARCHAR 255 &nbsp; &nbsp; 表单标识 &nbsp; &nbsp; 19 CATEGORY_ VARCHAR 255 &nbsp; &nbsp; 分类 &nbsp; &nbsp; 20 TENANT_ID_ VARCHAR 255 &nbsp; &nbsp; 多租户 &nbsp; &nbsp; ACT\\_HI_VARINST 变量历史 # 字段名 字段类型 长度 空 默认 描述 主键 外键 1 ID_ VARCHAR 64 &nbsp; &nbsp; 主键 &nbsp; &nbsp; 2 PROC_INST_ID_ VARCHAR 64 &nbsp; &nbsp; 流程时间 &nbsp; &nbsp; 3 EXECUTION_ID_ VARCHAR 64 &nbsp; &nbsp; 执行 &nbsp; &nbsp; 4 TASK_ID_ VARCHAR 64 &nbsp; &nbsp; 任务 &nbsp; &nbsp; 5 NAME_ VARCHAR 255 NOT NULL &nbsp; 名称 &nbsp; &nbsp; 6 VAR_TYPE_ VARCHAR 100 &nbsp; &nbsp; 类型 &nbsp; &nbsp; 7 REV_ INT 10 &nbsp; &nbsp; 乐观锁 &nbsp; &nbsp; 8 BYTEARRAY_ID_ VARCHAR 64 &nbsp; &nbsp; 内容 ACT\\_GE_BYTEARRAY &nbsp; &nbsp; 9 DOUBLE_ DOUBLE 22 &nbsp; &nbsp; 浮点值 &nbsp; &nbsp; 10 LONG_ BIGINT 19 &nbsp; &nbsp; 长整数值 &nbsp; &nbsp; 11 TEXT_ VARCHAR 4000 &nbsp; &nbsp; 文本值 &nbsp; &nbsp; 12 TEXT2_ VARCHAR 4000 &nbsp; &nbsp; jpa变量text存className,text2存id &nbsp; &nbsp; 13 CREATE_TIME_ DATETIME 19 &nbsp; &nbsp; 创建时间 &nbsp; &nbsp; 14 LAST_UPDATED_TIME_ DATETIME 19 &nbsp; &nbsp; 最后更新时间 &nbsp; &nbsp; ACT\\_ID_GROUP 群组 # 字段名 字段类型 长度 空 默认 描述 主键 外键 1 ID_ VARCHAR 64 &nbsp; &nbsp; 主键 &nbsp; &nbsp; 2 REV_ INT 10 &nbsp; &nbsp; 多租户 &nbsp; &nbsp; 3 NAME_ VARCHAR 255 &nbsp; &nbsp; 名称 &nbsp; &nbsp; 4 TYPE_ VARCHAR 255 &nbsp; &nbsp; 类型 &nbsp; &nbsp; ACT\\_ID_INFO 用户详细信息 # 字段名 字段类型 长度 空 默认 描述 主键 外键 1 ID_ VARCHAR 64 &nbsp; &nbsp; 主键 &nbsp; &nbsp; 2 REV_ INT 10 &nbsp; &nbsp; 乐观锁 &nbsp; &nbsp; 3 USER_ID_ VARCHAR 64 &nbsp; &nbsp; 用户 &nbsp; &nbsp; 4 TYPE_ VARCHAR 64 &nbsp; &nbsp; 类型 &nbsp; &nbsp; 5 KEY_ VARCHAR 255 &nbsp; &nbsp; 属性名 &nbsp; &nbsp; 6 VALUE_ VARCHAR 255 &nbsp; &nbsp; 属性值 &nbsp; &nbsp; 7 PASSWORD_ LONGBLOB 2147483647 &nbsp; &nbsp; 密码 &nbsp; &nbsp; 8 PARENT_ID_ VARCHAR 255 &nbsp; &nbsp; 上级关联 &nbsp; &nbsp; ACT\\_ID_MEMBERSHIP 用户群组关系 # 字段名 字段类型 长度 空 默认 描述 主键 外键 1 USER_ID_ VARCHAR 64 &nbsp; &nbsp; 用户 &nbsp; ACT\\_ID_USER 2 GROUP_ID_ VARCHAR 64 &nbsp; &nbsp; 群组 &nbsp; ACT\\_ID_GROUP ACT\\_ID_USER 用户基本信息 # 字段名 字段类型 长度 空 默认 描述 主键 外键 1 ID_ VARCHAR 64 &nbsp; &nbsp; 主键 &nbsp; &nbsp; 2 REV_ INT 10 &nbsp; &nbsp; 乐观锁 &nbsp; &nbsp; 3 FIRST_ VARCHAR 255 &nbsp; &nbsp; 名 &nbsp; &nbsp; 4 LAST_ VARCHAR 255 &nbsp; &nbsp; 姓 &nbsp; &nbsp; 5 EMAIL_ VARCHAR 255 &nbsp; &nbsp; 邮箱 &nbsp; &nbsp; 6 PWD_ VARCHAR 255 &nbsp; &nbsp; 密码 &nbsp; &nbsp; 7 PICTURE_ID_ VARCHAR 64 &nbsp; &nbsp; 头像 ACT\\_GE_BYTEARRAY &nbsp; &nbsp; ACT\\_PROCDEF_INFO 流程定义更新信息 # 字段名 字段类型 长度 空 默认 描述 主键 外键 1 ID_ VARCHAR 64 &nbsp; &nbsp; 主键 &nbsp; &nbsp; 2 PROC_DEF_ID_ VARCHAR 64 NOT NULL &nbsp; 流程定义 &nbsp; ACT\\_RE_PROCDEF 3 REV_ INT 10 &nbsp; &nbsp; 乐观锁 &nbsp; &nbsp; 4 INFO_JSON_ID_ VARCHAR 64 &nbsp; &nbsp; 内容 &nbsp; ACT\\_GE_BYTEARRAY ACT\\_RE_DEPLOYMENT 部署 # 字段名 字段类型 长度 空 默认 描述 主键 外键 1 ID_ VARCHAR 64 &nbsp; &nbsp; 主键 &nbsp; &nbsp; 2 NAME_ VARCHAR 255 &nbsp; &nbsp; 名称 &nbsp; &nbsp; 3 CATEGORY_ VARCHAR 255 &nbsp; &nbsp; 分类 &nbsp; &nbsp; 4 TENANT_ID_ VARCHAR 255 &nbsp; &nbsp; 多租户 &nbsp; &nbsp; 5 DEPLOY_TIME_ TIMESTAMP 19 &nbsp; &nbsp; 部署时间 &nbsp; &nbsp; ACT\\_RE_MODEL 模型 # 字段名 字段类型 长度 空 默认 描述 主键 外键 1 ID_ VARCHAR 64 &nbsp; &nbsp; 主键 &nbsp; &nbsp; 2 REV_ INT 10 &nbsp; &nbsp; 乐观锁 &nbsp; &nbsp; 3 NAME_ VARCHAR 255 &nbsp; &nbsp; 名称 &nbsp; &nbsp; 4 KEY_ VARCHAR 255 &nbsp; &nbsp; 标识 &nbsp; &nbsp; 5 CATEGORY_ VARCHAR 255 &nbsp; &nbsp; 分类 &nbsp; &nbsp; 6 CREATE_TIME_ TIMESTAMP 19 &nbsp; &nbsp; 创建时间 &nbsp; &nbsp; 7 LAST_UPDATE_TIME_ TIMESTAMP 19 &nbsp; &nbsp; 最后更新时间 &nbsp; &nbsp; 8 VERSION_ INT 10 &nbsp; &nbsp; 版本 &nbsp; &nbsp; 9 META_INFO_ VARCHAR 4000 &nbsp; &nbsp; 元数据 &nbsp; &nbsp; 10 DEPLOYMENT_ID_ VARCHAR 64 &nbsp; &nbsp; 部署 &nbsp; ACT\\_RE_DEPLOYMENT 11 EDITOR_SOURCE_VALUE_ID_ VARCHAR 64 &nbsp; &nbsp; 设计器原始信息 &nbsp; ACT\\_GE_BYTEARRAY 12 EDITOR_SOURCE_EXTRA_VALUE_ID_ VARCHAR 64 &nbsp; &nbsp; 设计器扩展信息 &nbsp; ACT\\_GE_BYTEARRAY 13 TENANT_ID_ VARCHAR 255 &nbsp; &nbsp; 多租户 &nbsp; &nbsp; ACT\\_RE_PROCDEF 流程定义 # 字段名 字段类型 长度 空 默认 描述 主键 外键 1 ID_ VARCHAR 64 &nbsp; &nbsp; 主键 &nbsp; &nbsp; 2 REV_ INT 10 &nbsp; &nbsp; 乐观锁 &nbsp; &nbsp; 3 CATEGORY_ VARCHAR 255 &nbsp; &nbsp; 分类 &nbsp; &nbsp; 4 NAME_ VARCHAR 255 &nbsp; &nbsp; 名称 &nbsp; &nbsp; 5 KEY_ VARCHAR 255 NOT NULL &nbsp; 标识 &nbsp; &nbsp; 6 VERSION_ INT 10 NOT NULL &nbsp; 版本 &nbsp; &nbsp; 7 DEPLOYMENT_ID_ VARCHAR 64 &nbsp; &nbsp; 部署 &nbsp; &nbsp; 8 RESOURCE_NAME_ VARCHAR 4000 &nbsp; &nbsp; 资源名称 &nbsp; &nbsp; 9 DGRM_RESOURCE_NAME_ VARCHAR 4000 &nbsp; &nbsp; 图片资源名称 &nbsp; &nbsp; 10 DESCRIPTION_ VARCHAR 4000 &nbsp; &nbsp; 描述 &nbsp; &nbsp; 11 HAS_START_FORM_KEY_ TINYINT 3 &nbsp; &nbsp; 拥有开始表单标识 &nbsp; &nbsp; 12 HAS_GRAPHICAL_NOTATION_ TINYINT 3 &nbsp; &nbsp; 拥有图形信息 &nbsp; &nbsp; 13 SUSPENSION_STATE_ INT 10 &nbsp; &nbsp; 暂停状态 1激活 2暂停 &nbsp; &nbsp; 14 TENANT_ID_ VARCHAR 255 &nbsp; &nbsp; 多租户 &nbsp; &nbsp; ACT\\_RU_EVENT_SUBSCR 事件订阅 # 字段名 字段类型 长度 空 默认 描述 主键 外键 1 ID_ VARCHAR 64 &nbsp; &nbsp; 主键 &nbsp; &nbsp; 2 REV_ INT 10 &nbsp; &nbsp; 乐观锁 &nbsp; &nbsp; 3 EVENT_TYPE_ VARCHAR 255 NOT NULL &nbsp; 类型 &nbsp; &nbsp; 4 EVENT_NAME_ VARCHAR 255 &nbsp; &nbsp; 名称 &nbsp; &nbsp; 5 EXECUTION_ID_ VARCHAR 64 &nbsp; &nbsp; 执行 &nbsp; ACT\\_RU_EXECUTION 6 PROC_INST_ID_ VARCHAR 64 &nbsp; &nbsp; 流程实例 &nbsp; &nbsp; 7 ACTIVITY_ID_ VARCHAR 64 &nbsp; &nbsp; 环节ID &nbsp; &nbsp; 8 CONFIGURATION_ VARCHAR 255 &nbsp; &nbsp; 配置 &nbsp; &nbsp; 9 CREATED_ TIMESTAMP 19 NOT NULL CURRENT_TIMESTAMP 创建时间 &nbsp; &nbsp; 10 PROC_DEF_ID_ VARCHAR 64 &nbsp; &nbsp; 流程定义 &nbsp; &nbsp; 11 TENANT_ID_ VARCHAR 255 &nbsp; &nbsp; 多租户 &nbsp; &nbsp; ACT\\_RU_EXECUTION 执行 # 字段名 字段类型 长度 空 默认 描述 主键 外键 1 ID_ VARCHAR 64 &nbsp; &nbsp; 主键 &nbsp; &nbsp; 2 REV_ INT 10 &nbsp; &nbsp; 乐观锁 &nbsp; &nbsp; 3 PROC_INST_ID_ VARCHAR 64 &nbsp; &nbsp; 流程实例 &nbsp; ACT\\_RU_EXECUTION 4 BUSINESS_KEY_ VARCHAR 255 &nbsp; &nbsp; 业务标识 &nbsp; &nbsp; 5 PARENT_ID_ VARCHAR 64 &nbsp; &nbsp; 父执行 &nbsp; ACT\\_RU_EXECUTION 6 PROC_DEF_ID_ VARCHAR 64 &nbsp; &nbsp; 流程定义 &nbsp; ACT\\_RE_PROCDEF 7 SUPER_EXEC_ VARCHAR 64 &nbsp; &nbsp; 父流程实例中对应的执行 &nbsp; ACT\\_RU_EXECUTION 8 ACT\\_ID_ VARCHAR 255 &nbsp; &nbsp; 环节ID &nbsp; &nbsp; 9 IS_ACTIVE_ TINYINT 3 &nbsp; &nbsp; 是否激活 &nbsp; &nbsp; 10 IS_CONCURRENT_ TINYINT 3 &nbsp; &nbsp; 是否并行分支 &nbsp; &nbsp; 11 IS_SCOPE_ TINYINT 3 &nbsp; &nbsp; 是否处于多实例或环节嵌套状态 &nbsp; &nbsp; 12 IS_EVENT_SCOPE_ TINYINT 3 &nbsp; &nbsp; 是否激活状态 &nbsp; &nbsp; 13 SUSPENSION_STATE_ INT 10 &nbsp; &nbsp; 暂停状态 1激活 2暂停 &nbsp; &nbsp; 14 CACHED_ENT_STATE_ INT 10 &nbsp; &nbsp; 缓存的状态，事件监听第1位 人工任务第2位 异步作业第3位 &nbsp; &nbsp; 15 TENANT_ID_ VARCHAR 255 &nbsp; &nbsp; 多租户 &nbsp; &nbsp; 16 NAME_ VARCHAR 255 &nbsp; &nbsp; 名称 &nbsp; &nbsp; 17 LOCK_TIME_ TIMESTAMP 19 &nbsp; &nbsp; 锁定时间 &nbsp; &nbsp; ACT\\_RU_IDENTITYLINK 参与者 # 字段名 字段类型 长度 空 默认 描述 主键 外键 1 ID_ VARCHAR 64 &nbsp; &nbsp; 主键 &nbsp; &nbsp; 2 REV_ INT 10 &nbsp; &nbsp; 乐观锁 &nbsp; &nbsp; 3 GROUP_ID_ VARCHAR 255 &nbsp; &nbsp; 群组 &nbsp; &nbsp; 4 TYPE_ VARCHAR 255 &nbsp; &nbsp; 类型 &nbsp; &nbsp; 5 USER_ID_ VARCHAR 255 &nbsp; &nbsp; 用户 &nbsp; &nbsp; 6 TASK_ID_ VARCHAR 64 &nbsp; &nbsp; 任务 &nbsp; ACT\\_RU_TASK 7 PROC_INST_ID_ VARCHAR 64 &nbsp; &nbsp; 流程实例 &nbsp; ACT\\_RU_EXECUTION 8 PROC_DEF_ID_ VARCHAR 64 &nbsp; &nbsp; 流程定义 &nbsp; ACT\\_RE_PROCDEF ACT\\_RU_JOB 异步作业 # 字段名 字段类型 长度 空 默认 描述 主键 外键 1 ID_ VARCHAR 64 &nbsp; &nbsp; 主键 &nbsp; &nbsp; 2 REV_ INT 10 &nbsp; &nbsp; 乐观锁 &nbsp; &nbsp; 3 TYPE_ VARCHAR 255 NOT NULL &nbsp; 类型 &nbsp; &nbsp; 4 LOCK_EXP_TIME_ TIMESTAMP 19 &nbsp; &nbsp; 锁定过期时间 &nbsp; &nbsp; 5 LOCK_OWNER_ VARCHAR 255 &nbsp; &nbsp; 锁定节点 &nbsp; &nbsp; 6 EXCLUSIVE_ BIT 0 &nbsp; &nbsp; 是否唯一 &nbsp; &nbsp; 7 EXECUTION_ID_ VARCHAR 64 &nbsp; &nbsp; 执行 &nbsp; &nbsp; 8 PROCESS_INSTANCE_ID_ VARCHAR 64 &nbsp; &nbsp; 流程实例 &nbsp; &nbsp; 9 PROC_DEF_ID_ VARCHAR 64 &nbsp; &nbsp; 流程定义 &nbsp; &nbsp; 10 RETRIES_ INT 10 &nbsp; &nbsp; 重试次数 &nbsp; &nbsp; 11 EXCEPTION_STACK_ID_ VARCHAR 64 &nbsp; &nbsp; 异常堆栈 &nbsp; ACT\\_GE_BYTEARRAY 12 EXCEPTION_MSG_ VARCHAR 4000 &nbsp; &nbsp; 异常信息 &nbsp; &nbsp; 13 DUEDATE_ TIMESTAMP 19 &nbsp; &nbsp; 截止时间 &nbsp; &nbsp; 14 REPEAT_ VARCHAR 255 &nbsp; &nbsp; 重复 &nbsp; &nbsp; 15 HANDLER_TYPE_ VARCHAR 255 &nbsp; &nbsp; 处理器类型 &nbsp; &nbsp; 16 HANDLER_CFG_ VARCHAR 4000 &nbsp; &nbsp; 处理器配置 &nbsp; &nbsp; 17 TENANT_ID_ VARCHAR 255 &nbsp; &nbsp; 多租户 &nbsp; &nbsp; ACT\\_RU_TASK 任务 # 字段名 字段类型 长度 空 默认 描述 主键 外键 1 ID_ VARCHAR 64 &nbsp; &nbsp; 主键 &nbsp; &nbsp; 2 REV_ INT 10 &nbsp; &nbsp; 乐观锁 &nbsp; &nbsp; 3 EXECUTION_ID_ VARCHAR 64 &nbsp; &nbsp; 执行 &nbsp; ACT\\_RU_EXECUTION 4 PROC_INST_ID_ VARCHAR 64 &nbsp; &nbsp; 流程实例 &nbsp; ACT\\_RU_EXECUTION 5 PROC_DEF_ID_ VARCHAR 64 &nbsp; &nbsp; 流程定义 &nbsp; ACT\\_RE_PROCDEF 6 NAME_ VARCHAR 255 &nbsp; &nbsp; 名称 &nbsp; &nbsp; 7 PARENT_TASK_ID_ VARCHAR 64 &nbsp; &nbsp; 父任务 &nbsp; &nbsp; 8 DESCRIPTION_ VARCHAR 4000 &nbsp; &nbsp; 描述 &nbsp; &nbsp; 9 TASK_DEF_KEY_ VARCHAR 255 &nbsp; &nbsp; 任务定义标识（环节ID） &nbsp; &nbsp; 10 OWNER_ VARCHAR 255 &nbsp; &nbsp; 被代理人 &nbsp; &nbsp; 11 ASSIGNEE_ VARCHAR 255 &nbsp; &nbsp; 负责人 &nbsp; &nbsp; 12 DELEGATION_ VARCHAR 64 &nbsp; &nbsp; 委托状态 PENDING委托中，RESOLVED已处理 &nbsp; &nbsp; 13 PRIORITY_ INT 10 &nbsp; &nbsp; 优先级 &nbsp; &nbsp; 14 CREATE_TIME_ TIMESTAMP 19 &nbsp; &nbsp; 创建时间 &nbsp; &nbsp; 15 DUE_DATE_ DATETIME 19 &nbsp; &nbsp; 截止时间 &nbsp; &nbsp; 16 CATEGORY_ VARCHAR 255 &nbsp; &nbsp; 分类 &nbsp; &nbsp; 17 SUSPENSION_STATE_ INT 10 &nbsp; &nbsp; 暂停状态 1激活 2暂停 &nbsp; &nbsp; 18 TENANT_ID_ VARCHAR 255 &nbsp; &nbsp; 多租户 &nbsp; &nbsp; 19 FORM_KEY_ VARCHAR 255 &nbsp; &nbsp; 表单标识 &nbsp; &nbsp; ACT\\_RU_VARIABLE 变量 # 字段名 字段类型 长度 空 默认 描述 主键 外键 1 ID_ VARCHAR 64 &nbsp; &nbsp; 主键 &nbsp; &nbsp; 2 REV_ INT 10 &nbsp; &nbsp; 乐观锁 &nbsp; &nbsp; 3 TYPE_ VARCHAR 255 NOT NULL &nbsp; 类型 &nbsp; &nbsp; 4 NAME_ VARCHAR 255 NOT NULL &nbsp; 名称 &nbsp; &nbsp; 5 EXECUTION_ID_ VARCHAR 64 &nbsp; &nbsp; 执行 &nbsp; ACT\\_RU_EXECUTION 6 PROC_INST_ID_ VARCHAR 64 &nbsp; &nbsp; 流程实例 &nbsp; ACT\\_RU_EXECUTION 7 TASK_ID_ VARCHAR 64 &nbsp; &nbsp; 任务 &nbsp; &nbsp; 8 BYTEARRAY_ID_ VARCHAR 64 &nbsp; &nbsp; 内容 &nbsp; ACT\\_GE_BYTEARRAY 9 DOUBLE_ DOUBLE 22 &nbsp; &nbsp; 浮点值 &nbsp; &nbsp; 10 LONG_ BIGINT 19 &nbsp; &nbsp; 长整数值 &nbsp; &nbsp; 11 TEXT_ VARCHAR 4000 &nbsp; &nbsp; 文本值 &nbsp; &nbsp; 12 TEXT2_ VARCHAR 4000 &nbsp; &nbsp; jpa变量text存className,text2存id 补充说明1）activiti的历史任务是单独的表来储存，表之间没有任何外间关联，从以上模型就可以看出 1、ACT_HI_ACTINST 流程活动历史记录信息2、ACT_HI_ATTACHMENT 3、ACT_HI_COMMENT 流程评论信息4、ACT_HI_DETAIL 流程明细信息5、ACT_HI_IDENTITYLINK 流程身份关系信息6、ACT_HI_PROCINST 流程历史信息7、ACT_HI_TASKINST 任务历史信息8、ACT_HI_VARINST 历史流程中的参数 2）historyService可查询历史数据表（可查询以上这些表，与流程历史相关数据的查询都可以通过&lt;span style=&quot;font-family: Arial, Helvetica, sans-serif;&quot;&gt;historyService来查询&lt;/span&gt;）1、historyService.createHistoricActivityInstanceQuery(); //查询ACT_HI_ACTINST表2、historyService.createHistoricDetailQuery(); //查询ACT_HI_DETAIL表3、historyService.createHistoricProcessInstanceQuery(); //查询ACT_HI_PROCINST表4、historyService.createHistoricTaskInstanceQuery(); //查询ACT_HI_TASKINST表5、historyService.createHistoricVariableInstanceQuery(); //查询ACT_HI_VARINST表 mybatis 配置&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt; &lt;configuration&gt; &lt;settings&gt; &lt;setting name=\"lazyLoadingEnabled\" value=\"false\" /&gt; &lt;/settings&gt; &lt;typeAliases&gt; &lt;typeAlias type=\"org.activiti.engine.impl.persistence.ByteArrayRefTypeHandler\" alias=\"ByteArrayRefTypeHandler\"/&gt; &lt;/typeAliases&gt; &lt;typeHandlers&gt; &lt;typeHandler handler=\"ByteArrayRefTypeHandler\" javaType=\"org.activiti.engine.impl.persistence.entity.ByteArrayRef\" jdbcType=\"VARCHAR\"/&gt; &lt;/typeHandlers&gt; &lt;mappers&gt; &lt;mapper resource=\"org/activiti/db/mapping/entity/Attachment.xml\" /&gt; &lt;mapper resource=\"org/activiti/db/mapping/entity/ByteArray.xml\" /&gt; &lt;mapper resource=\"org/activiti/db/mapping/entity/Comment.xml\" /&gt; &lt;mapper resource=\"org/activiti/db/mapping/entity/Deployment.xml\" /&gt; &lt;mapper resource=\"org/activiti/db/mapping/entity/Execution.xml\" /&gt; &lt;mapper resource=\"org/activiti/db/mapping/entity/Group.xml\" /&gt; &lt;mapper resource=\"org/activiti/db/mapping/entity/HistoricActivityInstance.xml\" /&gt; &lt;mapper resource=\"org/activiti/db/mapping/entity/HistoricDetail.xml\" /&gt; &lt;mapper resource=\"org/activiti/db/mapping/entity/HistoricProcessInstance.xml\" /&gt; &lt;mapper resource=\"org/activiti/db/mapping/entity/HistoricVariableInstance.xml\" /&gt; &lt;mapper resource=\"org/activiti/db/mapping/entity/HistoricTaskInstance.xml\" /&gt; &lt;mapper resource=\"org/activiti/db/mapping/entity/HistoricIdentityLink.xml\" /&gt; &lt;mapper resource=\"org/activiti/db/mapping/entity/IdentityInfo.xml\" /&gt; &lt;mapper resource=\"org/activiti/db/mapping/entity/IdentityLink.xml\" /&gt; &lt;mapper resource=\"org/activiti/db/mapping/entity/Job.xml\" /&gt; &lt;mapper resource=\"org/activiti/db/mapping/entity/Membership.xml\" /&gt; &lt;mapper resource=\"org/activiti/db/mapping/entity/Model.xml\" /&gt; &lt;mapper resource=\"org/activiti/db/mapping/entity/ProcessDefinition.xml\" /&gt; &lt;mapper resource=\"org/activiti/db/mapping/entity/Property.xml\" /&gt; &lt;mapper resource=\"org/activiti/db/mapping/entity/Resource.xml\" /&gt; &lt;mapper resource=\"org/activiti/db/mapping/entity/TableData.xml\" /&gt; &lt;mapper resource=\"org/activiti/db/mapping/entity/Task.xml\" /&gt; &lt;mapper resource=\"org/activiti/db/mapping/entity/User.xml\" /&gt; &lt;mapper resource=\"org/activiti/db/mapping/entity/VariableInstance.xml\" /&gt; &lt;mapper resource=\"org/activiti/db/mapping/entity/EventSubscription.xml\" /&gt; &lt;/mappers&gt;&lt;/configuration&gt; 下面是就那其中一个映射配置来说明，如HistoricProcessInstance.xml： &lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt; &lt;!-- ~ Licensed under the Apache License, Version 2.0 (the \"License\"); ~ you may not use this file except in compliance with the License. ~ You may obtain a copy of the License at ~ ~ http://www.apache.org/licenses/LICENSE-2.0 ~ ~ Unless required by applicable law or agreed to in writing, software ~ distributed under the License is distributed on an \"AS IS\" BASIS, ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. ~ See the License for the specific language governing permissions and ~ limitations under the License. --&gt; &lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt; &lt;mapper namespace=\"org.activiti.engine.impl.persistence.entity.HistoricTaskInstanceEntity\"&gt; &lt;!-- HISTORIC TASK INSTANCE INSERT --&gt; &lt;insert id=\"insertHistoricTaskInstance\" parameterType=\"org.activiti.engine.impl.persistence.entity.HistoricTaskInstanceEntity\"&gt; insert into $&#123;prefix&#125;ACT_HI_TASKINST ( ID_, PROC_DEF_ID_, PROC_INST_ID_, EXECUTION_ID_, NAME_, PARENT_TASK_ID_, DESCRIPTION_, OWNER_, ASSIGNEE_, START_TIME_, CLAIM_TIME_, END_TIME_, DURATION_, DELETE_REASON_, TASK_DEF_KEY_, FORM_KEY_, PRIORITY_, DUE_DATE_, CATEGORY_, TENANT_ID_ ) values ( #&#123;id ,jdbcType=VARCHAR&#125;, #&#123;processDefinitionId, jdbcType=VARCHAR&#125;, #&#123;processInstanceId, jdbcType=VARCHAR&#125;, #&#123;executionId, jdbcType=VARCHAR&#125;, #&#123;name ,jdbcType=VARCHAR&#125;, #&#123;parentTaskId ,jdbcType=VARCHAR&#125;, #&#123;description ,jdbcType=VARCHAR&#125;, #&#123;owner ,jdbcType=VARCHAR&#125;, #&#123;assignee ,jdbcType=VARCHAR&#125;, #&#123;startTime, jdbcType=TIMESTAMP&#125;, #&#123;claimTime, jdbcType=TIMESTAMP&#125;, #&#123;endTime, jdbcType=TIMESTAMP&#125;, #&#123;durationInMillis ,jdbcType=BIGINT&#125;, #&#123;deleteReason ,jdbcType=VARCHAR&#125;, #&#123;taskDefinitionKey ,jdbcType=VARCHAR&#125;, #&#123;formKey ,jdbcType=VARCHAR&#125;, #&#123;priority, jdbcType=INTEGER&#125;, #&#123;dueDate, jdbcType=TIMESTAMP&#125;, #&#123;category, jdbcType=VARCHAR&#125;, #&#123;tenantId, jdbcType=VARCHAR&#125; ) &lt;/insert&gt; &lt;!-- HISTORIC TASK INSTANCE UPDATE --&gt; &lt;update id=\"updateHistoricTaskInstance\" parameterType=\"org.activiti.engine.impl.persistence.entity.HistoricTaskInstanceEntity\"&gt; update $&#123;prefix&#125;ACT_HI_TASKINST set EXECUTION_ID_ = #&#123;executionId, jdbcType=VARCHAR&#125;, NAME_ = #&#123;name, jdbcType=VARCHAR&#125;, PARENT_TASK_ID_ = #&#123;parentTaskId, jdbcType=VARCHAR&#125;, DESCRIPTION_ = #&#123;description, jdbcType=VARCHAR&#125;, OWNER_ = #&#123;owner, jdbcType=VARCHAR&#125;, ASSIGNEE_ = #&#123;assignee, jdbcType=VARCHAR&#125;, CLAIM_TIME_ = #&#123;claimTime, jdbcType=TIMESTAMP&#125;, END_TIME_ = #&#123;endTime, jdbcType=TIMESTAMP&#125;, DURATION_ = #&#123;durationInMillis ,jdbcType=BIGINT&#125;, DELETE_REASON_ = #&#123;deleteReason ,jdbcType=VARCHAR&#125;, TASK_DEF_KEY_ = #&#123;taskDefinitionKey ,jdbcType=VARCHAR&#125;, FORM_KEY_ = #&#123;formKey ,jdbcType=VARCHAR&#125;, PRIORITY_ = #&#123;priority, jdbcType=INTEGER&#125;, DUE_DATE_ = #&#123;dueDate, jdbcType=TIMESTAMP&#125;, CATEGORY_ = #&#123;category, jdbcType=VARCHAR&#125; where ID_ = #&#123;id&#125; &lt;/update&gt; &lt;!-- HISTORIC TASK INSTANCE DELETE --&gt; &lt;delete id=\"deleteHistoricTaskInstance\" parameterType=\"org.activiti.engine.impl.persistence.entity.HistoricTaskInstanceEntity\"&gt; delete from $&#123;prefix&#125;ACT_HI_TASKINST where ID_ = #&#123;id&#125; &lt;/delete&gt; &lt;!-- HISTORIC TASK INSTANCE RESULT MAP --&gt; &lt;resultMap id=\"historicTaskInstanceResultMap\" type=\"org.activiti.engine.impl.persistence.entity.HistoricTaskInstanceEntity\"&gt; &lt;id property=\"id\" column=\"ID_\" jdbcType=\"VARCHAR\" /&gt; &lt;result property=\"processDefinitionId\" column=\"PROC_DEF_ID_\" jdbcType=\"VARCHAR\" /&gt; &lt;result property=\"processInstanceId\" column=\"PROC_INST_ID_\" jdbcType=\"VARCHAR\" /&gt; &lt;result property=\"executionId\" column=\"EXECUTION_ID_\" jdbcType=\"VARCHAR\" /&gt; &lt;result property=\"name\" column=\"NAME_\" jdbcType=\"VARCHAR\" /&gt; &lt;result property=\"parentTaskId\" column=\"PARENT_TASK_ID_\" jdbcType=\"VARCHAR\" /&gt; &lt;result property=\"description\" column=\"DESCRIPTION_\" jdbcType=\"VARCHAR\" /&gt; &lt;result property=\"owner\" column=\"OWNER_\" jdbcType=\"VARCHAR\" /&gt; &lt;result property=\"assignee\" column=\"ASSIGNEE_\" jdbcType=\"VARCHAR\" /&gt; &lt;result property=\"startTime\" column=\"START_TIME_\" jdbcType=\"TIMESTAMP\" /&gt; &lt;result property=\"claimTime\" column=\"CLAIM_TIME_\" jdbcType=\"TIMESTAMP\" /&gt; &lt;result property=\"endTime\" column=\"END_TIME_\" jdbcType=\"TIMESTAMP\" /&gt; &lt;result property=\"durationInMillis\" column=\"DURATION_\" jdbcType=\"BIGINT\" /&gt; &lt;result property=\"deleteReason\" column=\"DELETE_REASON_\" jdbcType=\"VARCHAR\" /&gt; &lt;result property=\"taskDefinitionKey\" column=\"TASK_DEF_KEY_\" jdbcType=\"VARCHAR\" /&gt; &lt;result property=\"formKey\" column=\"FORM_KEY_\" jdbcType=\"VARCHAR\" /&gt; &lt;result property=\"priority\" column=\"PRIORITY_\" jdbcType=\"INTEGER\" /&gt; &lt;result property=\"dueDate\" column=\"DUE_DATE_\" jdbcType=\"TIMESTAMP\" /&gt; &lt;result property=\"category\" column=\"CATEGORY_\" jdbcType=\"VARCHAR\" /&gt; &lt;result property=\"tenantId\" column=\"TENANT_ID_\" jdbcType=\"VARCHAR\" /&gt; &lt;/resultMap&gt; &lt;resultMap id=\"historicTaskInstanceAndVariablesResultMap\" type=\"org.activiti.engine.impl.persistence.entity.HistoricTaskInstanceEntity\"&gt; &lt;id property=\"id\" column=\"ID_\" jdbcType=\"VARCHAR\" /&gt; &lt;result property=\"processDefinitionId\" column=\"PROC_DEF_ID_\" jdbcType=\"VARCHAR\" /&gt; &lt;result property=\"processInstanceId\" column=\"PROC_INST_ID_\" jdbcType=\"VARCHAR\" /&gt; &lt;result property=\"executionId\" column=\"EXECUTION_ID_\" jdbcType=\"VARCHAR\" /&gt; &lt;result property=\"name\" column=\"NAME_\" jdbcType=\"VARCHAR\" /&gt; &lt;result property=\"parentTaskId\" column=\"PARENT_TASK_ID_\" jdbcType=\"VARCHAR\" /&gt; &lt;result property=\"description\" column=\"DESCRIPTION_\" jdbcType=\"VARCHAR\" /&gt; &lt;result property=\"owner\" column=\"OWNER_\" jdbcType=\"VARCHAR\" /&gt; &lt;result property=\"assignee\" column=\"ASSIGNEE_\" jdbcType=\"VARCHAR\" /&gt; &lt;result property=\"startTime\" column=\"START_TIME_\" jdbcType=\"TIMESTAMP\" /&gt; &lt;result property=\"claimTime\" column=\"CLAIM_TIME_\" jdbcType=\"TIMESTAMP\" /&gt; &lt;result property=\"endTime\" column=\"END_TIME_\" jdbcType=\"TIMESTAMP\" /&gt; &lt;result property=\"durationInMillis\" column=\"DURATION_\" jdbcType=\"BIGINT\" /&gt; &lt;result property=\"deleteReason\" column=\"DELETE_REASON_\" jdbcType=\"VARCHAR\" /&gt; &lt;result property=\"taskDefinitionKey\" column=\"TASK_DEF_KEY_\" jdbcType=\"VARCHAR\" /&gt; &lt;result property=\"formKey\" column=\"FORM_KEY_\" jdbcType=\"VARCHAR\" /&gt; &lt;result property=\"priority\" column=\"PRIORITY_\" jdbcType=\"INTEGER\" /&gt; &lt;result property=\"dueDate\" column=\"DUE_DATE_\" jdbcType=\"TIMESTAMP\" /&gt; &lt;result property=\"category\" column=\"CATEGORY_\" jdbcType=\"VARCHAR\" /&gt; &lt;result property=\"tenantId\" column=\"TENANT_ID_\" jdbcType=\"VARCHAR\" /&gt; &lt;collection property=\"queryVariables\" column=\"TASK_ID_\" javaType=\"ArrayList\" ofType=\"org.activiti.engine.impl.persistence.entity.HistoricVariableInstanceEntity\"&gt; &lt;id property=\"id\" column=\"VAR_ID_\"/&gt; &lt;result property=\"name\" column=\"VAR_NAME_\" javaType=\"String\" jdbcType=\"VARCHAR\" /&gt; &lt;result property=\"variableType\" column=\"VAR_TYPE_\" javaType=\"org.activiti.engine.impl.variable.VariableType\" jdbcType=\"VARCHAR\" /&gt; &lt;result property=\"revision\" column=\"VAR_REV_\" jdbcType=\"INTEGER\" /&gt; &lt;result property=\"processInstanceId\" column=\"VAR_PROC_INST_ID_\" jdbcType=\"VARCHAR\" /&gt; &lt;result property=\"executionId\" column=\"VAR_EXECUTION_ID_\" jdbcType=\"VARCHAR\" /&gt; &lt;result property=\"taskId\" column=\"VAR_TASK_ID_\" jdbcType=\"VARCHAR\" /&gt; &lt;result property=\"byteArrayRef\" column=\"VAR_BYTEARRAY_ID_\" typeHandler=\"ByteArrayRefTypeHandler\"/&gt; &lt;result property=\"doubleValue\" column=\"VAR_DOUBLE_\" jdbcType=\"DOUBLE\" /&gt; &lt;result property=\"textValue\" column=\"VAR_TEXT_\" jdbcType=\"VARCHAR\" /&gt; &lt;result property=\"textValue2\" column=\"VAR_TEXT2_\" jdbcType=\"VARCHAR\" /&gt; &lt;result property=\"longValue\" column=\"VAR_LONG_\" jdbcType=\"BIGINT\" /&gt; &lt;/collection&gt; &lt;/resultMap&gt; &lt;!-- HISTORIC TASK INSTANCE SELECT --&gt; &lt;select id=\"selectHistoricTaskInstance\" resultMap=\"historicTaskInstanceResultMap\"&gt; select * from $&#123;prefix&#125;ACT_HI_TASKINST where ID_ = #&#123;historicTaskInstanceId&#125; &lt;/select&gt; &lt;select id=\"selectHistoricTaskInstanceIdsByProcessInstanceId\" resultType=\"string\" parameterType=\"org.activiti.engine.impl.db.ListQueryParameterObject\" &gt; select ID_ from $&#123;prefix&#125;ACT_HI_TASKINST where PROC_INST_ID_ = #&#123;parameter&#125; &lt;/select&gt; &lt;select id=\"selectHistoricTaskInstancesByQueryCriteria\" parameterType=\"org.activiti.engine.impl.HistoricTaskInstanceQueryImpl\" resultMap=\"historicTaskInstanceResultMap\"&gt; $&#123;limitBefore&#125; select distinct RES.* $&#123;limitBetween&#125; &lt;include refid=\"selectHistoricTaskInstancesByQueryCriteriaSql\"/&gt; $&#123;orderBy&#125; $&#123;limitAfter&#125; &lt;/select&gt; &lt;select id=\"selectHistoricTaskInstanceCountByQueryCriteria\" parameterType=\"org.activiti.engine.impl.HistoricTaskInstanceQueryImpl\" resultType=\"long\"&gt; select count(RES.ID_) &lt;include refid=\"selectHistoricTaskInstancesByQueryCriteriaSql\"/&gt; &lt;/select&gt; &lt;sql id=\"selectHistoricTaskInstancesByQueryCriteriaSql\"&gt; from $&#123;prefix&#125;ACT_HI_TASKINST RES &lt;include refid=\"commonSelectHistoricTaskInstancesByQueryCriteriaSql\"/&gt; &lt;/sql&gt; &lt;select id=\"selectHistoricTaskInstancesWithVariablesByQueryCriteria\" parameterType=\"org.activiti.engine.impl.HistoricTaskInstanceQueryImpl\" resultMap=\"historicTaskInstanceAndVariablesResultMap\"&gt; $&#123;limitBefore&#125; select distinct RES.*, VAR.ID_ as VAR_ID_, VAR.NAME_ as VAR_NAME_, VAR.VAR_TYPE_ as VAR_TYPE_, VAR.REV_ as VAR_REV_, VAR.PROC_INST_ID_ as VAR_PROC_INST_ID_, VAR.EXECUTION_ID_ as VAR_EXECUTION_ID_, VAR.TASK_ID_ as VAR_TASK_ID_, VAR.BYTEARRAY_ID_ as VAR_BYTEARRAY_ID_, VAR.DOUBLE_ as VAR_DOUBLE_, VAR.TEXT_ as VAR_TEXT_, VAR.TEXT2_ as VAR_TEXT2_, VAR.LAST_UPDATED_TIME_ as VAR_LAST_UPDATED_TIME_, VAR.LONG_ as VAR_LONG_ $&#123;limitBetween&#125; &lt;include refid=\"selectHistoricTaskInstancesWithVariablesByQueryCriteriaSql\"/&gt; $&#123;orderBy&#125; $&#123;limitAfter&#125; &lt;/select&gt; &lt;select id=\"selectHistoricTaskInstancesWithVariablesByQueryCriteria_mssql_or_db2\" parameterType=\"org.activiti.engine.impl.HistoricTaskInstanceQueryImpl\" resultMap=\"historicTaskInstanceAndVariablesResultMap\"&gt; $&#123;limitBefore&#125; select distinct TEMPRES_ID_ as ID_, TEMPRES_PROC_DEF_ID_ as PROC_DEF_ID_, TEMPRES_PROC_INST_ID_ as PROC_INST_ID_, TEMPRES_EXECUTION_ID_ as EXECUTION_ID_, TEMPRES_NAME_ as NAME_, TEMPRES_PARENT_TASK_ID_ as PARENT_TASK_ID_, TEMPRES_DESCRIPTION_ as DESCRIPTION_, TEMPRES_OWNER_ as OWNER_, TEMPRES_ASSIGNEE_ as ASSIGNEE_, TEMPRES_START_TIME_ as START_TIME_, TEMPRES_CLAIM_TIME_ as CLAIM_TIME_, TEMPRES_END_TIME_ as END_TIME_, TEMPRES_DURATION_ as DURATION_, TEMPRES_TASK_DEF_KEY_ as TASK_DEF_KEY_, TEMPRES_FORM_KEY_ as FORM_KEY_, TEMPRES_PRIORITY_ as PRIORITY_, TEMPRES_DUE_DATE_ as DUE_DATE_, TEMPRES_DELETE_REASON_ as DELETE_REASON_, TEMPVAR_ID_ as VAR_ID_, TEMPVAR_NAME_ as VAR_NAME_, TEMPVAR_TYPE_ as VAR_TYPE_, TEMPVAR_REV_ as VAR_REV_, TEMPVAR_PROC_INST_ID_ as VAR_PROC_INST_ID_, TEMPVAR_EXECUTION_ID_ as VAR_EXECUTION_ID_, TEMPVAR_TASK_ID_ as VAR_TASK_ID_, TEMPVAR_BYTEARRAY_ID_ as VAR_BYTEARRAY_ID_, TEMPVAR_DOUBLE_ as VAR_DOUBLE_, TEMPVAR_TEXT_ as VAR_TEXT_, TEMPVAR_LAST_UPDATED_TIME_ as VAR_LAST_UPDATED_TIME_, TEMPVAR_TEXT2_ as VAR_TEXT2_, TEMPVAR_LONG_ as VAR_LONG_ $&#123;limitOuterJoinBetween&#125; RES.ID_ as TEMPRES_ID_, RES.PROC_DEF_ID_ as TEMPRES_PROC_DEF_ID_, RES.PROC_INST_ID_ as TEMPRES_PROC_INST_ID_, RES.EXECUTION_ID_ as TEMPRES_EXECUTION_ID_, RES.NAME_ as TEMPRES_NAME_ , RES.PARENT_TASK_ID_ as TEMPRES_PARENT_TASK_ID_, RES.DESCRIPTION_ as TEMPRES_DESCRIPTION_, RES.OWNER_ as TEMPRES_OWNER_, RES.ASSIGNEE_ as TEMPRES_ASSIGNEE_, RES.START_TIME_ as TEMPRES_START_TIME_, RES.END_TIME_ as TEMPRES_END_TIME_, RES.CLAIM_TIME_ as TEMPRES_CLAIM_TIME_, RES.DURATION_ as TEMPRES_DURATION_, RES.TASK_DEF_KEY_ as TEMPRES_TASK_DEF_KEY_, RES.FORM_KEY_ as TEMPRES_FORM_KEY_, RES.PRIORITY_ as TEMPRES_PRIORITY_, RES.DUE_DATE_ as TEMPRES_DUE_DATE_, RES.DELETE_REASON_ as TEMPRES_DELETE_REASON_, VAR.ID_ as TEMPVAR_ID_, VAR.NAME_ as TEMPVAR_NAME_, VAR.VAR_TYPE_ as TEMPVAR_TYPE_, VAR.REV_ as TEMPVAR_REV_, VAR.PROC_INST_ID_ as TEMPVAR_PROC_INST_ID_, VAR.EXECUTION_ID_ as TEMPVAR_EXECUTION_ID_, VAR.TASK_ID_ as TEMPVAR_TASK_ID_, VAR.BYTEARRAY_ID_ as TEMPVAR_BYTEARRAY_ID_, VAR.DOUBLE_ as TEMPVAR_DOUBLE_, VAR.TEXT_ as TEMPVAR_TEXT_, VAR.TEXT2_ as TEMPVAR_TEXT2_, VAR.LAST_UPDATED_TIME_ as TEMPVAR_LAST_UPDATED_TIME_, VAR.LONG_ as TEMPVAR_LONG_ &lt;include refid=\"selectHistoricTaskInstancesWithVariablesByQueryCriteriaSql\"/&gt; $&#123;orderBy&#125; $&#123;limitAfter&#125; &lt;/select&gt; &lt;sql id=\"selectHistoricTaskInstancesWithVariablesByQueryCriteriaSql\"&gt; from $&#123;prefix&#125;ACT_HI_TASKINST RES &lt;choose&gt; &lt;when test=\"includeTaskLocalVariables &amp;&amp; includeProcessVariables\"&gt; left outer join $&#123;prefix&#125;ACT_HI_VARINST VAR ON RES.ID_ = VAR.TASK_ID_ or RES.PROC_INST_ID_ = VAR.EXECUTION_ID_ &lt;/when&gt; &lt;otherwise&gt; &lt;if test=\"includeTaskLocalVariables\"&gt; left outer join $&#123;prefix&#125;ACT_HI_VARINST VAR ON RES.ID_ = VAR.TASK_ID_ &lt;/if&gt; &lt;if test=\"includeProcessVariables\"&gt; left outer join $&#123;prefix&#125;ACT_HI_VARINST VAR ON RES.PROC_INST_ID_ = VAR.EXECUTION_ID_ and VAR.TASK_ID_ is null &lt;/if&gt; &lt;/otherwise&gt; &lt;/choose&gt; &lt;include refid=\"commonSelectHistoricTaskInstancesByQueryCriteriaSql\"/&gt; &lt;/sql&gt; &lt;sql id=\"commonSelectHistoricTaskInstancesByQueryCriteriaSql\"&gt; &lt;if test=\"candidateUser != null || candidateGroups != null\"&gt; inner join $&#123;prefix&#125;ACT_HI_IDENTITYLINK HI on HI.TASK_ID_ = RES.ID_ &lt;/if&gt; &lt;if test=\"processFinished || processUnfinished || processInstanceBusinessKey != null || processInstanceBusinessKeyLike != null\"&gt; inner join $&#123;prefix&#125;ACT_HI_PROCINST HPI ON RES.PROC_INST_ID_ = HPI.ID_ &lt;/if&gt; &lt;if test=\"processDefinitionKey != null || processDefinitionKeyLike != null || processDefinitionName != null || processDefinitionNameLike != null\"&gt; inner join $&#123;prefix&#125;ACT_RE_PROCDEF D on RES.PROC_DEF_ID_ = D.ID_ &lt;/if&gt; &lt;foreach collection=\"queryVariableValues\" index=\"index\" item=\"var\"&gt; &lt;choose&gt; &lt;when test=\"var.local\"&gt; inner join $&#123;prefix&#125;ACT_HI_VARINST A$&#123;index&#125; on RES.ID_ = A$&#123;index&#125;.TASK_ID_ &lt;/when&gt; &lt;otherwise&gt; inner join $&#123;prefix&#125;ACT_HI_VARINST A$&#123;index&#125; on RES.PROC_INST_ID_ = A$&#123;index&#125;.PROC_INST_ID_ &lt;/otherwise&gt; &lt;/choose&gt; &lt;/foreach&gt; &lt;where&gt; &lt;if test=\"taskId != null\"&gt; RES.ID_ = #&#123;taskId&#125; &lt;/if&gt; &lt;if test=\"processDefinitionId != null\"&gt; and RES.PROC_DEF_ID_ = #&#123;processDefinitionId&#125; &lt;/if&gt; &lt;if test=\"processDefinitionKey != null\"&gt; and D.KEY_ = #&#123;processDefinitionKey&#125; &lt;/if&gt; &lt;if test=\"processDefinitionKeyLike != null\"&gt; and D.KEY_ like #&#123;processDefinitionKeyLike&#125; &lt;/if&gt; &lt;if test=\"processDefinitionName != null\"&gt; and D.NAME_ = #&#123;processDefinitionName&#125; &lt;/if&gt; &lt;if test=\"processDefinitionNameLike != null\"&gt; and D.NAME_ like #&#123;processDefinitionNameLike&#125; &lt;/if&gt; &lt;if test=\"processInstanceId != null\"&gt; and RES.PROC_INST_ID_ = #&#123;processInstanceId&#125; &lt;/if&gt; &lt;if test=\"processInstanceBusinessKey != null\"&gt; and HPI.BUSINESS_KEY_ = #&#123;processInstanceBusinessKey&#125; &lt;/if&gt; &lt;if test=\"processInstanceBusinessKeyLike != null\"&gt; and HPI.BUSINESS_KEY_ like #&#123;processInstanceBusinessKeyLike&#125; &lt;/if&gt; &lt;if test=\"taskDefinitionKey != null\"&gt; and RES.TASK_DEF_KEY_ = #&#123;taskDefinitionKey&#125; &lt;/if&gt; &lt;if test=\"taskDefinitionKeyLike != null\"&gt; and RES.TASK_DEF_KEY_ like #&#123;taskDefinitionKeyLike&#125; &lt;/if&gt; &lt;if test=\"executionId != null\"&gt; and RES.EXECUTION_ID_ = #&#123;executionId&#125; &lt;/if&gt; &lt;if test=\"taskName != null\"&gt; and RES.NAME_ = #&#123;taskName&#125; &lt;/if&gt; &lt;if test=\"taskNameLike != null\"&gt; and RES.NAME_ like #&#123;taskNameLike&#125; &lt;/if&gt; &lt;if test=\"taskParentTaskId != null\"&gt; and RES.PARENT_TASK_ID_ = #&#123;taskParentTaskId&#125; &lt;/if&gt; &lt;if test=\"taskDescription != null\"&gt; and RES.DESCRIPTION_ = #&#123;taskDescription&#125; &lt;/if&gt; &lt;if test=\"taskDescriptionLike != null\"&gt; and RES.DESCRIPTION_ like #&#123;taskDescriptionLike&#125; &lt;/if&gt; &lt;if test=\"taskDeleteReason != null\"&gt; and RES.DELETE_REASON_ = #&#123;taskDeleteReason&#125; &lt;/if&gt; &lt;if test=\"taskDeleteReasonLike != null\"&gt; and RES.DELETE_REASON_ like #&#123;taskDeleteReasonLike&#125; &lt;/if&gt; &lt;if test=\"taskOwner != null\"&gt; and RES.OWNER_ = #&#123;taskOwner&#125; &lt;/if&gt; &lt;if test=\"taskOwnerLike != null\"&gt; and RES.OWNER_ like #&#123;taskOwnerLike&#125; &lt;/if&gt; &lt;if test=\"taskAssignee != null\"&gt; and RES.ASSIGNEE_ = #&#123;taskAssignee&#125; &lt;/if&gt; &lt;if test=\"taskAssigneeLike != null\"&gt; and RES.ASSIGNEE_ like #&#123;taskAssigneeLike&#125; &lt;/if&gt; &lt;if test=\"taskPriority != null\"&gt; and RES.PRIORITY_ = #&#123;taskPriority&#125; &lt;/if&gt; &lt;if test=\"taskMinPriority != null\"&gt; and RES.PRIORITY_ &gt;= #&#123;taskMinPriority&#125; &lt;/if&gt; &lt;if test=\"taskMaxPriority != null\"&gt; and RES.PRIORITY_ &lt;= #&#123;taskMaxPriority&#125; &lt;/if&gt; &lt;if test=\"unfinished\"&gt; and RES.END_TIME_ is null &lt;/if&gt; &lt;if test=\"finished\"&gt; and RES.END_TIME_ is not null &lt;/if&gt; &lt;if test=\"processFinished\"&gt; and HPI.END_TIME_ is not null &lt;/if&gt; &lt;if test=\"processUnfinished\"&gt; and HPI.END_TIME_ is null &lt;/if&gt; &lt;if test=\"dueDate != null\"&gt; and RES.DUE_DATE_ = #&#123;dueDate&#125; &lt;/if&gt; &lt;if test=\"dueBefore != null\"&gt; and RES.DUE_DATE_ &lt; #&#123;dueBefore&#125; &lt;/if&gt; &lt;if test=\"dueAfter != null\"&gt; and RES.DUE_DATE_ &gt; #&#123;dueAfter&#125; &lt;/if&gt; &lt;if test=\"withoutDueDate\"&gt; and RES.DUE_DATE_ is null &lt;/if&gt; &lt;if test=\"creationDate != null\"&gt; and RES.START_TIME_ = #&#123;creationDate&#125; &lt;/if&gt; &lt;if test=\"creationBeforeDate != null\"&gt; and RES.START_TIME_ &lt; #&#123;creationBeforeDate&#125; &lt;/if&gt; &lt;if test=\"creationAfterDate != null\"&gt; and RES.START_TIME_ &gt; #&#123;creationAfterDate&#125; &lt;/if&gt; &lt;if test=\"completedDate != null\"&gt; and RES.END_TIME_ = #&#123;completedDate&#125; &lt;/if&gt; &lt;if test=\"completedBeforeDate != null\"&gt; and RES.END_TIME_ &lt; #&#123;completedBeforeDate&#125; &lt;/if&gt; &lt;if test=\"completedAfterDate != null\"&gt; and RES.END_TIME_ &gt; #&#123;completedAfterDate&#125; &lt;/if&gt; &lt;if test=\"category != null\"&gt; and RES.CATEGORY_ = #&#123;category&#125; &lt;/if&gt; &lt;if test=\"tenantId != null\"&gt; and RES.TENANT_ID_ = #&#123;tenantId&#125; &lt;/if&gt; &lt;if test=\"tenantIdLike != null\"&gt; and RES.TENANT_ID_ like #&#123;tenantIdLike&#125; &lt;/if&gt; &lt;if test=\"withoutTenantId\"&gt; and (RES.TENANT_ID_ = '' or RES.TENANT_ID_ is null) &lt;/if&gt; &lt;if test=\"candidateUser != null || candidateGroups != null\"&gt; and RES.ASSIGNEE_ is null and HI.TYPE_ = 'candidate' and ( &lt;if test=\"candidateUser != null\"&gt; HI.USER_ID_ = #&#123;candidateUser&#125; &lt;/if&gt; &lt;if test=\"candidateUser != null &amp;&amp; candidateGroups != null &amp;&amp; candidateGroups.size() &gt; 0\"&gt; or &lt;/if&gt; &lt;if test=\"candidateGroups != null &amp;&amp; candidateGroups.size() &gt; 0\"&gt; HI.GROUP_ID_ IN &lt;foreach item=\"group\" index=\"index\" collection=\"candidateGroups\" open=\"(\" separator=\",\" close=\")\"&gt; #&#123;group&#125; &lt;/foreach&gt; &lt;/if&gt; ) &lt;/if&gt; &lt;if test=\"involvedUser != null\"&gt; and ( exists(select LINK.USER_ID_ from $&#123;prefix&#125;ACT_HI_IDENTITYLINK LINK where USER_ID_ = #&#123;involvedUser&#125; and LINK.TASK_ID_ = RES.ID_) or RES.ASSIGNEE_ = #&#123;involvedUser&#125; or RES.OWNER_ = #&#123;involvedUser&#125; ) &lt;/if&gt; &lt;foreach item=\"queryVar\" collection=\"queryVariableValues\" index=\"index\"&gt; &lt;if test=\"!queryVar.local\"&gt; &lt;!-- When process instance variable is queried for, taskId should be null --&gt; and A$&#123;index&#125;.TASK_ID_ is null &lt;/if&gt; &lt;if test=\"queryVar.name != null\"&gt; &lt;!-- Match-all variable-names when name is null --&gt; and A$&#123;index&#125;.NAME_= #&#123;queryVar.name&#125; &lt;/if&gt; &lt;if test=\"!queryVar.type.equals('null')\"&gt; and A$&#123;index&#125;.VAR_TYPE_ = #&#123;queryVar.type&#125; &lt;/if&gt; &lt;!-- Variable value --&gt; &lt;if test=\"queryVar.textValue != null &amp;&amp; queryVar.longValue == null &amp;&amp; queryVar.doubleValue == null\"&gt; &lt;choose&gt; &lt;when test=\"queryVar.operator.equals('EQUALS_IGNORE_CASE') || queryVar.operator.equals('NOT_EQUALS_IGNORE_CASE')\"&gt; and lower(A$&#123;index&#125;.TEXT_) &lt;/when&gt; &lt;otherwise&gt; and A$&#123;index&#125;.TEXT_ &lt;/otherwise&gt; &lt;/choose&gt; &lt;choose&gt; &lt;when test=\"queryVar.operator.equals('LIKE')\"&gt;LIKE&lt;/when&gt; &lt;otherwise&gt;&lt;include refid=\"executionVariableOperator\" /&gt;&lt;/otherwise&gt; &lt;/choose&gt; #&#123;queryVar.textValue&#125; &lt;/if&gt; &lt;if test=\"queryVar.textValue2 != null\"&gt; and A$&#123;index&#125;.TEXT2_ &lt;choose&gt; &lt;when test=\"queryVar.operator.equals('LIKE')\"&gt;LIKE&lt;/when&gt; &lt;otherwise&gt;&lt;include refid=\"executionVariableOperator\" /&gt;&lt;/otherwise&gt; &lt;/choose&gt; #&#123;queryVar.textValue2&#125; &lt;/if&gt; &lt;if test=\"queryVar.longValue != null\"&gt; and A$&#123;index&#125;.LONG_ &lt;include refid=\"executionVariableOperator\" /&gt; #&#123;queryVar.longValue&#125; &lt;/if&gt; &lt;if test=\"queryVar.doubleValue != null\"&gt; and A$&#123;index&#125;.DOUBLE_ &lt;include refid=\"executionVariableOperator\" /&gt; #&#123;queryVar.doubleValue&#125; &lt;/if&gt; &lt;!-- Null variable type --&gt; &lt;if test=\"queryVar.textValue == null &amp;&amp; queryVar.textValue2 == null &amp;&amp; queryVar.longValue == null &amp;&amp; queryVar.doubleValue == null\"&gt; &lt;choose&gt; &lt;when test=\"queryVar.operator.equals('NOT_EQUALS')\"&gt; and (A$&#123;index&#125;.TEXT_ is not null or A$&#123;index&#125;.TEXT2_ is not null or A$&#123;index&#125;.LONG_ is not null or A$&#123;index&#125;.DOUBLE_ is not null or A$&#123;index&#125;.BYTEARRAY_ID_ is not null) &lt;/when&gt; &lt;otherwise&gt; and A$&#123;index&#125;.TEXT_ is null and A$&#123;index&#125;.TEXT2_ is null and A$&#123;index&#125;.LONG_ is null and A$&#123;index&#125;.DOUBLE_ is null and A$&#123;index&#125;.BYTEARRAY_ID_ is null &lt;/otherwise&gt; &lt;/choose&gt; &lt;/if&gt; &lt;/foreach&gt; &lt;/where&gt; &lt;/sql&gt; &lt;sql id=\"executionVariableOperator\"&gt; &lt;choose&gt; &lt;when test=\"queryVar.operator.equals('EQUALS')\"&gt;=&lt;/when&gt; &lt;when test=\"queryVar.operator.equals('EQUALS_IGNORE_CASE')\"&gt;=&lt;/when&gt; &lt;when test=\"queryVar.operator.equals('NOT_EQUALS')\"&gt;&lt;&gt;&lt;/when&gt; &lt;when test=\"queryVar.operator.equals('NOT_EQUALS_IGNORE_CASE')\"&gt;&lt;&gt;&lt;/when&gt; &lt;when test=\"queryVar.operator.equals('GREATER_THAN')\"&gt;&gt;&lt;/when&gt; &lt;when test=\"queryVar.operator.equals('GREATER_THAN_OR_EQUAL')\"&gt;&gt;=&lt;/when&gt; &lt;when test=\"queryVar.operator.equals('LESS_THAN')\"&gt;&lt;&lt;/when&gt; &lt;when test=\"queryVar.operator.equals('LESS_THAN_OR_EQUAL')\"&gt;&lt;=&lt;/when&gt; &lt;/choose&gt; &lt;/sql&gt; &lt;select id=\"selectHistoricTaskInstanceByNativeQuery\" parameterType=\"java.util.Map\" resultMap=\"historicTaskInstanceResultMap\"&gt; &lt;if test=\"resultType == 'LIST_PAGE'\"&gt; $&#123;limitBefore&#125; &lt;/if&gt; $&#123;sql&#125; &lt;if test=\"resultType == 'LIST_PAGE'\"&gt; $&#123;limitAfter&#125; &lt;/if&gt; &lt;/select&gt; &lt;select id=\"selectHistoricTaskInstanceByNativeQuery_mssql_or_db2\" parameterType=\"java.util.Map\" resultMap=\"historicTaskInstanceResultMap\"&gt; &lt;if test=\"resultType == 'LIST_PAGE'\"&gt; $&#123;limitBeforeNativeQuery&#125; &lt;/if&gt; $&#123;sql&#125; &lt;if test=\"resultType == 'LIST_PAGE'\"&gt; $&#123;limitAfter&#125; &lt;/if&gt; &lt;/select&gt; &lt;select id=\"selectHistoricTaskInstanceCountByNativeQuery\" parameterType=\"java.util.Map\" resultType=\"long\"&gt; $&#123;sql&#125; &lt;/select&gt;&lt;/mapper&gt; 官方文档5.21中文翻译文档下载 英文文档地址","categories":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/tags/Java/"},{"name":"Activiti","slug":"Activiti","permalink":"https://gowa2017.github.io/tags/Activiti/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}]},{"title":"升级到10.14后vnc及虚拟机无法获得鼠标焦点的问题","slug":"升级到10.14后vnc及虚拟机无法获得鼠标焦点的问题","date":"2018-10-22T00:59:22.000Z","updated":"2018-10-22T00:59:22.000Z","comments":true,"path":"macOS/升级到10.14后vnc及虚拟机无法获得鼠标焦点的问题.html","link":"","permalink":"https://gowa2017.github.io/macOS/升级到10.14后vnc及虚拟机无法获得鼠标焦点的问题.html","excerpt":"为了尝鲜，同事升级了 macOS 10.14 后，我也升级了，升级了以后就出现了几个非常蛋疼的问题，具体就是在虚拟机中我的鼠标点击没有用了，键盘也无效。然后 vnc 上点击连接窗口的话不会自动定位到对应的设备，而是会到 选择连接的界面。","text":"为了尝鲜，同事升级了 macOS 10.14 后，我也升级了，升级了以后就出现了几个非常蛋疼的问题，具体就是在虚拟机中我的鼠标点击没有用了，键盘也无效。然后 vnc 上点击连接窗口的话不会自动定位到对应的设备，而是会到 选择连接的界面。 偶然想到，在我第一次重新启动虚拟机的时候，弹出了一个需要辅助功能来控制的框，我没有在意，就拒绝了。于是抱着这个线索在谷歌搜索了一下，果然有这样的情况。 打开 系统偏好设置 —&gt; 安全性与隐私 —&gt; 隐私标签 —&gt; 辅助功能 点击下面的那个锁，输入管理员密码，再在右边的应用列表内打勾就OK了。","categories":[{"name":"macOS","slug":"macOS","permalink":"https://gowa2017.github.io/categories/macOS/"}],"tags":[{"name":"macOS","slug":"macOS","permalink":"https://gowa2017.github.io/tags/macOS/"}],"keywords":[{"name":"macOS","slug":"macOS","permalink":"https://gowa2017.github.io/categories/macOS/"}]},{"title":"CentOS7中的KVM共享网络设置","slug":"CentOS7中的KVM共享网络设置","date":"2018-10-18T14:01:00.000Z","updated":"2018-10-18T14:01:00.000Z","comments":true,"path":"Linux/CentOS7中的KVM共享网络设置.html","link":"","permalink":"https://gowa2017.github.io/Linux/CentOS7中的KVM共享网络设置.html","excerpt":"","text":"最近网络拓扑变更，本来能访问外网的 kvm 虚拟机都可以的，但是突然就不行，很奇怪为什么会这样，只能来研究一下了。 基本情况宿主机 H ，部署了两个IP，一个是访问外网的 192.168.50.201/24，内网IP 172.28.20.231/24，上连路由器 192.168.50.1。然后路由器可访问 172.0.0.0/16 这个网段。 KVM IP是 192.168.122.2 通过 网桥的形式与 H 通信。 宿主机路由默认路由走的是 192.168.50.201 外网，内网添加了一条静态路由： route add -net 172.230.0.0 netmask 255.255.0.0 gw 172.28.20.1 这样下来，H 是能正常访问内外网的。 同样，KVM 访问宿主机也没有什么问题。无论是 172.28.20.231 还是 192.168.50.201 都没问题。 但是访问 外网 和 172.网段就不行。 解决实际上，默认使用的是 nat 模式来共享网络，但是由于我把转发数据给关了，导致了从外部回来的数据包只能到达我们的宿主机而无法到达虚拟机。 网络分析通过查看宿主机的网络设备情况： ip addr4: virbr0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000 link/ether 52:54:00:c3:68:e6 brd ff:ff:ff:ff:ff:ff inet 192.168.122.1/24 brd 192.168.122.255 scope global virbr0 valid_lft forever preferred_lft forever5: virbr0-nic: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc pfifo_fast master virbr0 state DOWN group default qlen 1000 link/ether 52:54:00:c3:68:e6 brd ff:ff:ff:ff:ff:ff9: vnet0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast master virbr0 state UNKNOWN group default qlen 1000 link/ether fe:54:00:dc:a4:d5 brd ff:ff:ff:ff:ff:ff inet6 fe80::fc54:ff:fedc:a4d5/64 scope link valid_lft forever preferred_lft forever virbr0 是一个网络设备， virbr0-nic，则是为其虚拟的一个接口卡， vnet0 则是我们 H 机的设备，不过是在链路层相连的。两个接口都只有链路层地址，没有网络层地址。 brctl showbridge name bridge id STP enabled interfacesvirbr0 8000.525400c368e6 yes virbr0-nic vnet0 两个接口都加入了这个网桥。 通过 NAT 共享的时候，KVM 会把数据包发送给 virbr0 。通过它的路由可以看出这点： route print0.0.0.0 0.0.0.0 192.168.122.1 192.168.122.2 20 关键在于主机的转发（利用iptables）： -A FORWARD -d 192.168.122.0/24 -o virbr0 -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT-A FORWARD -s 192.168.122.0/24 -i virbr0 -j ACCEPT-A FORWARD -i virbr0 -o virbr0 -j ACCEPT-A FORWARD -o virbr0 -j REJECT --reject-with icmp-port-unreachable-A FORWARD -i virbr0 -j REJECT --reject-with icmp-port-unreachable-A POSTROUTING -s 192.168.122.0/24 -d 224.0.0.0/24 -j RETURN-A POSTROUTING -s 192.168.122.0/24 -d 255.255.255.255/32 -j RETURN-A POSTROUTING -s 192.168.122.0/24 ! -d 192.168.122.0/24 -p tcp -j MASQUERADE --to-ports 1024-65535-A POSTROUTING -s 192.168.122.0/24 ! -d 192.168.122.0/24 -p udp -j MASQUERADE --to-ports 1024-65535-A POSTROUTING -s 192.168.122.0/24 ! -d 192.168.122.0/24 -j MASQUERADE","categories":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/tags/Linux/"}],"keywords":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}]},{"title":"python中的正则表达式","slug":"python中的正则表达式","date":"2018-10-15T16:39:35.000Z","updated":"2018-10-15T16:39:35.000Z","comments":true,"path":"Python/python中的正则表达式.html","link":"","permalink":"https://gowa2017.github.io/Python/python中的正则表达式.html","excerpt":"需要对经营地址匹配对应的社区，无奈看了别人的代码不是很清楚，只能就组看一下官方文档了。原文地址 关于正则表达式的基础就不赘述了，自己去看吧。只看一下在 Python 内的使用。正则表达式HowTo","text":"需要对经营地址匹配对应的社区，无奈看了别人的代码不是很清楚，只能就组看一下官方文档了。原文地址 关于正则表达式的基础就不赘述了，自己去看吧。只看一下在 Python 内的使用。正则表达式HowTo 正则表达式的实现，是在 re 模块内实现的。 | 的作用| 的作用是把任意的两个正则表达式 A B 给组合起来形成一个可匹配 A 或者 B 的新表达式 A|B。 | 可以组合任意数量的正则表达式。也可以在分组内进行使用。当扫描目标字符串的时候， | 分隔开的表达式会从左至右进行匹配。当有一个模式完全匹配，则会接受这个分支。也就是说，一旦 A 匹配上了，那么就不会再继续进行匹配 B 了，即使会产生一个更长的匹配。也就是说 | 是不贪婪的。匹配一个字面意义的 |，可以使用 \\|，或者放在 [|] 内。 模块内容re.compile(pattern, flags=0)把一个正则表达式编译到一个 正则表达式对象 ，此对象可以使用其mathch(), search()等方法来进行匹配。 表达式的行为可以通过 flags 来进行改变。可以是下面的值，通过 | 进行组合。 prog = re.compile(pattern)result = prog.match(string) 与 result = re.match(pattern, string) 是相等的。不过把表达式编译成正则表达式对象后重复使用会更加有效率。 re.A/re.ASCII re.DEBUG re.I/re.IGNORECASE re.L/re.LOCALE re.M/re.MULTILINE re.S/re.DOTALL re.X/re.VERBOSE re.search(pattern, string, flags=0)扫描 string，查找第一个匹配 pattern 的位置，返回一个对象的 匹配对象 。如果查找不到匹配的位置，返回 None 。 re.match(pattern, string, flags=0)如果 string 开头的 0 或 多个字符匹配了模式 pattern ，返回一个对应的匹配对象。如果不匹配的话，就返回 None 。 即使是在 MULTILINE 模式下，这也只会匹配字符串的开始，而不是在每行的开始进行匹配。 如果想要匹配 string 内的任意位置，使用 re.search() 代替。 re.fullmatch(pattern, string, flags=0)如果 string 完全匹配 pattern ，那么返回一个匹配对象。不匹配就返回 None 。 re.split(pattern, string, maxsplit=0, flags=0)通过出现的 pattern 来分隔字符串 string 。","categories":[{"name":"Python","slug":"Python","permalink":"https://gowa2017.github.io/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://gowa2017.github.io/tags/Python/"}],"keywords":[{"name":"Python","slug":"Python","permalink":"https://gowa2017.github.io/categories/Python/"}]},{"title":"pandas.DataFrame的使用","slug":"pandas.DataFrame的使用","date":"2018-10-14T07:03:59.000Z","updated":"2018-10-14T07:03:59.000Z","comments":true,"path":"Python/pandas.DataFrame的使用.html","link":"","permalink":"https://gowa2017.github.io/Python/pandas.DataFrame的使用.html","excerpt":"","text":"pandas.DataFram 提供了一下很好的封装好了方法给我们，可以很容易的筛选，获取，变更数据。根据官方文档来看一下顺便翻译 。原文地址 DataFrameDataFrame是一个二维标记数据结构，具有可能不同类型的列。您可以将其视为电子表格或SQL表，或Series对象的字典。它通常是最常用的pandas对象。与Series类似，DataFrame接受许多不同类型的输入： Dict of 1D ndarrays, lists, dicts, or Series 2-D numpy.ndarray Structured or record ndarray A series 另一个数据帧除了数据，您还可以选择传递索引（行标签）和列（列标签）参数。如果传递索引和/或列，则可以保证生成的DataFrame的索引和/或列。因此，系列的字典加上特定索引将丢弃与传递的索引不匹配的所有数据。 如果未传递轴标签，则将根据常识规则从输入数据构造它们。 原型class pandas.DataFrame(data=None, index=None, columns=None, dtype=None, copy=False) 这个类会返回一个二维，尺寸可变，具有行、列标记轴的表格数据结构。算术运算在行标签和列标签上对齐。可以被认为是Series对象的类似dict的容器。 pandas 最基本的数据结构。 参数 data: numpy ndarray (structured or homogeneous), dict, or DataFrame numpy 数组，字典，或数据帧。Dict 可以包含系列，数组，常量或 类似列表的对象。如果数据是字典，在 Python3.6 以上会维护一个参数顺序。 index:Index or array-like 索引或类数组。用来构成帧数据的索引。默认是范围索引。 columns:Index or array-like 索引或类数组。用来构帧数据的列标签。默认是 (0,1,2,….n)。 dtype: dtype, 默认 None。强制为某一数据类型。只允许单一 dtype，如果是 Node，则会进行推断。 copy: boolean Default False 从数据复制数据。只会影响数据帧/2D ndarray 输入 。 例子从字典构建数据帧 In [1]: d = &#123;'col1': [1, 2], 'col2': [3, 4]&#125;In [2]: df = pd.DataFrame(data=d)In [3]: dfOut[3]: col1 col20 1 31 2 4 注意这个推断出来的 dtype 是 int64： In [7]: df.dtypesOut[7]:col1 int64col2 int64dtype: object 为了强制使用一个 dtype： In [10]: df = pd.DataFrame(data=d, dtype=np.int8)In [11]: df.dtypesOut[11]:col1 int8col2 int8dtype: object 从 numpy 数组构建数据帧： In [12]: df2 = pd.DataFrame(np.random.randint(low=0, high=10, size=(5, 5)), columns=['a', 'b', 'c', 'd', 'e'])In [13]: df2Out[13]: a b c d e0 5 3 3 6 51 4 0 8 6 32 3 5 4 5 93 2 7 1 2 84 1 0 0 0 0 属性（以上面的df2为例） T：行列转置 at：从 「行，列」 对访问一个唯一值 axes：返回代表了数据帧轴的列表。[RangeIndex(start=0, stop=5, step=1),Index([u’a’, u’b’, u’c’, u’d’, u’e’], dtype=’object’)] columns：列标签 Index([u’a’, u’b’, u’c’, u’d’, u’e’], dtype=’object’) dtypes：数据类型 empty：表示数据是否为空 ftypes：返回DataFrame中的ftypes（稀疏/密集和dtype的指示）a int64:denseb int64:densec int64:densed int64:densee int64:densedtype: object iat：通过整数表示位置的 「行，列」 对来访问唯一值。df2.iat[1,2] iloc：只通过整型位置为基础的索引来选择数据。 index：数据帧的索引（行标签）RangeIndex(start=0, stop=5, step=1) ix：主要基于标签位置的索引器，具有整数位置回退。 loc：通过标签或者布尔数组来访问一组行列值。 ndim：数据帧维数。 shape：数据帧形状。 size：元素总数。 style：Property returning a Styler object containing methods for building a styled HTML representation fo the DataFrame. values：返回数据帧的 numpy 表示。 变换 DataFrame.astype(dtype[, copy=True, errors=’raise’, **kwargs]) 这个函数实际上是对系列进行操作的。把某一系列的类型进行转换。 copy=True/False 表示是返回一个新的副本还是就在原来的数据上进行修改。 DataFrame.infer_objects() 对于 对象 类型的列推测一个更好的数据类型。可用 df.infer_objects().dtypes 进行测试 DataFrame.copy([deep=True]) 复制出来一个对象。 deep=True/False 决定了是产生一个全新的对象，还是只是引用原来的对象。 DataFrame.isna() 检测遗失值 DataFrame.notna() 同上，意义相反。 DataFrame.bool()索引，遍历 DataFrame.head(n) 显示前 n 行。 DataFrame.at 访问一个唯一值。这通过一个 行/列 对来标识。但这个采用的是标签来访问。 DataFrame.iat 同上。但是是通过数位置来访问。 DataFrame.loc 通过标签(s)或布尔数组来访问很多行。 DataFrame.iloc 同上，不过是通过整型的位置索引来访问。 DataFrame.insert(loc, column, value[, allow_duplicates=False]) 在指定的位置插入列 DataFrame.iter() 列标签迭代器 DataFrame.items() 在（列标签，系列）对上的迭代器。实际上是一列一列的迭代。 DataFrame.keys() 所有的列标签 DataFrame.iteritems() 在（列标签，系列）对上的迭代器。实际上是一列一列的迭代。 DataFrame.iterrows() 通过（索引，系列）对遍历行。一行一行迭代。 DataFrame.itertuples([index, name])将DataFrame行作为命名元组迭代，索引值作为元组的第一个元素。 DataFrame.lookup(row_lables, col_labels) DataFrame.pop(item) 从 frame 删除 列 并返回。 DataFrame.tail(n) 返回后面几行 DataFrame.xs(key[, axis, level, drop_level]) 返回一个交叉区域（多行 或多列）。这个有点难以理解，好像是多用于多索引的时候。 DataFrame.get(key[, default]) 根据 key(列表） 获取给定项。 DataFrame.isin(values) 返回一个 布尔数据帧。这个帧表示了 DataFrame 内的每个元素是否被包含在value内。 DataFrame.where(crond[, other=nan, inplace=False, axis=None, level=None, errors=’raise’, try_cast=False, raise_on_error=None]) 返回一个形状与自己一样的对象。其中 crond 条件为 True 的地方数据来源于自身，否则的话就从其他地方来。这个的意思就是，选择出 条件crond 为真的地方的数据一样。 DataFrame.mask(cond[other=nan, inplace=False, axis=None, level=None, errors=’raise’, try_cast=False, raise_on_error=None]) 这个与上面操作相同，只是返回的数据相反。就相当于盖住条件为真的元素。 DataFrame.query(expr[, inplace]) 通过布尔表达式查询帧列。二元操作函数应用，分组和窗口 DataFrame.apply(func[, axis=0, broadcast=None, raw=False, reduce=None, result_type=None, args=(), **kwds]) 沿某一轴应用一个函数。传递给这个函数的对象是 系列对象，其索引要么是 数据帧 的索引(axis =0)，或者数据帧的列( axis=1 )。默认情况下返回的值类型根据 函数的返回值推测，不然的话就根据 result_type 来返回。这里非常要明白一个问题，通过 axis 来指定 传递数据的索引，也就决定了函数从沿哪个方向应用。 DataFrame.applymap(func) 对每个元素应用函数。如 df.applymap(lambda x: len(x)) DataFrame.pipe(func, *args, **kwargs) 当想链式调用这个函数的话就非常的有用了。 DataFrame.agg(func[, axis]) 通过指定轴上的一个或多个操作来聚合。也即是可对特定的行或者列进行对应的函数操作。 DataFrame.transform(func, *args, **kwargs) 调用函数生成类似索引的NDFrame并返回带有转换值的NDFrame DataFrame.groupby([by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, squeeze=False, observed=False, **kwargs]) 使用映射（字典或关键函数，对分组应用给定函数，返回系列结果）或一系列列来分组。 DataFrame.rolling(window[, min_periods, …]) Provides rolling window calculations. DataFrame.expanding([min_periods, center, axis]) Provides expanding transformations. DataFrame.ewm([com, span, halflife, alpha, …]) Provides exponential weighted functions 计算，状态描述重新索引/选择/标签操作缺失数据操作reshaping，排序，置换结合/联合/合并时间系列相关绘图序列号/IO/变换","categories":[{"name":"Python","slug":"Python","permalink":"https://gowa2017.github.io/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://gowa2017.github.io/tags/Python/"}],"keywords":[{"name":"Python","slug":"Python","permalink":"https://gowa2017.github.io/categories/Python/"}]},{"title":"安装instantclient连接oracle数据库","slug":"安装instantclient连接oracle数据库","date":"2018-09-26T05:08:44.000Z","updated":"2018-09-26T05:08:44.000Z","comments":true,"path":"Oracle/安装instantclient连接oracle数据库.html","link":"","permalink":"https://gowa2017.github.io/Oracle/安装instantclient连接oracle数据库.html","excerpt":"","text":"很久没有用。对接上级数据需要用到 Oracle，没法，只能重新捡起来了。 Oracle 官方的文档还是比较完善的，看起来就是比较麻烦。方便下次吧。 客户端下载在页面 https://www.oracle.com/technetwork/topics/linuxx86-64soft-092277.html 下载好对于的 instant 与 sqlplus 版本。我下载的是 12.2 版本。 我下载的是当前用户的 Home 目录下，也就是 ~。把他们解压到一起： cdunzip instantclient-basic-linux.x64-12.2.0.1.0.zipunzip instantclient-sqlplus-linux.x64-12.2.0.1.0.zip 下载完毕后可以看一下都有些什么文件： ls -1 instantclient_12_2adrciBASIC_READMEgeneziglogin.sqllibclntshcore.so.12.1libclntsh.solibclntsh.so.12.1libipc1.solibmql1.solibnnz12.solibocci.so.12.1libociei.solibocijdbc12.solibons.soliboramysql12.solibsqlplusic.solibsqlplus.soojdbc8.jarsqlplusSQLPLUS_READMEuidrvcixstreams.jar 安装官方文档上的说明还有一些后续步骤需要做： https://www.oracle.com/technetwork/database/features/instant-client/sqlplus-cloud-3080557.html 动态连接库 cd instantclient_12_2ln -s libclntsh.so.12.1 libclntsh.so 建立这么一个软连接后，需要在动态库寻找路径里面加入这个。有两种方法可以做到。 export LD_LIBRARY_PATH=~/instantclient_12_2:$LD_LIBRARY_PATH 或者在配置文件内指定： echo /home/myuser/instantclient_12_2 &gt; /etc/ld.so.conf.d/oic.confldconfig 相关环境变量设置： export ORACLE_HOME=~/instantclient_12_2export TNS_ADMIN=~/instantclient_12_2export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$ORACLE_HOMEexport PATH=$PATH:$ORACLE_HOMEexport NLS_LANG=\"AMERICAN_AMERICA.AL32UTF8\" #这个是为了防止乱码 连接我们可以采用 tnsname.ora 来连接，或者直接用命令行连接： cd instantclient_12_2touch tnsname.ora 命令行连接 sqlplus user/password@//172.230.1.11:1521/topicis 数据导出为csv因为想要将数据导出，然后装到 MySQL 去，所以选择了以 csv 的形式，可更方便一些。关于数据的导出， Oracle 很多都是用的 pl/sql 或者现在新出品的 sql developer，但是我需要的是定时任务自动执行这样，所以只能使用 sqlplus 来进行导出来。 主要就是利用 sqlplus 的 spool 命令来把显示内容转存到文件中。我们可以用一个简单的示例来展示： sqlplus user/password@//172.230.1.11:1521/topicis &lt;&lt; EOFspool test.csvselect sysdate from dual;spool off;EOF 事实上我们可以把想要执行的命令放到一个 sql 文件中，然后以 @filename 的形式来调用。比如上面的语句我们就可以放在一个文件 test.sql 中：spool test.csvselect sysdate from dual;spool off; sqlplus user/password@//172.230.1.11:1521/topicis &lt;&lt; EOF@testEOF","categories":[{"name":"Oracle","slug":"Oracle","permalink":"https://gowa2017.github.io/categories/Oracle/"}],"tags":[{"name":"Oracle","slug":"Oracle","permalink":"https://gowa2017.github.io/tags/Oracle/"}],"keywords":[{"name":"Oracle","slug":"Oracle","permalink":"https://gowa2017.github.io/categories/Oracle/"}]},{"title":"FloatingActionButton在安卓6.0上崩溃的问题","slug":"FloatingActionButton在安卓6.0上崩溃的问题","date":"2018-09-25T09:56:53.000Z","updated":"2018-09-25T09:56:53.000Z","comments":true,"path":"Android/FloatingActionButton在安卓6.0上崩溃的问题.html","link":"","permalink":"https://gowa2017.github.io/Android/FloatingActionButton在安卓6.0上崩溃的问题.html","excerpt":"这个问题其实不是什么大问题。6.0似乎用的人不多了没怎么在意。空的时候搜索了一下 stackoverflow 果然有人遇到相同问题。","text":"这个问题其实不是什么大问题。6.0似乎用的人不多了没怎么在意。空的时候搜索了一下 stackoverflow 果然有人遇到相同问题。 原问：https://stackoverflow.com/questions/49291349/floating-action-button-not-working-in-marshmallow-and-lollipop 我原来的 fab 代码如下： &lt;android.support.design.widget.FloatingActionButton android:id=\"@+id/btn_push\" android:layout_width=\"wrap_content\" android:layout_height=\"wrap_content\" android:layout_alignParentBottom=\"true\" android:layout_alignParentEnd=\"true\" android:layout_alignParentRight=\"true\" android:layout_marginBottom=\"10dp\" android:layout_marginEnd=\"10dp\" android:layout_marginRight=\"10dp\" android:clickable=\"true\" android:focusable=\"true\" android:visibility=\"gone\" android:backgroundTint=\"@color/blue\" android:src=\"@drawable/ic_done_white_36dp\" /&gt; 改成： &lt;android.support.design.widget.FloatingActionButton android:id=\"@+id/btn_push\" android:layout_width=\"wrap_content\" android:layout_height=\"wrap_content\" android:layout_alignParentBottom=\"true\" android:layout_alignParentEnd=\"true\" android:layout_alignParentRight=\"true\" android:layout_marginBottom=\"10dp\" android:layout_marginEnd=\"10dp\" android:layout_marginRight=\"10dp\" android:clickable=\"true\" android:focusable=\"true\" android:visibility=\"gone\" app:backgroundTint=\"@color/blue\" app:src=\"@drawable/ic_done_white_36dp\" /&gt; 原因：在低版本使用一个 vector drawables 的时候，需要用这个来指定。 To use VectorDrawableCompat, you need to set android.defaultConfig.vectorDrawables.useSupportLibrary = true. To use VectorDrawableCompat, you need to make two modifications to your project. First, set android.defaultConfig.vectorDrawables.useSupportLibrary = true in your build.gradle file, and second, use app:srcCompat instead of android:src to refer to vector drawables.","categories":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"}],"keywords":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}]},{"title":"关于职业与工作方向的思考","slug":"关于职业与工作方向的思考","date":"2018-09-24T15:28:38.000Z","updated":"2018-09-24T15:28:38.000Z","comments":true,"path":"杂项/关于职业与工作方向的思考.html","link":"","permalink":"https://gowa2017.github.io/杂项/关于职业与工作方向的思考.html","excerpt":"一直以来，我所学颇杂。没有一个固定的方向。但人到中年，果然不能不考虑一下今后的路该怎么走。我们这个行业是一个人才辈出的行业，也是一个长江后浪推前浪的行业，稍不注意，就会为时代所淘汰。","text":"一直以来，我所学颇杂。没有一个固定的方向。但人到中年，果然不能不考虑一下今后的路该怎么走。我们这个行业是一个人才辈出的行业，也是一个长江后浪推前浪的行业，稍不注意，就会为时代所淘汰。 大学大学念的是 电子科学与技术，其中涉及的基本课程是比较多的。如 模拟电路，数字电路，C语言，单片机，汇编，信用与系统，通信原理，量子力学等课程。但其实都没有用心去学，多数的时间都浪费在电脑游戏上面，至今想来，后悔不已，但可惜时光已不再。 而毕业后的第一份工作，也不是和我的专业有关，而是进入了一个做手机渠道的问题，在其中浑浑噩噩的度过了两年。最终才接触了真正与程序，软件有关的东西。 游戏从游戏开始，才真正的算是开始了解些东西。从第一份工作的时候，其实我就没有停止过对于程序的探索。但苦于实在是不得入门，完全不知道从哪里开始。而自己做看过的书籍，却没有一本是教我怎么样去写一个漂亮的程序出来的。如，APUE，LINUX相关的东西。2011年左右，移动互联网还不是很繁荣的时代，多数的游戏还是在PC上，自然就逃不了C++，MFC等内容。问题是，我们书本上学的东西，全是让在 Terminal 下进行写代码，哪里会教用用来写一个界面呢。 我接触此游戏也是从后台开始的。这个游戏，不需要太多的开发工作，框架引擎是已经选定了的。所需要多的，就是将其假设起来，通过修改相关的配置文件，利用Lua编写的程序来实现各种功能。 恰好，这就是我所擅长的，对APUE的多次阅读，让我对LINUX的理解其实是非常深刻的。在那个圈子里，小有名气。而我也从未停止对于知识的渴望。MYSQL相关的知识就是在那个时候所学习的。 设置，游戏涉及到的还不仅仅如此，还会涉及到各种展示如 html制作，cdn, ddos防御等等。这些知识，居然在那个时候虽不是很深入，但却也有了相当的了解。 后面换的工作，也是与运维有关，确实，多数工作都是在Linux上，难度都不大，只是对于业务系统的了解深度，决定了工作的效率。 转行生活总得继续，云服务的出现，让传统运维越来越少，不能不转行了。安卓、iOS兴起，让每个人都无法避免的想要加入移动互联网。 虽然和我共事，工作的人，都觉得我的技术过硬，有点厉害。但其实我却不这么觉得，因为我觉得我自己无法设计出一个完成的系统架构，解决一个项目的业务。这就跟我无法在只学了终端下编程就能写出GUI程序一样。 最近的一分工作是写安卓代码。以前从来没有接触过Java，有点心惊。在此之前，我从来没有使用过IDE写过一行代码，全都是VIM。但是据说，如果是写JAVA的话，还是用IDE吧，VIM就算了。诚如其言，我还是使用了AS。 接触其中，才觉得其实安卓也不是很难。特别是其在使用性上越来越方便，其宗旨是让用户更多的专注在业务逻辑上的时候，我已经不再纠结于我的控件是否摆放得非常的符合人体学了。 因为我们是以项目为导向，而不是以产品为导向。主要目的是解决问题，而不是提高体验。估计这话产品经理听到了会很不爽的。 但这其中还是有很多值得研究的东西。当第一眼看到以前的老人写的代码的时候，感觉是懵逼的。完全不知所言。但当对安卓的整体架构有了了解以后，就再也不会看不明白了。 比如，我现在就十分鄙视用 AsyncHttpClient 来做网络请求来，我觉得还是 Retrofit 比较好使。我现在讨厌把业务逻辑也放在 View 内，造成我改一个需求的时候，头昏眼花。我觉得 MVP 就是一个非常不错的做法，虽然，会增加一些开发的工作量，但会大大减少维护的难度呢。 当然，一直为大家所推崇的，dagger + rxjava 我还没有空去了解，但我觉得不远了。 未来马上 30 了，这是一个坎，程序员的中年危机，比哪个行业都来惨烈。是 30 岁了还在电脑面前写代码，同时要听着那个新来的小伙计在那咂咂乎乎；还是自己去做点什么事情呢？不知道曾经在哪里看到过一句话，每一个程序员最终的归宿都是项目经理。 但这却不是我所想，至少最近几年内我无法想象。那么这三四年内我所能做的事情，难道就只是提高自己的技术，做一个自由的职业者么？但我与同行比起来似乎我并不具备什么优势呢？","categories":[{"name":"杂项","slug":"杂项","permalink":"https://gowa2017.github.io/categories/杂项/"}],"tags":[{"name":"杂项","slug":"杂项","permalink":"https://gowa2017.github.io/tags/杂项/"}],"keywords":[{"name":"杂项","slug":"杂项","permalink":"https://gowa2017.github.io/categories/杂项/"}]},{"title":"git命令之-rebase","slug":"git命令之-rebase","date":"2018-09-18T15:36:36.000Z","updated":"2018-09-18T15:36:36.000Z","comments":true,"path":"Git/git命令之-rebase.html","link":"","permalink":"https://gowa2017.github.io/Git/git命令之-rebase.html","excerpt":"很遗憾，用了这么久的 git ，对于其分支模型实在是没有仔细了解的。因为公司用的是 svn，我只是自己在本地用 git 进行了代码管理。比较无奈的是，公司的 svn 版本库结构很坑，无法用 git-svn 来实现比较友善的管理，只徒呼奈何了。","text":"很遗憾，用了这么久的 git ，对于其分支模型实在是没有仔细了解的。因为公司用的是 svn，我只是自己在本地用 git 进行了代码管理。比较无奈的是，公司的 svn 版本库结构很坑，无法用 git-svn 来实现比较友善的管理，只徒呼奈何了。 有一个疑问就是，我能否在一个叫做 dev 分支上进行开发，然后把功能完善后，合并到 master 分支。 更实际一点，为了避免需要解决很复杂的代码冲突问题。我在主分支 master 上同步 svn 上的代码，每次想要合并把 dev 代码合并过去的时候，都先用 svn 把别人更新的代码更新下来，再用 merge 命令进行合并。我想用实例来操作是最好的。 Rebase 命令基本命令： git rebase [-i | --interactive] [options] [--exec &lt;cmd&gt;] [--onto &lt;newbase&gt;] [&lt;upstream&gt; [&lt;branch&gt;]]git rebase [-i | --interactive] [options] [--exec &lt;cmd&gt;] [--onto &lt;newbase&gt;] --root [&lt;branch&gt;]git rebase --continue | --skip | --abort | --quit | --edit-todo | --show-current-patch 这里，我们来解释一下两个名字： upstream 上游。这指的是我们想要将其变更拉取过来的分支。 branch 分支。表示的是我们想要将变更应用到的分支。 如果指定了 。git rebase 命令会首先做一个 git checkout &lt;branch&gt;（切换到我们指定的分支）。否则的话就停留当前分支上进行动作。 如果 没有指定（表示需要拉取其变更的分支），那么在 branch..remote 和 branch.merge 选项中配置的 upstream 会被使用，如果 —fork—point 选项被假设。 如果当前不在任何分支上或当前分支没有配置一个 upstream，那么 rebase 会失败。 所有当前分支中的提交造成的变更，且不在 upstream 中的变更，会被存储到一个临时的区域。 当前分支会被重置到 upstream，若指定了 —onto 选项，则会重置到 newbase 。这和 git reset --hard &lt;upstream&gt;有相同的影响。ORGI_HEAD 被设置为指向重置前的分支顶。 那么，之前存储在临时区域的提交就会在当前分支上按序重放。 例子如果我们有以下分支： A---B---C topic /D---E---F---G master 执行下面两个命令都会有同样的结果： git rebase mastergit rebase master topic A&apos;--B&apos;--C&apos; topic /D---E---F---G master 事实上 git rebase master topic 与 git checkout topicgit rebase master 相同。 重复变更内容的处理如果上游分支中存在了我们当前分支中已经有了的变更，那么当前分支上的这个变更会被忽略。就如下面的例子( A， A’ 代表了两个相同的变更，但只是 commit 信息不一样。)： A---B---C topic /D---E---A&apos;---F master 如果我们当前位于 topic 分支，我们执行 git rebase master 的结果将会是下面这样的： B&apos;---C&apos; topic /D---E---A&apos;---F master 基于多分支迁移我们来看一下，基于一个分支与另一个分支的差异来迁移变更到 topic 分支。 这里，我们假设我们的 topic 分支是从 next 分支衍生的。 o---o---o---o---o master \\ o---o---o---o---o next \\ o---o---o topic 现在我们想让 topic 分支变成是基于 master 衍生的。我们可以执行下面这个命令： git rebase --onto master next topic 最后的结果就是： o---o---o---o---o master | \\ | o&apos;--o&apos;--o&apos; topic \\ o---o---o---o---o next 上面这个操作，也就真实的展示了一个比较让人难以理解的概念 变基。 变基：改变一个分支的基准位置(commit)。 对变基的直观解释。实例我们先初始化一个库。 git init temp cd testecho README &gt;&gt; README.mdgit add .git commit -m &apos;add readme file&apos;echo file1 &gt;&gt; file1git add .git commit -m &apos;add file1&apos; 再另外一个分支更新文件： git co -b devecho file2 &gt;&gt; file2git add .git commit -m &apos;add file2&apos; 切换回主分支，再添加个文件： git co masterecho file3 &gt;&gt; file3git add .git commit -m &apos;add file3&apos; 现在我打算把 dev 分支上的改动合并到 master 分支。一般来说，我们可以采用 merge 命令。 如果 upstream branch 已经包含了一个你已经做了的改变，那么这个变化会被跳过。在下面的操作中（ A’ 与 A 做了相同的变化，但是 commit 信息不一样） A---B---C topic /D---E---A&apos;---F master 其结果是： B&apos;---C&apos; topic /D---E---A&apos;---F master —onto下面来看一下怎么样将一个 topic 分支移植到 mergegit co mastergit merge devgit log --pretty=oneline b67203a314ab47dde68016f4a2fc04b6ee056e28 (HEAD -&gt; master) Merge branch &apos;dev&apos;1d38148fa8a973e41f41e02b9554b06137896956 add file3bbad65a53a9f545c11f8db8678a63b47201dc433 (dev) add file2f0c5b7b7674cc7956f3d89e06ce041ccaa4cd545 add file1acd1ecdd9f88a1c936ca15946bc48c1104ef55f2 add readme file 我们的提交历史变更成这样。我们再看看 rebase 的区别。 rebase先把我们的记录恢复到之前的 master 状态。 git reset --hard head^git rebase devgit log --pretty=oneline e90bb2e9d5996d16c45682596dd4014c4981dd41 (HEAD -&gt; master) add file3bbad65a53a9f545c11f8db8678a63b47201dc433 (dev) add file2f0c5b7b7674cc7956f3d89e06ce041ccaa4cd545 add file1acd1ecdd9f88a1c936ca15946bc48c1104ef55f2 add readme file 操作结果有所不同。 merge 显示的历史顺序和我们进行的合并操作有关，而 rebase 显示顺序和我们实际动作发生的过程相关。同时，rebase 少了一个 join 操作。 我们来换个办法，在 dev 分支上 rebase master 然后，再合并。可是这个时候我懵逼了，我们如何取消了已经 rebase 的操作呢？ 没有对应的 undo 操作。只能通过找到 ref-log 来操作。 git refloge90bb2e (HEAD -&gt; master) HEAD@&#123;0&#125;: rebase finished: returning to refs/heads/mastere90bb2e (HEAD -&gt; master) HEAD@&#123;1&#125;: rebase: add file3bbad65a (dev) HEAD@&#123;2&#125;: rebase: checkout dev1d38148 HEAD@&#123;3&#125;: reset: moving to head^b67203a HEAD@&#123;4&#125;: merge dev: Merge made by the &apos;recursive&apos; strategy.1d38148 HEAD@&#123;5&#125;: checkout: moving from master to master1d38148 HEAD@&#123;6&#125;: checkout: moving from dev to masterbbad65a (dev) HEAD@&#123;7&#125;: checkout: moving from master to dev1d38148 HEAD@&#123;8&#125;: commit: add file3f0c5b7b HEAD@&#123;9&#125;: checkout: moving from dev to masterbbad65a (dev) HEAD@&#123;10&#125;: commit: add file2f0c5b7b HEAD@&#123;11&#125;: checkout: moving from master to devf0c5b7b HEAD@&#123;12&#125;: commit: add file1acd1ecd HEAD@&#123;13&#125;: commit (initial): add readme file git reset --hard 1d38148git co devgit rebase mastergit log --pretty=oneline 0b5d862609228abb1255775ab9c2124f01fd7ed5 (HEAD -&gt; dev) add file21d38148fa8a973e41f41e02b9554b06137896956 (master) add file3f0c5b7b7674cc7956f3d89e06ce041ccaa4cd545 add file1acd1ecdd9f88a1c936ca15946bc48c1104ef55f2 add readme file 似乎可以发现一个问题。当我们在 dev 分支上 rebase master 的时候，实际上是找到两者共同的祖先，然后先进行 master 的重放，再把 dev 自己的修改放在后面去。 仔细观察一下我们的日志： 0b5d862 (HEAD -&gt; dev) HEAD@&#123;4&#125;: merge dev: Fast-forward1d38148 (master) HEAD@&#123;5&#125;: checkout: moving from dev to master0b5d862 (HEAD -&gt; dev) HEAD@&#123;6&#125;: rebase finished: returning to refs/heads/dev0b5d862 (HEAD -&gt; dev) HEAD@&#123;7&#125;: rebase: add file21d38148 (master) HEAD@&#123;8&#125;: rebase: checkout masterbbad65a HEAD@&#123;9&#125;: checkout: moving from master to dev 先切换到 dev 分支 rebase： 检出 master 上的更新 应用 dev 分支上的更新 add file2 更新 HEAD 指向最新 dev 分支 我的工作流程 日常的工作在 dev 分支。 需要提交的时候，git svn rebase 更新 svn 代码下来 把 master 的变更应用到 dev 合并到主分支 git svn dcommit","categories":[{"name":"Git","slug":"Git","permalink":"https://gowa2017.github.io/categories/Git/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://gowa2017.github.io/tags/Git/"}],"keywords":[{"name":"Git","slug":"Git","permalink":"https://gowa2017.github.io/categories/Git/"}]},{"title":"关于机器学习的基本概念","slug":"关于机器学习的基本概念","date":"2018-09-15T12:41:08.000Z","updated":"2018-09-15T12:41:08.000Z","comments":true,"path":"TensorFlow/关于机器学习的基本概念.html","link":"","permalink":"https://gowa2017.github.io/TensorFlow/关于机器学习的基本概念.html","excerpt":"","text":"纯属好奇心驱使的了解一下 TensorFlow 的相关知识，这 Google 有对应的课程可以了解真好，居然还真的需要一些袋鼠知识才能比较直观的理解呢。当然，理解基础知识，有利于后面对使用的快速上手和了解。 课程地址 基本概念按照课程上的解释，机器学习，会根据已有的数据集 （我们称之为 样本）来进行训练，得出一个模型。然后根据模块来对数据进行预测。 数据集 是一系列有 特征（ feature ) 与 标签 ( label ) 的集合。 而需要进行预测的数据，则是，只有特征，没有标签。模型会根据特征，进行计算，得出标签的预测值。 回归与分类回归模型可预测连续值。例如，回归模型做出的预测可回答如下问题： 加利福尼亚州一栋房产的价值是多少？ 用户点击此广告的概率是多少？ 分类模型可预测离散值。例如，分类模型做出的预测可回答如下问题： 某个指定电子邮件是垃圾邮件还是非垃圾邮件？ 这是一张狗、猫还是仓鼠图片？ 特征与权重一个模型的输入可能有多个特征，每个特征的影响重要程度，可能并不一样，我们称之为特征的 权重 。对于 线性回归 还会有个初值。 训练与损失预测肯定是有偏差的。 训练模型指的是通过有标签的样本来学习（确定）所有权重和偏差的理想值。 在监督式学习中，机器学习算法通过以下方式构建模型：检查多个样本并尝试找出可最大限度地减少损失的模型；这一过程称为经验风险最小化。 损失是一个数值，表示对于单个样本而言模型预测的准确程度。 训练模型的目标是从所有样本中找到一组平均损失“较小”的权重和偏差。 损失的评估样本中的标签，与模型预测值之间的差异就是损失。 可以一个数学函数来对损失进行评估。 平方损失线性回归常见的损失函数是 平方损失 L2。这种评估是用样本中的 标签值 - 预测值 进行平方计算。 均方误差MSE均方误差 (MSE) 指的是每个样本的平均平方损失。要计算 MSE，请求出各个样本的所有平方损失之和，然后除以样本数量： MSE = \\frac{1}{N} \\sum_{(x,y)\\in D} (y - prediction(x))^2迭代预测都会有损失，我们的训练模型的目的是找出平均损失最小的权重和偏差。 迭代方法是一种广泛用于降低损失的方法，而且使用起来简单有效。 对于线性回归： y' = b + w_1x_1b, w1 我们可以随便选一个初值。这个时候，预测得到的值 y’ 与 样本中的标签值 y 作为参数，让损失函数进行计算得到损失。如果我们以 均方误差MSE 来评估损失的话，那么每次训练，都会评估 MSE，生成新的 w1 ，直到 MSE 不再变化，或者变化及其缓慢。这个时候我们可以说模型已经收敛（损失函数收敛）。 梯度下降法在上面提到的迭代方法中，我们说学习的时候每次都会评估损失，生成新的权重参数，直到模型收敛。但是怎么生成参数，却没有进行解释。 平均损失的曲线与 w_1相关。只有一个 w_1 值会让平均损失最小。 通过计算整个数据集中 w1 每个可能值的来找到收敛点这种方法效率太低。。 梯度下降法会根据平均损失的变化来确定生成 w1 的值。给 w1 一个初值，然后计算平均损失曲线在此处的 梯度。 梯度 是偏导数的矢量，其有方向和大小两个属性。梯度始终指向损失曲线中增长最为迅猛的方向。梯度下降法算法会沿着负梯度的方向走一步，以便尽快降低损失。 为了确定损失函数曲线上的下一个点，梯度下降法算法会将梯度大小的一部分与起点相加。 由于高数没学好，对于 梯度 不是很明白，但是没明白我心里就不踏实，所以去看了一下。 梯度根据 维基百科 解释： 在单变量的实值函数的情况（一元函数），梯度只是导数，或者，对于一个线性函数，也就是线的斜率。 梯度一词有时用于斜度，也就是一个曲面沿着给定方向的倾斜程度。可以通过取向量梯度和所研究的方向的内积来得到斜度。梯度的数值有时也被称为梯度。 大家自己看了。 学习速率（步长）梯度下降法算法用梯度乘以一个称为学习速率（有时也称为步长）的标量，以确定下一个点（ w1 值）的位置。例如，如果梯度大小为 2.5，学习速率为 0.01，则梯度下降法算法会选择距离前一个点 0.025 的位置作为下一个点。 如果步长过小，我们可能很久很久才能到达损失最低的位置；而步长过大，则我们可能永远也达不到损失最低的位置。 所以如果我们训练了一个模型后，就要进行一个测试认证模型的准确度。准确度太低的话，我们就要调整我们的模型超参数了。超参数是编程人员在机器学习算法中用于调整的旋钮。如步长。 随机梯度下降法我们用梯度下降法来生成下一个 w_1 的值。对于每个 w_1，我们需要一个样本集来计算损失曲线函数，然后求得梯度。这个样本集我们称之为 批量。如果 批量是以亿为单位的话，那么这个计算就非常的低效了。 包含随机抽样样本的大型数据集可能包含冗余数据。实际上，批量大小越大，出现冗余的可能性就越高。一些冗余可能有助于消除杂乱的梯度，但超大批量所具备的预测价值往往并不比大型批量高。 如果我们可以通过更少的计算量得出正确的平均梯度，会怎么样？通过从我们的数据集中随机选择样本，我们可以通过小得多的数据集估算（尽管过程非常杂乱）出较大的平均值。 随机梯度下降法 (SGD) 将这种想法运用到极致，它每次迭代只使用一个样本（批量大小为 1）。如果进行足够的迭代，SGD 也可以发挥作用，但过程会非常杂乱。“随机”这一术语表示构成各个批量的一个样本都是随机选择的。 小批量随机梯度下降法（小批量 SGD）是介于全批量迭代与 SGD 之间的折衷方案。小批量通常包含 10-1000 个随机选择的样本。小批量 SGD 可以减少 SGD 中的杂乱样本数量，但仍然比全批量更高效。","categories":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://gowa2017.github.io/categories/TensorFlow/"}],"tags":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://gowa2017.github.io/tags/TensorFlow/"},{"name":"机器学习","slug":"机器学习","permalink":"https://gowa2017.github.io/tags/机器学习/"},{"name":"ML","slug":"ML","permalink":"https://gowa2017.github.io/tags/ML/"}],"keywords":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://gowa2017.github.io/categories/TensorFlow/"}]},{"title":"MVP架构指导性说明","slug":"MVP架构指导性说明","date":"2018-09-11T12:12:12.000Z","updated":"2018-09-11T12:12:12.000Z","comments":true,"path":"Android/MVP架构指导性说明.html","link":"","permalink":"https://gowa2017.github.io/Android/MVP架构指导性说明.html","excerpt":"有很多关于MVP架构的文章和例子，有很多不同的实现。开发人员社区一直在努力以最佳方式使这种模式适应Android。本文转自国外一篇文章，地址是https://medium.com/@cervonefrancesco/model-view-presenter-android-guidelines-94970b430ddf","text":"有很多关于MVP架构的文章和例子，有很多不同的实现。开发人员社区一直在努力以最佳方式使这种模式适应Android。本文转自国外一篇文章，地址是https://medium.com/@cervonefrancesco/model-view-presenter-android-guidelines-94970b430ddf如果决定采用MVP模式，你就是在做一个架构选择，同时你的代码库会改变，实现新功能的方式也会改变。也应该清楚我们不能不面对一些安卓通用的问题比如 activity 生命周期，而且你应该问一下你自己几个问题： 我们应不应该保存 presenter的状态？ 要不要持久化 presenter？ presenter 有没有生命周期？ 本篇文章按以下顺序给出一个 指南 或 最佳实践 列表： 解决使用本模式最常见的问题（或者是我自己遇到过的） 最大化这种模式的优点。 分层简介 Model： 管理数据 的接口。 Model 的责任包括：调用API，缓存数据，管理数据库等等。Model 也可以是一个与其他 Model 通信来完成 Model 功能的接口。例如，如果使用的是 Repository 模式 ，那么，Model 就是一个库；如果使用的是 Clean architecture，那么 Model 就是一个交互器。 Presenter： model 与 view 中间人。所有的业务逻辑都在这个地方。 Presenter 的责任是：查询 model，更新 view ，响应用户的操作，更新 model。 View：以 Presenter 决定的方式来展现数据。 view 可以以 Activity， Fragment， Android widget 或其他任何能做展示进度条，更新 TextView ，填充一个 RecyclerView 的东西。 下面是一些个人观点。 1. 沉默及被动的View安卓有一个最大的问题就是其 views （ Activitys, Fragment， …）很难被测试，因为框架太复杂。为了解决这个问题，你应该实现 Passive View 模式。通过使用一个控制器，此模式的实现将视图的行为降低到绝对最小值，在我们的模式里，此控制器就是 Presenter。这个选择显著的提升了可测试性。 比如，你有一个用户名/密码表单，还有一个提交按钮，你不用在 View 里面去写验证有效性的逻辑，而在 Presenter 里面去写。 View 干的事情就收集用户名和密码，然后传递给 Presenter。 2. 使Presenter独立于框架为了让前一个目的确实有效（提高可测试性），确认 Presenter 不依赖于安卓的类。只使用 Java 依赖的原因有两个：将 Presenter 从实现细节（安卓框架）抽象出来，因此可以为 Presenter 编写非指令化测试，可以在本地的 JVM 上快速的进行测试而不需要一个模拟器。 如果我需要一个 Context 怎么办？那就尽量不要用它。如果你需要一个 Context 时，你应该问一下自己为什么你会需要它。例如，你可能会用这个上下文来访问 shared preferences 或资源。但是，你不应该在 Presenter 里干这个事情：你应该在 View 里面访问资源，在 Model 里访问 shared preferences。这只是两个简单的例子，但我可以打赌，大多数时候，这只是一个错误的责任问题。 顺便说一下，当你需要解耦一个对象时，依赖倒置原则 （dependency inversion principle ）在这种情况下会有很多帮助。 3. 写一个契约类来描述View与Presenter间的交互当你要写一个新功能的时候，首先写一个契约类是个非常好的习惯。契约类描述了View 与 Presenter 间的通信，这可以帮助更好的设计交互问题。 Android Architecture谷歌的做法就非常的棒，一个契约类接口包含两个内部类：一个用来描述View， 一个用来描述 Presenter。 比如： public interface SearchRepositoriesContract &#123; interface View &#123; void addResults(List&lt;Repository&gt; repos); void clearResults(); void showContentLoading(); void hideContentLoading(); void showListLoading(); void hideListLoading(); void showContentError(); void hideContentError(); void showListError(); void showEmptyResultsView(); void hideEmptyResultsView(); &#125; interface Presenter extends BasePresenter&lt;View&gt; &#123; void load(); void loadMore(); void queryChanged(String query); void repositoryClick(Repository repo); &#125;&#125; 从方法名称，我们就知道我们描述其应该干的事情。而且，View 变得非常的简单。 View 约束之前说过， View 通过 Activity 或 Fragment 实现：Presenter 必须依赖于 View 接口，而不是直接依赖于 Activity：这样，就将 presenter 与 view 的实现解耦。这正好是 SOLID 原则里面的 D：依赖抽象，不依赖具体。 我们可以随意改变 View，而不需要去变更 Presenter 的代码。我们可以通过建立一个 mock view 来对 Presenter 做单元测试。 Presenter 约束我们真的需要一个 Presenter 约束类么？ 实际上不，但我会说 需要。关于这个话题，有两种不同的意见。 某些人认为，应该需要这个契约类。因为我们把 View 从 Presenter 解耦出来。 然而，某些开发者认为，你正在抽象一个本来就已经是抽象了的东西，你就不需要写一个接口。而且，你可能绝不会再写一个可选的 Presenter，所以这只是浪费时间和代码。 无论如何，有这么一个类可以帮助你写一个 mock Presenter，但如果你使用类似 Mockito 这样的工具的话你就不需要任何接口。 我个人来说，我因为两个原因，所以要写这个 Presneter 接口类： 我不是为 Presenter 写接口。我是用它来描述 View 与 Presenter 的交互。这会让事情变得更加清楚。 这并不怎么花时间 4. 定义命名约定以分离职责Presenter 一般会有两类方法： Actions（如 load()）：描述 Presenter 做了什么。 User events（如 queryChanged()）： 通过用户的行为触发的动作。 actions 越多，View 中的逻辑就越多。相反，用户事件表明他们会向 Presenter 决定该做什么。 举个实例，一个搜索应该只在用户输入了指定数量的字符后才会发生。在这种情况下，View 只需要调用 queryChanged(...) 方法，Presenter 会决定合适来启动搜索的逻辑。 然而，loadMore()方法，会当用户滑动到列表底部的时候被调用，然后 Presenter 会加载结果的另外一页。这个选择意味着，当用户滑动到底部时，View 知道一个新页必须被加载。为了反转这个逻辑，我会把这个方法命名为 onScrolledToEnd()。 当我们在说这个 契约设计 短语的时候，你必须决定 每个用户事件，其对应的动作是什么，这个逻辑归属于谁。 5. 不要在Presenter接口内写Activity-lifecycle-style回调标题的意思是，Presenter 内不应该含有onCreate(...), onStart(), onResume() 这样的方法，这因为几个原因 ： 这样的话，Presenter 将会用 Activity 的生命周期相耦合。如果当我要用 Fragment 替换 Activity 的时候怎么办？我该什么时候调用 presenter.onCreate(state)？在 Fragment 的onCreate(...), onCreateView(...)or onViewCreated(...) 中么？当我使用的是自定义的 View 时候呢？ Presenter 不应该有这么复杂的生命周期。安卓主要组件是这样设计的，但不意味着你应该在任何地方都这样做。只要有机会简化，就尽量简化。 作为调用一个相似名字方法的替代，在 Activity 生命周期回调函数中，可以调用 Presenter 的动作。如，可以在 Activity.onCreate()结束的时候，调用 load() 。 6. Presenter 与 View 1 对 1 关联没有View， Presenter 就没有意义。其与 View 共存亡撒。其同时只会管理一个 View。 可以在 Presenter 以几种方法操作对 View 的依赖。一种方式是在 Presenter 接口中提供类似 attach(View view) 和 detach(View view) 的方法，就和前面的例子一样。这种实现的问题是，View 是 nullable 的，我们必须在每当 Presenter 需要一个 View 的时候进行检查。这有点烦人。 我刚说，Presenter 与 View 一一对应。我们可以利用这点。 Presenter 可以利用 View 作为其构造器参数。顺便一提，你可能会需要一个方法来为某些事件订阅 Presenter。 所以，我建议使用 start() 这样的方法来运行 Presenter 的业务。 dettach() 是什么？ 如果你有一个 start() 方法，那么你可能需要最少一个方法来释放依赖。我们把某些 让 Presenter 订阅某些事件的方法叫做 start()，释放依赖的这个方法我们就叫 stop()。 public interface BasePresenter&lt;V&gt; &#123; void attach(V view); void detach();&#125; public interface BasePresesnter &#123; void start(); void stop();&#125; 7. 不要在 Presenter 内保存状态我说的是用一个 Bundle 。如果你想遵守第二条规则的话，就不要这样做。你不应该把数据序列化到 Bundle，因为 Presenter 将会与安卓的类相耦合。 我没有说 Presenter 是无状态的，因为这是说谎。就跟前面的例子一样， Presenter 最好会拥有 page number/offset 这两个值状态。 所以，你必须保持 Presenter，是不是？ 8. 不要保持 Presenter不需要这种解决方法，主要是因为我认为 Presenter 并不是我们应该持久化的东西，其不是一个数据类，确切的说。 某些建议提供了一个在配置改变期间使用保留的 Fragment 或 Loaders 来获取 Presenter 的方法。我认为这不是最好的解决方案。使用这个办法，Presenter 在方向改变的时候会存在，但是当安卓杀掉进程并重新创建 Activity 时，这个 Activity 将会和一个新的 Presenter 一起建立。因为这个原因，这个方法解决了一半的问题。 那怎么办？ 9. 为Model提供缓存以恢复View状态在我看来，解决“恢复状态”问题需要调整应用程序架构。这篇文章提出了一个符合这种想法的很好的解决方案。作者建议使用一个类似 Repository 的接口或者任何其他用来管理数据东西 来缓存 网络请求结果，其作用域与整个应用相关，而不是与Activity相关（所以其在方向改变的时候存活）。 这个接口是一个更智能的 Model。上面这个方法可能会提供最少一个 磁盘缓存策略 和一个可能的 内存缓存。因此，及时进程已经销毁，Presenter 可以使用磁盘上的数据来恢复 View 的状态。 View 只需要担心几个必要的请求参数来恢复状态就行了。例如，我们的例子中，我们只需要存储查询。 现在，我们有两个选择： 在 Model 层抽象这个行为，当 Presenter 调用 repository.get(param) 的时候，如果页面已经存在缓存中，直接返回，否则的话就调用 网络 API。 在 Presenter 层管理。给 Presenter 在契约类中添加一个方法来恢复 View 状态。如 restore(params), loadFromCache(params) or reload(params)。","categories":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"},{"name":"MVP","slug":"MVP","permalink":"https://gowa2017.github.io/tags/MVP/"}],"keywords":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}]},{"title":"关于使用Lsyncd进行数据镜像同步","slug":"关于使用Lsyncd进行数据镜像同步","date":"2018-09-08T04:23:44.000Z","updated":"2018-09-08T04:23:44.000Z","comments":true,"path":"Linux/关于使用Lsyncd进行数据镜像同步.html","link":"","permalink":"https://gowa2017.github.io/Linux/关于使用Lsyncd进行数据镜像同步.html","excerpt":"","text":"公司的业务没有做共享存储，而是采用 Lsyncd 来进行两台服务器间的文件同步（主要是 图片，文书等）。但是有的时候会出现问题，比如在某一台设备挂了的时候，重启了，另外一台机器上存在的文件居然会被删除，我很纳闷这到底是怎么回事。所以想来学习一下这个内容。 简介Lsyncd 是一个开源项目，项目地址在这里 。 wiki地址在这里 Lsyncd会观察某一目录树的事件监控接口（ inotify 或 fsevents ）。 其会把几秒内发生的事件集合起来，然后安排一个或多个进程来同步变化。默认情况下使用的是 rsync 。Lsyncd 是一个轻量的实时镜像解决方案，其不需要安装新的文件系统或块设备，也不会影响本地文件系统的性能。 Rsync + ssh是一种高级操作配置，它使用SSH来执行文件，目录直接在目标上移动，而不是通过网络重新传输移动目标。 可以通过配置文件实现细粒度的自定义。自定义操作配置甚至可以从头开始编写，从shell脚本到用Lua语言编写的代码。这样就可以实现简单，强大和灵活的配置。 Lsyncd 2.2.1 requires rsync &gt;= 3.1 on all source and target machines. 使用场景Lsyncd 设计来在需要少量配置，就能把期待的变化同步到远程目录。在想从一个安全区域同步数据到不是太安全区域的时候也很有用。 简单使用例子lsyncd -rsync /home remotehost.org::share/ 这会观察本地目录 /home 及其子目录，将所有的变化同步到远程主机 remotehost.org 中的 share 目录。 lsyncd -rsyncssh /home remotehost.org backup-home/ 这个命令也会观察和同步 /home 目录。不同的是其使用一个 ssh 连接，其会将 move 事件在远程主机上执行，而不是重新传输文件。 配置文件Lsyncd 的配置文件以 Lua 语法来写。其设计目的是简单而高效。这两者并不矛盾，但某些妥协是必须的。为了尽可能的达到这两个目的，Lsyncd 的配置可以在不同的层达成。 较低的层增加了适应性，同时界面变得更具吸引力。 Settings对于所有层的脚本， settings 调用可以被用来改变服务层的配置。 比如，下面的配置就会告诉 Lsyncd 将日志记录在 /tmp/lsyncd.log ，然后把其状态信息阶段性的更新到 /tmp/lsyncd.status ，并且，不要成为一个 daemon 进程。 settings &#123; logfile = \"/tmp/lsyncd.log\", statusFile = \"/tmp/lsyncd.status\", nodaemon = true,&#125; 如果是从2.0升级来的话，要注意到 settings 变成了一个函数，而不是一个变量。所以 必须 删除 settings 与 { 间的 = 号。 在 settings 中有效的键如下： logfile = FILENAME 日志路径 pidfile = FILENAME pid文件路径 nodaemon = BOOL 是否成为一个守护进程 statusFile = FILENAME 状态记录文件 statusInterval = NUMBER 报告状态信息到状态日志文件的间隔 logfacility = STRING syslog 设备，默认是 user logident = STRING syslog标准，默认是 lsyncd insist = BOOL 即使一个或多个目标因为不可达而失败也要开机启动 inotifyMode = STRING 指定对于在 inotify 系统上要监听的事件。可以是 Modify, CloseWrite(默认) 或 CloseWrite, Modify。 maxProcesses = NUMBER Lsyncd 最多可以派生出来的进程。这通过 sync{} 来增加。 还有一个额外的参数可以设置，这会被 Syncs 继承。 maxDelays = NUMBER 当事件已经入队这么多秒后，即使低于延时计时其也会进行动作。 Layer 4（默认配置）可以从三个默认的配置实现中选择一个：rsync, direct, rsyncssh。 如果要将本地目录使用默认的 rsync 行为来同步，只需要把下面的代码加入配置文件： sync &#123; defalut.rsync, source = \"DIRNAME\", target = \"DIRNAME\" &#125; 参数的顺序不重要。如果 target 是一非本地路径，那么需要填写是一个绝对路径。可以也这种方式添加多个 sync 。源目录可以相同，也可不相同，这都没有什么问题。每个 sync 都必须指定 source。 根据我们所选择的行为，其他的 sync 可能都不同。可选：可以在每个 sync 内重写 maxDelays, maxProcesses 参数。 也可以通过将默认init函数设置为false来跳过初始rsync进程： sync &#123; default.rsync, source = \"DIRNAME\", target = \"DIRNAME\", init = false&#125; 这是一个可能很危险的优化;因此，只有在启动 Lsyncd 时确定源和目标是同步的，才能使用它。 您可以选择的默认行为如下： default.rsync默认的 rsync 配置会在单独的 1000 个事件发生，或铀时到达 delay 秒后动作。其会把所有有变更的文件过滤列表传递给派生的 Rsync 进程（通过管道）。Lsyncd 可能以如下的形式调用 Rsync ： /usr/bin/rsync -ltsd --delete --include-from=- --exclude=* SOURCE TARGET 可以通过 rsync 参数来设置，调用 Rsync 时的选项： sync &#123; default.rsync, source = \"/home/user/src/\", target = \"foohost.com:~/trg/\", delay = 15, rsync = &#123; binary = \"/usr/local/bin/rsync\", archive = true, compress = true &#125;&#125; 下表是一些 sync 参数的选项。可以先看一下 Rsync 命令的文档来更详细的了解。 parameter = TYPE default value comment acls = BOOL false append = BOOL false (Lsyncd &gt;= 2.2.0) append-verify = BOOL false (Lsyncd &gt;= 2.2.0) archive = BOOL false backup = BOOL false (Lsyncd &gt;= 2.2.0) backup_dir = DIR false (Lsyncd &gt;= 2.2.0) binary = FILENAME \"/usr/bin/rsync\" Lsyncd calls this binary as rsync checksum = BOOL false chmod = STRING (Lsyncd &gt;= 2.2.0) chown = USER:GROUP (Lsyncd &gt;= 2.2.0) compress = BOOL false copy_dirlinks = BOOL false (Lsyncd &gt;= 2.2.0) copy_links = BOOL false cvs_exclude = BOOL dry_run = BOOL false exclude = PATTERN TABLE of PATTERNs also allowed excludeFrom = FILENAME executability = BOOL false existing = BOOL false (Lsyncd &gt;= 2.2.0) group = BOOL false groupmap = STRING (Lsyncd &gt;= 2.2.0) hard_links = BOOL false ignore_times = BOOL false inplace = BOOL false (Lsyncd &gt;= 2.1.6) ipv4 = BOOL false ipv6 = BOOL false links = BOOL true one_file_system = BOOL false owner = BOOL false password_file = FILENAME (Lsyncd &gt;= 2.1.2) perms = BOOL false protect_args = BOOL true prune_empty_dirs = BOOL false quiet = BOOL false rsh = COMMAND rsync_path = PATH (path to rsync on remote host) sparse = BOOL false suffix = SUFFIX (Lsyncd &gt;= 2.2.0) temp_dir = DIR times = BOOL true update = BOOL false usermap = STRING (Lsyncd &gt;= 2.2.0) verbose = BOOL false whole_file = BOOL false xattrs = BOOL false _extra = TABLE of STRINGS. If absolutely needed, additional arguments can be specified as a TABLE of STRINGS(example: { \"--omit-dir-times\", \"--omit-link-times\" }). Note that the underscore highlights this as workaround. If you need something that is not covered by the above options, please request it via a feature request on the project website. Most notably, do not add -r for recursive or -a which implies recursive, since Lsyncd will handle that by itself. Additionally do not add -R for relative, which will ruin Lsyncd &lt;-&gt; Rsync communication. ### default.rsyncssh 这个与上一配置的不同之处就是在移动文件或文件夹的时候，是通过 ssh 命令来执行，而不是重新传输文件。这个配置文件会像 *default.rsync* 那样派生出 *Rsync* 进程和一个 `/usr/bin/ssh HOST mv ORIGIN DESTINATION` 命令。 这个配置文件不需要 *target* 参数，其需要分开的两个参数 *host, targetdir* 。 可以使用rsync参数更改Rsync的选项，如上面描述的default.rsync。 通过 *ssh* 可以配置的参数如下： binary = FILENAME Lsyncd calls this binary as ssh (default: /usr/bin/ssh) identityFile = FILE Uses this file to identify for public key authentication. options = TABLE A table of addition extended options to pass to ssh's -o option. port = PORT Adds --port=PORT to the ssh call. _extra = STRING TABLE Similar to rsync._extra this can be used as quick workaround if absolutely needed. 例子： settings &#123; logfile = \"/var/log/lsyncd.log\", statusFile = \"/var/log/lsyncd-status.log\", statusInterval = 20&#125;sync &#123; default.rsyncssh, source=\"/srcdir\", host=\"remotehost\", excludeFrom=\"/etc/lsyncd.exclude\", targetdir=\"/dstdir\", rsync = &#123; archive = true, compress = false, whole_file = false &#125;, ssh = &#123; port = 1234 &#125;&#125; 注意 rsync 与 ssh 间的逗号。如果是从2.0升级来的话，要注意到 settings 变成了一个函数，而不是一个变量。所以 必须 删除 settings 与 { 间的 = 号。 要在一个单独的连接内执行多个任务， Lsyncd 会在远程主机上调用 xargs 命令。 xargs 命令的参数，可以通过配置 xargs 来修改。 binary = FILENAME Lsyncd calls this binary as xargs on the remote host (default: /usr/bin/xargs) delimiter = DELIMITER delimiting character to separate filenames. By default the 0 character is used. Very old holds may need newline instead. _extra = STRING TABLE By default { '-0', 'rm -rf' }. Remove the -0 if you chose newline delimiter instead. Otherwise leave it as is. 例子： sync &#123; default.rsyncssh, source = \"/home/user/src/\", host = \"foohost.com\", targetdir = \"~/trg/\",&#125; default.direct这个配置能以更好的性能同步两个本地目录（相对于 default.rsync）。default.direct 与 default.rsync 一样，在启动的时候使用 rsync 来初始化同步。然而，在常规操作中，default.direct 使用 /bin/cp, /bin/move, /bin/mv 来保持同步。所有的参数都和 default.rsync 一致。 例子： sync &#123; default.direct, source = \"/home/user/src/\", target = \"/home/user/trg/\"&#125; Exclusions还有参数可以指定给 sync{}： excludeFrom = FILENAME 从文件内加载排除规则，一行一条规则 exclude = LIST 从字符串内加载排除规则 排除规则是在rsync的排除模式之后建模的，但稍微简单一些。Lsyncd 支持如下特性： 若某个事件的路径中的某些片段匹配这些文本，那么排除。比如 /bin/foo/bar 匹配规则 foo 。 如果规则以 / 开始，那么只匹配路径的开始 如果规则以 / 结束，那么只匹配路径的结束 ？ 匹配任何不是 / 的字符 匹配 0 或多次非 / 字符 ** 匹配任何字符 0 或多次。 例子： sync &#123; default.rsync, source = \"/home/user/src/\", targetdir = \"/home/user/dst/\", exclude = &#123; '*.bak' , '*.tmp' &#125;&#125; Deletions默认情况下， Lsyncd 会删除目标中在源目录中不存在的文件这是保持目标和源同步的一个基本部分。然而，很多用户不想要这个功能，所以，所有的默认实现都把 delete 作为一个附加参数。 delete 的合法值是： delete = true Default. Lsyncd will delete on the target whatever is not in the source. At startup and what's being deleted during normal operation. delete = false Lsyncd will not delete any files on the target. Not on startup nor on normal operation. (Overwrites are possible though) delete = 'startup' Lsyncd will delete files on the target when it starts up but not on normal operation. delete = 'running' Lsyncd will not delete files on the target when it starts up but will delete those that are removed during normal operation. Layer 3 开始动作本层，可创建自定义配置。下面的例子使用 bash 命令保持一个本地目录的同步： bash = &#123; delay = 5, maxProcesses = 3, onCreate = \"cp -r ^sourcePathname ^targetPathname\", onModify = \"cp -r ^sourcePathname ^targetPathname\", onDelete = \"rm -rf ^targetPathname\", onMove = \"mv ^o.targetPathname ^d.targetPathname\", onStartup = '[[ if [ \"$(ls -A ^source)\" ]; then cp -r ^source* ^target; fi]]',&#125; 我们一步步的来解释这个例子。技术上说，所有的 Lsyncd 配置都是一个 Lua 表，里面以键值对填充。先建立一个 bash 变量，并给他赋予一个值 {…}。 bash = &#123; ... &#125; 接着就以一个 delay = 5, 来进行填充一个设置项。如果不要延时的话，就不要设置这个项，那么 Lsyncd 会在有变化的时候立即动作。 Actions 动作有6个动作 onAttrib 属性变更时调用 onCreate 新文件在目录中建立时调用 onModify 文件发生变化时调用 onDelete 文件或目录被删除 onMove 当文件或目录在可观察的文件树内移动 onStartup 只在 Lsyncd 启动时调用 当没有 onMove 定义，或 移动动作是从外部进入目录数，或从当前可观察目录树到外部，那么动作会分解为 onDelete 或 onCreate。 onStartup 时会屏蔽所有的其他动作，直到其完成。 以 Lua String 的形式指定要进行的操作。这些操作可以被任何 Lua 运行的方式进行分隔，在上面的例子中是 ‘TEXT’, “TEXT”, or ‘[[TEXT]]’ 。 以 / 开始的操作，告诉 Lsyncd 在开始的时候直接执行二进制命令而不是派成一个shell。如： onCreate = \"/usr/bin/zip /usr/var/all.zip ^sourcePath\"onModify = \"/usr/bin/zip /usr/var/all.zip ^sourcePath\" 将会把所有新建立和修改的文件使用绝对路径添加到 /usr/var/all.zip。任何不是以 / 开头的命令会使 Lsyncd 派生一个 shell 进程，并以命令的形式进行执行动作。 Variables 变量变量参数通过 ^ 来指定。要注意，变量在双引号内是隐式引用的，如果想要他们是另外一个双引号引用字符串的一部分，那么需要进入更深的一层了。如： onCreate = '[[ su user -c \"/usr/bin/zip /usr/var/all.zip ^o.sourcePath \" ]], 会展开成 su user -c &quot;/usr/bin/zip /usr/var/all.zip &quot;source&quot;&quot; 这并不正确。必须走更深一层重写上面的语句： onCreate = function(event) spawnShell('[[ su user -c \"/usr/bin/zip /usr/var/all.zip \\\"$1\\\"\" ]], event.sourcePath) end 看起来是一个 lua 函数哦。 All possible variables ^source 被观察的源目录的绝对路径 ^target 配置文件中的target属性 ^path 相对于被观察目录的文件或目录的相对路径；在目录后面有一个 `/` ^pathname 意义同上。不过尾部没有 `/` ^sourcePath 被观察目录的绝对路径与文件或目录的相对路径；这和本地文件或目录的绝对路径相等。目录在尾部会有一个 `/` ^sourcePathname 同上，目录尾部没有 `/` ^targetPath 配置文件中的 target 属性，加上相对路径。目录后面有一个 `/` ^targetPathname 同上。不过目录尾部没有 `/` 对于 onMove 事件， o., d. 可以放在 path, pathname, sourcePath, sourcePathname, targetPath, targetPathname 来指定 move 的源或者目标。没有这些变量的话，就引用 move 的源。 上面的例子中，将文件或目录移动到目标目录内： onMove = \"mv ^o.targePathname ^d.targetPathname\", 执行控制(退出代码)这个例子的启动时有几个单词。看起来有点复杂，那其只仅是一些简单的 bash 脚本， Lsyncd 没有制定任何东西。其只是简单的递归复制源到目标，不过其首先测试源目录内有没有文件。否则的话，命令会返回一个非 0 的错误代码。 onStartup = '[[ if [ \"$(ls -A ^source)\" ]; then cp -r ^source* ^target; fi ]], 默认情况下， Lsyncd 会忽略所有的返回值，但 onStartup 是个例外，因为需要根据这个返回值来判断能否继续执行。你可以通过添加一个 exitcodes 参数来改变这个行为： exitcodes = &#123; [0] = \"ok\", [1] = \"again\", [2] = \"die\"&#125; 键为退出代码指定所需操作的字符串。 again 一定时间后重新执行动作，或者 1秒 （delay设置为 immediate） die 结束 Lsyncd 所有其他的值都会让 Lsyncd 继续执行。 Layer 2: 高级动作第三，四层是在配置文件，而这一层就是在写代码了。在这一，二层必须一些编码知识。 不像 Layer 3 一样给事件指定字符串， Lua 函数也可用来做些正确的事情。 下面例子会把所有 .ps 结尾的文件转换为 PDF： autopdf = &#123; onCreate = function(event) log(\"Normal\", \"got an create event\") if string.ends(event.pathname, \".ps\") then spawn(event, \"/usr/bin/ps2pdf\", event.sourcePath) end end&#125; 这个函数可以包含任何合法的 Lua 代码。 Lsyncd 提供了在用户脚本中可用的一系列函数。 log(Category, …)记录一条消息到 file/stdout/syslog。第一个参数是分类，其他的参数字符都会被记录。日志分类必须以大写字母开始。 Normal, Error 是标准的分类。所有其他的分类都是为了调试。 spawn(Event, Binary, …)派生一个新进程，把事件（列表）作为第一个参数。第二个参数指定要调用的二进制命令。其他的参数都是给这个二进制命令的。 如果第三个参数是 &lt; ，那么从第四个开始的参数就不会当作参数传递给命令。第四个参数将被当做字符串通过 stdin 以管道的形式传递给命令。 不要使用 Lua 的 os.execute 而不使用 spawn，因为它会阻塞进程直到命令执行完毕。 Lsyncd 的 spawn 会立即返回，而子进程会继续执行。 spawnShell(Event, Command, … )与 spawn 类似，不会其会调用一个 shell 。所有的参数都以 $1, $2, $3 的形式引用。下面是一个简单的 spawnShell 实现： function spawnShell(agent, command, ....) return spawn(agent, \"/bin/sh\", \"-c\", command, \"/bin/sh\", ...)end terminate(exitcode)结束 Lsyncd 。 event Field Meaning event.config the configuration as called with sync{} event.inlet see layer 1 about inlets event.etype the event type. Can be ‘ATTRIB’, ‘CREATE’, ‘MODIFY’, ‘DELETE’, ‘MOVE’ event.status the status of the event. ‘wait’ when it is ready to be spawned and ‘active’ if there is a process running associated with this event event.isdir true if the event relates to a directory event.name the filename, directories end with a slash event.basename the filename, directories do not end with a slash event.path see ^path of Layer 3 event.pathname see ^pathname of Layer 3 event.source see ^source of Layer 3 event.sourcePath see ^sourcePath of Layer 3 event.sourcePathname see ^sourcePathname of Layer 3 event.target see ^target of Layer 3 event.targetPath see ^targetPath of Layer 3 event.targetPathname see ^targetPathname of Layer 3 onMove 动作有两个参数，就是 move 动作的源与目标。 下面的例子会记录所有的移动事件： tattleMove = &#123; onMove = function(oEvent, dEvent) log(\"Normal\", \"A moved happened from \", oEvent.pathname, \"to\", dEvent.pathname) end,&#125; 动作函数应该短而且快。其会在 Lsyncd 的主线程内运行。如果要做很多长时的事情，那么调用 spawn{} 来开启一个子进程。 一个事件只能关联一个子进程。 第3层只是Lsyncd在初始化时自动为您编写第2层函数。在第3层配置上使用-log FWrite启动Lsyncd，以查看它为您动态写入和加载的功能。因此，层3和层2也可以随意混合。 Layer 1：入口Layer 2允许我们为每个事件建立一个子进程。然而，当以 rsync 默认行为的时候你可能为几个事件调用一个进程。这就可以通过 入口 来实现。当一个事件发生的时候， Lsyncd 会调用 action 项，同时以 inlet 作为第一个参数。inlet 可以用来抓取一个事件，或者事件列表。 下面就是默认的 rsync 使用的 action 函数： action = function( inlet ) local elist = inlet.getEvents( ) local config = inlet.getConfig( ) local paths = elist.getPaths( ) log( \"Normal\", \"rsyncing list\\n\", table.concat( paths, '\\n' ) ) spawn(elist, '/usr/bin/rsync', '&lt;', table.concat( paths, '\\000' ), '--delete', config.rsync._computed, '--from0', '--include-from=-', '--exclude=*', config.source, config.target )end inlet 的函数如下： Function Description inlet.getEvent() Retrieves the next event as in Layer 2 configuration. Multiple calls to getEvent() will return the same event unless it has spawn{}ed an action. inlet.getEvents(test) Returns a list of all events that are ready. test is optional for a function that will be called for every event to test if it should be included in the list. It has one parameter the event and returns true if an event should be included. If nil every ready event will be included in the list inlet.discardEvent() Discards an event. The next call to getEvent will thus receive another event, even if no action has been spawned for this event inlet.getConfig() returns the same as event.config. The configuration of the sync{} inlet.addExclude() adds an exclusion pattern to this sync (see Exclusions) inlet.rmExclude() removes an exclusion pattern from this sync inlet.createBlanketEvent() puts an event on the top of the Delay FIFO that blocks all events and is blocked by all events. This is used for onStartup. getEvents 返回的事件列表可以给 spawn{} 作为参数。其具有以下函数： Function Description elist.getPaths(delimiter) returns a string of the paths (as in event.path separated by delimiter. By default \\n is used as delimiter. elist.getSourcePaths(delimiter) returns a string of the sourcePaths (as in event.sourcePath separated by delimiter. By default \\n is used as delimiter. 小心调用getEvents（）及其函数，因为根据事件的数量，它们会导致相当多的CPU负载 如果用户脚本没有自己提供第1层操作，则第2层功能就是遵循默认加载的第1层操作。 ------- Default action calls user scripts on**** functions.--action = function( inlet ) -- in case of moves getEvent returns the origin and destination of the move local event, event2 = inlet.getEvent( ) local config = inlet.getConfig( ) local func = config[ 'on'.. event.etype ] if func then func( event, event2 ) end -- if function didnt change the wait status its not interested -- in this event -&gt; drop it. if event.status == \"wait\" then inlet.discardEvent( event ) endend, 如果在配置中找不到“onMove”字段，Lsyncd将自动将Move事件拆分为Create和Delete事件。当处理在第1层动作函数中移动时，只需将“onMove”设置为“true”即可。 除了action之外，Lsyncd在初始化时为每个sync {}调用init。这是默认的init函数，如果用户脚本没有，则会加载该函数。它为第2层和第3层提供onStartup（）功能。 ------- called on (re)initalizing of lsyncd.--init = function( inlet ) local config = inlet.getConfig( ) -- calls a startup if provided by user script. if type( config.onStartup ) == \"function\" then local event = inlet.createBlanketEvent( ) config.onStartup( event ) if event.status == 'wait' then -- user script did not spawn anything -- thus the blanket event is deleted again. inlet.discardEvent( event ) end end end, 另一个例子是default.rsync的init。特别地，它会更改配置，因为如果不存在，它会向目标添加斜杠。 ------- Spawns the recursive startup sync-- init = function( inlet ) local config = inlet.getConfig( ) local event = inlet.createBlanketEvent( ) if string.sub(config.target, -1) ~= \"/\" then config.target = config.target .. \"/\" end log(\"Normal\", \"recursive startup rsync: \", config.source, \" -&gt; \", config.target) spawn(event, \"/usr/bin/rsync\", \"--delete\", config.rsync._computed .. \"r\", config.source, config.target )end, 当子进程完成并收集其僵尸进程时，Lsyncd会调用collect条目的功能。 当回收返回 again 时，agent（event [list]）会被设置为 “wait”， 且将会在 delay 秒内变为就绪。默认的collect函数在exitcodes []表中查找退出代码的条目。否则，下面大多数不幸的长代码除了制作好的日志消息之外什么都不做。 ------- Called when collecting a finished child process--collect = function(agent, exitcode) local config = agent.config if not agent.isList and agent.etype == \"Blanket\" then if exitcode == 0 then log(\"Normal\", \"Startup of '\",agent.source,\"' finished.\") elseif config.exitcodes and config.exitcodes[exitcode] == \"again\" then log(\"Normal\", \"Retrying startup of '\",agent.source,\"'.\") return \"again\" else log(\"Error\", \"Failure on startup of '\",agent.source,\"'.\") terminate(-1) -- ERRNO end return end local rc = config.exitcodes and config.exitcodes[exitcode] if rc == \"die\" then return rc end if agent.isList then if rc == \"again\" then log(\"Normal\", \"Retrying a list on exitcode = \",exitcode) else log(\"Normal\", \"Finished a list = \",exitcode) end else if rc == \"again\" then log(\"Normal\", \"Retrying \",agent.etype, \" on \",agent.sourcePath,\" = \",exitcode) else log(\"Normal\", \"Finished \",agent.etype, \" on \",agent.sourcePath,\" = \",exitcode) end end return rcend,","categories":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/tags/Linux/"}],"keywords":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}]},{"title":"TensorFlow的环境安装","slug":"TensorFlow的环境安装","date":"2018-09-06T06:36:51.000Z","updated":"2018-09-06T06:36:51.000Z","comments":true,"path":"TensorFlow/TensorFlow的环境安装.html","link":"","permalink":"https://gowa2017.github.io/TensorFlow/TensorFlow的环境安装.html","excerpt":"也来学习一下机器学习的 TensorFlow 是什么。第一步当然是搭建环境了。据说大多数用的都是 Python 来使用这个库。所以我也这样想了。安装官方的教程，在 Mac 上进行安装。官方教程","text":"也来学习一下机器学习的 TensorFlow 是什么。第一步当然是搭建环境了。据说大多数用的都是 Python 来使用这个库。所以我也这样想了。安装官方的教程，在 Mac 上进行安装。官方教程 有四种安装方式： Virtualenv “原生”pip Docker 从源代码安装（详情请参阅这篇单独的指南）。 官方建议采用 Virtualenv 安装方式 这就设置到要安装 Virtualenv 环境了。而这我看了一下教程，又是需要用 pip 来安装的。所以我们一步步来吧。 保证机器上有 Python 环境我的 Mac 已经有 2.7.10 的 Python 就不需要自己安装了。 安装 pip 包管理器curl https://bootstrap.pypa.io/get-pip.py -o get-pip.pypython get-pip.pyCollecting pip Downloading https://files.pythonhosted.org/packages/5f/25/e52d3f31441505a5f3af41213346e5b6c221c9e086a166f3703d2ddaf940/pip-18.0-py2.py3-none-any.whl (1.3MB) 100% |████████████████████████████████| 1.3MB 483kB/sCollecting wheel Downloading https://files.pythonhosted.org/packages/81/30/e935244ca6165187ae8be876b6316ae201b71485538ffac1d718843025a9/wheel-0.31.1-py2.py3-none-any.whl (41kB) 100% |████████████████████████████████| 51kB 729kB/sInstalling collected packages: pip, wheelSuccessfully installed pip-18.0 wheel-0.31.1 更详细的解释可以看 这里 安装 virtualenv官方的安装教程在 这里 简单的使用 pip 安装就好了。当然你也可以选择其他的方式。 sudo pip install virtualenvCollecting virtualenv Downloading https://files.pythonhosted.org/packages/b6/30/96a02b2287098b23b875bc8c2f58071c35d2efe84f747b64d523721dc2b5/virtualenv-16.0.0-py2.py3-none-any.whl (1.9MB) 100% |████████████████████████████████| 1.9MB 286kB/sInstalling collected packages: virtualenvSuccessfully installed virtualenv-16.0.0 安装 TensorFlow这个就可以完全按照官方教程来了：Virtualenv安装TensorFlow-Mac 建立 Virtualenv 环境virtualenv --system-site-packages tensorflow 激活 Virtualenv 环境：$ cd tensorflow$ source ./bin/activate # If using bash, sh, ksh, or zsh$ source ./bin/activate.csh # If using csh or tcsh 确保安装 pip 8.1 或更高版本(targetDirectory)$ easy_install -U pip 将 TensorFlow 及其所需的所有软件包安装到活动 Virtualenv 环境(targetDirectory)$ pip install --upgrade tensorflow # for Python 2.7(targetDirectory)$ pip3 install --upgrade tensorflow # for Python 3.n 可选。如果第 6 步失败了（通常是因为您所调用的 pip 版本低于 8.1），请通过发出以下格式的命令在活动 Virtualenv 环境中安装 TensorFlow$ pip install --upgrade tfBinaryURL # Python 2.7$ pip3 install --upgrade tfBinaryURL # Python 3.n 注意请注意，每次在新的 shell 中使用 TensorFlow 时，您都必须激活 Virtualenv 环境。如果 Virtualenv 环境当前未处于活动状态（即提示符不是 (targetDirectory)），请调用以下某个命令： $ cd targetDirectory$ source ./bin/activate # If using bash, sh, ksh, or zsh$ source ./bin/activate.csh # If using csh or tcsh 您的提示符将变成如下所示，这表示您的 tensorflow 环境已处于活动状态： (targetDirectory)$ 当 Virtualenv 环境处于活动状态时，您就可以从该 shell 运行 TensorFlow 程序了。 用完 TensorFlow 后，可以通过发出以下命令来停用此环境： (targetDirectory)$ deactivate 提示符将恢复为您的默认提示符（由 PS1 所定义）。 验证安装 OK 从 shell 中调用 Python，如下所示： $python 在 Python 交互式 shell 中输入以下几行简短的程序代码： # Pythonimport tensorflow as tfhello = tf.constant('Hello, TensorFlow!')sess = tf.Session()print(sess.run(hello)) 如果系统输出以下内容，则说明您可以开始编写 TensorFlow 程序了： Hello, TensorFlow!","categories":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://gowa2017.github.io/categories/TensorFlow/"}],"tags":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://gowa2017.github.io/tags/TensorFlow/"},{"name":"Python","slug":"Python","permalink":"https://gowa2017.github.io/tags/Python/"}],"keywords":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://gowa2017.github.io/categories/TensorFlow/"}]},{"title":"Cocos Creator生成项目的启动工作流程","slug":"Cocos Creator生成项目的启动工作流程","date":"2018-09-02T02:46:11.000Z","updated":"2018-09-02T02:46:11.000Z","comments":true,"path":"Cocos-Creator/Cocos Creator生成项目的启动工作流程.html","link":"","permalink":"https://gowa2017.github.io/Cocos-Creator/Cocos Creator生成项目的启动工作流程.html","excerpt":"最近才有机会来看一下这个东西，虽然非常的喜欢Lua，但是现有的项目还是懒得去转换成Lua了，毕竟 Cocos Creator 还是很好用的至少简单，所以来理一理其工作流程。","text":"最近才有机会来看一下这个东西，虽然非常的喜欢Lua，但是现有的项目还是懒得去转换成Lua了，毕竟 Cocos Creator 还是很好用的至少简单，所以来理一理其工作流程。 js 绑定Cocos Creator 使用的是 Cocos2d-X 引擎的 js 绑定，开发语言也是 js 了。这里顺带提一下，关于用 Lua 还是 js 绑定的问题。主要的方式如下：引擎开启一个 脚本运行（ Lua 是 Lua State，JavaScript 用的是 V8 等等），然后把 C++ 写的代码，注入到这个引擎内。这样，引擎内就可以以调用注入函数的形式，调用底层代码。 而对于我们的用户而言，所看到的据，我们所编写的 Js/Lua 脚本，居然能够产生就跟原生代码一样的效果。 安卓的启动我们用 Cocos Creator 打包好的安卓项目内，与通常的安卓项目没有什么太大的差异，不过是利用了一些 Jni 技术来加载底层代码。但我们现在只关注启动的流程。 启动的 Activity 是一个叫做 AppActivity 的东西，在其 onCreate() 函数内进行了 SDK 的初始化： @Overrideprotected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); // Workaround in https://stackoverflow.com/questions/16283079/re-launch-of-activity-on-home-button-but-only-the-first-time/16447508 if (!isTaskRoot()) &#123; // Android launched another instance of the root activity into an existing task // so just quietly finish and go away, dropping the user back into the activity // at the top of the stack (ie: the last state of this task) // Don't need to finish it again since it's finished in super.onCreate . return; &#125; // DO OTHER INITIALIZATION BELOW SDKWrapper.getInstance().init(this);&#125; SDKWrapper 也是由项目自动生成的类，我们可以看一下其内调用到的函数： public void init(Context context) &#123; if (PACKAGE_AS) &#123; try &#123; mClass.getMethod(\"init\", Context.class).invoke(mClass, context); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; SDKWrapper.nativeLoadAllPlugins(); &#125; &#125;private static native void nativeLoadAllPlugins(); 对于 Jni 技术不是很了解，但是我只想看一下其主要过程就行了。最终都会执行到引擎的 C++ 类： AppDelegate.cpp。 在其中的一个方法内就能看到，加载初始化的代码： bool AppDelegate::applicationDidFinishLaunching()&#123;#if CC_TARGET_PLATFORM == CC_PLATFORM_IOS &amp;&amp; PACKAGE_AS SDKManager::getInstance()-&gt;loadAllPlugins();#endif // initialize director auto director = Director::getInstance(); auto glview = director-&gt;getOpenGLView(); if(!glview) &#123;#if(CC_TARGET_PLATFORM == CC_PLATFORM_WP8) || (CC_TARGET_PLATFORM == CC_PLATFORM_WINRT) glview = GLViewImpl::create(\"SCMJ\");#else glview = GLViewImpl::createWithRect(\"SCMJ\", cocos2d::Rect(0,0,900,640));#endif director-&gt;setOpenGLView(glview); &#125; // set FPS. the default value is 1.0/60 if you don't call this director-&gt;setAnimationInterval(1.0 / 60); ScriptingCore* sc = ScriptingCore::getInstance(); ScriptEngineManager::getInstance()-&gt;setScriptEngine(sc); se::ScriptEngine* se = se::ScriptEngine::getInstance(); jsb_set_xxtea_key(\"0d948dcc-c014-46\"); jsb_init_file_operation_delegate();#if defined(COCOS2D_DEBUG) &amp;&amp; (COCOS2D_DEBUG &gt; 0) // Enable debugger here jsb_enable_debugger(\"0.0.0.0\", 5086);#endif se-&gt;setExceptionCallback([](const char* location, const char* message, const char* stack)&#123; // Send exception information to server like Tencent Bugly. &#125;); jsb_register_all_modules();#if (CC_TARGET_PLATFORM == CC_PLATFORM_ANDROID || CC_TARGET_PLATFORM == CC_PLATFORM_IOS) &amp;&amp; PACKAGE_AS se-&gt;addRegisterCallback(register_all_anysdk_framework); se-&gt;addRegisterCallback(register_all_anysdk_manual);#endif se-&gt;start(); jsb_run_script(\"main.js\"); return true;&#125; 简单的解释据： 初始化 openGL 视图。 初始化脚本核心引擎。 注入所有模块。 启动脚本引擎 执行脚本 main.js。 这样就将控制权转交给了脚本引擎中的 main.js。 main.js每个项目都会生成一个 main.js 文件。我是也 link 方式生成的项目，所以位于 build/jsb-link/main.js 。这个脚本，才会进行加载我们用 Cocos Creator 建立的项目内容。 if (window.jsb) &#123; require('src/settings.js'); require('src/jsb_polyfill.js'); boot(); return; &#125; 上面这段代码，会在加载了我们的设置内容，统一接口文件后，开始进行启动操作。 这 boot() 函数，我们可以看到，进入初始场景（ settings 设置），加载项目相关的 js 然后启动游戏的代码： // load scene cc.director.loadScene(launchScene, null, function () &#123; if (cc.sys.isBrowser) &#123; // show canvas canvas.style.visibility = ''; var div = document.getElementById('GameDiv'); if (div) &#123; div.style.backgroundImage = ''; &#125; &#125; cc.loader.onProgress = null; console.log('Success to load scene: ' + launchScene); &#125; ); &#125;; // jsList var jsList = settings.jsList; if (!false) &#123; var bundledScript = settings.debug ? 'src/project.dev.js' : 'src/project.js'; if (jsList) &#123; jsList = jsList.map(function (x) &#123; return 'src/' + x; &#125;); jsList.push(bundledScript); &#125; else &#123; jsList = [bundledScript]; &#125; &#125; // anysdk scripts if (cc.sys.isNative &amp;&amp; cc.sys.isMobile) &#123;// jsList = jsList.concat(['src/anysdk/jsb_anysdk.js', 'src/anysdk/jsb_anysdk_constants.js']); &#125; var option = &#123; //width: width, //height: height, id: 'GameCanvas', scenes: settings.scenes, debugMode: settings.debug ? cc.DebugMode.INFO : cc.DebugMode.ERROR, showFPS: (!false &amp;&amp; !false) &amp;&amp; settings.debug, frameRate: 60, jsList: jsList, groupList: settings.groupList, collisionMatrix: settings.collisionMatrix, renderMode: 0 &#125; cc.game.run(option, onStart); 当加载完我们项目相关的 js 后，就会把这些参数，传递给给 引擎的 game 对象 run 方法。启动游戏了 jsb_register_all_modules 将相关的底层接口注册到js引擎bool jsb_register_all_modules()&#123; se::ScriptEngine* se = se::ScriptEngine::getInstance(); se-&gt;addBeforeInitHook([]()&#123; JSBClassType::init(); &#125;); se-&gt;addBeforeCleanupHook([se]()&#123; se-&gt;garbageCollect(); PoolManager::getInstance()-&gt;getCurrentPool()-&gt;clear(); se-&gt;garbageCollect(); PoolManager::getInstance()-&gt;getCurrentPool()-&gt;clear(); &#125;); se-&gt;addRegisterCallback(jsb_register_global_variables); se-&gt;addRegisterCallback(run_prepare_script); se-&gt;addRegisterCallback(register_all_cocos2dx); se-&gt;addRegisterCallback(jsb_register_Node_manual); se-&gt;addRegisterCallback(register_all_cocos2dx_manual); se-&gt;addRegisterCallback(JSB_register_opengl);...&#125; 在这个函数中，首先获取一个 ScriptEngine(se) 的实例，然后就会进行一系列的加载操作。暂时我们不用关心一些与我们可能会使用到的东西无关的内容。我们关注一下，对于导出的 js 接口是怎么样导入的。 se-&gt;addRegisterCallback(run_prepare_script);在引擎启动前，会预先的准备一个 jsb 环境，这个环境的建立，是使用 js 脚本编写的，存在于 jsb_prepare.js 中。 在脚本 jsb_prepare.js 中，定义了命名空间 cc, jsb 定义了 cc 中的一些方法，如 cc.clone()；定义了 cc.Class ，一个用来构造类的基类及其相关方法。以及更多内容。更详细的内容可以查看源码。 se-&gt;addRegisterCallback(register_all_cocos2dx);注册很多很多函数了。 bool register_all_cocos2dx(se::Object* obj)&#123; // Get the ns se::Value nsVal; if (!obj-&gt;getProperty(\"cc\", &amp;nsVal)) &#123; se::HandleObject jsobj(se::Object::createPlainObject()); nsVal.setObject(jsobj); obj-&gt;setProperty(\"cc\", nsVal); &#125; se::Object* ns = nsVal.toObject(); js_register_cocos2dx_Acceleration(ns); js_register_cocos2dx_Action(ns); js_register_cocos2dx_FiniteTimeAction(ns); js_register_cocos2dx_ActionInstant(ns); js_register_cocos2dx_Hide(ns); js_register_cocos2dx_TMXObjectGroupInfo(ns); js_register_cocos2dx_Node(ns); js_register_cocos2dx_ParticleSystem(ns); js_register_cocos2dx_ParticleSystemQuad(ns); js_register_cocos2dx_ParticleSpiral(ns); js_register_cocos2dx_ActionInterval(ns); js_register_cocos2dx_MoveBy(ns); js_register_cocos2dx_MoveTo(ns); .... &#125; 可以看到，这首先会把从 se 对象获取 cc 属性，如果获取的 cc 属性为空，就会新建一个。 同时，很直白的把这个属性的值，称呼为 ns ，也就是命名空间的意思。 接着，就会一个个的注入各个模块了。我们来看一下 Director 模块。 bool js_register_cocos2dx_Director(se::Object* obj)&#123; auto cls = se::Class::create(\"Director\", obj, nullptr, nullptr); cls-&gt;defineFunction(\"pause\", _SE(js_cocos2dx_Director_pause)); cls-&gt;defineFunction(\"isPurgeDirectorInNextLoop\", _SE(js_cocos2dx_Director_isPurgeDirectorInNextLoop)); cls-&gt;defineFunction(\"setEventDispatcher\", _SE(js_cocos2dx_Director_setEventDispatcher)); cls-&gt;defineFunction(\"setContentScaleFactor\", _SE(js_cocos2dx_Director_setContentScaleFactor)); cls-&gt;defineFunction(\"getDeltaTime\", _SE(js_cocos2dx_Director_getDeltaTime)); cls-&gt;defineFunction(\"getContentScaleFactor\", _SE(js_cocos2dx_Director_getContentScaleFactor)); cls-&gt;defineFunction(\"getWinSizeInPixels\", _SE(js_cocos2dx_Director_getWinSizeInPixels));...&#125; 首先会 cc 的对象建立一个类，然后对类定义各个函数映射。就是这么简单的过程。 se-&gt;addRegisterCallback(run_boot_script);注入完成后，就会运行我们的启动脚本 jsb_boot.js。 这个函数会定义 cc.sys 空间，加载 jsb.js 脚本。已经定义一些单例的类。详细的内容还是需要自己看脚本哈。 _initSys();//+++++++++++++++++++++++++something about CCGame end+++++++++++++++++++++++++++++jsb.urlRegExp = new RegExp(\"^(?:https?|ftp)://\\\\S*$\", \"i\");cc._engineLoaded = false;(function (config) &#123; require(\"script/jsb.js\"); cc._engineLoaded = true; console.log(cc.ENGINE_VERSION);&#125;)(); jsb.js这个脚本才是把我们各种常用的函数给加载起来的。 // JavaScript Bindings helper file//// DO NOT ALTER THE ORDERrequire('script/jsb_cocos2d.js');require('script/jsb_common.js');require('script/jsb_property_impls.js');require('script/jsb_property_apis.js');require('script/jsb_create_apis.js');require('script/extension/jsb_cocos2d_extension.js');if (window.ccui) &#123; require('script/ccui/jsb_cocos2d_ui.js'); require('script/ccui/jsb_ccui_property_impls.js'); require('script/ccui/jsb_ccui_property_apis.js'); require('script/ccui/jsb_ccui_create_apis.js');&#125;require('script/jsb_opengl_constants.js');require('script/jsb_opengl.js');if (window.sp) &#123; require('script/jsb_spine.js');&#125;if (window.dragonBones) &#123; require('script/jsb_dragonbones.js');&#125;require(\"script/jsb_audioengine.js\");require(\"script/jsb_cocosanalytics.js\"); 在此之后，才正式进入我们的项目的 main.js 启动环节。 Cocos Creator 专有内容我一直很纳闷，在 main.js 内用 cc.game.run() 启动游戏，到底是在哪里实现的这个方法，一直没有找到。后面谷歌良久，才发现，这是在 Cocos Creator 实现的。 在 Cocos Creator Code 目录下，有几个提供给 Cocos Creator 使用的 js 模块。 我们以 cc.game 为例来看一下。 最后一句 cc.game = module.exports = game; 表明了，将这个模块导出到了 cc.game 。 cc.game.run()对于我们启动游戏的逻辑 cc.game.run()，其代码定义如下： run: function (config, onStart) &#123; this._initConfig(config); this.onStart = onStart; this.prepare(game.onStart &amp;&amp; game.onStart.bind(game));&#125; 其中 onStart() 是我们自己定义的（也是系统生成的，但我们可以进行修改）。我们把配置信息传递过来后 game 就会保留这些信息。然后运行 prepare() 方法。 prepare(cb)prepare (cb) &#123; // Already prepared if (this._prepared) &#123; if (cb) cb(); return; &#125; // Load game scripts let jsList = this.config.jsList; if (jsList &amp;&amp; jsList.length &gt; 0) &#123; var self = this; cc.loader.load(jsList, function (err) &#123; if (err) throw new Error(JSON.stringify(err)); self._prepareFinished(cb); &#125;); &#125; else &#123; this._prepareFinished(cb); &#125; &#125; 这个很简单了，其实就是把我们配置好的 jsList 全部通过 loader 加载进来。然后就完成了。 之后，执行 准备结束函数 _prepareFinished(cb)_prepareFinished (cb) &#123; this._prepared = true; // Init engine this._initEngine(); // Log engine version console.log('Cocos Creator v' + cc.ENGINE_VERSION); this._setAnimFrame(); this._runMainLoop(); this.emit(this.EVENT_GAME_INITED); if (cb) cb();&#125; _initEngine()_initEngine() 只是开启渲染这么一个作用： _initEngine () &#123; if (this._rendererInitialized) &#123; return; &#125; this._initRenderer(); if (!CC_EDITOR) &#123; this._initEvents(); &#125; this.emit(this.EVENT_ENGINE_INITED);&#125; _initRenderer这个方法干的事情可就多了。具体我也不是很会解释了。对图形不是很懂。 _initRenderer () &#123; // Avoid setup to be called twice. if (this._rendererInitialized) return; let el = this.config.id, width, height, localCanvas, localContainer, isWeChatGame = cc.sys.platform === cc.sys.WECHAT_GAME, isQQPlay = cc.sys.platform === cc.sys.QQ_PLAY; if (isWeChatGame || CC_JSB) &#123; this.container = localContainer = document.createElement(\"DIV\"); this.frame = localContainer.parentNode === document.body ? document.documentElement : localContainer.parentNode; if (cc.sys.browserType === cc.sys.BROWSER_TYPE_WECHAT_GAME_SUB) &#123; localCanvas = wx.getSharedCanvas(); &#125; else if (CC_JSB) &#123; localCanvas = window.__cccanvas; &#125; else &#123; localCanvas = canvas; &#125; this.canvas = localCanvas; &#125; else if (isQQPlay) &#123; this.container = cc.container = document.createElement(\"DIV\"); this.frame = document.documentElement; this.canvas = localCanvas = canvas; &#125; else &#123; var element = (el instanceof HTMLElement) ? el : (document.querySelector(el) || document.querySelector('#' + el)); if (element.tagName === \"CANVAS\") &#123; width = element.width; height = element.height; //it is already a canvas, we wrap it around with a div this.canvas = localCanvas = element; this.container = localContainer = document.createElement(\"DIV\"); if (localCanvas.parentNode) localCanvas.parentNode.insertBefore(localContainer, localCanvas); &#125; else &#123; //we must make a new canvas and place into this element if (element.tagName !== \"DIV\") &#123; cc.warnID(3819); &#125; width = element.clientWidth; height = element.clientHeight; this.canvas = localCanvas = document.createElement(\"CANVAS\"); this.container = localContainer = document.createElement(\"DIV\"); element.appendChild(localContainer); &#125; localContainer.setAttribute('id', 'Cocos2dGameContainer'); localContainer.appendChild(localCanvas); this.frame = (localContainer.parentNode === document.body) ? document.documentElement : localContainer.parentNode; function addClass (element, name) &#123; var hasClass = (' ' + element.className + ' ').indexOf(' ' + name + ' ') &gt; -1; if (!hasClass) &#123; if (element.className) &#123; element.className += \" \"; &#125; element.className += name; &#125; &#125; addClass(localCanvas, \"gameCanvas\"); localCanvas.setAttribute(\"width\", width || 480); localCanvas.setAttribute(\"height\", height || 320); localCanvas.setAttribute(\"tabindex\", 99); &#125; this._determineRenderType(); // WebGL context created successfully if (this.renderType === this.RENDER_TYPE_WEBGL) &#123; var opts = &#123; 'stencil': true, // MSAA is causing serious performance dropdown on some browsers. 'antialias': cc.macro.ENABLE_WEBGL_ANTIALIAS, 'alpha': cc.macro.ENABLE_TRANSPARENT_CANVAS &#125;; if (isWeChatGame) &#123; opts['preserveDrawingBuffer'] = true; &#125; renderer.initWebGL(localCanvas, opts); this._renderContext = renderer.device._gl; // Enable dynamic atlas manager by default if (!cc.macro.CLEANUP_IMAGE_CACHE) &#123; cc.dynamicAtlasManager.enabled = true; &#125; &#125; if (!this._renderContext) &#123; this.renderType = this.RENDER_TYPE_CANVAS; // Could be ignored by module settings renderer.initCanvas(localCanvas); this._renderContext = renderer.device._ctx; &#125; cc.renderer = renderer; this.canvas.oncontextmenu = function () &#123; if (!cc._isContextMenuEnable) return false; &#125;; this._rendererInitialized = true; &#125; _setAnimFrame这玩意看起来是设置一下帧频率的？ _setAnimFrame: function () &#123; this._lastTime = new Date(); var frameRate = game.config.frameRate; this._frameTime = 1000 / frameRate; if (CC_JSB) &#123; jsb.setPreferredFramesPerSecond(frameRate); window.requestAnimFrame = window.requestAnimationFrame; window.cancelAnimFrame = window.cancelAnimationFrame; &#125; else &#123; if (frameRate !== 60 &amp;&amp; frameRate !== 30) &#123; window.requestAnimFrame = this._stTime; window.cancelAnimFrame = this._ctTime; &#125; else &#123; window.requestAnimFrame = window.requestAnimationFrame || window.webkitRequestAnimationFrame || window.mozRequestAnimationFrame || window.oRequestAnimationFrame || window.msRequestAnimationFrame || this._stTime; window.cancelAnimFrame = window.cancelAnimationFrame || window.cancelRequestAnimationFrame || window.msCancelRequestAnimationFrame || window.mozCancelRequestAnimationFrame || window.oCancelRequestAnimationFrame || window.webkitCancelRequestAnimationFrame || window.msCancelAnimationFrame || window.mozCancelAnimationFrame || window.webkitCancelAnimationFrame || window.oCancelAnimationFrame || this._ctTime; &#125; &#125; &#125;, _stTime: function(callback)&#123; var currTime = new Date().getTime(); var timeToCall = Math.max(0, game._frameTime - (currTime - game._lastTime)); var id = window.setTimeout(function() &#123; callback(); &#125;, timeToCall); game._lastTime = currTime + timeToCall; return id; &#125;, _ctTime: function(id)&#123; window.clearTimeout(id); &#125;, _runMainLoop_runMainLoop: function () &#123; var self = this, callback, config = self.config, director = cc.director, skip = true, frameRate = config.frameRate; debug.setDisplayStats(config.showFPS); callback = function () &#123; if (!self._paused) &#123; self._intervalId = window.requestAnimFrame(callback); if (frameRate === 30) &#123; if (skip = !skip) &#123; return; &#125; &#125; director.mainLoop(); &#125; &#125;; self._intervalId = window.requestAnimFrame(callback); self._paused = false;&#125; 等这些执行完毕后，才会执行什么开启的函数。 main.js我们生成项目的 main.js 会先加载配置文件，加载 jsb_polyfill.js 文件： if (window.jsb) &#123; require('src/settings.js'); require('src/jsb_polyfill.js'); boot(); return;&#125; 然后启动 boot 函数： function boot () &#123; // 这个settings 在 settings.js 里面获取 var settings = window._CCSettings; window._CCSettings = undefined; // 在非debug的时候执行 if ( !settings.debug ) &#123; var uuids = settings.uuids; var rawAssets = settings.rawAssets; var assetTypes = settings.assetTypes; var realRawAssets = settings.rawAssets = &#123;&#125;; for (var mount in rawAssets) &#123; var entries = rawAssets[mount]; var realEntries = realRawAssets[mount] = &#123;&#125;; for (var id in entries) &#123; var entry = entries[id]; var type = entry[1]; // retrieve minified raw asset if (typeof type === 'number') &#123; entry[1] = assetTypes[type]; &#125; // retrieve uuid realEntries[uuids[id] || id] = entry; &#125; &#125; var scenes = settings.scenes; for (var i = 0; i &lt; scenes.length; ++i) &#123; var scene = scenes[i]; if (typeof scene.uuid === 'number') &#123; scene.uuid = uuids[scene.uuid]; &#125; &#125; var packedAssets = settings.packedAssets; for (var packId in packedAssets) &#123; var packedIds = packedAssets[packId]; for (var j = 0; j &lt; packedIds.length; ++j) &#123; if (typeof packedIds[j] === 'number') &#123; packedIds[j] = uuids[packedIds[j]]; &#125; &#125; &#125; &#125; // init engine var canvas; // 在浏览器下，是利用了一个特定的画布 if (cc.sys.isBrowser) &#123; canvas = document.getElementById('GameCanvas'); &#125; if (false) &#123; var ORIENTATIONS = &#123; 'portrait': 1, 'landscape left': 2, 'landscape right': 3 &#125;; BK.Director.screenMode = ORIENTATIONS[settings.orientation]; initAdapter(); &#125; function setLoadingDisplay () &#123; // Loading splash scene var splash = document.getElementById('splash'); var progressBar = splash.querySelector('.progress-bar span'); cc.loader.onProgress = function (completedCount, totalCount, item) &#123; var percent = 100 * completedCount / totalCount; if (progressBar) &#123; progressBar.style.width = percent.toFixed(2) + '%'; &#125; &#125;; splash.style.display = 'block'; progressBar.style.width = '0%'; cc.director.once(cc.Director.EVENT_AFTER_SCENE_LAUNCH, function () &#123; splash.style.display = 'none'; &#125;); &#125; var onStart = function () &#123; if (false) &#123; BK.Script.loadlib(); &#125; cc.view.resizeWithBrowserSize(true); if (!false &amp;&amp; !false) &#123; // UC browser on many android devices have performance issue with retina display if (cc.sys.os !== cc.sys.OS_ANDROID || cc.sys.browserType !== cc.sys.BROWSER_TYPE_UC) &#123; cc.view.enableRetina(true); &#125; if (cc.sys.isBrowser) &#123; setLoadingDisplay(); &#125; if (cc.sys.isMobile) &#123; if (settings.orientation === 'landscape') &#123; cc.view.setOrientation(cc.macro.ORIENTATION_LANDSCAPE); &#125; else if (settings.orientation === 'portrait') &#123; cc.view.setOrientation(cc.macro.ORIENTATION_PORTRAIT); &#125; cc.view.enableAutoFullScreen([ cc.sys.BROWSER_TYPE_BAIDU, cc.sys.BROWSER_TYPE_WECHAT, cc.sys.BROWSER_TYPE_MOBILE_QQ, cc.sys.BROWSER_TYPE_MIUI, ].indexOf(cc.sys.browserType) &lt; 0); &#125; // Limit downloading max concurrent task to 2, // more tasks simultaneously may cause performance draw back on some android system / brwosers. // You can adjust the number based on your own test result, you have to set it before any loading process to take effect. if (cc.sys.isBrowser &amp;&amp; cc.sys.os === cc.sys.OS_ANDROID) &#123; cc.macro.DOWNLOAD_MAX_CONCURRENT = 2; &#125; &#125; // init assets cc.AssetLibrary.init(&#123; libraryPath: 'res/import', rawAssetsBase: 'res/raw-', rawAssets: settings.rawAssets, packedAssets: settings.packedAssets, md5AssetsMap: settings.md5AssetsMap &#125;); if (false) &#123; cc.Pipeline.Downloader.PackDownloader._doPreload(\"WECHAT_SUBDOMAIN\", settings.WECHAT_SUBDOMAIN_DATA); &#125; var launchScene = settings.launchScene; // load scene cc.director.loadScene(launchScene, null, function () &#123; if (cc.sys.isBrowser) &#123; // show canvas canvas.style.visibility = ''; var div = document.getElementById('GameDiv'); if (div) &#123; div.style.backgroundImage = ''; &#125; &#125; cc.loader.onProgress = null; console.log('Success to load scene: ' + launchScene); &#125; ); &#125;; // jsList var jsList = settings.jsList; // 这个就用来加载工程内的 js 了 if (!false) &#123; var bundledScript = settings.debug ? 'src/project.dev.js' : 'src/project.js'; if (jsList) &#123; jsList = jsList.map(function (x) &#123; return 'src/' + x; &#125;); jsList.push(bundledScript); &#125; else &#123; jsList = [bundledScript]; &#125; &#125; // anysdk scripts if (cc.sys.isNative &amp;&amp; cc.sys.isMobile) &#123;// jsList = jsList.concat(['src/anysdk/jsb_anysdk.js', 'src/anysdk/jsb_anysdk_constants.js']); &#125; // 游戏运行选项 var option = &#123; //width: width, //height: height, id: 'GameCanvas', scenes: settings.scenes, debugMode: settings.debug ? cc.DebugMode.INFO : cc.DebugMode.ERROR, showFPS: (!false &amp;&amp; !false) &amp;&amp; settings.debug, frameRate: 60, jsList: jsList, groupList: settings.groupList, collisionMatrix: settings.collisionMatrix, renderMode: 0 &#125; cc.game.run(option, onStart); &#125;","categories":[{"name":"Cocos Creator","slug":"Cocos-Creator","permalink":"https://gowa2017.github.io/categories/Cocos-Creator/"}],"tags":[{"name":"Cocos Creator","slug":"Cocos-Creator","permalink":"https://gowa2017.github.io/tags/Cocos-Creator/"}],"keywords":[{"name":"Cocos Creator","slug":"Cocos-Creator","permalink":"https://gowa2017.github.io/categories/Cocos-Creator/"}]},{"title":"Cocos-Creator浏览器正常，打包apk错误的问题","slug":"Cocos-Creator浏览器正常，打包apk错误的问题","date":"2018-09-01T04:02:48.000Z","updated":"2018-09-01T04:02:48.000Z","comments":true,"path":"Cocos-Creator/Cocos-Creator浏览器正常，打包apk错误的问题.html","link":"","permalink":"https://gowa2017.github.io/Cocos-Creator/Cocos-Creator浏览器正常，打包apk错误的问题.html","excerpt":"","text":"拷了份代码，浏览器，模拟器都正常预览，使用。而一打包到安卓下就不行了。具体的表现形式是，一直黑屏，用adb 查看 logcat 的话，是js_polyfill 报出了一个错误，调用 startPhase失败。搜索良久找不到方案。 资源缺失偶尔发现一个问题就是，当我进入一个Prefab的时候，会提示这个Prefab内使用的资源丢失了。而我看我场景内，有这个Prefab实例的又显示正常，于是进行了一下同步，再进行打包。 居然就OK了。。 实在是坑爹了。","categories":[{"name":"Cocos Creator","slug":"Cocos-Creator","permalink":"https://gowa2017.github.io/categories/Cocos-Creator/"}],"tags":[{"name":"Cocos Creator","slug":"Cocos-Creator","permalink":"https://gowa2017.github.io/tags/Cocos-Creator/"},{"name":"Cocos-Js","slug":"Cocos-Js","permalink":"https://gowa2017.github.io/tags/Cocos-Js/"},{"name":"Cocos-Creator","slug":"Cocos-Creator","permalink":"https://gowa2017.github.io/tags/Cocos-Creator/"}],"keywords":[{"name":"Cocos Creator","slug":"Cocos-Creator","permalink":"https://gowa2017.github.io/categories/Cocos-Creator/"}]},{"title":"关于fab会报错及popmenu背景是黑色的问题","slug":"关于fab会报错及popmenu背景是黑色的问题","date":"2018-08-31T10:51:45.000Z","updated":"2018-08-31T10:51:45.000Z","comments":true,"path":"Android/关于fab会报错及popmenu背景是黑色的问题.html","link":"","permalink":"https://gowa2017.github.io/Android/关于fab会报错及popmenu背景是黑色的问题.html","excerpt":"遇到一个问题，就是我以前用的是Activity继承的是 FragmentActivit，然后可以使用 getActivity()函数。而我换成AppCompactActivity后，就不能使用这个了，我就打算用this,或者getBaseContext来做上下文，结果就是popMenu居然背景变成黑色了，换了多个主题还是一样。后面发现了问题。","text":"遇到一个问题，就是我以前用的是Activity继承的是 FragmentActivit，然后可以使用 getActivity()函数。而我换成AppCompactActivity后，就不能使用这个了，我就打算用this,或者getBaseContext来做上下文，结果就是popMenu居然背景变成黑色了，换了多个主题还是一样。后面发现了问题。 Context大多数时候，我们的View都需要一个上下文。当我们在建立一个View或者扩张一个布局文件的时候，都需要一个上下文。我们需要的屏幕信息，风格信息，都可以从Context内获取。 上面的问题，应该是我获取的上下文不对，所以会产生，与整体风格不一致的问题。 由于我是在 按钮的回调函数内，建立的菜单。很明显，在内部类里，我们时不能直接使用 this的，这个时候，正确的使用方式应该是MainActivity.this这样，换成这样的方式后，果然就正常了。 ApplicationContext这个上下文在应用存在期间，一直可用，所以对于生命周期长，或无法获取上下文的时候，可以使用这个来作为上下文。 在CodePath上有一篇文章进行了描述上下文：https://guides.codepath.com/android/Using-Context Context 用来做什么下面是一些例子。 显式启动一个组件// Provide context if MyActivity is an internal activity.Intent intent = new Intent(context, MyActivity.class);startActivity(intent); 当显式启动一个组件时候，我们需要两部分信息： 包名，标识了包含这个组件的应用。 要启动组件的 完整引用Java类名 如果是启动一个内部组件，context 参数可以传递为当前应用的包名，可通过 context.getPackageName()获取。 建立视图（View）TextView textView = new TextView(context); Context 包含了视图需要的如下信息： 设备尺寸，已经在 dp,sp 转换为 px的规格 风格属性 OnClick 属性引用的 Activity 扩张一个 XML 布局文件当我们要把一个XML布局文件扩展到内存的时候，我们使用 Context 来获取 LayoutInflater。 // A context is required when creating views.// 建立视图的时候，会需要一个上下文LayoutInflater inflater = LayoutInflater.from(context);inflater.inflate(R.layout.my_layout, parent); 发送本地广播当我们发送广播或者注册广播接收者的时候，用Context 来获取 LocalBroadcastManager。 // The context contains a reference to the main Looper, // which manages the queue for the application's main thread.// context 包含了对 主 Looper 的引用// Looper 管理应用主线程的队列。Intent broadcastIntent = new Intent(\"custom-action\");LocalBroadcastManager.getInstance(context).sendBroadcast(broadcastIntent); 获取系统服务要想从一个应用发送通知，需要使用到 NotificationManager 系统服务。 // Context objects are able to fetch or start system services.NotificationManager notificationManager = (NotificationManager) getSystemService(NOTIFICATION_SERVICE);int notificationId = 1;// Context is required to construct RemoteViewsNotification.Builder builder = new Notification.Builder(context).setContentTitle(\"custom title\");notificationManager.notify(notificationId, builder.build()); 应用上下文 VS Activity上下文主题和风格多数时候都是使用在应用级别，但他们也可以在Activity级别进行使用。在这种方式下，某个Activity就可以和其他的Activity有不同的风格（比如，需要隐藏ActivonBar等等）。AndroidManifest.xml中在 Application中有一个属性 android:theme，同样，这个属性可以用在 Activity上： &lt;application android:allowBackup=\"true\" android:icon=\"@mipmap/ic_launcher\" android:label=\"@string/app_name\" android:theme=\"@style/AppTheme\" &gt; &lt;activity android:name=\".MainActivity\" android:label=\"@string/app_name\" android:theme=\"@style/MyCustomTheme\"&gt; 因为这个原因，所以我们要明白，我们会拥有一个 Application Context 和 Activity Context，上下文存在于他们对应的生命周期中。大多数 Views应该传递一个 Activity Context 来获得需要的 主题，风格，规格等信息。如果 Activity 并没有使用主题，那么默认使用 Application使用的。 大多数情况下，应该使用 Activity Context。正常情况下，Java 中的 this 引用了一个类的实例，因此可是在一个Activity中来用在 需要 Context 的地方。 public class MainActivity extends AppCompatActivity &#123; @Override protected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); Toast.makeText(this, \"hello\", Toast.LENGTH_SHORT).show(); &#125;&#125; 匿名函数当使用匿名函数来实现 监听器时， Java中的 this 使用在最近被声明的类上。在这种情况下，外层的类 MainActivity 必须指开来表明其引用的是 MainActivity 实例。 public class MainActivity extends AppCompatActivity &#123; @Override protected void onCreate(Bundle savedInstanceState) &#123; TextView tvTest = (TextView) findViewById(R.id.abc); tvTest.setOnClickListener(new View.OnClickListener() &#123; @Override public void onClick(View view) &#123; Toast.makeText(MainActivity.this, \"hello\", Toast.LENGTH_SHORT).show(); &#125; &#125;); &#125; &#125;``` ## 适配器### 数组适配器当为一各ListView构造适配器的时候， 典型的会在 布局扩张过程中调用 `getContext()`。这个方法，经常使用初始化 ArrayAdapter 的Context。```java if (convertView == null) &#123; convertView = LayoutInflater .from(getContext()) .inflate(R.layout.item_user, parent, false); &#125; 如果你使用 Application Context来初始化 ArrayAdapter，你会发现，主题/风格并没有被应用。因此，确定你传递的是一个 Activity Context。 RecyclerView Adapterpublic class MyRecyclerAdapter extends RecyclerView.Adapter&lt;MyRecyclerAdapter.ViewHolder&gt; &#123; @Override public ViewHolder onCreateViewHolder(ViewGroup parent, int viewType) &#123; View v = LayoutInflater .from(parent.getContext()) .inflate(R.layout.itemLayout, parent, false); return new ViewHolder(v); &#125; @Override public void onBindViewHolder(ViewHolder viewHolder, int i) &#123; // If a context is needed, it can be retrieved // from the ViewHolder's root view. Context context = viewHolder.itemView.getContext(); // Dynamically add a view using the context provided. if(i == 0) &#123; TextView tvMessage = new TextView(context); tvMessage.setText(\"Only displayed for the first item.\") viewHolder.customViewGroup.addView(tvMessage); &#125; &#125; public static class ViewHolder extends RecyclerView.ViewHolder &#123; public FrameLayout customViewGroup; public ViewHolder(view imageView) &#123; // Very important to call the parent constructor // as this ensures that the imageView field is populated. super(imageView); // Perform other view lookups. customViewGroup = (FrameLayout) imageView.findById(R.id.customViewGroup); &#125; &#125;&#125; ArrayAdapter 需要一个上下文传递到其构造器，而RecyclerView.Adapter不需要。因为其会在扩张必要的时候，可以从父布局那里推测出来正确的上下文。 相关的 RecyclerView 总是会把其自身作为 RecyclerView.Adapter.onCreateViewHolder()的父视图传递。 如果在 onCreateViewHolder()外需要使用上下文，而这里又有一个ViewHolder实例变量，就可以通过 viewHolder.itemView.getContext()来获取上下文。在基本的 ViewHolder类中，itemView 是一个 public, non-null, final字段。 避免内存泄漏Application Context 典型的用在单例实例需要被创建的时候，比如一个自定义的管理类需要 Context 信息来获取对系统服务的访问，但是其会在多个Activity中使用。因为对Activity Context的引用会导致那个Activity 在其停止后内存不会被释放，这就必须使用 Application Context。 下面的例子中，如果被存储的 context 是一个 Activity或Service，其在被安卓系统销毁后，并不会被垃圾回收器回收。因为 CustomManager 持有了对它的一个静态引用。 public class CustomManager &#123; private static CustomManager sInstance; public static CustomManager getInstance(Context context) &#123; if (sInstance == null) &#123; // This class will hold a reference to the context // until it's unloaded. The context could be an Activity or Service. sInstance = new CustomManager(context); &#125; return sInstance; &#125; private Context mContext; private CustomManager(Context context) &#123; mContext = context; &#125;&#125; 适当的存储一个Context:使用 Application Context为了避免内存泄漏，不要在其生命周期外持有对它的引用。检查所有你的背景线程，过起的handlers，及内部类，看看他们是不是会持有上下文引用。 正确的方式是在CustomManager.getInstance()中存储 Application Context。应用上下文是单例的，且其与应用进程的生命周期相绑定。 当需要一个在组件的生命周期外引用其上下文时，使用 应用上下文。 public static CustomManager getInstance(Context context) &#123; if (sInstance == null) &#123; // When storing a reference to a context, use the application context. // Never store the context itself, which could be a component. sInstance = new CustomManager(context.getApplicationContext()); &#125; return sInstance;&#125;","categories":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"}],"keywords":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}]},{"title":"android使用AppCompatActivity添加应用操作栏","slug":"android使用AppCompatActivity添加应用操作栏","date":"2018-08-28T13:28:12.000Z","updated":"2018-08-28T13:28:12.000Z","comments":true,"path":"Android/android使用AppCompatActivity添加应用操作栏.html","link":"","permalink":"https://gowa2017.github.io/Android/android使用AppCompatActivity添加应用操作栏.html","excerpt":"我们的项目是以前的一个大牛搞的，我是刚接触安卓，不是很理解一些做法。比如说，其继承自 FragmentActivity 的 BaseActivity，却不是使用的 AppCompatActivity。然后其头部的操作栏，也是自己定义了一个ActionBar,感觉有点过时了。特意的看了一下现在的实现办法。","text":"我们的项目是以前的一个大牛搞的，我是刚接触安卓，不是很理解一些做法。比如说，其继承自 FragmentActivity 的 BaseActivity，却不是使用的 AppCompatActivity。然后其头部的操作栏，也是自己定义了一个ActionBar,感觉有点过时了。特意的看了一下现在的实现办法。 AppCompatActivity先看一下类继承关系(Mac 快捷键 ctrl+h)： 对这个类的解释是： 对使用 support library 操作栏特性的 activity的基类。在API 等级 7 以上运行时，可以通过扩展这个类并把这个Activity的主题设置为类似 Theme.AppCompat的主题。至于怎么样添加 操作栏 参考 Action Bar API指南 FragmentActivity这个类是为了使用 Fragment, Loader API的 Activity 的基类。 使用此类而不是新平台的内置片段和加载器支持时，必须分别使用getSupportFragmentManager（）和getSupportLoaderManager（）方法来访问这些功能。 已知限制：当使用 标签时，这个实现无法使用 父view的Id来作为 新fragment的ID。必须明确的在 标签内指定一个Id（或tag） 总结通过以上对比，可以发现，其实 AppCompatActivity 兼容以前所有的特性，并提供更新的特性。 这就怪不得当我在 FragmentActivity 继承的类中使用 FloatingActionButton 的时候会报错的问题。 Toolbar在 V7 支持库可以将小部件 Toolbar 作为应用栏使用。也可以通过其他方式实现应用栏，例如，某些主题默认情况下会设置一个 ActionBar 作为应用栏。但是，使用 appcompat Toolbar 设置的应用栏能兼容最广泛的设备，也使您能够随着应用的发展自定义应用栏。添加应用栏 从 Android 3.0（API 级别 11）开始，所有使用默认主题的 Activity 均使用 ActionBar 作为应用栏。不过，经过不同 Android 版本的演化，应用栏功能已逐渐添加到原生 ActionBar 中。因此，原生 ActionBar 的行为会随设备使用的 Android 系统的版本而发生变化。相比之下，最新功能已添加到支持库版本的 Toolbar 中，并且这些功能可以在任何能够使用该支持库的设备上使用。 因此，您应使用支持库的 Toolbar 类来实现 Activity 的应用栏。使用支持库的工具栏有助于确保您的应用在最大范围的设备上保持一致的行为。例如，Toolbar 小部件能够在运行 Android 2.1（API 级别 7）或更高版本的设备上提供 Material Design 体验，但除非设备运行的是 Android 5.0（API 级别 21）或更高版本，否则原生操作栏不会支持 Material Design。 向 Activity 添加工具栏扩展一个AppCompatActivity public class MyActivity extends AppCompatActivity &#123; // ...&#125; 注：请为您应用中每个使用 Toolbar 作为应用栏的 Activity 进行此更改。 在应用清单中，将 元素设置为使用 appcompat 的其中一个 NoActionBar 主题。使用这些主题中的一个可以防止应用使用原生 ActionBar 类提供应用栏。例如： &lt;application android:theme=\"@style/Theme.AppCompat.Light.NoActionBar\" /&gt; 向 Activity 的布局添加一个 Toolbar。例如，以下布局代码可以添加一个 Toolbar 并赋予其浮动在 Activity 之上的外观： &lt;android.support.v7.widget.Toolbar android:id=\"@+id/my_toolbar\" android:layout_width=\"match_parent\" android:layout_height=\"?attr/actionBarSize\" android:background=\"?attr/colorPrimary\" android:elevation=\"4dp\" android:theme=\"@style/ThemeOverlay.AppCompat.ActionBar\" app:popupTheme=\"@style/ThemeOverlay.AppCompat.Light\"/&gt; Material Design 规范建议应用栏具有 4 dp 的仰角。 将工具栏定位在 Activity 布局的顶部，因为您要使用它作为应用栏。 在 Activity 的 onCreate() 方法中，调用 Activity 的 setSupportActionBar() 方法，然后传递 Activity 的工具栏。该方法会将工具栏设置为 Activity 的应用栏。例如： @Overrideprotected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); setContentView(R.layout.activity_my); Toolbar myToolbar = (Toolbar) findViewById(R.id.my_toolbar); setSupportActionBar(myToolbar); &#125; 您的应用现在具有一个基本操作栏。默认情况下，操作栏只包含应用的名称和一个溢出菜单。选项菜单最初只包含 Settings 菜单项。您可以按照添加和处理操作中所述向操作栏和溢出菜单添加更多操作。 将工具栏设置为 Activity 的应用栏后，您就可以访问 v7 appcompat 支持库的 ActionBar 类提供的各种实用方法。您可以通过此方法执行许多有用的操作，例如隐藏和显示应用栏。 要使用 ActionBar 实用方法，请调用 Activity 的 getSupportActionBar()方法。此方法将返回对 appcompat ActionBar 对象的引用。获得该引用后，您就可以调用任何一个 ActionBar 方法来调整应用栏。例如，要隐藏应用栏，请调用 ActionBar.hide()。 添加与控制动作应用栏允许为用户的动作添加按钮。此功能允许您将当前上下文的最重要操作放在应用程序的顶部。例如，当用户查看他们的照片卷时，照片浏览应用可能会显示共享并在顶部创建相册按钮;当用户查看单张照片时，该应用可能会显示裁剪和过滤按钮。 应用栏的空间是有限制的。如果一个app声明了太多的动作而无法容纳的话，应用栏会把过量的动作发送到一个 overflow菜单。应用栏也可以指定一个动作永远在一个 overflow菜单中，而不是显示在应用栏中。 添加动作按钮动作溢出中可用的所有操作按钮和其他项都在XML菜单资源中定义。要向操作栏添加操作，请在项目的res/menu/目录中创建新的XML文件。 &lt;menu xmlns:android=\"http://schemas.android.com/apk/res/android\" &gt; &lt;!-- \"Mark Favorite\", should appear as action button if possible --&gt; &lt;item android:id=\"@+id/action_favorite\" android:icon=\"@drawable/ic_favorite_black_48dp\" android:title=\"@string/action_favorite\" app:showAsAction=\"ifRoom\"/&gt; &lt;!-- Settings, should always be in the overflow --&gt; &lt;item android:id=\"@+id/action_settings\" android:title=\"@string/action_settings\" app:showAsAction=\"never\"/&gt;&lt;/menu&gt; app:showAsAction属性指定动作是否显示在应用栏上。当设置为app:showAsAction=&quot;ifRoom&quot;时，如果应用栏上有空间，就会显示在应用栏上；如果没有空间的话，就会发送到overflow菜单。app:showAsAction=&quot;never&quot;则会设置永远都在overflow菜单内。 响应动作当用户选择了应用栏上的项目的时候，系统会调用 activity的onOptionsItemSelected()方法，并传递一个MenuItem过去以表示是哪个项被点击了。在我们的onOptionsItemSelected()实现中，调用MenuItem.getItemId()来确定，哪个项被按下。返回的ID与您在相应元素的android：id属性中声明的值匹配。 例如，以下代码检查用户选择的操作。如果方法无法识别用户的操作，则会调用超类方法： @Overridepublic boolean onOptionsItemSelected(MenuItem item) &#123; switch (item.getItemId()) &#123; case R.id.action_settings: // User chose the \"Settings\" item, show the app settings UI... return true; case R.id.action_favorite: // User chose the \"Favorite\" action, mark the current item // as a favorite... return true; default: // If we got here, the user's action was not recognized. // Invoke the superclass to handle it. return super.onOptionsItemSelected(item); &#125;&#125; 添加返回按钮您的应用应该可以让用户轻松找到返回应用主屏幕的方式。一种简单的方法是在应用栏上为除主要活动之外的所有活动提供“向上”按钮。当用户选择“向上”按钮时，应用程序将导航到父活动。 本课程向您展示如何通过在清单中声明活动的父级并启用应用栏的“向上”按钮来向活动添加“向上”按钮。 声明一个父activity要支持活动中的向上功能，您需要声明活动的父级。您可以通过设置android：parentActivityName属性在应用程序清单中执行此操作。 android：parentActivityName属性是在Android 4.1（API级别16）中引入的。要支持使用旧版Android的设备，请定义名称 - 值对，其名称为“android.support.PARENT_ACTIVITY”，值为父活动的名称。 例如，假设您的应用具有名为MainActivity的主要活动和单个子活动。以下清单代码声明了这两个活动，并指定了父/子关系： &lt;application ... &gt; ... &lt;!-- The main/home activity (it has no parent activity) --&gt; &lt;activity android:name=\"com.example.myfirstapp.MainActivity\" ...&gt; ... &lt;/activity&gt; &lt;!-- A child of the main activity --&gt; &lt;activity android:name=\"com.example.myfirstapp.MyChildActivity\" android:label=\"@string/title_activity_child\" android:parentActivityName=\"com.example.myfirstapp.MainActivity\" &gt; &lt;!-- Parent activity meta-data to support 4.0 and lower --&gt; &lt;meta-data android:name=\"android.support.PARENT_ACTIVITY\" android:value=\"com.example.myfirstapp.MainActivity\" /&gt; &lt;/activity&gt;&lt;/application&gt; 启用向上按钮要为具有父活动的活动启用“向上”按钮，请调用应用栏的setDisplayHomeAsUpEnabled（）方法。 通常，您会在创建活动时执行此操作。例如，以下onCreate（）方法将工具栏设置为MyChildActivity的应用栏，然后启用该应用栏的“向上”按钮： @Overrideprotected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); setContentView(R.layout.activity_my_child); // my_child_toolbar is defined in the layout file Toolbar myChildToolbar = (Toolbar) findViewById(R.id.my_child_toolbar); setSupportActionBar(myChildToolbar); // Get a support ActionBar corresponding to this toolbar ActionBar ab = getSupportActionBar(); // Enable the Up button ab.setDisplayHomeAsUpEnabled(true);&#125; 您不需要在活动的onOptionsItemSelected（）方法中捕获up动作。相反，该方法应调用其超类，如响应操作中所示。超类方法通过导航到父活动响应Up选项，如应用清单中指定的那样。 使用操作视图和操作提供程序v7 appcompat支持库Toobar为用户提供了几种与您的应用交互的不同方式。上面的课程描述了如何定义一个动作，可以是一个按钮或一个菜单项。本课程介绍如何添加两个通用组件： 操作视图是在应用栏中提供丰富功能的操作。例如，搜索操作视图允许用户在应用栏中键入其搜索文本，而无需更改活动或片段。 动作提供者是具有自己的自定义布局的动作。该操作最初显示为按钮或菜单项，但当用户单击该操作时，操作提供程序将以您想要定义的任何方式控制操作的行为。 例如，操作提供程序可能通过显示菜单来响应单击。 Android支持库提供了几个专门的操作视图和操作提供程序小部件。 例如，SearchView小部件实现用于输入搜索查询的操作视图，ShareActionProvider小部件实现用于与其他应用程序共享信息的操作提供程序。 您还可以定义自己的操作视图和操作提供程序。 添加一个操作视图要添加操作视图，请在工具栏的菜单资源中创建元素，如上节添加操作按钮所述。将以下两个属性之一添加到元素： actionViewClass：实现操作的窗口小部件的类。 actionLayout：描述操作组件的布局资源。 将showAsAction属性设置为“ifRoom | collapseActionView”或“never | collapseActionView”。 collapseActionView标志指示当用户未与其交互时如何显示窗口小部件：如果窗口小部件位于应用栏上，则应用应将窗口小部件显示为图标。 如果窗口小部件位于溢出菜单中，则应用程序应将窗口小部件显示为菜单项。 当用户与操作视图交互时，它会展开以填充应用栏。 例如，以下代码将SearchView小部件添加到应用栏： &lt;item android:id=\"@+id/action_search\" android:title=\"@string/action_search\" android:icon=\"@drawable/ic_search\" app:showAsAction=\"ifRoom|collapseActionView\" app:actionViewClass=\"android.support.v7.widget.SearchView\" /&gt; 如果用户未与窗口小部件交互，则应用程序将窗口小部件显示为android：icon指定的图标。 （如果应用栏中没有足够的空间，应用程序会将操作添加到溢出菜单。）当用户点击图标或菜单项时，窗口小部件会扩展以填充工具栏，允许用户与其进行交互。 如果需要配置操作，请在活动的onCreateOptionsMenu（）回调中执行此操作。 您可以通过调用getActionView（）方法获取操作视图的对象引用。 例如，以下代码获取上一代码示例中定义的SearchView小部件的对象引用： @Overridepublic boolean onCreateOptionsMenu(Menu menu) &#123; getMenuInflater().inflate(R.menu.main_activity_actions, menu); MenuItem searchItem = menu.findItem(R.id.action_search); SearchView searchView = (SearchView) searchItem.getActionView(); // Configure the search info and add any event listeners... return super.onCreateOptionsMenu(menu);&#125; 响应动作视图扩展如果操作的元素具有collapseActionView标志，则应用程序会将操作视图显示为图标，直到用户与操作视图进行交互。 当用户单击该图标时，onOptionsItemSelected（）的内置处理程序将展开操作视图。 如果您的活动子类重写onOptionsItemSelected（）方法，则您的override方法必须调用super.onOptionsItemSelected（），以便超类可以展开操作视图。 如果要在展开或折叠操作时执行某些操作，可以定义实现MenuItem.OnActionExpandListener的类，并将该类的成员传递给setOnActionExpandListener（）。 例如，您可能希望根据操作视图是展开还是折叠来更新活动。 以下代码段显示了如何定义和传递侦听器： @Overridepublic boolean onCreateOptionsMenu(Menu menu) &#123; getMenuInflater().inflate(R.menu.options, menu); // ... // Define the listener OnActionExpandListener expandListener = new OnActionExpandListener() &#123; @Override public boolean onMenuItemActionCollapse(MenuItem item) &#123; // Do something when action item collapses return true; // Return true to collapse action view &#125; @Override public boolean onMenuItemActionExpand(MenuItem item) &#123; // Do something when expanded return true; // Return true to expand action view &#125; &#125;; // Get the MenuItem for the action item MenuItem actionMenuItem = menu.findItem(R.id.myActionItem); // Assign the listener to that action item MenuItemCompat.setOnActionExpandListener(actionMenuItem, expandListener); // Any other things you have to do when creating the options menu... return true;&#125; 添加一个动作提供者要声明操作提供程序，请在工具栏的菜单资源中创建元素，如添加操作按钮中所述。 添加actionProviderClass属性，并将其设置为操作提供程序类的完全限定类名。 例如，以下代码声明了一个ShareActionProvider，它是一个在支持库中定义的小部件，允许您的应用与其他应用共享数据： &lt;item android:id=\"@+id/action_share\" android:title=\"@string/share\" app:showAsAction=\"ifRoom\" app:actionProviderClass=\"android.support.v7.widget.ShareActionProvider\"/&gt; 在这种情况下，没有必要为小部件声明一个图标，因为ShareActionProvider提供了自己的图形。 如果您使用自定义操作，请声明一个图标。 有关创建自定义操作提供程序的信息，请参阅ActionProvider参考。 有关配置ShareActionProvider的信息，请参阅该类的参考。","categories":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"},{"name":"Activity","slug":"Activity","permalink":"https://gowa2017.github.io/tags/Activity/"}],"keywords":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}]},{"title":"dom4j来解析xml-省市区-三级联动选择","slug":"dom4j来解析xml-省市区-三级联动选择","date":"2018-08-24T07:55:42.000Z","updated":"2018-08-24T07:55:42.000Z","comments":true,"path":"Java/dom4j来解析xml-省市区-三级联动选择.html","link":"","permalink":"https://gowa2017.github.io/Java/dom4j来解析xml-省市区-三级联动选择.html","excerpt":"","text":"本来一直没有用到过xml，也从来不知道为什么xml/json应用会这么广，谁让我是一个水逼代码货。但是果然就是与到了，从别人的网站上扒下来需要用到的xml行政区域代码，然后要做一个三级联动选择器。于是github，谷歌开始。 Android-PickerViewandroid-pickerview项目地址 据说这个可以，但用起来看了一下果然应该是可以的。懒得自己去适配wheelview了，就打算用这个吧。这个需要三个列表。一个列表保存的是省级数据，一个保存市级数据，一个保存区县的数据。我们就需要把我们的xml文档给解析过来。 dom4j我的文档格式类似下面： &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;r tm=\"2018/08/01 14:29:46\"&gt; &lt;t c=\"110000\"&gt;北京&lt;/t&gt; &lt;t&gt; &lt;t c=\"110100\"&gt;北京-北京市&lt;/t&gt; &lt;t&gt; &lt;t c=\"110101\"&gt;北京-北京市-东城区&lt;/t&gt; &lt;t c=\"110102\"&gt;北京-北京市-西城区&lt;/t&gt; &lt;t c=\"110103\"&gt;北京-北京市-崇文区&lt;/t&gt; &lt;t c=\"110104\"&gt;北京-北京市-宣武区&lt;/t&gt; &lt;t c=\"110105\"&gt;北京-北京市-朝阳区&lt;/t&gt; &lt;t c=\"110106\"&gt;北京-北京市-丰台区&lt;/t&gt; &lt;t c=\"110107\"&gt;北京-北京市-石景山区&lt;/t&gt; &lt;t c=\"110108\"&gt;北京-北京市-海淀区&lt;/t&gt; &lt;t c=\"110109\"&gt;北京-北京市-门头沟区&lt;/t&gt; &lt;t c=\"110111\"&gt;北京-北京市-房山区&lt;/t&gt; &lt;t c=\"110112\"&gt;北京-北京市-通州区&lt;/t&gt; &lt;t c=\"110113\"&gt;北京-北京市-顺义区&lt;/t&gt; &lt;t c=\"110114\"&gt;北京-北京市-昌平区&lt;/t&gt; &lt;t c=\"110115\"&gt;北京-北京市-大兴区&lt;/t&gt; &lt;t c=\"110116\"&gt;北京-北京市-怀柔区&lt;/t&gt; &lt;t c=\"110117\"&gt;北京-北京市-平谷区&lt;/t&gt; &lt;/t&gt; &lt;t c=\"110200\"&gt;北京-县&lt;/t&gt; &lt;t&gt; &lt;t c=\"110228\"&gt;北京-县-密云县&lt;/t&gt; &lt;t c=\"110229\"&gt;北京-县-延庆县&lt;/t&gt; &lt;/t&gt; &lt;/t&gt; &lt;t c=\"120000\"&gt;天津&lt;/t&gt; &lt;t&gt; .... 比较简单，开始的时候我是准备用map来搞的，但是不好适配上面的那个选择器，最后还是麻烦点，效率低点的用list来适配了。 基本概念dom 把xml文档内的标签都当做元素，有一个根元素，我们文档内就是 r 这个元素。然后其有很多子节点，有的节点有属性 c，而有的没有。没有 c 属性的，则其具有子节点。理解后解析过程就很简单了。 代码解析我首先构造出省，市，区县的实体类： public class Province &#123; private String code; private String name; private List&lt;City&gt; citys;&#125;public class City &#123; private String code; private String name; private List&lt;Zone&gt; zones;&#125;public class Zone &#123; private String code; private String value; &#125; 最后我们得出的是一个List\\数据结构。 public class AreaDataModel &#123; // 需要一个安卓的上下文来获取assets目录 public static List&lt;Province&gt; getData(Context ctx)&#123; List&lt;Province&gt; provinces = new ArrayList&lt;Province&gt;(); DocumentBuilderFactory factory = DocumentBuilderFactory.newInstance(); try &#123; DocumentBuilder builder = factory.newDocumentBuilder(); Document document = builder.parse(ctx.getAssets().open(\"area.xml\")); Element root = document.getDocumentElement(); NodeList items = root.getChildNodes(); // 根节点的子节点，一级节点，我这样称呼它，是为省份信息 for (int i = 0; i &lt; items.getLength(); i++) &#123; Node node = items.item(i); if (node.getNodeType() == Node.ELEMENT_NODE) &#123; Element e = (Element) node; if (e.hasAttribute(\"c\")) &#123; Province province = new Province(); province.setCode(e.getAttribute(\"c\").substring(0,2)); province.setName(e.getTextContent()); province.setCitys(new ArrayList&lt;City&gt;()); provinces.add(province); // 如果没有`c`属性，那么这个拥有子节点，是市级数据。 &#125; else &#123; addCitysToProvince(e, provinces); &#125; &#125; &#125; System.out.println(provinces.size()); int n1 = 0; int n2 = 0; for (int i = 0; i &lt; provinces.size(); i++) &#123; Province province = provinces.get(i); n1 += province.getCitys().size(); for (int j = 0; j &lt; province.getCitys().size(); j++) &#123; n2 += province.getCitys().get(j).getZones().size(); &#125; &#125; System.out.println(n1); System.out.println(n2); &#125; catch (Exception e) &#123; e.printStackTrace(); System.out.println(e.getMessage()); &#125; return provinces; &#125; // 把市级数据添加到省级数据内 private static void addCitysToProvince(Element element, List&lt;Province&gt; provinces) &#123; NodeList nodeList = element.getChildNodes(); for (int i = 0; i &lt; nodeList.getLength(); i++) &#123; Node node = nodeList.item(i); if (node.getNodeType() == Node.ELEMENT_NODE)&#123; Element e = (Element) node; // 有 `c` 属性的，是市级数据。 if (e.hasAttribute(\"c\"))&#123; Province province = findProvinceByCode(e.getAttribute(\"c\").substring(0,2),provinces); if (province!=null)&#123; City city = new City(); city.setCode(e.getAttribute(\"c\").substring(2,4)); String name = e.getTextContent(); city.setName(name.substring(name.lastIndexOf(\"-\")+1)); city.setZones(new ArrayList&lt;Zone&gt;()); province.getCitys().add(city); &#125; else &#123; System.out.printf(\"%s,%s\\n\",e.getAttribute(\"c\"),e.getTextContent()); &#125; // 否则的话，是区县数据， &#125; else&#123; addZonesToProvince(e,provinces); &#125; &#125; &#125; &#125; // 通过省分代码找到对应的省级数据 private static Province findProvinceByCode(String code, List&lt;Province&gt; provinces)&#123; for (int i = 0; i &lt; provinces.size(); i++) &#123; Province province = provinces.get(i); if (province.getCode().equals(code))&#123; return province; &#125; &#125; return null; &#125;// 把区县数据添加到省内 private static void addZonesToProvince(Element element, List&lt;Province&gt; provinces)&#123; NodeList nodeList = element.getChildNodes(); for (int i = 0; i &lt; nodeList.getLength(); i++) &#123; Node node = nodeList.item(i); if (node.getNodeType() == Node.ELEMENT_NODE)&#123; Element e = (Element) node; String code = e.getAttribute(\"c\"); String pro = code.substring(0,2); String cityCode = code.substring(2,4); String zoneCode = code.substring(4); Province province = findProvinceByCode(pro,provinces); City city = findCityByCode(cityCode,province.getCitys()); if (city == null)&#123; System.out.printf(\"%s,%s\\n\",code,e.getTextContent()); &#125; else &#123; Zone zone = new Zone(); zone.setCode(zoneCode); String name = e.getTextContent(); zone.setValue(name.substring(name.lastIndexOf(\"-\")+1)); city.getZones().add(zone); &#125; &#125; &#125; &#125; // 根据区域代码找出归属的城市 private static City findCityByCode(String code, List&lt;City&gt; cities)&#123; for (int i = 0; i &lt; cities.size(); i++) &#123; City city = cities.get(i); if (city.getCode().equals(code))&#123; return city; &#125; &#125; return null; &#125;&#125; 当我们得出了我们想要的数据结构，那我们要适配选择器了。 实现选择代码// 分别省，市，县的列表 private List&lt;Province&gt; mProvinces = new ArrayList&lt;&gt;(); private List&lt;List&lt;City&gt;&gt; mCities = new ArrayList&lt;&gt;(); private List&lt;List&lt;List&lt;Zone&gt;&gt;&gt; mZones = new ArrayList&lt;&gt;(); 通过我们解析的数据来初始化这三个列表： mProvinces = AreaDataModel.getData(this); for (int i = 0; i &lt; mProvinces.size(); i++) &#123; Province province = mProvinces.get(i); // 如果省份的城市为空，为了避免NPE错误，给他加上一个空的市，空的区 if (province.getCitys().isEmpty()) &#123; City newCity = new City(); newCity.setName(\"\"); newCity.setCode(\"00\"); List&lt;Zone&gt; tmp = new ArrayList&lt;&gt;(); tmp.add(new Zone(\"00\", \"\")); newCity.setZones(tmp); province.getCitys().add(newCity); &#125; mCities.add(province.getCitys()); List&lt;List&lt;Zone&gt;&gt; cityZone = new ArrayList&lt;&gt;(); for (int j = 0; j &lt; province.getCitys().size(); j++) &#123; //没有区县的市给他加一个空的。 if (province.getCitys().get(j).getZones().isEmpty())&#123; province.getCitys().get(j).getZones().add(new Zone(\"00\",\"\")); &#125; cityZone.add(province.getCitys().get(j).getZones()); &#125; mZones.add(cityZone); &#125;&#125; 然后把数据绑定到我们的选择器上： final OptionsPickerView pvOptions = new OptionsPickerBuilder(this, new OnOptionsSelectListener() &#123; @Override public void onOptionsSelect(int options1, int options2, int options3, View v) &#123; StringBuffer sb = new StringBuffer(); sb.append(mProvinces.get(options1).getName()); sb.append(\"-\"); sb.append(mCities.get(options1).get(options2).getName()); sb.append(\"-\"); sb.append(mZones.get(options1).get(options2).get(options3).getValue()); String areazone = sb.toString().replace(\"--\",\"\"); idcardAddress.setTvContent(areazone); areaCode = String.format(\"%s%s%s\", mProvinces.get(options1).getCode(), mCities.get(options1).get(options2).getCode(), mZones.get(options1).get(options2).get(options3).getCode()); showToast(areazone); Log.d(TAG, \"onOptionsSelect: \" + areaCode); &#125;&#125;) .setTitleText(\"城市选择\") .setDividerColor(Color.BLACK) .setTextColorCenter(Color.BLACK) //设置选中项文字颜色 .setContentTextSize(20) .build();pvOptions.setPicker(mProvinces, mCities, mZones);//三级选择器pvOptions.show(); 这样就大功告成了。","categories":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/tags/Java/"},{"name":"XML","slug":"XML","permalink":"https://gowa2017.github.io/tags/XML/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}]},{"title":"理解MySQL的查询执行计划","slug":"理解MySQL的查询执行计划","date":"2018-08-22T05:09:25.000Z","updated":"2018-08-22T05:09:25.000Z","comments":true,"path":"MySQL/理解MySQL的查询执行计划.html","link":"","permalink":"https://gowa2017.github.io/MySQL/理解MySQL的查询执行计划.html","excerpt":"根据表，列，索引和WHERE子句中的条件的详细信息，MySQL优化器会考虑许多技术来有效地执行SQ​​L查询中涉及的查找。可以在不读取所有行的情况下执行对巨大表的查询;可以在不比较每个行组合的情况下执行涉及多个表的连接。优化程序选择执行最有效查询的操作集称为“查询执行计划”，也称为EXPLAIN计划。您的目标是识别EXPLAIN计划中表明查询已经过优化的方面，并了解SQL语法和索引技术，以便在看到一些低效的操作时改进计划。","text":"根据表，列，索引和WHERE子句中的条件的详细信息，MySQL优化器会考虑许多技术来有效地执行SQ​​L查询中涉及的查找。可以在不读取所有行的情况下执行对巨大表的查询;可以在不比较每个行组合的情况下执行涉及多个表的连接。优化程序选择执行最有效查询的操作集称为“查询执行计划”，也称为EXPLAIN计划。您的目标是识别EXPLAIN计划中表明查询已经过优化的方面，并了解SQL语法和索引技术，以便在看到一些低效的操作时改进计划。 使用EXPLAIN优化查询EXPLAIN语句提供有关MySQL如何执行语句的信息： 当您在SELECT语句之前使用关键字EXPLAIN时，MySQL会显示优化程序中有关语句执行计划的信息。也就是说，MySQL解释了它将如何处理语句，包括有关表如何连接以及以何种顺序连接的信息。有关使用EXPLAIN获取执行计划信息的信息，请参见第下一节“EXPLAIN输出格式”。 EXPLAIN EXTENDED生成可以使用SHOW WARNINGS显示的其他执行计划信息。请参见下面章节“扩展EXPLAIN输出格式”。 EXPLAIN PARTITIONS对于检查涉及分区表的查询很有用 在EXPLAIN的帮助下，您可以看到应该向表添加索引的位置，以便通过使用索引查找行来更快地执行语句。您还可以使用EXPLAIN来检查优化程序是否以最佳顺序连接表。要提示优化器使用与SELECT语句中命名表的顺序相对应的连接顺序，请使用SELECT STRAIGHT_JOIN而不是SELECT来开始语句。 如果在您认为应该使用索引时遇到问题，请运行ANALYZE TABLE来更新表统计信息，例如密钥的基数，这会影响优化程序的选择。 EXPLAIN还可用于获取有关表中列的信息。 EXPLAIN tbl_name与DESCRIBE tbl_name和SHOW COLUMNS FROM tbl_name同义。 EXPLAIN输出格式EXPLAIN 提供了 select 语句的执行计划。 EXPLAIN为SELECT语句中使用的每个表返回一行信息。 它按照MySQL在处理语句时读取它们的顺序列出输出中的表。 MySQL使用嵌套循环连接方法解析所有连接。 这意味着MySQL从第一个表中读取一行，然后在第二个表，第三个表中找到匹配的行，依此类推。 处理完所有表后，MySQL会通过表列表输出所选列和回溯，直到找到有更多匹配行的表。 从该表中读取下一行，并继续下一个表。 使用EXTENDED关键字时，EXPLAIN会生成额外的信息，可以通过在EXPLAIN语句后面发出SHOW WARNINGS语句来查看。 EXPLAIN EXTENDED还会显示已过滤的列。 您不能在同一个EXPLAIN语句中一起使用EXTENDED和PARTITIONS关键字。MySQL Workbench具有Visual Explain功能，可以直观地显示EXPLAIN输出。请参阅教程：使用说明来提高查询性能。 EXPLAIN Output Columns本节介绍EXPLAIN生成的输出列。后面的部分提供有关类型和额外列的其他信息。 EXPLAIN的每个输出行都提供有关一个表的信息。每行包含表“EXPLAIN输出列”中汇总的值，并在表后面进行了更详细的描述。 Column Meaning id The SELECT identifier select_type The SELECT type table The table for the output row partitions The matching partitions type The join type possible_keys The possible indexes to choose key The index actually chosen key_len The length of the chosen key ref The columns compared to the index rows Estimate of rows to be examined filtered Percentage of rows filtered by table condition Extra Additional information idselect 标识符。在本次查询中 select 的序列号。如果此行引用的是其他行的 union，那么序列可以是 NULL。在这种情况下，table列会显示一个类似的值来表明这一行引用了 Id 为 M,N 行的查询结果 联合。 select_type可能有下面这些值。 SIMPLE Simple SELECT (not using UNION or subqueries) PRIMARY 最外层的 SELECT UNION 第二个或后续的在一个UNION中的 SELECT 语句。 DEPENDENT UNION 第二个或后续的在一个UNION中的 SELECT 语句,依赖于外部查询 UNION RESULT UNION的结果。 SUBQUERY 子查询中的第一个select DEPENDENT SUBQUERY 子查询中的第一个select, 依赖于外部查询 DERIVED 衍生表 UNCACHEABLE SUBQUERY 无法缓存结果的子查询，必须为外部查询的每一行重新计算 UNCACHEABLE UNION 一个属于 UNCACHEABLE SUBQUERY 的 UNION 中的第二个或更晚的查询。 DEPENDENT用来表明使用了相关的子查询。Section 13.2.10.7, “Correlated Subqueries”. DEPENDENT SUBQUERY 与 UNCACHEABLE SUBQUERY 不同。对于DEPENDENT SUBQUERY，子查询仅针对来自其外部上下文的变量的每组不同值重新评估一次。对于UNCACHEABLE SUBQUERY，将为外部上下文的每一行重新评估子查询。 子查询的可缓存性与查询缓存中查询结果的缓存不同（Section 8.10.3.1, “How the Query Cache Operates”。查询执行期间发生子查询缓存，而查询缓存仅在查询执行完成后用于存储结果。 table输出行引用的表的名称。这也可以是以下值之一: :该行引用的是id值为M和N的行的并集。 :行引用的是id值为N的行的派生表结果。例如，派生表可能来自FROM中的子查询 partitions记录将与查询匹配的分区。仅当使用PARTITIONS关键字时，才会显示此列。对于非分区表，该值为NULL。Section 19.3.4, “Obtaining Information About Partitions” typejoin 类型。详见下一节。 possible_keys在表内可以使用的键。请注意，此列完全独立于EXPLAIN输出中显示的表的顺序。这意味着 possible_keys 中的键在生成表顺序可能会不可用。 如果此列为NULL，则没有相关索引。在这种情况下，您可以通过检查WHERE子句以检查它是否引用适合索引列来提高查询性能。 SHOW INDEX FROM tbl_name 可以查看表的索引。 key表明查询中使用到的索引。 需要注意的时候，这一列中的值可能没有包含在 possible_keys列中。这在possible_keys中的索引都不适合使用来查找行，但所选择的所有行是其他索引的列的时候。这就是说，此列中出现的索引覆盖了选择的列，因此尽管其不会使用这个索引来获取行数据，但索引扫描会被数据行扫描更快。 对于 InnoDB，及时查询选择了主键，也有可能使用一个二级索引，这是因为InnoDB的二级索引都存储了主键值。如果值是 null，那么说明没有找到任何索引来使用。 如果想要强制使用，或者忽略 possible_keys 中的值，可以在查询中使用FORCE INDEX, USE INDEX, or IGNORE INDEX。 对于 MyISAM，NDB表，使用 ANALYZE TABLE来帮助优化器选择更好的索引。 key_len表明MySQL决定使用的索引长度。对于多部分的索引，key_len决定了会使用其中的多少部分。如果 key 为null，那么这里也是null。 因为索引存储格式的问题，可能为NULL的索引长度会比 NOT NULL的索引长度长。 refref列显示哪些列或常量与键列中指定的索引进行比较，以从表中选择行 rowsrows列指示MySQL认为必须检查以执行查询的行数 对于InnoDB表，此数字是估计值，可能并不总是准确的。 filtered表示被表条件筛选后剩余的行的百分比。最大值100，表示没有过滤掉行。值从100开始减少表示过滤量增加。rows 列显示了估计会测试的行，而rows*filtered则显示了会在后续的表中进行join的行。比如，如果 rows 是 1000 ，而 filtered 是50%，与后面的表进行join的行就是 1000\\50%=500*行。当使用 EXPLAIN EXTENDED的时候会显示这一列。 Extra此列包含有关MySQL如何解析查询的其他信息。有关不同值的说明，请参阅EXPLAIN附加信息一节。 EXPLAIN Join TypesEXPLAIN输出的type列描述了表的连接方式。以下列表描述了从最佳类型到最差类型的连接类型： system 该表只有一行（=系统表）。这是const连接类型的特例。 const 表最多有一个匹配行，在查询开始的时候就会读取。因为只有一行，所以这一行内的列可以被优化器当做常量对待。const表非常快，因为它们只读一次。当您将PRIMARY KEY或UNIQUE索引的所有部分与常量值进行比较时，将使用const。在以下查询中，tbl_name可用作const表： SELECT * FROM tbl_name WHERE primary_key=1;SELECT * FROM tbl_name WHERE primary_key_part1=1 AND primary_key_part2=2; eq_ref 对于前面表格中的每个行组合，从该表中读取一行。除了 system,const，这是最佳的join方式了。当一个索引的所有部分被join使用且此索引是主键或 UNIQUE NOT NULL索引的时候被使用。当使用 =操作符在索引列的时候，可以使用 eq_ref。比较值可以是常量，也可以是使用在此表之前读取的表中的列的表达式，在下面的例子中，MySQL可以使用 eq_ref join 来处理ref_table： SELECT * FROM ref_table,other_table WHERE ref_table.key_column=other_table.column;SELECT * FROM ref_table,other_table WHERE ref_table.key_column_part1=other_table.column AND ref_table.key_column_part2=1; ref 对于前面表中的每个行组合，将从此表中读取具有匹配索引值的所有行。如果连接仅使用键的最左前缀或者键不是PRIMARY KEY或UNIQUE索引，则使用ref（换句话说，其不能根据索引值找到唯一行的时候）。当使用的索引只会匹配几行的时候，这是一个非常不错的join类型。ref可以在索引列上使用 =&lt;&gt;这样的操作符上使用。 SELECT * FROM ref_table WHERE key_column=expr;SELECT * FROM ref_table,other_table WHERE ref_table.key_column=other_table.column;SELECT * FROM ref_table,other_table WHERE ref_table.key_column_part1=other_table.column AND ref_table.key_column_part2=1; fulltext 使用FULLTEXT索引执行连接 ref_or_null 这和 ref有点类似，不同的是MySQL会有一个额外操作，就是会搜索包含NULL的行。这个join类型优化经常用来在解析子查询。Section 8.2.1.9, “IS NULL Optimization” SELECT * FROM ref_table WHERE key_column=expr OR key_column IS NULL; index_merge 这个join类型表明 Index Merge optimization 被使用。在这种情况下，key列包含所使用的索引列表，key_len包含一个使用索引中最长长度的列表。Section 8.2.1.3, “Index Merge Optimization” unique_subquery 这个类型在某些in子查询时。替换eq_ref value IN (SELECT primary_key FROM single_table WHERE some_expr) unique_subquery只是一个索引查找函数，它可以完全替换子查询以提高效率。 index_subquery 与index_merge类似。其会替换 in 查询，但是其在子查询内的 非唯一的索引上工作，如： value IN (SELECT key_column FROM single_table WHERE some_expr) range 给定范围内的行被获取。key 列表示使用了什么索引。key_len表明使用的所有最长长度。ref列为null。当一个索引列与一个常量进行比较（使用 =, &lt;&gt;, &gt;, &gt;=, &lt;, &lt;=, IS NULL, &lt;=&gt;, BETWEEN, LIKE, or IN()操作）会使用： SELECT * FROM tbl_name WHERE key_column = 10;SELECT * FROM tbl_name WHERE key_column BETWEEN 10 and 20;SELECT * FROM tbl_name WHERE key_column IN (10,20,30);SELECT * FROM tbl_name WHERE key_part1 = 10 AND key_part2 IN (10,20,30); index 与ALL类似，但是是扫描所有索引。有两种发生方式。如果索引是当前查询的覆盖索引且能用来满足所有从表内需要的数据，那么只扫描索引树。在这种情况下，列Extra会显示Using index。索引扫描比ALL快，因为索引比表数据小多了。使用索引中的读取执行全表扫描，以按索引顺序查找数据行。Uses index不会出现在Extra列。当查询仅使用属于单个索引的列时，MySQL可以使用此连接类型 ALL 全表扫描 EXPLAIN Extra InformationExtra列包含了MySQL如何解析查询的额外信息。下面是一些可能的值。如果你想让你的查询尽可能快的话，找出在Extra中使用了Using filesort，Using temporary的行。 Child of ‘table’ pushed join@1 此表在连接中被引用为表的子节点，可以将其下推到NDB内核。 仅当启用了下推连接时，才适用于MySQL NDB Cluster 7.2及更高版本。 有关更多信息和示例，请参阅ndb_join_pushdown服务器系统变量的说明 const row not found 查询的表为空 Distinct MySQL正在寻找不同的值，因此它在找到第一个匹配行后停止为当前行组合搜索更多行。 Full scan on NULL key 当优化程序无法使用索引查找访问方法时，子查询优化将作为回退策略发生 Impossible HAVING HAVING子句始终为false，无法选择任何行 Impossible WHERE WHERE子句始终为false，无法选择任何行。 Impossible WHERE noticed after reading const tables MySQL已经读取了所有const（和系统）表，并注意到WHERE子句始终为false。 No matching min/max row 没有行满足查询的条件，例如SELECT MIN（...）FROM ... WHERE condition no matching row in const table 对于具有连接的查询，有一个空表或没有满足唯一索引条件的行的表。 No tables used 该查询没有FROM子句，或者具有FROM DUAL子句。 Not exists MySQL能够对查询执行LEFT JOIN优化，并且在找到与LEFT JOIN条件匹配的行之后，不会检查此表中更多行以用于上一行组合，以下是可以通过以下方式优化的查询类型的示例： SELECT * FROM t1 LEFT JOIN t2 ON t1.id=t2.id WHERE t2.id IS NULL; 加入 t2.id 被定义为not null。在这种情况下，MySQL会扫描 t1 并在 t2 中寻找寻找值为 t1.id 的行。如果在 t2 中找到一个匹配行，其就会发现，t2.id 将永远不会为null，那么就不会继续再扫描 t2 表了。换句话说，MySQL只需要在 t2 中找到一行，而不管其到底有多少匹配。 Range checked for each record (index map: N) EXPLAIN Output Interpretation扩展EXPLAIN 输出格式估计查询性能","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://gowa2017.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://gowa2017.github.io/tags/MySQL/"}],"keywords":[{"name":"MySQL","slug":"MySQL","permalink":"https://gowa2017.github.io/categories/MySQL/"}]},{"title":"一次惨痛的数据库恢复经历","slug":"一次惨痛的数据库恢复经历","date":"2018-08-21T09:44:33.000Z","updated":"2018-08-21T09:44:33.000Z","comments":true,"path":"MySQL/一次惨痛的数据库恢复经历.html","link":"","permalink":"https://gowa2017.github.io/MySQL/一次惨痛的数据库恢复经历.html","excerpt":"后台在测试的时候，不小心把数据库备份导入了原来的库。这别，用mysqldump导出的语句会一个个的把表给drop调，然后重新建表，再插入数据。而这个时候，服务是没有停机的，有的业务表依然在有数据的写入，这样很可能造成数据的不一致问题。","text":"后台在测试的时候，不小心把数据库备份导入了原来的库。这别，用mysqldump导出的语句会一个个的把表给drop调，然后重新建表，再插入数据。而这个时候，服务是没有停机的，有的业务表依然在有数据的写入，这样很可能造成数据的不一致问题。 完整备份恢复利用晚上的完整备份恢复。 binlog找出破坏语句mysqlbinlog mysql_bin_log.000015 | grep DROP -A6 找出时间段内的sql。因为建立了 drop/create/insert 三个过程。所以先要找出这就成语句的行号。然后进行删除。 找到create语句的行号。 grep -n -E 'CREATE TABLE|ENGINE' out | awk -F: '&#123;print $1&#125;' &gt; lines 把行号转换为 开始,结束行这样的格式。sed 's/$/,/;N;s/\\n//' lines &gt; line 然后我们删除这些行 #!/usr/bin/sed -f61,81d123,147d..... 这个写成脚本，然后上面的 61,81d这样的，替换成line文件中的行号。 接下来插入语句 grep -n -E &apos;DISABLE|ENABLE&apos; out2 | awk -F: &apos;&#123;print $1&#125;&apos; &gt; lines2 sed &apos;s/$/,/;N;s/\\n//&apos; lines2 &gt; line2 如上继续删除行 另外，发现对于备份恢复，是有特征是 INSERT INTO ... VALUES 这样。直接删除： sed -i /INSERT.*VALUES/d' out.sql 出现问题中文乱码的问题。 根据验证，似乎是使用 mysqlbinlog … | mysql 这样的操作，得出的中文 就会乱码。 而将文件导出后再导入至数据库则不会乱码。 数据重复有外键约束的，重复插入了同一行，无法删除。处理办法： SET FOREIGN_KEY_CHECKS=0; 然后删除，之后恢复外键检查即可。 SET FOREIGN_KEY_CHECKS=1;","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://gowa2017.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://gowa2017.github.io/tags/MySQL/"}],"keywords":[{"name":"MySQL","slug":"MySQL","permalink":"https://gowa2017.github.io/categories/MySQL/"}]},{"title":"建立一个可持续发展的安卓Client","slug":"建立一个可持续发展的安卓Client","date":"2018-08-16T13:43:44.000Z","updated":"2018-08-16T13:43:44.000Z","comments":true,"path":"Android/建立一个可持续发展的安卓Client.html","link":"","permalink":"https://gowa2017.github.io/Android/建立一个可持续发展的安卓Client.html","excerpt":"Retrofit提供了广泛的功能，并且有许多可能的配置。 许多较大的应用程序需要一些特定的设置，例如OAuth身份验证。 为了实现一个干净和稳定的项目，我们将向您介绍我们对可持续Android客户端的想法：ServiceGenerator。本文是译文：原文地址","text":"Retrofit提供了广泛的功能，并且有许多可能的配置。 许多较大的应用程序需要一些特定的设置，例如OAuth身份验证。 为了实现一个干净和稳定的项目，我们将向您介绍我们对可持续Android客户端的想法：ServiceGenerator。本文是译文：原文地址 Retrofit 工作原理Retrofit使用一个http客户端(OkHttp)来执行网络请求。这个执行会在后台线程进行。 当 OkHttp 客户端从服务器收到响应，其就把响应返回给Retrofit。Retrofit把这个响应 压到 converter内，然后把其包装在一个可用的有意义的Java对象内，这一步依然是在后台线程完成。最后，当所有的事情都干完后，Retrofit就会把结果返回到 app 的 UI线程。 默认情况下，返回的结果以 Call 形式进行封装。从一个接收和准备结果的线程返回到安卓的UI线程这个动作叫做 call adapter。 ServiceGeneratorRetrofit对象及其构建器是所有请求的核心。在这里，您可以配置和准备请求，响应，身份验证，日志记录和错误处理。不幸的是，我们已经看到太多开发人员只是复制并粘贴这些部分而不是把这些操作分出来放在一个干净的类中。ServiceGenerator给出了解决办法，此是基于 Bart Kiers’ idea.。 让我们从简单的代码开始吧。在其当前状态下，它仅定义一种方法来为给定的类/接口创建基本REST客户端，该方法从接口返回服务类。 public class ServiceGenerator &#123; private static final String BASE_URL = \"https://api.github.com/\"; private static Retrofit.Builder builder = new Retrofit.Builder() .baseUrl(BASE_URL) .addConverterFactory(GsonConverterFactory.create()); private static Retrofit retrofit = builder.build(); private static OkHttpClient.Builder httpClient = new OkHttpClient.Builder(); public static &lt;S&gt; S createService( Class&lt;S&gt; serviceClass) &#123; return retrofit.create(serviceClass); &#125;&#125; createService方法接收一个serviceClass作为参数，这个serviceClass是一个用来进行API请求的接口，然后建立一个可用的客户端。在这个的客户端上，您将能够执行网络请求。 为什么ServiceGenerator都声明为static只有一个原因，在整个App中，我们只想打开一个连接，使用同样的 Retrofit, OkHttpClient来控制所有的请求，响应，缓存等。只使用一个OkHttpClient来重用打开套接字是很普遍的做法。这就意味着，我们需要使用依赖注入来注入OkHttpClient到类中或使用一个静态字段。这里我们选择了静态字段。因为我们在整个类中使用OkHttpClient，所以我们需要使所有字段和方法都是静态的。 除了加快速度之外，当我们不必一次又一次地重新创建相同的对象时，我们可以在移动设备上节省一些宝贵的内存 使用 ServiceGenerator我们来看一下建立一个请求的例子： String API_BASE_URL = \"https://api.github.com/\";OkHttpClient.Builder httpClient = new OkHttpClient.Builder();Retrofit.Builder builder = new Retrofit.Builder() .baseUrl(API_BASE_URL) .addConverterFactory( GsonConverterFactory.create() );Retrofit retrofit = builder .client( httpClient.build() ) .build();GitHubClient client = retrofit.create(GitHubClient.class); 如果只是一个请求，这很简单。但是我们的应用一般都会调用N个接口，这就显得非常的麻烦了。使用 ServiceGenerator，事情就简单起来了： GitHubClient client = ServiceGenerator.createService(GitHubClient.class); 一句代码就OK。 所有的事情都转移到了ServiceGenerator中。但多数时候，我们的ServiceGenerator不会这么简单，这就需要我们自己调整代码来适应我们的应用了。 日志我们希望能看到Retrofit发出的或者收到的数据。Retrofit 2的日志通过一个叫 HttpLoggingInterceptor 拦截器完成，我们需要把这个拦截器的一个实例添加到OkHttpClient。可能会有如下这样的代码： public class ServiceGenerator &#123; private static final String BASE_URL = \"https://api.github.com/\"; private static Retrofit.Builder builder = new Retrofit.Builder() .baseUrl(BASE_URL) .addConverterFactory(GsonConverterFactory.create()); private static Retrofit retrofit = builder.build(); private static HttpLoggingInterceptor logging = new HttpLoggingInterceptor() .setLevel(HttpLoggingInterceptor.Level.BODY); private static OkHttpClient.Builder httpClient = new OkHttpClient.Builder(); public static &lt;S&gt; S createService( Class&lt;S&gt; serviceClass) &#123; if (!httpClient.interceptors().contains(logging)) &#123; httpClient.addInterceptor(logging); builder.client(httpClient.build()); retrofit = builder.build(); &#125; return retrofit.create(serviceClass); &#125;&#125; 在这里有几个地方要注意。首先不要多次添加拦截器，我们通过 httpClient.interceptors().contains(logging)来判断是否已添加。第二，不要每次都在createService方法中 构建 retrofit对象，这样我们使用 ServiceGenerator的目的就失败了。 认证准备身份验证的要求略有不同。您可以在我们的基本身份验证，令牌身份验证，OAuth甚至Hawk身份验证教程中了解更多信息。因为每个身份验证实现的细节都有所不同，所以您可能需要更改ServiceGenerator。其中一个是您需要将额外参数传递给createService以创建客户端。 让我们看一下Hawk身份验证的示例： public class ServiceGenerator &#123; private static final String BASE_URL = \"https://api.github.com/\"; private static Retrofit.Builder builder = new Retrofit.Builder() .baseUrl(BASE_URL) .addConverterFactory(GsonConverterFactory.create()); private static Retrofit retrofit = builder.build(); private static HttpLoggingInterceptor logging = new HttpLoggingInterceptor() .setLevel(HttpLoggingInterceptor.Level.BODY); private static OkHttpClient.Builder httpClient = new OkHttpClient.Builder(); public static &lt;S&gt; S createService( Class&lt;S&gt; serviceClass, final HawkCredentials credentials) &#123; if (credentials != null) &#123; HawkAuthenticationInterceptor interceptor = new HawkAuthenticationInterceptor(credentials); if (!httpClient.interceptors().contains(interceptor)) &#123; httpClient.addInterceptor(interceptor); builder.client(httpClient.build()); retrofit = builder.build(); &#125; &#125; return retrofit.create(serviceClass); &#125;&#125; 我们的createService现在有了第二个参数HawkCredentials。如果传递非null值，它将创建必要的Hawk身份验证拦截器并将其添加到Retrofit客户端。我们还需要重建Retrofit以将我们的更改应用于接下来的请求。另外，您可能会在其他教程中看到ServiceGenerator略有不同的版本。别迷惑！我们建议您保持ServiceGenerator的纤薄并使用特定的使用场景。 错误处理当我们在一个请求中要检测是否成功返回的时候： call.enqueue(new Callback&lt;List&lt;GitHubRepo&gt;&gt;() &#123; @Override public void onResponse(Call&lt;List&lt;GitHubRepo&gt;&gt; call, Response&lt;List&lt;GitHubRepo&gt;&gt; response) &#123; if (response.isSuccessful()) &#123; Toast.makeText(ErrorHandlingActivity.this, \"server returned so many repositories: \" + response.body().size(), Toast.LENGTH_SHORT).show(); // todo display the data instead of just a toast &#125; else &#123; // error case switch (response.code()) &#123; case 404: Toast.makeText(ErrorHandlingActivity.this, \"not found\", Toast.LENGTH_SHORT).show(); break; case 500: Toast.makeText(ErrorHandlingActivity.this, \"server broken\", Toast.LENGTH_SHORT).show(); break; default: Toast.makeText(ErrorHandlingActivity.this, \"unknown error\", Toast.LENGTH_SHORT).show(); break; &#125; &#125; &#125; @Override public void onFailure(Call&lt;List&lt;GitHubRepo&gt;&gt; call, Throwable t) &#123; Toast.makeText(ErrorHandlingActivity.this, \"network failure :( inform the user and possibly retry\", Toast.LENGTH_SHORT).show(); &#125;&#125;); 这样做没有错，但是非常的低效。我们必须在我们的每个请求中进行这样的处理操作，到处进行复制粘贴。而当我们要改变遇到这样情况时的行为，就会变成一个噩梦。即使我们将这段逻辑放到一个中心方法类，您也必须记住在每个响应回调中调用此方法。 处理全局错误场景的最佳方法是在所有请求的一个中心位置处理它们：一个OkHttp拦截器。 全局错误处理: OkHttp Interceptor关于拦截器OkHttp Interceptors 拦截器是一种强大的机制，可以监视，重写和重试调用。下面这是一个简单的拦截器，记录传出请求和传入响应。 class LoggingInterceptor implements Interceptor &#123; @Override public Response intercept(Interceptor.Chain chain) throws IOException &#123; Request request = chain.request(); long t1 = System.nanoTime(); logger.info(String.format(\"Sending request %s on %s%n%s\", request.url(), chain.connection(), request.headers())); Response response = chain.proceed(request); long t2 = System.nanoTime(); logger.info(String.format(\"Received response for %s in %.1fms%n%s\", response.request().url(), (t2 - t1) / 1e6d, response.headers())); return response; &#125;&#125; 对chain.proceed（request）的调用是每个拦截器实现的关键部分。这种看起来很简单的方法是所有HTTP工作发生的地方，在这里产生满足请求的响应。 拦截器可以链式的。加入你有一个压缩拦截器和一个校验和拦截器，不可能会需要判断数据是否已被压缩，然后再进行校验和计算。OkHttp使用 List 来跟踪拦截器，拦截器按序调用。 应用拦截器拦截器一般会注册成为 应用拦截器 或者 网络拦截器。我们用上面定义的 LoggingInterceptor来表现他们的不同之处。 在 OkHttpClient.Builder 上调用 addInterceptor 来注册成为应用拦截器。 OkHttpClient client = new OkHttpClient.Builder() .addInterceptor(new LoggingInterceptor()) .build();Request request = new Request.Builder() .url(\"http://www.publicobject.com/helloworld.txt\") .header(\"User-Agent\", \"OkHttp Example\") .build();Response response = client.newCall(request).execute();response.body().close(); http://www.publicobject.com/helloworld.txt 重定向到了 https://publicobject.com/helloworld.txt，OkHttp会自动跟随重定向。我们的应用拦截器调用一次，然后 从 chain.proceed() 返回的响应拥有 重定向的信息： INFO: Sending request http://www.publicobject.com/helloworld.txt on nullUser-Agent: OkHttp ExampleINFO: Received response for https://publicobject.com/helloworld.txt in 1179.7msServer: nginx/1.4.6 (Ubuntu)Content-Type: text/plainContent-Length: 1759Connection: keep-alive 我们可以看到我们被重定向了，因为response.request().url() 与request.url()并不相同。 网络拦截器注册网络拦截器也很简单，只要调用addNetworkInterceptor()就OK了。 OkHttpClient client = new OkHttpClient.Builder() .addNetworkInterceptor(new LoggingInterceptor()) .build();Request request = new Request.Builder() .url(\"http://www.publicobject.com/helloworld.txt\") .header(\"User-Agent\", \"OkHttp Example\") .build();Response response = client.newCall(request).execute();response.body().close(); 运行的时候，拦截器会被调用两次。一次是在初始请求http://www.publicobject.com/helloworld.txt，另外一个是重定向后的请求https://publicobject.com/helloworld.txt。 INFO: Sending request http://www.publicobject.com/helloworld.txt on Connection&#123;www.publicobject.com:80, proxy=DIRECT hostAddress=54.187.32.157 cipherSuite=none protocol=http/1.1&#125;User-Agent: OkHttp ExampleHost: www.publicobject.comConnection: Keep-AliveAccept-Encoding: gzipINFO: Received response for http://www.publicobject.com/helloworld.txt in 115.6msServer: nginx/1.4.6 (Ubuntu)Content-Type: text/htmlContent-Length: 193Connection: keep-aliveLocation: https://publicobject.com/helloworld.txtINFO: Sending request https://publicobject.com/helloworld.txt on Connection&#123;publicobject.com:443, proxy=DIRECT hostAddress=54.187.32.157 cipherSuite=TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA protocol=http/1.1&#125;User-Agent: OkHttp ExampleHost: publicobject.comConnection: Keep-AliveAccept-Encoding: gzipINFO: Received response for https://publicobject.com/helloworld.txt in 80.9msServer: nginx/1.4.6 (Ubuntu)Content-Type: text/plainContent-Length: 1759Connection: keep-alive 网络请求还包含更多数据，例如OkHttp添加的Accept-Encoding：gzip标头，用于通告支持响应压缩。网络拦截器的链具有非空Connection，可用于询问用于连接到Web服务器的IP地址和TLS配置。","categories":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/tags/Java/"},{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"},{"name":"Retrofit","slug":"Retrofit","permalink":"https://gowa2017.github.io/tags/Retrofit/"}],"keywords":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}]},{"title":"android集成腾讯X5内核浏览office文件","slug":"android集成腾讯X5内核浏览office文件","date":"2018-08-08T13:08:34.000Z","updated":"2018-08-08T13:08:34.000Z","comments":true,"path":"Android/android集成腾讯X5内核浏览office文件.html","link":"","permalink":"https://gowa2017.github.io/Android/android集成腾讯X5内核浏览office文件.html","excerpt":"最近的情况是安卓本身没有什么打开docx文档的能力，而项目实在是需要这么一个功能，所以研究良久，还是打算集成一下腾讯的X5内核来打开office文件。网站上所说的，共享微信或者QQ的内核，但是说实话我是果然没有看到有共享的，不知道什么缘故。疑问留在后面，先看如何集成再说。","text":"最近的情况是安卓本身没有什么打开docx文档的能力，而项目实在是需要这么一个功能，所以研究良久，还是打算集成一下腾讯的X5内核来打开office文件。网站上所说的，共享微信或者QQ的内核，但是说实话我是果然没有看到有共享的，不知道什么缘故。疑问留在后面，先看如何集成再说。 sdk下载前往官方网站下载 sdk x5SDK下载。选择下载完整版。 Android Studio下载完后，压缩包内有一个集成示例，先把 .jar 文件复制放到我们项目的 app/libs 下面。 在 app/src/main/java 下建立目录 jniLibs/armeabi，把Demo内对应的 liblbs.so 文件复制过去。 然后，还要在build.gradle中的 defaultConfig加入如下代码： ndk &#123; abiFilters &quot;armeabi&quot;, &quot;armeabi-v7a&quot;, &quot;x86&quot;, &quot;mips&quot;&#125; 初始化在我们的 Application 内，要加入 初始化的代码： QbSdk.PreInitCallback cb = new QbSdk.PreInitCallback() &#123; @Override public void onViewInitFinished(boolean arg0) &#123; // TODO Auto-generated method stub //x5內核初始化完成的回调，为true表示x5内核加载成功，否则表示x5内核加载失败，会自动切换到系统内核。 Log.d(\"app\", \" onViewInitFinished is \" + arg0); &#125; @Override public void onCoreInitFinished() &#123; // TODO Auto-generated method stub &#125;&#125;;// 允许非wifi状态下载内核QbSdk.setDownloadWithoutWifi(true);//x5内核初始化接口QbSdk.initX5Environment(getApplicationContext(), cb); Docx 文档的读取我们建立一个 Activity 来展示 docx 文档。 布局布局文件如下： &lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;LinearLayout xmlns:android=\"http://schemas.android.com/apk/res/android\" xmlns:app=\"http://schemas.android.com/apk/res-auto\" xmlns:tools=\"http://schemas.android.com/tools\" android:layout_width=\"match_parent\" android:layout_height=\"match_parent\" android:orientation=\"vertical\" tools:context=\"cn.nanming.smartcompany.ui.activity.comregister.ComRegisterDocxViewActivity\"&gt; &lt;cn.nanming.smartcompany.ui.customview.MyActionBar android:layout_width=\"match_parent\" android:layout_height=\"wrap_content\" app:function=\"left_btn|title\" app:titleText=\"文书预览\" /&gt; &lt;FrameLayout android:id=\"@+id/fl_container\" android:layout_width=\"match_parent\" android:layout_height=\"match_parent\" /&gt;&lt;/LinearLayout&gt; 代码我们是利用了 X5中的 TbsViewer来战士docx文档的，这个只能在代码中动态添加，而不能在布局文件内指定。其需要一个 Activity 实例作为参数。 只支持本地文件，所以远程文件必须下载到本地后打开。 private FrameLayout mFrameLayout;private TbsReaderView mTbsReaderView;private String filePath;@Overrideprotected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); setContentView(R.layout.activity_com_register_docx_view); mFrameLayout = (FrameLayout) findViewById(R.id.fl_container); filePath = getIntent().getStringExtra(\"file\"); if (!TextUtils.isEmpty(filePath)) &#123; openFile(filePath); &#125;&#125;private void openFile(String path) &#123; mTbsReaderView = new TbsReaderView(this, new TbsReaderView.ReaderCallback() &#123; @Override public void onCallBackAction(Integer integer, Object o, Object o1) &#123; &#125; &#125;); //通过bundle把文件传给x5,打开的事情交由x5处理 Bundle bundle = new Bundle(); //传递文件路径 bundle.putString(\"filePath\", path); //加载插件保存的路径 bundle.putString(\"tempPath\", Environment.getExternalStorageDirectory() + File.separator + \"temp\"); //加载文件前的初始化工作,加载支持不同格式的插件 boolean b = mTbsReaderView.preOpen(\"docx\", false); if (b) &#123; mTbsReaderView.openFile(bundle); &#125; mFrameLayout.addView(mTbsReaderView);&#125;@Overrideprotected void onDestroy() &#123; super.onDestroy(); mTbsReaderView.onStop();&#125; 如上代码就能让我们展示传递过来的文件路径了。 结果 存在问题无法加载按照官方的说法，会优先共享 微信 QQ时使用的X5内核。但无法保证一定会这样。所以我想的是要让APP果然能自动进行下载内核。但一直没有方法，最后是从文件着手进行分析的。 经过一段时间的摸索，发现加载内核后会在 /data/data/cn.xxxx... 目录下生成一系列的 app_开头的目录。 app_dynamic_jar_outputapp_tbsapp_texturesapp_webview 当我把这个目录清空后，则会进行初始化（我把所有的QQ系的应用全删了）。 而我只是删除 app_tbs 目录的话，内核不会自动进行下载，初始化设备。 我猜想，在这个APP的某个地方，已经设置了一个标志位来表示内核已经下载了这样。但还未进行深入的研究。 对于代码写入表格无法显示在docx中，用Poi写入表格的行，无法显示出来。而用msword打开则是正常的。这应该是docx插件的问题，因为即使在手Q上也是无法打开。 我的解决办法是：先在表格内写入大量行，最后根据用了多少，把不用的给remove掉。","categories":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}],"tags":[{"name":"Word","slug":"Word","permalink":"https://gowa2017.github.io/tags/Word/"},{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"},{"name":"Docx","slug":"Docx","permalink":"https://gowa2017.github.io/tags/Docx/"},{"name":"X5","slug":"X5","permalink":"https://gowa2017.github.io/tags/X5/"},{"name":"Tbs","slug":"Tbs","permalink":"https://gowa2017.github.io/tags/Tbs/"}],"keywords":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}]},{"title":"英雄之旅","slug":"英雄之旅","date":"2018-08-06T05:11:40.000Z","updated":"2018-08-06T05:11:40.000Z","comments":true,"path":"Novel/英雄之旅.html","link":"","permalink":"https://gowa2017.github.io/Novel/英雄之旅.html","excerpt":"英雄之旅从本质上说，不论如何变化，英雄故事总是一段旅程。英雄离开舒适、平淡的地方，到充满挑战的陌生世界去冒险。它可以是外部之旅，去一个明确的地点：迷宫、森林、洞穴、陌生的城市或者国度————这个新的地域会成为英雄和反派及挑战者角力的竞挤场。","text":"英雄之旅从本质上说，不论如何变化，英雄故事总是一段旅程。英雄离开舒适、平淡的地方，到充满挑战的陌生世界去冒险。它可以是外部之旅，去一个明确的地点：迷宫、森林、洞穴、陌生的城市或者国度————这个新的地域会成为英雄和反派及挑战者角力的竞挤场。 而也有很多故事让英雄去经历一段内心之旅，在头脑、内心、精神领域里展开旅途。在所有精彩的故事中，英雄都会改变和成长，在旅途中改变自己的人生：从绝望到充满希望、变缺点为优点、由愚笨到智慧、由爱生恨再生爱。这些情感的旅程让故事变得好看，并且牢牢地吸引着观众。 英雄之旅的那些阶段在所有的类型的故事中都能找得到，不是仅限于那些“英雄式”的激烈行动和冒险。每一个故事的主角都是旅途中的英雄，即便路途只是延伸在他的脑海里，或者只在人际关系的空间里。 英雄之旅的每一站都会自然而然地出现，即便作者对它们并不熟知，但是，如果你对这个最古老的叙事入门有一些了解，你在发现问题和改进叙述方面会得到很大的帮助。把这十二个阶段当作英雄之旅的路线图吧。这只是抵达终点的诸多路径之一，但它绝对是最灵活最长久，最值得依赖的一条大路。 英雄之旅的阶段 正常世界 冒险召唤 拒斥召唤 见导师 越过第一道边界 考验、伙伴、敌人 接近最深的洞穴 磨难 报酬（掌握宝剑） 返回的路 复活 携万能药回归 英雄之旅模型英雄之旅1、正常世界大多数故事都让英雄从正常而平凡的世界进入一个崭新而陌生的非常世界。这种“离水之鱼”的思路启发了无数电影和电视剧。 如果你想刻画一条背井离水的鱼，你就得首先刻画它所在的正常世界，从而与它即将进入的离异世界之间产生鲜明的对比。 2、冒险召唤英雄必须面对问题、挑战、或者奇遇。一旦冒险召唤响起，它就无法无限期地赖在襁褓般的正常世界里。 也许大地正在面临衰竭，就像亚瑟王传说里寻找圣杯的情节一样，只有圣杯能治愈大地的创伤。在《星球大战》里面，冒险召唤是莉亚公主危急之中给老智者欧比旺·肯诺比发出的全息信号，通过他使卢克加入冒险。莉亚被达斯·维德抢走，就像希腊的春之女神珀耳塞福涅被冥王普路同抢到阴间一样，救回她对恢复宇宙的平衡至关重要。 3、拒斥召唤这个阶段关乎恐惧。在这个时点，英雄一般会在冒险的出发点犹豫不决、拒斥召唤或者表露迟疑。他毕竟正面对最强烈的恐惧——未知世界的恐惧。英雄在此时还没有全身心的投入冒险，他可能还在考虑要不要顺着原路退回去。需要有一些其他的影响使他度过这个恐惧的转折点，比如环境的变化、自然秩序进一步遭受侵犯或者来自导师的鼓励和支持。 4、导师（智慧的长者）在这个阶段开始之前，很多故事已经引入了一个巫师梅林（出自亚瑟王故事）式的角色——也就是英雄的导师。英雄和导师之间的关系是神话中最常见的主题之一，也是最具有象征意义的。它代表着父子、师生、医患和神人之间的关系。 导师可以以如下形象出现，年长而智慧的巫师（《星球大战》）、严厉的军事教官（《军官与绅士》）、或者两鬓斑白的拳击教练（《洛奇》），如果把电视剧《玛丽·泰勒·摩尔秀》看做神话，导师就是路·格兰特。在《大白鲨》里，导师则是罗伯特·肖饰演的那个鲨鱼通。 导师的功能是帮助英雄做好面对未知的准备。他们可以提供建议、指导或者魔法装备。《星球大战》里的欧比旺把卢克父亲的激光剑交给了他，他将在对原力的阴暗面时使用它。在《绿野仙踪》里，善良女巫葛琳达给多萝西提供了指引，并且给了她最终把她送回家的红宝石鞋子。 当然，导师的作用仅止于此。英雄归根结底还是要独自面对未知。导师只是经常需要在英雄的屁股后面温柔地踢上一脚，把他踹进未知的冒险中去。 5、越过第一道边界现在，英雄终于全身心的投入冒险了，并且越过第一道边界，第一次完全进入了故事中的非常世界。他准备好迎接冒险召唤中的问题或挑战。此时此刻，故事和冒险才真正地走起来了。热气球飞升，罗曼史开启，船帆乘风，飞机飞船升空，马车队出发轰隆轰隆。 6、考验、伙伴和敌人既然英雄已经越过了第一道边界，他自然而然地就要迎接新的挑战和考验，与他人成为伙伴或者敌人，并且开始熟悉非常世界里的规则。 7、接近最深的洞穴英雄终于来到了险境的边缘，比如幽深的地底、宝物的藏匿之所。一般来说，这里是英雄最大敌人的总部，非常世界里最危险的地点——最深的洞穴。英雄进入这个恐怖空间也就是越过了第二道边界。英雄一般都会在洞口做准备、做计划、用智慧战胜恶人手下的警卫，这就是“接近”阶段。 “接近”这一行动包含了所有的准备行动——为了进入的洞穴和迎接死亡威胁所做的准备。 8、磨难在这一阶段里，英雄直接面对他人生中最大的恐惧，他的命运坠入谷底。他在战斗中被敌对势力逼至死亡的边缘，不得不面对生死危局。磨难对于观众来说是一个“黑暗时刻”，我们被吊在悬念和紧张之中，难以预料英雄的生死。而英雄就像《圣经》里的约拿一般，“身陷鱼腹”，命运叵测。 磨难在所有的故事里都是至关重要的阶段，英雄在磨难中必须死去或貌似死去，以便他能获得重生。这是英雄神话散发出魔力的主要阶段，经历了故事前面那些阶段，观众已经对英雄和他的命运产生了认同感。发生在英雄身上的事情我们也会感同身受，故事催促着我们去和英雄一起经历在死亡边缘徘徊的时刻。我们的情感暂时被压抑，以便在英雄死而复生的时刻被激活，而激活的结果就是，我们感受到无比的兴奋和喜悦。 作为关键元素，磨难也出现在帮会或者秘密组织的入会、晋级仪式里。如会者被迫在某中恐怖的经历中体验死亡，而后体验复活——好似作为一个帮会新人获得了再生。所有故事的英雄其实都是被带去见识生死的入会者。 所有的故事都需要这样的一个生死时刻，让英雄和他的目标都陷入致命的危机。 9、报酬（掌握宝剑）经历了屠龙除魔和九死一生之后，英雄和观众完全有理由庆祝一番。英雄现在掌握了他一路追寻的宝物的所有权。宝物（或曰报酬）即可以是魔剑之类的奇异兵器，也可以是圣杯或者万能药之类能拯救大地衰竭的宝器。 作为报酬的“宝剑”也有可能是知识和经验，它能加深对敌对势力的理解，并且促成最终的和解。 在这个阶段，英雄和父母的矛盾也迎刃而解。 10、返回的路英雄和还没有衣锦还乡呢。我们这就要进入第三幕：英雄曾经在磨难中直面黑暗势力，现在要着手处理后事了。如果他尚未与父母、神灵或者敌对势力和解，他们或许会对他穷追不舍。一些经典的追逐场面就发生在这一阶段，英雄因为掌握了宝剑、万能药或者宝物而在返回的路上被复仇或者追击。 这一阶段标志着返回正常世界的决定。英雄认识到，非常世界到底不是久留之地，而前方仍然潜伏着危险、诱惑和考验。 11、复活在古代，猎人和战士在回到家园之前都必须接受净化，因为他们的双手沾满了鲜血。同理，经历过死亡之地的英雄在回到正常世界以前，必须在最终的死亡磨难和复活中获得重生和洗涤。 这一般都是第二个生死难测的时刻，几乎是阶段死亡与重生的在线。死亡和黑暗会在最终失败前孤注一掷。就像期末考试一样，英雄必须再接受一次考验，让大家看看他是不是真的在磨难里学到了了东西。 英雄因为这些死而复生的阶段而改变，他将有能力返回正常的生活，作为一个有新鲜见识的新人而重生。 12、携万能药回归英雄回到了正常世界，但如果他没有从非常世界带回万能药、宝物、或者教训，英雄之旅就是毫无意义的。万能药具有治疗的魔力，它可能像圣杯那样具有治疗大地衰竭的神奇功效，或者它只是一些知识和经历，在未来的某一天会对大家有所帮助。 万能药经常是旅途中赢得的宝物，但它也可以是爱情、自由、智慧或者知识——“有一个非常世界，可以从中生还”。有时候，万能药只是一个可以回家之后缓缓道来的故事。 如果在最深的洞穴磨难之中什么都没有带回来，英雄就命中注定要重复冒险。很多喜剧都有这样的结尾，傻瓜角色吃一堑不长一智，又做出了当初使他陷入窘境的同一件蠢事。 概括 英雄出场在正常世界里，在那里，-&gt; 他接到冒险召唤。 -&gt; 他起先会迟疑或者拒斥召唤，但是 -&gt; 他会受到导师的激励，从而 -&gt; 越过第一道边界而进入了非常世界，在那里， -&gt; 遇到了考验、伙伴和敌人。 -&gt; 他接近最深的洞穴，越过第二道边接， -&gt; 通过磨难。 -&gt; 他获得了报酬并且 -&gt; 在向正常世界返回的路上受到追逐。 -&gt; 他越过第三道边界，经历了复活，被经历所改变。 -&gt; 他带着实惠、宝物，或者携万能药回归，让正常世界受益。","categories":[{"name":"Novel","slug":"Novel","permalink":"https://gowa2017.github.io/categories/Novel/"}],"tags":[{"name":"Novel","slug":"Novel","permalink":"https://gowa2017.github.io/tags/Novel/"}],"keywords":[{"name":"Novel","slug":"Novel","permalink":"https://gowa2017.github.io/categories/Novel/"}]},{"title":"android中的canvas使用","slug":"android中的canvas使用","date":"2018-08-05T01:20:16.000Z","updated":"2018-08-05T01:20:16.000Z","comments":true,"path":"Android/android中的canvas使用.html","link":"","permalink":"https://gowa2017.github.io/Android/android中的canvas使用.html","excerpt":"canvas类中拥有 draw 调用。联系要绘制某些内容的话，需要四个组件：用来存储像素的bitmap，用来包含绘制调用的Canvas，绘制区域（如矩行，路径，文字，bitmap），以及一个画刷（用来定义绘制的颜色和风格）。","text":"canvas类中拥有 draw 调用。联系要绘制某些内容的话，需要四个组件：用来存储像素的bitmap，用来包含绘制调用的Canvas，绘制区域（如矩行，路径，文字，bitmap），以及一个画刷（用来定义绘制的颜色和风格）。 本章参考原文：https://guides.codepath.com/android/Basic-Painting-with-Views。 自定义一个Viewpublic class SimpleDrawingView extends View &#123; public SimpleDrawingView(Context context, AttributeSet attrs) &#123; super(context, attrs); &#125;&#125; 在我们的布局文件内加入这个自定义的View： &lt;hello.gowa.com.myapplication.customview.SimpleDrawingView android:layout_width=\"match_parent\" android:layout_height=\"wrap_content\" /&gt; 定义绘制定义画刷public class SimpleDrawingView extends View &#123; // setup initial color private final int paintColor = Color.BLACK; // defines paint and canvas private Paint drawPaint; public SimpleDrawingView(Context context, AttributeSet attrs) &#123; super(context, attrs); setFocusable(true); setFocusableInTouchMode(true); setupPaint(); &#125; // Setup paint with color and stroke styles private void setupPaint() &#123; drawPaint = new Paint(); drawPaint.setColor(paintColor); drawPaint.setAntiAlias(true); drawPaint.setStrokeWidth(5); drawPaint.setStyle(Paint.Style.STROKE); drawPaint.setStrokeJoin(Paint.Join.ROUND); drawPaint.setStrokeCap(Paint.Cap.ROUND); &#125;&#125; 重写onDraw函数@Overrideprotected void onDraw(Canvas canvas) &#123; canvas.drawCircle(50, 50, 20, drawPaint); drawPaint.setColor(Color.GREEN); canvas.drawCircle(50, 150, 20, drawPaint); drawPaint.setColor(Color.BLUE); canvas.drawCircle(50, 250, 20, drawPaint);&#125; 上面的代码，绘制了三个不同颜色的圆。形状的绘制，通过 Canvas里面的各种调用来实现的。 处理触摸事件如果现在我们想在每次用户触摸一下屏幕的时候，就在触摸的地方绘制一个圈，那我们就必须跟踪用户所触摸的每个点。在onTouch事件中我们可以获得这个坐标。： public class SimpleDrawingView extends View &#123; // setup initial color private final int paintColor = Color.BLACK; // defines paint and canvas private Paint drawPaint; // Store circles to draw each time the user touches down private List&lt;Point&gt; circlePoints; public SimpleDrawingView(Context context, AttributeSet attrs) &#123; super(context, attrs); setupPaint(); // same as before circlePoints = new ArrayList&lt;Point&gt;(); &#125; // Draw each circle onto the view @Override protected void onDraw(Canvas canvas) &#123; for (Point p : circlePoints) &#123; canvas.drawCircle(p.x, p.y, 5, drawPaint); &#125; &#125; // Append new circle each time user presses on screen @Override public boolean onTouchEvent(MotionEvent event) &#123; float touchX = event.getX(); float touchY = event.getY(); circlePoints.add(new Point(Math.round(touchX), Math.round(touchY))); // indicate view should be redrawn postInvalidate(); return true; &#125; private void setupPaint() &#123; // same as before drawPaint.setStyle(Paint.Style.FILL); // change to fill // ... &#125;&#125; 根据路径绘制Path类可以包含多个线条，轮廓甚至其他形状。我们添加一个Path 变量来跟踪我们的绘制： public class SimpleDrawingView extends View &#123; private Path path = new Path(); // Get x and y and append them to the path public boolean onTouchEvent(MotionEvent event) &#123; float pointX = event.getX(); float pointY = event.getY(); // Checks for the event that occurs switch (event.getAction()) &#123; case MotionEvent.ACTION_DOWN: // Starts a new line in the path path.moveTo(pointX, pointY); break; case MotionEvent.ACTION_MOVE: // Draws line between last point and this point path.lineTo(pointX, pointY); break; default: return false; &#125; postInvalidate(); // Indicate view should be redrawn return true; // Indicate we've consumed the touch &#125; // ...&#125; 在onDraw中进行绘制路径： public class SimpleDrawingView extends View &#123; // ... onTouchEvent ... // Draws the path created during the touch events @Override protected void onDraw(Canvas canvas) &#123; canvas.drawPath(path, drawPaint); &#125; private void setupPaint() &#123; // same as before drawPaint.setStyle(Paint.Style.STROKE); // change back to stroke // ... &#125;&#125; 后面的效果类似于手写字一样。 用 bitmap缓存来提高效率当在 canvas上绘制的时候，可以将图片缓存到 bitmap 来大大的提高效率。","categories":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"}],"keywords":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}]},{"title":"git-svn来管理svn仓库","slug":"git-svn来管理svn仓库","date":"2018-08-03T04:44:57.000Z","updated":"2018-08-03T04:44:57.000Z","comments":true,"path":"Git/git-svn来管理svn仓库.html","link":"","permalink":"https://gowa2017.github.io/Git/git-svn来管理svn仓库.html","excerpt":"个人是比较喜欢Git的，至于说svn与git熟优熟劣，这个见仁见智，不过对于代码管理而言，svn会省很多事情，但是对于分支开发来说，git确实要好用点。公司开始就使用svn，我也只能去习惯，所以我打算用git来管理svn代码。这不，看一下关于git-svn的文档来了解一下。","text":"个人是比较喜欢Git的，至于说svn与git熟优熟劣，这个见仁见智，不过对于代码管理而言，svn会省很多事情，但是对于分支开发来说，git确实要好用点。公司开始就使用svn，我也只能去习惯，所以我打算用git来管理svn代码。这不，看一下关于git-svn的文档来了解一下。 本页面原文：https://git-scm.com/docs/git-svn#git-svn-svnuseSvmProps git svn 命令描述git svn是 git 与 svn 之间的转换通道。其在git,svn之间提供了一个双向的通道。 git svn 可以跟踪一个标准的 遵循 trunk/branches/tags 布局结构的svn 版本库（通过 —stdlayout 选项指定）。其也可以跟踪其他以 -T/-t/-b指定的布局。在下面的init命令我们会看到。 一旦 跟踪了一个版本库后，本地的Git版本库就可以 fetch 从svn 库拖代码下来，而svn版本库可以通过git命令 dcommit 命令进行更新。 使用参考init初始化一个空的Git版本库，但会有额外的 git svn需要的元数据。svn版本库的URL可以被当做一个命令行参数传递，或作为 -T/-t/-b 的参数。可选地，目标目录可以被指定为第二个命令行参数。通常，这个命令初始化当前目录。-T\\—trunk=\\-t\\—tags=\\-b\\—branches=\\-s, —stdlayout上面这些参数对于init来说都是可选的。这其中的每个参数都可指向相对于版本库内的相对路径（—tags=project/tags），或者一个完整地址（—tags=https://foo.org/project/tags）。 当svn版本库将 tags 或 branches放到多个路径时，可以指定一个或多个 --tags, --branchs。--stdlayout是把 tags,branches,trunk设置为相对路径（svn默认方式）的简写。其他选项的优先级高于--stdlayout。 当init执行后，在.git/config文件内，会有一个 svn-remote的节点。 [svn-remote &quot;svn&quot;] url = svn://guan.isum.cn/smart/nanming/code/smartpeople/android/SmartConsumer fetch = :refs/remotes/git-svn —no-metadata 在上面的节点内设置 noMetadata 选项。一个不推荐的设置。阅读本页面的 svn.noMetadata 一节的内容来查看更多细节。 —use-svm-propsSet the useSvmProps option in the [svn-remote] config. —use-svnsync-propsSet the useSvnsyncProps option in the [svn-remote] config. —rewrite-root=\\Set the rewriteRoot option in the [svn-remote] config. —rewrite-uuid=\\Set the rewriteUUID option in the [svn-remote] config. —username=\\ 为传递需要svn处理的认证信息，指定用户名。对于其他传输（如 ssh+svn），必须在URL内包含用户名。 —prefix=\\ 如果指定了trunk/branches/tags，此选项允许指定一个放在远程地址前的前缀。这个前缀不会自动包含一个/，需要我们手动加上。如果--branches/-b已经指定，那么这个前缀必须包含一个拖尾的/。强烈建议在任何时候都使用带有/的前缀，这样SVN跟踪的引用会被定位到refs/remotes/$prefix/，这与git本身的对于远程跟踪引用的布局兼容refs/remotes/$remote/。对于在同一个共用的资源库内跟踪多个不同的项目时使用一个前缀也很有用。默认情况下， 前缀设置为 origin/。 在git 2.0前，默认的前缀是 &quot;&quot;（无前缀）。这就意味着SVN跟踪的引用是放在refs/remotes/*，这与现在的git自身的跟踪布局并不兼容。如果为了与以前的模式相兼容的话，传递一个空的前缀&quot;&quot;。 —ignore-refs=\\ 当把这个表达式传递给 clone, init时，这个表达式会被保留为一个配置使用的键。查看 fetch 一节中关于 —ignore-refs的描述。 —ignore-paths=\\ 描述同上，具体作用查看后面的章节。 —include-paths=\\ 描述同上，具体作用查看后面的章节。 —no-minimize-url 当跟踪多个目录时（通过 --stdlayout, --branches, --tags选项），git svn会尝试连接到svn库的根目录下。这种方式在整个库都被移动的时候对于跟踪历史信息很有用，但在读权限限制的时候这可能会出现些问题。--no-minimize-url可以取消这个默认的做法。默认情况下这个选项是关闭的。 fetch从版本库拉取我们跟踪，但是本地没有的代码。这个操作会根据需要自动更新rev_map。（在后面的 File 一节查看 $GIT_DIR/svn/*/.rev_map.**） —localtime 以本地时区来存储 commint 时间，而不是以UTC时间。这会让 git log（即使没有 date=local）也会显示来与 svn log时间一致（svn log 使用的是本地时区时间）。 —parent 只从版本库获取当前 HEAD。—ignore-refs=\\ 忽略匹配这个给定的表达式的tags或 branches。 ^refs/remotes/origin/(?!tags/wanted-tag|wanted-branch).*$ 可以用来允许指定的引用。 config key: svn-remote.&lt;name&gt;.ignore-refs 如果 忽略引用的键已经设置，同事命令行参数也有指定，那么两个地方的值都会被使用。 —ignore-paths=\\ 每次都会忽略这个选项指定的路径。 config key: svn-remote.&lt;name&gt;.ignore-paths 这个选项在命令行和配置文件内指定都有。 clone相当于 init 后执行 fetch命令 rebase从SVN 获取当前HEAD的版本，同时变换基准工作位置到对应的revision（这不会提交到 SVN）。 这个命令与 svn update或 git pull，例外的是它使用git rebase而不是git merge来保留线性历史记录，以便于使用git svn进行dcommitting。 此命令接受所有 git svn fetch， git rebase接受的选项。然而，--fetch-all只会从当前的 [svn-remote]节点获取，而不是所有的 [svn-remote]节点。 和 git rebase类似，这个操作要求工作树是干净的，同时没有任何为提交的变更。 如果有必要的话，这个操作会自动的更新 rev_map。 -l, —local 不从远程获取；只是在之前从 SVN 库内获取的最新 提交上执行 git rebase。 dcommit把当前分支上的不同直接提交到 SVN 库内，接着会 rebase 或 reset（这依赖于SVN和head间是否有变更）。git中的每个commit都会在svn中创建一个 revision。 当一个可选的 git 分支名称（或一个 git 提交对象名称）指定的时候，下面的子命令工作在对应的分支上，而不是工作在当前分支上。 —no-rebase 在提交后，不要 rebase or reset。 —commit-url \\ branch在SVN内创建一个分支。 -m, —message 提交一个描述信息。 -t, —tag 使用 tags_subdir 而不是 branches_subdir来建立一个tag（这两个dir都是在 init 命令中指定的）。 -d\\,—destination=\\ 在init, clone的时候，如果指定了多于一个的 —branches, —tags，必须要指定要创建分支（标签）的位置。用以下命令可以查看所有引用的分支或标签： git config --get-all svn-remote.&lt;name&gt;.branchesgit config --get-all svn-remote.&lt;name&gt;.tags 其中 \\ 是 SVN 版本库的名称，在init的时候，由 -R指定（默认情况下是 svn）。 —username 指定本次提交的用户名。 —commit-urlUse the specified URL to connect to the destination Subversion repository. This is useful in cases where the source SVN repository is read-only. This option overrides configuration property commiturl. git config --get-all svn-remote.&lt;name&gt;.commiturl —parentsCreate parent folders. This parameter is equivalent to the parameter —parents on svn cp commands and is useful for non-standard repository layouts. tag创建标签，这个等于 branch -t log查看日志。对于 svn log 命令的特性被支持： -r \\[:\\],—revision=\\[:\\] 还有些非数字的参数：HEAD, NEXT, BASE, PREV。 —limit=\\ —incremental 新特性： —show-commit —oneline blamefind-revset-treecreate-ignoreshow-ignoremkdirscommit-diffinfoproplistpropgetpropsetshow-externalsgcreset选项 —shared[=(false|true|umask|group|all|world|everybody)] —template= -r , —revision -stdin —rmdir -e, —edit -l num, —find-copies-harder -A , —authors-file= —authors-prog= -q, —quiet -m, —merge -s, —strategy= -p, —preserve-merges -n, —dry-run —use-log-author —add-author-from 高级选项 -i, —id -R, —svn-remote —follow-parent CONFIG FILE-ONLY OPTIONS svn.noMetadata, svn-remote..noMetadata BASIC EXAMPLESHANDLING OF SVN BRANCHESCAVEATSBUGSCONFIGURATIONFILES","categories":[{"name":"Git","slug":"Git","permalink":"https://gowa2017.github.io/categories/Git/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://gowa2017.github.io/tags/Git/"},{"name":"Svn","slug":"Svn","permalink":"https://gowa2017.github.io/tags/Svn/"}],"keywords":[{"name":"Git","slug":"Git","permalink":"https://gowa2017.github.io/categories/Git/"}]},{"title":"ssh代理隧道","slug":"ssh代理隧道","date":"2018-08-02T15:19:57.000Z","updated":"2018-08-02T15:19:57.000Z","comments":true,"path":"Linux/ssh代理隧道.html","link":"","permalink":"https://gowa2017.github.io/Linux/ssh代理隧道.html","excerpt":"内网穿透，隧道，这些个东西，听得也非常久了，但是会真的了解这到底是什么原理么？我是喜欢寻根究底的人，所以就只能是仔细了解一下了。之前就看过 TCP/IP 详解的第二版，第七章对防火墙与nat有一定的描述。","text":"内网穿透，隧道，这些个东西，听得也非常久了，但是会真的了解这到底是什么原理么？我是喜欢寻根究底的人，所以就只能是仔细了解一下了。之前就看过 TCP/IP 详解的第二版，第七章对防火墙与nat有一定的描述。 缘由由于IPv4地址其实是不够用的，而在没有完全迁移到IPv6的情况下，就出现了nat这么一个临时的解决方案，但这个技术出现的结果却是延缓了IPv6的推广与使用。 运营商不会为每个用户分配一个公网地址，而是只会在一个NAT设备上分配一个或多个地址，然后对NAT下面的设备分配的是内网地址。 很简单的一个道理，你看一下你自己家路由器上的地址，电信一般是 100.64.x.x ，而联通一般是 10.x.x.x 这样的，都是其内部的地址。但是你访问外网的时候你会发现你地址变了。上类似于 ip138.com ip.cn 这样的网站就能看到自己的地址了 nat的类型nat的类型有多种，最为常见的，就是基于端口+IP的映射。其基本原理，就是在nat 后面的设备主动发起网络访问的时候，会记录 nat 下设备的内网ip 和发起访问的端口。那么，这个ip+端口可以唯一的标识，整个内网中的服务；nat 设备会对此进行记录。 过程例如，假入我的设备 ip 是 192.168.0.2，nat 上设置了一个公网ip 222.222.222.222。当我访问网站 www.baidu.com的时候，我的本来报文是 192.168.0.2:port 的源地址，会被记录在nat 设备上，同时把报文 修改为 222.222.222.222:port 这样的源地址。 当返回报文的目标地址是 222.222.222.222:port 的时候，就会根据查询到的 nat 记录来进行报文的转发。 而为什么很多时候我们在自己的机器上开了对应的服务，外部访问不到，就是因为无法在 nat 上找到对应的映射记录。 穿透问题的难点就是在于，让nat 设备记录一下我们的开放的服务。 当我们主动访问一个外部地址的时候，nat设备会记录我们的 ip:port，之后，就能进行交互通信。那么，如果我们以 ip:port 发起访问的服务，收到返回的数据后，转交到我们正常开放的服务，那不就恰好可以满足我们的要求了么。 原理就是这么简单。 SSH 反向代理所谓反向代理，指的是，由被访问端请求代理服务器的 sshd 为自己进行代理服务。 在这样的场景下，被访问端的 ssh 是一个 client，而 代理服务器的 sshd 是一个 server。 代理的请求，由被访问端来发起。 前提对于反向代理而言，其是通过被访问端与代理服务器间的 ssh 连接来进行数据的传输的，这也叫作隧道。 SSH 命令选项ssh 支持诸多的选项来控制其行为，例如： -L(local) 基本形式是[bind_address:]port:host:hostport这个选项指定，到本地[bind_address:}port的连接，会被转发到远程主机 host:hostport。这通过分配一个套接字（socket）在本地监听一个 tcp 端口，且能绑定一个本地地址或unix域套接字来实现。当连接到本地的时候 [bind_address:]port的时候，连接会通过隧道转发到远程主机上，同时远程主机会连接的 host:hostport。 -R(remote) 基本形式是[bind_address:]port:host:hostport。这个选项指定，连接到远程主机[bind_address:]port的连接，都会被转发到本地的 host:hostport 上。这通过给远程主机上分配一个套接字监听在 port 上实现。当一个连接到达远程主机的 port时，连接会通过通过安全隧道传输到ssh client，而ssh client会连接到本地的 host:hostport。 -D(daemon) 基本形式是 [bind_address]:port。用以指定一个本地的，动态的应用层的转发端口。这会在本地监听一个套接字，一旦有此监听的套接字建立连接，就会通过此隧道进行数据转发。当前支持的是 SOCKS4,SOCKS5协议。 -f 后台运行 -C 压缩 -N 不执行远程命令 实例现在，我有一台安卓手机，有一台公网服务器111.111.111.111。手机用的是移动网络上网，但是我想远程连接其开启的 8022 端口，我该怎么办？ 其实非常的简单，在安卓主机上执行： ssh -NR 8022:localhost:8022 111.111.111.111 这个命令的意思，是请求远程主机 111.111.111.111 把所有连接到 其 8022 端口的连接，都转发到 我们执行命令的安卓主机上的 8022 端口。 整个过程其实是这样： 首先在我们的安卓手机开启 sshd 服务，监听8022端口。 安卓手机通过 ssh 命令作为 client 连接111.111.111.111 主机（通过 ssh 协议 22端口，sshd服务） 111.111.111.111 收到ssh 发来的命令后，会开启8022端口监听。 数据到达 111.111.111.111 的8022端口，则会通过 把数据传到ssh client上。 ssh client 连接安卓手机上开启的 8022 端口。 整个过程就这样完成了。其上，大可不必纠结于端口与服务的名称。反正只要知道一个问题就是，想要实现穿透， 首先，内网机器要与外网机器建立联系。 然后，外网机器为内网机器监听一个端口。 内网机器开启自己的服务监听端口 外网机器把监听端口获取的数据传给内网机器的客户端。 内网机器客户端把数据转交给本地服务。 ssh socks 代理单纯的把 ssh 用做一个 socks 代理服务器也是可以的。例如当我有一台双网卡的机器 A 172.230.0.28/58.16.22.138。我现在想访问 B 172.230.0.30 机器上的 http 服务。直接访问肯定是不行的。 首先我们开一个代理： ssh -ND :8888 user@A 我们可以用 curl 开测试一下： curl -x socks://localhost:8888 http://172.230.0.30/main/ 果然是能正常访问的。 补充有的时候，开启反向代理，会发现无论怎么设置，其监听的IP 都是 127.0.0.1，这个需要我们对 sshd 服务进行配置： GatewayPorts yes","categories":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/tags/Linux/"},{"name":"SSH","slug":"SSH","permalink":"https://gowa2017.github.io/tags/SSH/"}],"keywords":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}]},{"title":"利用poi对docx文档进行加密","slug":"利用poi对docx文档进行加密","date":"2018-07-29T04:30:45.000Z","updated":"2018-07-29T04:30:45.000Z","comments":true,"path":"Java/利用poi对docx文档进行加密.html","link":"","permalink":"https://gowa2017.github.io/Java/利用poi对docx文档进行加密.html","excerpt":"事情的起因是，公司业务上对于某一类型的文书是在客户端生成，然后上传到服务器，openoffice转换成pdf文书，然后展示给用户。以避免用户对文书进行的修改。而，docx模板替换后生成的文书，转换成pdf后会丢失格式。最为明显的是，对于图片进行旋转后，docx显示正常，而openoffice无效果的问题。","text":"事情的起因是，公司业务上对于某一类型的文书是在客户端生成，然后上传到服务器，openoffice转换成pdf文书，然后展示给用户。以避免用户对文书进行的修改。而，docx模板替换后生成的文书，转换成pdf后会丢失格式。最为明显的是，对于图片进行旋转后，docx显示正常，而openoffice无效果的问题。 解决方案最终，协商出一个折衷的方法，就是对docx文档进行加密，这样展示的话就没有什么问题了。虽然这并不能避免进行复制后到其他地方进行操作，但也是最快捷的解决办法了。 加密级别对文档的加密有好几个级别， 文档的访问限制 文档的修改限制 文档内部分内容的修改限制 POI的实现文档的修改限制这个级别的加密，用户想要修改必须输入正确的密码才能继续修改，而且POI实现起来也比较简单： try &#123; XWPFDocument document = new XWPFDocument(); document.createParagraph().createRun().setText(\"此文档禁止修改\"); OutputStream os = new FileOutputStream(\"test.docx\"); document.enforceReadonlyProtection(\"foobar\", HashAlgorithm.md5); document.write(os); os.close();&#125; catch (Exception e)&#123; System.out.println(e.getMessage()); e.printStackTrace();&#125; 这样加密了以后，文档打开阅览没有问题，但是一旦需要修改就要求输入密码了。 文档访问加密这个级别的加密，打开文件都需要输入密码。密码错误则无法打开。我们用上面的文档来进行加密。 POIFSFileSystem fs = new POIFSFileSystem(); EncryptionInfo info = new EncryptionInfo(EncryptionMode.agile);// EncryptionInfo info = new EncryptionInfo(EncryptionMode.agile, CipherAlgorithm.aes192, HashAlgorithm.sha384, -1, -1, null); Encryptor enc = info.getEncryptor(); enc.confirmPassword(\"foobaa\");// Read in an existing OOXML file try &#123; OPCPackage opc = OPCPackage.open(new File(\"test.docx\"), PackageAccess.READ_WRITE); OutputStream os = enc.getDataStream(fs); opc.save(os); opc.close();// Write out the encrypted version FileOutputStream fos = new FileOutputStream(\"docx_e.docx\"); fs.writeFilesystem(fos); fos.close(); &#125; catch (Exception e)&#123; System.out.println(e.getMessage()); e.printStackTrace(); &#125; 这样操作过后，打开文档就需要输入密码，否则打开失败。 同时，我们可以看到，我们可以使用不同的密码来进行不同级别的加密限制。 部分内容的修改限制这个级别的加密，可以使有的部分可以修改，有的内容禁止修改。我们使用对文件整体修改的例子上，对部分内容不加限制的代码如下： try &#123; XWPFDocument document = new XWPFDocument(); document.createParagraph().createRun().setText(\"此文档禁止修改\");// 注意这里 CTPermStart ctPermStart = document.getDocument().getBody().addNewPermStart(); ctPermStart.setEdGrp(STEdGrp.EVERYONE); ctPermStart.setId(\"123456\"); //note the Id document.createParagraph().createRun().setText(\"此处可以修改\"); document.getDocument().getBody().addNewPermEnd().setId(\"123456\"); //note the same Id// 注意 setId。 OutputStream os = new FileOutputStream(\"test.docx\"); document.enforceReadonlyProtection(\"foobar\", HashAlgorithm.md5); document.write(os); os.close(); &#125; catch (Exception e)&#123; System.out.println(e.getMessage()); e.printStackTrace(); &#125; &#125; 如此之后，我们可以发现，后面的这句文字可以修改，而其他的都不能修改。","categories":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/tags/Java/"},{"name":"Word","slug":"Word","permalink":"https://gowa2017.github.io/tags/Word/"},{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"},{"name":"Docx","slug":"Docx","permalink":"https://gowa2017.github.io/tags/Docx/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}]},{"title":"openoffice-XML-生成word中的图片","slug":"openoffice-XML-生成word中的图片","date":"2018-07-22T12:49:43.000Z","updated":"2018-07-22T12:49:43.000Z","comments":true,"path":"Java/openoffice-XML-生成word中的图片.html","link":"","permalink":"https://gowa2017.github.io/Java/openoffice-XML-生成word中的图片.html","excerpt":"","text":"事情的需求是这样的，用poi来生成文书的，需要在里面插入图片，正常的情况下是没有问题的，但是对于一个是横向的图片（宽&gt;高）的，要 在A4纸上打印出来就非常的丑陋了，要实现将图片进行旋转，并且居中，缩放的操作这个可难到我了。使用的是poi来进行生成，然后用Openoffice来转换为pdf，很明显openOffice对某些支持不不是很好。但依然 还是要了解一下图片，在Word内是怎么样表示的。 前言图片，图标，形状等等，在word中都是以 DrawingML 来表示的一个可绘制的对象。在一个WordprocessingML中，有可能包含几种图形对象： 图片 已锁定的画布 流程图 图表 当这些对象要出现在 WordprocessingML 文档时，必须包含指定对象在文档页面中的放置位置信息。如：对象是在行内还是锚定了一个位置。 WordprocessingML Drawing 命令空间实现了这些能力，包含了所有用来锚定和显示 DrawingML 对象的信息。 anchor下面的例子显示了一个居中显示的图片的xml代码： &lt;w:r&gt; &lt;w:drawing&gt; &lt;wp:anchor relativeHeight=\"10\" allowOverlap=\"true\"&gt; &lt;wp:positionH relativeFrom=\"margin\"&gt; &lt;wp:align&gt;center&lt;/wp:align&gt; &lt;/wp:positionH&gt; &lt;wp:positionV relativeFrom=\"margin\"&gt; &lt;wp:align&gt;center&lt;/wp:align&gt; &lt;/wp:positionV&gt; &lt;wp:extent cx=\"2441542\" cy=\"1828800\"/&gt; &lt;wp:wrapSquare wrapText=\"bothSides\"/&gt; &lt;a:graphic&gt; ... &lt;/a:graphic&gt; &lt;/wp:anchor&gt; &lt;/w:drawing&gt; &lt;/w:r&gt; anchor 元素，说明，这个对象不会放在文本行内，而anchor的子元素则说明，这个对象居会垂直居中和水平居中，且文本可以以方形环绕它。 anchor 包含了下面这些子元素 positionH (Horizontal Positioning)指定浮动绘制对象在文档中的水平位置。位置有两部分来指定 基准位置 —— 此元素的relativeFrom属性指定应该从文档的哪个部分来进行计算。 计算位置 —— 子元素的子元素align or posOffset，指定距离基准位置的何处。 此元素的XML代码定义如下： &lt;complexType name=\"CT_PosH\"&gt; &lt;sequence&gt; &lt;choice minOccurs=\"1\" maxOccurs=\"1\"&gt; &lt;element name=\"align\" type=\"ST_AlignH\" minOccurs=\"1\" maxOccurs=\"1\"/&gt; &lt;element name=\"posOffset\" type=\"ST_PositionOffset\" minOccurs=\"1\" maxOccurs=\"1\"/&gt; &lt;/choice&gt; &lt;/sequence&gt; &lt;attribute name=\"relativeFrom\" type=\"ST_RelFromH\" use=\"required\"/&gt; &lt;/complexType&gt; 下面的代码指定了一个位于页面中的元素： &lt;wp:anchor ... &gt; &lt;wp:positionH relativeFrom=\"margin\"&gt; &lt;wp:align&gt;center&lt;/wp:align&gt; &lt;/wp:positionH&gt; &lt;wp:positionV relativeFrom=\"margin\"&gt; &lt;wp:align&gt;center&lt;/wp:align&gt; &lt;/wp:positionV&gt; &lt;/wp:anchor&gt; 属性relativeFrom(Horizontal Position Relative Base)这个指定基准位置，可能的值由 ST_RelFromH简单类型定义。 ST_RelFromH (Horizontal Relative Positioning) character (Character) column (Column) insideMargin (Inside Margin) leftMargin (Left Margin) margin (Page Margin) outsideMargin (Outside Margin) page (Page Edge) rightMargin (Right Margin) xml定义如下: &lt;simpleType name=\"ST_RelFromH\"&gt; &lt;restriction base=\"xsd:token\"&gt; &lt;enumeration value=\"margin\"/&gt; &lt;enumeration value=\"page\"/&gt; &lt;enumeration value=\"column\"/&gt; &lt;enumeration value=\"character\"/&gt; &lt;enumeration value=\"leftMargin\"/&gt; &lt;enumeration value=\"rightMargin\"/&gt; &lt;enumeration value=\"insideMargin\"/&gt; &lt;enumeration value=\"outsideMargin\"/&gt; &lt;/restriction&gt; &lt;/simpleType&gt; 子元素align (Relative Horizontal Alignment)指定水平对齐。 下面这个例子，表明这个对象会对齐在页面的左，上。 ```xml left&lt;/wp:align&gt; &lt;/wp:positionH&gt; … &lt;/wp:anchor&gt;可用值：* left Left Alignment* right Right Alignment* center Center Alignment* inside Inside* outside Outside#### posOffset (Absolute Position Offset)## positionV (Vertical Positioning)和 positionH 一样要指定计算基准位置，偏移参数。```xml&lt;complexType name=&quot;CT_PosV&quot;&gt; &lt;sequence&gt; &lt;choice minOccurs=&quot;1&quot; maxOccurs=&quot;1&quot;&gt; &lt;element name=&quot;align&quot; type=&quot;ST_AlignV&quot; minOccurs=&quot;1&quot; maxOccurs=&quot;1&quot;/&gt; &lt;element name=&quot;posOffset&quot; type=&quot;ST_PositionOffset&quot; minOccurs=&quot;1&quot; maxOccurs=&quot;1&quot;/&gt; &lt;/choice&gt; &lt;/sequence&gt; &lt;attribute name=&quot;relativeFrom&quot; type=&quot;ST_RelFromV&quot; use=&quot;required&quot;/&gt;&lt;/complexType&gt; ST_RelFromH margin Page Margin page Page Edge paragraph Paragraph line Line topMargin Top Margin bottomMargin Bottom Margin insideMargin Inside Margin outsideMargin Outside Margin align 可用值 top Top bottom Bottom center Center Alignment inside Inside outside Outside","categories":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/tags/Java/"},{"name":"Word","slug":"Word","permalink":"https://gowa2017.github.io/tags/Word/"},{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}]},{"title":"android使用poi生成文书出错解决","slug":"android使用poi生成文书出错解决","date":"2018-07-20T01:04:40.000Z","updated":"2018-07-20T01:04:40.000Z","comments":true,"path":"Java/android使用poi生成文书出错解决.html","link":"","permalink":"https://gowa2017.github.io/Java/android使用poi生成文书出错解决.html","excerpt":"本来事情一切正常，使用的是poi来生成docx的文档。但是偶然间不知道在什么版本的时候，生成的时候会报错。提示是某个类没有实现List接口，但是非常明显的，之前都正常，并没有做什么特别的操作为什么会出现这样的问题呢？","text":"本来事情一切正常，使用的是poi来生成docx的文档。但是偶然间不知道在什么版本的时候，生成的时候会报错。提示是某个类没有实现List接口，但是非常明显的，之前都正常，并没有做什么特别的操作为什么会出现这样的问题呢？ 具体情况java.lang.IncompatibleClassChangeError: Class &apos;org.apache.xmlbeans.impl.store.Cur&apos; does not implement interface &apos;java.util.List&apos; in call to &apos;int java.util.List.size()&apos; (declaration of &apos;org.apache.xmlbeans.impl.store.Saver&apos; appears in /data/app/cn.nanming.smartenterprise-lkfuXmBwdO_QyMt5K6sRdg==/base.apk!classes3.dex) 就是这么一句简单的描述，app就挂了，按照字面意思，说的是Cur类并没有实现 List.size() 接口，但为什么之前都是正常的呢？ 更坑爹的是，debug版本的apk文件没有任何问题，release版本的 开启允许 debug的版本也没有问题，压根就无法找出问题。 第一次猜测通过对比前一版本正常的apk包来进行了对比，发现对于正常的包，所有的 xmlbeans 的类是封装在 class2.dex 内的，而不正常的包就封装分别把类打包在了 class2.dex/class2.dex/class2.dex 内。才出现这样的问题。 我怀疑是不是分包的问题，但是百度良久依然没有发现什么有价值的解决办法。我们可以保存在 主 class.dex内的类，但是却无法分别指定某些类归属于哪个包的。 最终放弃了这个办法。 第二次猜测在谷歌上找到的相关问题症状，显示的都是因为重复类导致的。但通过在idea来寻找，并没有发现重复的类。而通过 包依赖来分析，依然也没有发现重复的不同版本的依赖。 第三种猜测昨天偶然的时候，看到在 libs 下有两个jar包，一个是 poi-shadow， 一个是 poi-scratchpad-3.17-beta1.jar，而查阅 poi.apache.org 发现，后一个包是针对操作 2003格式的文档的，而我操作的是 2007 文档，有ooxml就够了于是就把它删除了，之后重新编译，居然就OK了。 最终但我却依然无法知道具体是什么情况，导致了这样的错误发生。","categories":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/tags/Java/"},{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}]},{"title":"vnc在CentOS的开启相关知识","slug":"vnc在CentOS的开启相关知识","date":"2018-07-18T02:02:22.000Z","updated":"2018-07-18T02:02:22.000Z","comments":true,"path":"Linux/vnc在CentOS的开启相关知识.html","link":"","permalink":"https://gowa2017.github.io/Linux/vnc在CentOS的开启相关知识.html","excerpt":"","text":"自己用才MAC，但是公司用的VPN是网御星云的，必须在windows下用，但是服务器配置还可以，单独用的话有点浪费。于是装了CentOS，KVM布置了一个虚拟机，然后准备开启VNC来支持。另外，所使用的idea也需要在图形化的界面下进行调试，也需要开启VNC。 原理简单来说，就是我们在服务器上启动一个 vnc服务器，CentOS的叫做 Xvnc，此服务器会接受我们 我们的连接，然后监控窗口系统的信息发送给我们，再把我们的操作反馈到服务器的窗口信息。 所以，使用 vnc 的前提是，我们开启了窗口系统，怎么开启，这里不赘述，自行谷歌。 安装先安装 gnome 桌面环境: yum groupinstall &quot;GNOME Desktop&quot; CentOS上的安装，非常简单： yum install vncserver 就OK了，然后，直接在当前用户下执行命令： vncserver 就OK了，但是这里有很多细节其实我们还不知道的。 配置执行 vncserver 命令的时候，我们可以指定很多选项，如果不指定任何选项的话，会默认使用第一个可用的 显示ID，通常是 1。用这个显示ID启动 Xvnc，在Xvnc会话里启动窗口管理器。我们可以以 vncserver :13这样的形式指定显示ID。 $HOME/.vnc/xstartup 一个shell脚本，指定当VNC桌面开始时执行的 X 程序。如果这文件不存在，vncserver会建立一个默认的 xstartup 脚本，此脚本尝试 启动你选择的窗口管理器。 /etc/tigervnc/vncserver-config-defaults 这是一个可选的，系统层面的文件与$HOME/.vnc/config相等。如果此文件存在并定义了传递给Xvnc的选项，所有用户都会默认使用这些选项。$HOME/.vnc/config会重写这个文件内设置。文件的加载顺序是：/etc/tigervnc/vncserver-config-defaults, $HOME/.vnc/config, /etc/tigervnc/vncserver-config-mandatory所有文件都不一定要求必须存在。 /etc/tigervnc/vncserver-config-mandatory系统层面与$HOME/.vnc/config想等的配置文件。如果这个文件定义了参数，那么就其会覆盖 $HOME/.vnc/config内定义的对应参数。 $HOME/.vnc/config 用户的配置文件 $HOME/.vnc/passwd 密码文件 $HOME/.vnc/host:display#.log 日志文件 $HOME/.vnc/host:display#.pid pid文件 以服务的形式启动CentOS 7cp /lib/systemd/system/vncserver@.service /etc/systemd/system/vncserver@.service 把此文件中的 一用户名替代 。 执行 systemctl daemon-reload 执行 systemctl enable vncserver@&lt;display&gt;.service 问题以服务的形式启动失败了，最后是以命令的形式进行启动的。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/tags/Linux/"},{"name":"VNC","slug":"VNC","permalink":"https://gowa2017.github.io/tags/VNC/"}],"keywords":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}]},{"title":"利用idea调试maven项目","slug":"利用idea调试maven项目","date":"2018-07-17T08:37:41.000Z","updated":"2018-07-17T08:37:41.000Z","comments":true,"path":"Java/利用idea调试maven项目.html","link":"","permalink":"https://gowa2017.github.io/Java/利用idea调试maven项目.html","excerpt":"","text":"事情是这样的，之前曾经idea上调试过项目，但是出现一个很头疼的问题是，后面再调用哪个API都会直接跳转到到了登录界面。而如果将环境部署以后，则正常，谷歌良久，终于找到了解决办法，但是，之前的疑问依然没有解决。为什么开始的时候同样的操作是可以的，而后就不行了呢。 环境 OS: CentOS 7.5 x86_64 IDE: ideaU 开发语言: Java 框架：jeeplus 编译：maven-&gt;war 中间件： tomcat 7.0.94 开始的时候，直接导入项目，编译，然后在idea的 Run/Debug Configration 处添加好 tomcatserver local项目，指定好我的tomcat 路径，然后直接小臭虫就开始debug了。 可是后面换了个机器，重新装一一下系统就坑了，不行了。谷歌才找到了解决的办法 解决办法ideaU -&gt; edit configration -&gt; 添加 maven -&gt; command line 输入 tomcat7:run 然后保存好后。 点小臭虫居然就可以了，这是为什么呢？ 另外一种办法在 idea 有了 tomcat server 插件集成的情况下。按如下步骤进行： 选择 Edit Configurations 点 + 号，添加一个 Tomcat Server Local 配置 在新添加的配置的 标签 Server 下指定自己的 Tomcat 程序位置 在 Deployment 标签下，点 + 号添加我们的 smart.war exploded 。 运行即可","categories":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/tags/Java/"},{"name":"Maven","slug":"Maven","permalink":"https://gowa2017.github.io/tags/Maven/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}]},{"title":"CentOS中的ip命令","slug":"CentOS中的ip命令","date":"2018-07-14T03:07:19.000Z","updated":"2018-07-14T03:07:19.000Z","comments":true,"path":"Linux/CentOS中的ip命令.html","link":"","permalink":"https://gowa2017.github.io/Linux/CentOS中的ip命令.html","excerpt":"","text":"据说ifconfig命令已经过时了，而且都比较推荐转移到ip命令。虽然好久不接触运维但是还是需要了解一下。 基本格式ip helpUsage: ip [ OPTIONS ] OBJECT &#123; COMMAND | help &#125; ip [ -force ] -batch filenamewhere OBJECT := &#123; link | address | addrlabel | route | rule | neigh | ntable | tunnel | tuntap | maddress | mroute | mrule | monitor | xfrm | netns | l2tp | macsec | tcp_metrics | token &#125; OPTIONS := &#123; -V[ersion] | -s[tatistics] | -d[etails] | -r[esolve] | -h[uman-readable] | -iec | -f[amily] &#123; inet | inet6 | ipx | dnet | bridge | link &#125; | -4 | -6 | -I | -D | -B | -0 | -l[oops] &#123; maximum-addr-flush-attempts &#125; | -o[neline] | -t[imestamp] | -ts[hort] | -b[atch] [filename] | -rc[vbuf] [size] | -n[etns] name | -a[ll] &#125; 可以看到，其基本格式是 ip 选项 操纵对象 操纵命令 的形式，而其可以操纵的对象还有点多啊 操作对象link 链路层多数时候我们应该不会操纵这些东西，所以只看一下基本的命令格式就算了： ip link helpUsage: ip link add [link DEV] [ name ] NAME [ txqueuelen PACKETS ] [ address LLADDR ] [ broadcast LLADDR ] [ mtu MTU ] [ numtxqueues QUEUE_COUNT ] [ numrxqueues QUEUE_COUNT ] type TYPE [ ARGS ] ip link delete &#123; DEVICE | dev DEVICE | group DEVGROUP &#125; type TYPE [ ARGS ] ip link set &#123; DEVICE | dev DEVICE | group DEVGROUP &#125; [ &#123; up | down &#125; ] [ type TYPE ARGS ] [ arp &#123; on | off &#125; ] [ dynamic &#123; on | off &#125; ] [ multicast &#123; on | off &#125; ] [ allmulticast &#123; on | off &#125; ] [ promisc &#123; on | off &#125; ] [ trailers &#123; on | off &#125; ] [ txqueuelen PACKETS ] [ name NEWNAME ] [ address LLADDR ] [ broadcast LLADDR ] [ mtu MTU ] [ netns &#123; PID | NAME &#125; ] [ link-netnsid ID ] [ alias NAME ] [ vf NUM [ mac LLADDR ] [ vlan VLANID [ qos VLAN-QOS ] ] [ rate TXRATE ] [ max_tx_rate TXRATE ] [ min_tx_rate TXRATE ] [ spoofchk &#123; on | off&#125; ] [ query_rss &#123; on | off&#125; ] [ state &#123; auto | enable | disable&#125; ] ] [ trust &#123; on | off&#125; ] ] [ master DEVICE ] [ nomaster ] [ addrgenmode &#123; eui64 | none &#125; ] [ protodown &#123; on | off &#125; ] ip link show [ DEVICE | group GROUP ] [up] [master DEV] [type TYPE] ip link help [ TYPE ]TYPE := &#123; vlan | veth | vcan | dummy | ifb | macvlan | macvtap | bridge | bond | ipoib | ip6tnl | ipip | sit | vxlan | gre | gretap | ip6gre | ip6gretap | vti | nlmon | bond_slave | geneve | bridge_slave | macsec &#125; 基本的命令有 add/set/delete/show，根据链路层的定义，链路层的设备有多种类型，还可以设置各种属性，如MTU，IPV6地址等。 我们可能会用到的应该就是 ip link set eth0 down 这样的了，开启或者关闭网卡。 addr 网络层这个可能是用得最多的一个命令了，先看一下命令格式： ip addr helpUsage: ip address &#123;add|change|replace&#125; IFADDR dev IFNAME [ LIFETIME ] [ CONFFLAG-LIST ] ip address del IFADDR dev IFNAME [mngtmpaddr] ip address &#123;save|flush&#125; [ dev IFNAME ] [ scope SCOPE-ID ] [ to PREFIX ] [ FLAG-LIST ] [ label LABEL ] [up] ip address [ show [ dev IFNAME ] [ scope SCOPE-ID ] [ master DEVICE ] [ type TYPE ] [ to PREFIX ] [ FLAG-LIST ] [ label LABEL ] [up] ] ip address &#123;showdump|restore&#125;IFADDR := PREFIX | ADDR peer PREFIX [ broadcast ADDR ] [ anycast ADDR ] [ label IFNAME ] [ scope SCOPE-ID ]SCOPE-ID := [ host | link | global | NUMBER ]FLAG-LIST := [ FLAG-LIST ] FLAGFLAG := [ permanent | dynamic | secondary | primary | [-]tentative | [-]deprecated | [-]dadfailed | temporary | CONFFLAG-LIST ]CONFFLAG-LIST := [ CONFFLAG-LIST ] CONFFLAGCONFFLAG := [ home | nodad | mngtmpaddr | noprefixroute | autojoin ]LIFETIME := [ valid_lft LFT ] [ preferred_lft LFT ]LFT := forever | SECONDSTYPE := &#123; vlan | veth | vcan | dummy | ifb | macvlan | macvtap | bridge | bond | ipoib | ip6tnl | ipip | sit | vxlan | gre | gretap | ip6gre | ip6gretap | vti | nlmon | bond_slave | ipvlan | geneve | bridge_slave | vrf | macsec &#125; addip addr add 192.168.1.2/24 dev lo delip addr del 192.168.1.2/24 dev lo route 路由ip route helpUsage: ip route &#123; list | flush &#125; SELECTOR ip route save SELECTOR ip route restore ip route showdump ip route get ADDRESS [ from ADDRESS iif STRING ] [ oif STRING ] [ tos TOS ] [ mark NUMBER ] ip route &#123; add | del | change | append | replace &#125; ROUTESELECTOR := [ root PREFIX ] [ match PREFIX ] [ exact PREFIX ] [ table TABLE_ID ] [ proto RTPROTO ] [ type TYPE ] [ scope SCOPE ]ROUTE := NODE_SPEC [ INFO_SPEC ]NODE_SPEC := [ TYPE ] PREFIX [ tos TOS ] [ table TABLE_ID ] [ proto RTPROTO ] [ scope SCOPE ] [ metric METRIC ]INFO_SPEC := NH OPTIONS FLAGS [ nexthop NH ]...NH := [ via ADDRESS ] [ dev STRING ] [ weight NUMBER ] NHFLAGSOPTIONS := FLAGS [ mtu NUMBER ] [ advmss NUMBER ] [ rtt TIME ] [ rttvar TIME ] [reordering NUMBER ] [ window NUMBER ] [ cwnd NUMBER ] [ initcwnd NUMBER ] [ ssthresh NUMBER ] [ realms REALM ] [ src ADDRESS ] [ rto_min TIME ] [ hoplimit NUMBER ] [ initrwnd NUMBER ] [ features FEATURES ] [ quickack BOOL ] [ congctl NAME ] [ expires TIME ]TYPE := &#123; unicast | local | broadcast | multicast | throw | unreachable | prohibit | blackhole | nat &#125;TABLE_ID := [ local | main | default | all | NUMBER ]SCOPE := [ host | link | global | NUMBER ]NHFLAGS := [ onlink | pervasive ]RTPROTO := [ kernel | boot | static | NUMBER ]TIME := NUMBER[s|ms]BOOL := [1|0]FEATURES := ecn","categories":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/tags/Linux/"}],"keywords":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}]},{"title":"了解REST","slug":"了解REST","date":"2018-07-14T02:21:06.000Z","updated":"2018-07-14T02:21:06.000Z","comments":true,"path":"Java/了解REST.html","link":"","permalink":"https://gowa2017.github.io/Java/了解REST.html","excerpt":"","text":"REST (Representational State Transfer)是一个设计分发系统时的架构风格。其不是标准，而只是一系列的约束，比如是无状态的，客户端/服务端关联，以及一个接口。REST并不是严格的与HTTP有关系，但这是最常见的情况。 原则 Resource ：这个表示易于理解和目录结构或者 URIs。 Representations：传输 XML、JSON数据来代表对应的对象或者属性 Messages：显式的使用HTTP方法。 Stateless：在请求之间，服务器并不会存储客户端的上下文。状态依赖会限制伸缩性。客户端来保存会话状态。 HTTP方法使用 HTTP方法来 映射 CRUD（create, retrieve, update, delete）操作到HTTP请求。 GET获取信息。GET 请求必须是安全的，幂等的，意思就是无论以同样的参数重复多少次，这个结果应该是一样的。他们可能会有副作用，但是用户并不期望，所以对于系统的操作来说是他们并不是严重的。请求也可能是局部的或者有条件的： GET /addresses/1 POST请求对于URI处的资源根据提供的实体做一些事情。通常，POST用来创建新的 实体，也可以用来更新。 POST /addresses PUT存储一个实体到对应的URI。PUT可以建立一个新实体或者更新一个实体。一个PUT请求是幂等的。幂等是 PUT 与POST主要不同。 PUT /addresses/1 PUT 会替换一个已存在的实体。如果只有数据元素的子集被提供，那么其他的就会被替换为null。 HTTP status codesStatus codes indicate the result of the HTTP request. 1XX - informational 2XX - success 3XX - redirection 4XX - client error 5XX - server error","categories":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/tags/Java/"},{"name":"REST","slug":"REST","permalink":"https://gowa2017.github.io/tags/REST/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}]},{"title":"开启主机对IPv6的支持","slug":"开启主机对IPv6的支持","date":"2018-07-12T13:03:21.000Z","updated":"2018-07-12T13:03:21.000Z","comments":true,"path":"Linux/开启主机对IPv6的支持.html","link":"","permalink":"https://gowa2017.github.io/Linux/开启主机对IPv6的支持.html","excerpt":"","text":"事情的是经过是，摩尔互联的节点客户端，无法启动。返回的错误是 address famliy not support，根据这个原因我推测，应该是绑定套接字的时候，不支持这个协议族，而查看了一下 ip addr，有ipv4地址，但是没有链路层地址和ipv6地址。 原理从 TCP/IP 协议详解上了解到，ipV6地址，其实应该是每个接口都会有，而且每个接口可能会有几个。有链路本地地址，子网的，全局的IPV6地址，而我这个一个都没有，肯定是系统给禁止了。于是我们就来把他找出来吧。 用 strace ./mol_node 就能看出点端倪了。 配置文件模块加载内核协议栈要支持IpV6，首先要加载 ipv6模块。在文件中 /etc/modprobe.d/disable_ipv6.conf 中有类似字样： alias ipv6 offoptions ipv6 disable=1 看名字就能知道，我们需要把 off 改为 on， 1 改为0. 这样才会加载进来模块。 网络支持文件 /etc/sysconfig/network中，NETWORKING_IPV6=no 改为 NETWORKING_IPV6=yes 系统配置/etc/sysctl.conf 把下列选项都改为1: net.ipv6.conf.all.disable_ipv6 = 1net.ipv6.conf.default.disable_ipv6 = 1net.ipv6.conf.lo.disable_ipv6 = 1 重启了之后，一看。果然可以了。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/tags/Linux/"}],"keywords":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}]},{"title":"android中使用的MVP架构","slug":"android中使用的MVP架构","date":"2018-07-11T13:38:22.000Z","updated":"2018-07-11T13:38:22.000Z","comments":true,"path":"Android/android中使用的MVP架构.html","link":"","permalink":"https://gowa2017.github.io/Android/android中使用的MVP架构.html","excerpt":"","text":"从未写过代码的人，现在转行做安卓，很多问题其实都不知道。就比如吧，刚上班一周就开始马上贡献代码给公司了，但其实做得非常的差。刚开始的时候是做一些，拉取数据，然后在RecyclerView中进行展示，或者在一LinearLayout内展示内容。但一般遇到业务逻辑比较复杂，而且后面老是变更各种需求的时候，这个问题就比较麻烦了。 典型问题比如业务上，我们把不同的数据，如：人员信息，职务信息，基本情况分别放在三个表内，现在接口那边，为减轻服务器压力，并不会进行联合查询，而是分别返回，每个接口返回对应的数据。那么，当我们需要基于三个返回的数据进行业务判断的时候，那么我们就需要等待三个数据都返回后再进行操作。 那么，我们要么是通过同过串联式调用，第一个调用成功后，在其网络获取请求的回调函数中调用第二个接口。这是非常低的。 或者并发调用，使用一个handler，等待三个接口返回的数据都到达后进行处理。 最疯狂的时候，需要调用10个接口的数据来进行处理，这可能是顶层设计的问题，或者是后端优化不行的问题，但是已经不大可能改了。只能是这样将就着去适配。 偶然看到了 google 的 例子内看到了他们对于架构的描述。 MVC平常用得最多的可能就是 MVC，model, view, controler，view负责显示逻辑，model负责获取数据，controler负责业务逻辑。但事实上在安卓内，我们是把一大坨代码，都放在activity或者 fragment中的，哈哈，what’s a fuck。等到业务需求变更的时候，一种想死的心油然而生。 就比如我们干的事情，在view中，写获取数据，写业务逻辑，简直就是坨屎在那里。 MVP这可能是现在用得最多的架构模式了。model属于数据获取模型，presenter用于处理业务逻辑，view负责显示就OK了。 但事实上这个架构不好理解，特别是连续不断的回调实在让人蛋疼。而对于是以接口的方式进行相互连接，而不是对象持有的方式也让人有点感觉茫然。好在，谷歌提供了一些比较实际的例子。 整个架构的关键就在于 Presenter，它对 Model，View都进行了引用，所以能在两者间进行通信和调度。最终看了代码的感觉是，其专心的只是逻辑，至于数据从哪里来，怎么显示，他不是很关心，这个交由 Model, View自己去实现。 Contract代码中使用了一个 接口类来定义每个 View, Presenter要实现的接口。 每个activity/fragment都会定义附加逻辑及model。 public interface TasksContract &#123; interface View extends BaseView&lt;Presenter&gt; &#123; void setLoadingIndicator(boolean active); void showTasks(List&lt;Task&gt; tasks); void showAddTask(); void showTaskDetailsUi(String taskId); void showTaskMarkedComplete(); void showTaskMarkedActive(); void showCompletedTasksCleared(); void showLoadingTasksError(); void showNoTasks(); void showActiveFilterLabel(); void showCompletedFilterLabel(); void showAllFilterLabel(); void showNoActiveTasks(); void showNoCompletedTasks(); void showSuccessfullySavedMessage(); boolean isActive(); void showFilteringPopUpMenu(); &#125; interface Presenter extends BasePresenter &#123; void result(int requestCode, int resultCode); void loadTasks(boolean forceUpdate); void addNewTask(); void openTaskDetails(@NonNull Task requestedTask); void completeTask(@NonNull Task completedTask); void activateTask(@NonNull Task activeTask); void clearCompletedTasks(); void setFiltering(TasksFilterType requestType); TasksFilterType getFiltering(); &#125;&#125; 定义了V/P需要实现的接口。 初始化通过在 View 中来初始化 Presenter：，在 onCreate()方法中： private TasksPresenter mTasksPresenter; mTasksPresenter = new TasksPresenter( Injection.provideTasksRepository(getApplicationContext()), tasksFragment); 这样就获得了对 Presenter 的引用。第一个参数是传递给构造器的 model实现，这个有点特别，因为他实现了缓存等操作比较复杂，我们先不关注这个。 在 Presenter的构造器中： public TasksPresenter(@NonNull TasksRepository tasksRepository, @NonNull TasksContract.View tasksView) &#123; mTasksRepository = checkNotNull(tasksRepository, \"tasksRepository cannot be null\"); mTasksView = checkNotNull(tasksView, \"tasksView cannot be null!\"); mTasksView.setPresenter(this);&#125; 其持有了 model/view，所以其就能进行两者的调用操作了。 Presenter 与 Model交互看一个简单的方法，当需要获取所有的任务列表的时候，在 View中会看到如此的调用： mPresenter.loadTasks(false); 但我们观察一下这个方法，会发现： mTasksRepository.getTasks(new TasksDataSource.LoadTasksCallback() &#123; @Override public void onTasksLoaded(List&lt;Task&gt; tasks) &#123; List&lt;Task&gt; tasksToShow = new ArrayList&lt;Task&gt;(); // This callback may be called twice, once for the cache and once for loading // the data from the server API, so we check before decrementing, otherwise // it throws \"Counter has been corrupted!\" exception. if (!EspressoIdlingResource.getIdlingResource().isIdleNow()) &#123; EspressoIdlingResource.decrement(); // Set app as idle. &#125; // We filter the tasks based on the requestType for (Task task : tasks) &#123; switch (mCurrentFiltering) &#123; case ALL_TASKS: tasksToShow.add(task); break; case ACTIVE_TASKS: if (task.isActive()) &#123; tasksToShow.add(task); &#125; break; case COMPLETED_TASKS: if (task.isCompleted()) &#123; tasksToShow.add(task); &#125; break; default: tasksToShow.add(task); break; &#125; &#125; // The view may not be able to handle UI updates anymore if (!mTasksView.isActive()) &#123; return; &#125; if (showLoadingUI) &#123; mTasksView.setLoadingIndicator(false); &#125; processTasks(tasksToShow); &#125; @Override public void onDataNotAvailable() &#123; // The view may not be able to handle UI updates anymore if (!mTasksView.isActive()) &#123; return; &#125; mTasksView.showLoadingTasksError(); &#125;&#125;); 其实是调用了 model去获取任务，调用方法的时候，同时传递给 model一个回调，其在获取数据成功后就会进行回调： mTasksRepository.getTasks(new TasksDataSource.LoadTasksCallback() &#123;... ...processTasks(tasks); private void processTasks(List&lt;Task&gt; tasks) &#123; if (tasks.isEmpty()) &#123; // Show a message indicating there are no tasks for that filter type. processEmptyTasks(); &#125; else &#123; // Show the list of tasks mTasksView.showTasks(tasks); // Set the filter label's text. showFilterLabel(); &#125; &#125;&#125; 回调过后，其就调用 View 的方法来更新界面显示了。 瞧，多么简单。","categories":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"},{"name":"MVP","slug":"MVP","permalink":"https://gowa2017.github.io/tags/MVP/"}],"keywords":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}]},{"title":"Word-OOXML中的drawingML","slug":"Word-OOXML中的drawingML","date":"2018-07-10T13:06:34.000Z","updated":"2018-07-10T13:06:34.000Z","comments":true,"path":"Java/Word-OOXML中的drawingML.html","link":"","permalink":"https://gowa2017.github.io/Java/Word-OOXML中的drawingML.html","excerpt":"","text":"DrawingML中的所有媒体对象都存储在一个图片形状中。这个图片形状使用一个 blipFill 元素来显示媒体对象。如果是音频的情况下，使用的是图标；在视频情况下，使用的是一个一帧来显示。 简单例子 &lt;p:pic&gt; &lt;p:nvPicPr&gt; ...&lt;/p:nvPicPr&gt; &lt;p:blipFill&gt; &lt;a:blip r:embed=\"rId4\" r:link=\"\" /&gt; &lt;a:stretch&gt; &lt;a:fillRect /&gt; &lt;/a:stretch&gt; &lt;/p:blipFill&gt; &lt;p:spPr&gt; ... &lt;/p:spPr&gt; &lt;/p:pic&gt; blipFill元素用来引用图片文件，因为引用的是这个文件包内的文件，所以使用了一个 关联ID（relationship ID）。 图片DrawingML 文件格式被分解为下面的三个部分： 指定基本图片 指定图片属性 转换图标 下面一个一个的来看这个。 指定基本图片图片通过 pic 元素插入文档中，这与 shape 元素类似，但有一些关键的不同，这些关键的不同使图片信息保存得更加完整。基本的图片会包含一个 blipfill 元素和一些基本的 non-visual（不可见）属性 。 &lt;p:pic&gt; &lt;p:nvPicPr&gt; &lt;p:cNvPr id=\"4\" name=\"St_Patrick's_Day.jpg\"/&gt; &lt;p:cNvPicPr&gt; &lt;a:picLocks noChangeAspect=\"1\"/&gt; &lt;/p:cNvPicPr&gt; &lt;p:nvPr/&gt; &lt;/p:nvPicPr&gt; &lt;p:blipFill&gt; &lt;a:blip r:embed=\"rId2\"/&gt; &lt;a:stretch&gt; &lt;a:fillRect/&gt; &lt;/a:stretch&gt; &lt;/p:blipFill&gt; &lt;p:spPr&gt; &lt;a:xfrm&gt; &lt;a:off x=\"1346200\" y=\"914400\"/&gt; &lt;a:ext cx=\"3657600\" cy=\"2743200\"/&gt; &lt;/a:xfrm&gt; &lt;a:prstGeom prst=\"rect\"&gt; &lt;a:avLst/&gt; &lt;/a:prstGeom&gt; &lt;a:noFill/&gt; &lt;a:ln&gt; &lt;a:noFill/&gt; &lt;/a:ln&gt; &lt;/p:spPr&gt; &lt;/p:pic&gt; 给图片指定属性现在基本的图片已经指定了，我们可以可以把注意力转移到更复杂的属性上面，比如重新着色，图片描述等。下面的例子中，把 绿色 转变成了紫色。这可以通过 duotone 元素来实现，这个元素允许两个基本的颜色来重新着色整个图片。一个用于在图片的暗色部分，一个用于图片的亮色部分。 &lt;p:pic&gt; &lt;p:nvPicPr&gt; &lt;p:cNvPr id=\"4\" name=\"St_Patrick's_Day.jpg\" descr=\"This is a Saint Patrick's day picture\"/&gt; &lt;p:cNvPicPr&gt; &lt;a:picLocks noChangeAspect=\"1\"/&gt; &lt;/p:cNvPicPr&gt; &lt;p:nvPr/&gt; &lt;/p:nvPicPr&gt; &lt;p:blipFill&gt; &lt;a:blip r:embed=\"rId2\"&gt; &lt;a:duotone&gt; &lt;a:srgbClr val=\"000000\"/&gt; &lt;a:schemeClr val=\"accent4\"/&gt; &lt;/a:duotone&gt; &lt;/a:blip&gt; &lt;a:stretch&gt; &lt;a:fillRect/&gt; &lt;/a:stretch&gt; &lt;/p:blipFill&gt; &lt;p:spPr&gt; &lt;a:xfrm&gt; &lt;a:off x=\"1346200\" y=\"914400\"/&gt; &lt;a:ext cx=\"3657600\" cy=\"2743200\"/&gt; &lt;/a:xfrm&gt; &lt;a:prstGeom prst=\"rect\"&gt; &lt;a:avLst/&gt; &lt;/a:prstGeom&gt; &lt;a:noFill/&gt; &lt;a:ln&gt; &lt;a:noFill/&gt; &lt;/a:ln&gt; &lt;/p:spPr&gt; &lt;/p:pic&gt; 转换图片现在，基本属性和附加属性都已经指定了，现在我们可以配合形状属性来使用了。下面的例子用同一张图片，加上了3D视角，一个简单的阴影，一个边框。这些形状属性可以同样使用到shape元素。一个图片特定的不同就是，边框。形状的边框只会向外，而图片是内外都会扩张。 &lt;p:pic&gt; &lt;p:nvPicPr&gt; &lt;p:cNvPr id=\"4\" name=\"St_Patrick's_Day.jpg\" descr=\"This is a Saint Patrick's day picture\"/&gt; &lt;p:cNvPicPr&gt; &lt;a:picLocks noChangeAspect=\"1\"/&gt; &lt;/p:cNvPicPr&gt; &lt;p:nvPr/&gt; &lt;/p:nvPicPr&gt; &lt;p:blipFill&gt; &lt;a:blip r:embed=\"rId2\"&gt; &lt;a:duotone&gt; &lt;a:srgbClr val=\"000000\"/&gt; &lt;a:schemeClr val=\"accent4\"/&gt; &lt;/a:duotone&gt; &lt;/a:blip&gt; &lt;a:stretch&gt; &lt;a:fillRect/&gt; &lt;/a:stretch&gt; &lt;/p:blipFill&gt; &lt;p:spPr&gt; &lt;a:xfrm&gt; &lt;a:off x=\"1346200\" y=\"914400\"/&gt; &lt;a:ext cx=\"3657600\" cy=\"2743200\"/&gt; &lt;/a:xfrm&gt; &lt;a:prstGeom prst=\"rect\"&gt; &lt;a:avLst/&gt; &lt;/a:prstGeom&gt; &lt;a:noFill/&gt; &lt;a:ln w=\"57150\"&gt; &lt;a:solidFill&gt; &lt;a:schemeClr val=\"bg1\"/&gt; &lt;/a:solidFill&gt; &lt;/a:ln&gt; &lt;a:effectLst&gt; &lt;a:outerShdw blurRad=\"50800\" dist=\"50800\" dir=\"2700000\" algn=\"tl\" rotWithShape=\"0\"&gt; &lt;a:srgbClr val=\"7D7D7D\"&gt; &lt;a:alpha val=\"65000\"/&gt; &lt;/a:srgbClr&gt; &lt;/a:outerShdw&gt; &lt;/a:effectLst&gt; &lt;a:scene3d&gt; &lt;a:camera prst=\"perspectiveRelaxedModerately\"/&gt; &lt;a:lightRig rig=\"threePt\" dir=\"t\"&gt; &lt;a:rot lat=\"0\" lon=\"0\" rev=\"18900000\"/&gt; &lt;/a:lightRig&gt; &lt;/a:scene3d&gt; &lt;/p:spPr&gt; &lt;/p:pic&gt; 坐标系统及变换坐标系统所有的 drawingML形状都位于一个2D的笛卡尔空间内，原点是（0，0），原点位于左上角。坐标的单位以 EMU（914400EMUS 1 英寸），可为正也可为负。 形状变换一个 形状变换 可以总结为下面的连续操作： 变换 和 缩放需要了解 原始的 边界盒子成为一个矩形，这通过 offset, extents来指定。 在中心点 和 flipH, flipV 之间进行翻转。 根据 rot 属性 围绕中心点进行旋转。 为了渲染不在一个组内的形状，渲染器简单的对原始形状应用形状变换。 缩放和转换形状形状可以水平缩放，垂直缩放，尺寸转换或者填充一个给定的边界盒子。边界盒子通过指定 offset 的 x,y 来指定（a:off 的 x,y 属性）以及 extents x,y （a:ext的 x,y，两者都必须大于或者等于0）。边界盒子的左上角位于 offset指定的，边界盒子的右下角位于 offset + extent。 如果开始的形状 宽度为0（垂直线）， cx 和 a:ext 属性会被忽略，水平缩放被跳过。类似，如果 开始形状的高度为0，cy, a:ext都会被忽略，然后垂直缩放被跳过。 上面的形状可以如下表示： &lt;a:xfrm&gt; &lt;a:off x=\"1866680\" y=\"990600\"/&gt; &lt;a:ext cx=\"1371600\" cy=\"1371600\"/&gt; &lt;/a:xfrm&gt; 在上面的例子中，当转换这个形状来填充指定的边界盒子的时候，任何给这个形状的效果都会消失。 这个例子显示了，在缩放形状的时候，不需要任何额外的参数。边界盒子用来表示缩放已经足够了。下面的XML片段表示了一个 星形 的 offset, extents在缩放前后的效果。在这个实际的例子中，边界盒子被选择来具有相同的左上角，也就是同样的offset。 缩放前： &lt;a:xfrm&gt; &lt;a:off x=\"1066800\" y=\"990600\"/&gt; &lt;a:ext cx=\"1371600\" cy=\"1371600\"/&gt; &lt;/a:xfrm&gt; 缩放后： &lt;a:xfrm&gt; &lt;a:off x=\"1066800\" y=\"990600\"/&gt; &lt;a:ext cx=\"2438400\" cy=\"2133600\"/&gt; &lt;/a:xfrm&gt; 形状旋转通过 rot 属性来表示旋转。形状会围绕 边界盒子的中心顺时针旋转，角度由 rot 指定。每个单位是 1/1000 弧分（1/60000 度）。 上面例子中小的个星星经过 45度顺时针旋转后，就变成了下面这样。 &lt;a:xfrm rot=\"2700000\"&gt; &lt;a:off x=\"1066800\" y=\"990600\"/&gt; &lt;a:ext cx=\"1371600\" cy=\"1371600\"/&gt; &lt;/a:xfrm&gt; 翻转形状翻转，是在一个 水平线，和垂直线，于中心点相交 处进行反射。flipH, flipV 属性控制水平和垂直翻转。这两个数值都可以没有，也可以都等于0 ，这个时候表明不需要进行翻转，都等于1表示需要进行翻转。 下面的例子就是水平和垂直进行了翻转。 &lt;a:xfrm flipH=\"1\" flipV=\"1\"&gt; &lt;a:off x=\"3964937\" y=\"2652643\"/&gt; &lt;a:ext cx=\"168838\" cy=\"1219199\"/&gt; &lt;/a:xfrm&gt; 形状定义和属性DrawingML我使用一般就是针对形状和属性进行，这包括两个方便的主题： 预定义的形状 自定义形状和属性 坐标系统为了指定一个形状，我们要先了解一些高等级的系统，就叫做坐标系统吧。这就是文档，形状，和路径的坐标系统，下面我们会介绍。 文档坐标系统为了在文档内指定一个形状，我们必须要先了解文档坐标系统。这个系统也拥有 x, y组件，而且从 (0,0)开始，位于 左上角。这个坐标向右，向下增长。文档的坐标的单位是 EMU（ 91440 EMUs /英寸，36000 EMUs/cm）。还有，为了给形状指定一个位置，还要指定形状的宽高，这也叫做形状的 extent。这个值的单位也是 EMU。为了指定这两个值，可以如下面这样： &lt;p:sp&gt; &lt;p:spPr&gt; &lt;a:xfrm&gt; &lt;a:off x=\"3200400\" y=\"1600200\"/&gt; &lt;a:ext cx=\"1200000\" cy=\"1000000\"/&gt; &lt;/a:xfrm&gt; &lt;/p:spPr&gt; &lt;/p:sp&gt; 这里我们会看到，新形状被放在 文档中(3200400, 1600200）位置。其大小为 1200000 EMUs，1000000 EMUs。 宽高就设置了形状包含的边界盒子。 形状坐标系统现在我们有了形状，我们可以进入形状内部的坐标系了。形状坐标系也有 x,y 组件，（0，0）位于左上角。 宽高通过 extent来指定，单位也是EMU。这个坐标系用来定义 很多形状属性的位置。 路径坐标系这坐标系的 x,y 也是从 (0,0） 左上角开始的。特别的是，这个坐标系内的其单位是相对于 坐标空间内的值。这与形状坐标系有相同的规格但是不同的单位。形状坐标系使用 EMUs，路径坐标系使用（1/width）作为 x 的单位，(1/height）作为 y 的单位。这就是说，如果路径指定为 宽高 (2, 1），那么，路径坐标（1,1）就在形状坐标系内等于 (6000000,1000000）。路径坐标会会更容易理解些，后面会看到，path 元素描述的时候会说到。 所有的规格和坐标都必须用全部数字来指定。 指定一个预定义形状准确来说，有187个预定义的形状可以使用。 使用预定义形状指定一个预定义形状非常的简单，下面我们来指定一个星形： &lt;p:sp&gt; &lt;p:spPr&gt; &lt;a:xfrm&gt; &lt;a:off x=\"1981200\" y=\"533400\"/&gt; &lt;a:ext cx=\"1143000\" cy=\"1066800\"/&gt; &lt;/a:xfrm&gt; &lt;a:prstGeom prst=\"heart\"&gt; &lt;/a:prstGeom&gt; &lt;/p:spPr&gt; &lt;/p:sp&gt; 调整一个预定义形状有的时候预定义形状也不是很够用我们就需要进行一些调整。预定义的形状使用 线，曲线，就和一个自定义形状被定义时一样。为了允许调整这样预定义形状，我们定义了一些属性，而不是关注规格。 下面的代码可以指定一个形状： &lt;p:sp&gt; &lt;p:spPr&gt; &lt;a:xfrm&gt; &lt;a:off x=\"3276600\" y=\"990600\"/&gt; &lt;a:ext cx=\"978408\" cy=\"484632\"/&gt; &lt;/a:xfrm&gt; &lt;a:prstGeom prst=\"rightArrow\"&gt; &lt;a:avLst&gt; &lt;a:gd name=\"adj1\" fmla=\"val 50000\"/&gt; &lt;a:gd name=\"adj2\" fmla=\"val 50000\"/&gt; &lt;/a:avLst&gt; &lt;/a:prstGeom&gt; &lt;/p:spPr&gt; &lt;/p:sp&gt;","categories":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/tags/Java/"},{"name":"Word","slug":"Word","permalink":"https://gowa2017.github.io/tags/Word/"},{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}]},{"title":"升级glibc到2.18及出现的问题","slug":"升级glibc到2.18及出现的问题","date":"2018-07-09T14:52:07.000Z","updated":"2018-07-09T14:52:07.000Z","comments":true,"path":"Linux/升级glibc到2.18及出现的问题.html","link":"","permalink":"https://gowa2017.github.io/Linux/升级glibc到2.18及出现的问题.html","excerpt":"同时要用个mol_node这个东西来挂挖矿的钱包，但是libc库要求最低是2.18，但是我这个最低的是2.17的，当然不能用了，还好，gcc 4.8.5的，直接用来编译升级就好了。","text":"同时要用个mol_node这个东西来挂挖矿的钱包，但是libc库要求最低是2.18，但是我这个最低的是2.17的，当然不能用了，还好，gcc 4.8.5的，直接用来编译升级就好了。 开始前执行程序的时候报了一个错： /lib64/libc.so.6 version GLIBC_2.18 not found 很明显链接的库不是2.18的。根据 tlpi上所说的，动态加载库有三个名字比较重要。文件名，库名，链接器名，而且用ldconfig 来进行管理与更新。如： realname : libmath.so.1.3 文件名 soname : libmath.so.1 库名 linkername : libmath.so 链接器编译的时候链接的名称。 ldconfig命令干的活，就是在默认目录和我们制定的库目录内寻找所有的库文件，然后根据文件名来更新最新的连接。比如吧，看一下我们需要的 libc.so.6现在的指向。 ll /lib64/libc.so.6lrwxrwxrwx 1 root root 12 Jul 9 22:30 /lib64/libc.so.6 -&gt; libc-2.17.so 瞧，是个符号链接文件吧。我们就是要把后面的变成2.18来。 升级升级非常的简单： wget http://ftp.gnu.org/gnu/glibc/glibc-2.18.tar.gztar –zxvf glibc-2.18.tar.gzcd glibc-2.18mkdir buildcd build../configure --prefix=/usr --disable-profile --enable-add-ons --with-headers=/usr/include --with-binutils=/usr/binmake –j4make install 安装后就会发现， ll /lib64/libc.so.6lrwxrwxrwx 1 root root 12 Jul 9 22:30 /lib64/libc.so.6 -&gt; libc-2.18.so 遇到的问题我开始没有执行 make install，然后想着不安装，自己编译了受手动制定链接定制就行了。 果断的一个 rm -f /lib64/libc.so.6，然后，结果就坑了。所有的命令都执行不了，因为没有了这个共享库了，很多命令都是基于这个库的。型号，万能的谷歌。 让我先把命令找回来。想到这个动态库本来就是链接到一个真实文件的，那如果我们要指定加载的库位置，不需要这个链不也是可以的，确实是这样的。我们可以指定运行时加载库的加载库 LD_PRELOAD=/lib64/libc-2.17.so ln -s /lib64/libc-2.17.so /lib64/libc.so.6 这样就恢复原状，后面执行 make install就OK了","categories":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/tags/Linux/"}],"keywords":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}]},{"title":"SpringMVC工作流程","slug":"SpringMVC工作流程","date":"2018-07-07T11:46:35.000Z","updated":"2018-07-07T11:46:35.000Z","comments":true,"path":"Java/SpringMVC工作流程.html","link":"","permalink":"https://gowa2017.github.io/Java/SpringMVC工作流程.html","excerpt":"转行开始安卓了，以前做运维的很多技能都用不着了，但是开发这个东西，还是需要经验和技术的积累。比如说什么 Spring,Mybatis,bootstrap等等，以前只接触服务端开发，压根就不知道这些东西啊。正好，让我们从jeeplus这个公司大佬用着的框架来熟悉一下。","text":"转行开始安卓了，以前做运维的很多技能都用不着了，但是开发这个东西，还是需要经验和技术的积累。比如说什么 Spring,Mybatis,bootstrap等等，以前只接触服务端开发，压根就不知道这些东西啊。正好，让我们从jeeplus这个公司大佬用着的框架来熟悉一下。 工作流程简述转自：Spring MVC工作流程图 流程图 UML图 简要描述 用户向服务器发送请求，请求被Spring 前端控制Servelt DispatcherServlet捕获； DispatcherServlet对请求URL进行解析，得到请求资源标识符（URI）。然后根据该URI，调用HandlerMapping获得该Handler配置的所有相关的对象（包括Handler对象以及Handler对象对应的拦截器），最后以HandlerExecutionChain对象的形式返回； DispatcherServlet 根据获得的Handler，选择一个合适的HandlerAdapter。（附注：如果成功获得HandlerAdapter后，此时将开始执行拦截器的preHandler(…)方法） 提取Request中的模型数据，填充Handler入参，开始执行Handler（Controller)。 在填充Handler的入参过程中，根据你的配置，Spring将帮你做一些额外的工作： HttpMessageConveter： 将请求消息（如Json、xml等数据）转换成一个对象，将对象转换为指定的响应信息数据转换：对请求消息进行数据转换。如String转换成Integer、Double等数据格式化：对请求消息进行数据格式化。 如将字符串转换成格式化数字或格式化日期等数据验证： 验证数据的有效性（长度、格式等），验证结果存储到BindingResult或Error中 Handler执行完成后，向DispatcherServlet 返回一个ModelAndView对象； 根据返回的ModelAndView，选择一个适合的ViewResolver（必须是已经注册到Spring容器中的ViewResolver)返回给DispatcherServlet ； ViewResolver 结合Model和View，来渲染视图 将渲染结果返回给客户端。 DispatcherServlet这个在 web.xml文件内进行了定义： &lt;servlet&gt; &lt;servlet-name&gt;springServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath*:/spring/spring-mvc*.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;&lt;/servlet&gt; 其会加载 spring/spring-mvc* 这几个文件。具体而言，就是 spring-mvc.xml这个文件，这个文件定义了很多的接口，资源。比如 handler, converter, Resolver等等。 handlerMapping具体的代码并不是很清晰，但网络上的文章足以让我们有一个概括的认识：springMVC—4种映射处理器handlerMapping。 我们使用的jeePlus使用的是 注解来进行映射的，&lt;mvc:annotation-driven/&gt;标签，即声明了对于注解的支持。关于这个标签的更多信息，请参考Spring MVC 解读—— &lt;!-- 默认的注解映射的支持，org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping --&gt;&lt;mvc:annotation-driven content-negotiation-manager=\"contentNegotiationManager\"&gt; &lt;mvc:message-converters register-defaults=\"true\"&gt; &lt;!-- 将StringHttpMessageConverter的默认编码设为UTF-8 --&gt; &lt;bean class=\"org.springframework.http.converter.StringHttpMessageConverter\"&gt; &lt;constructor-arg value=\"UTF-8\"/&gt; &lt;/bean&gt; &lt;!-- 将Jackson2HttpMessageConverter的默认格式化输出为false --&gt; &lt;bean class=\"org.springframework.http.converter.json.MappingJackson2HttpMessageConverter\"&gt; &lt;property name=\"supportedMediaTypes\"&gt; &lt;list&gt; &lt;value&gt;application/json;charset=UTF-8&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;property name=\"prettyPrint\" value=\"false\"/&gt; &lt;property name=\"objectMapper\"&gt; &lt;bean class=\"com.jeeplus.core.mapper.JsonMapper\"&gt;&lt;/bean&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!-- 使用XML格式输出数据 --&gt; &lt;bean class=\"org.springframework.http.converter.xml.MarshallingHttpMessageConverter\"&gt; &lt;constructor-arg&gt; &lt;bean class=\"org.springframework.oxm.xstream.XStreamMarshaller\"&gt; &lt;property name=\"streamDriver\"&gt; &lt;bean class=\"com.thoughtworks.xstream.io.xml.StaxDriver\"/&gt; &lt;/property&gt; &lt;property name=\"annotatedClasses\"&gt; &lt;list&gt; &lt;value&gt;com.jeeplus.core.persistence.BaseEntity&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;/constructor-arg&gt; &lt;property name=\"supportedMediaTypes\" value=\"application/xml\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;/mvc:message-converters&gt;&lt;/mvc:annotation-driven&gt; 上文中提到，mvc的所有自定义命名空间（如 mvc, context），都是以BeanDefinitionParser接口的实现来解析的。这个接口，有多个实现： 这是为了在不同的命令空间下进行解析，我们现在关注的是org.springframework.web.servlet.config.AnnotationDrivenBeanDefinitionParser。具体的代码，不关注，我只想要了解有这么一回事就行了。 在 上面类的 parse() 方法中，做了很多的事情，但我所关心的是，其中一句代码：MvcNamespaceUtils.registerDefaultComponents(parserContext, source); 注册了一些默认的组件。 public static void registerDefaultComponents(ParserContext parserContext, Object source) &#123; registerBeanNameUrlHandlerMapping(parserContext, source); registerHttpRequestHandlerAdapter(parserContext, source); registerSimpleControllerHandlerAdapter(parserContext, source);&#125; 其中，似乎第一个就是进行 url 与 handler相映射的注册。 我们可以这样理解，在mvc框架启动的过程中，启动了服务 DispatchServlet，然后还注册了很多的handlerMapping。当然，用注解来进行，url &lt;-&gt; 方法的映射。 doServcie()/doDispatch()这两个方法会根据请求数据，解析后找到 handlerMapping，然后根据 url 找到方法，直接调用即可。 protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; HttpServletRequest processedRequest = request; HandlerExecutionChain mappedHandler = null; boolean multipartRequestParsed = false; WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); try &#123; try &#123; ModelAndView mv = null; Object dispatchException = null; try &#123; processedRequest = this.checkMultipart(request); multipartRequestParsed = processedRequest != request; mappedHandler = this.getHandler(processedRequest); if (mappedHandler == null || mappedHandler.getHandler() == null) &#123; this.noHandlerFound(processedRequest, response); return; &#125; HandlerAdapter ha = this.getHandlerAdapter(mappedHandler.getHandler()); String method = request.getMethod(); boolean isGet = \"GET\".equals(method); if (isGet || \"HEAD\".equals(method)) &#123; long lastModified = ha.getLastModified(request, mappedHandler.getHandler()); if (this.logger.isDebugEnabled()) &#123; this.logger.debug(\"Last-Modified value for [\" + getRequestUri(request) + \"] is: \" + lastModified); &#125; if ((new ServletWebRequest(request, response)).checkNotModified(lastModified) &amp;&amp; isGet) &#123; return; &#125; &#125; if (!mappedHandler.applyPreHandle(processedRequest, response)) &#123; return; &#125; mv = ha.handle(processedRequest, response, mappedHandler.getHandler()); if (asyncManager.isConcurrentHandlingStarted()) &#123; return; &#125; this.applyDefaultViewName(processedRequest, mv); mappedHandler.applyPostHandle(processedRequest, response, mv); &#125; catch (Exception var20) &#123; dispatchException = var20; &#125; catch (Throwable var21) &#123; dispatchException = new NestedServletException(\"Handler dispatch failed\", var21); &#125; this.processDispatchResult(processedRequest, response, mappedHandler, mv, (Exception)dispatchException); &#125; catch (Exception var22) &#123; this.triggerAfterCompletion(processedRequest, response, mappedHandler, var22); &#125; catch (Throwable var23) &#123; this.triggerAfterCompletion(processedRequest, response, mappedHandler, new NestedServletException(\"Handler processing failed\", var23)); &#125; &#125; finally &#123; if (asyncManager.isConcurrentHandlingStarted()) &#123; if (mappedHandler != null) &#123; mappedHandler.applyAfterConcurrentHandlingStarted(processedRequest, response); &#125; &#125; else if (multipartRequestParsed) &#123; this.cleanupMultipart(processedRequest); &#125; &#125;&#125; 其简单的过程，就是通过 request 来获取 handler，然后根据 hanlder 获取 handlerAdapter，最后，把请求交给 mv = ha.handle(processedRequest, response, mappedHandler.getHandler()); 唉，就到这吧，有空专心研发的时候再仔细看看呢。","categories":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/tags/Java/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}]},{"title":"使用join进行联合查询","slug":"使用join进行联合查询","date":"2018-07-07T07:36:52.000Z","updated":"2018-07-07T07:36:52.000Z","comments":true,"path":"MySQL/使用join进行联合查询.html","link":"","permalink":"https://gowa2017.github.io/MySQL/使用join进行联合查询.html","excerpt":"单表已经无法满足我们的需求了，总不能把所有的数据字段都放在一个表撒，所以分表就是必须的，关联查询，经常会用到。就比如公司最近的业务就是一个主表，存储状态数据。所有的相关数据分布在好几张表内，如何建立有效高效的查询，就非常必要了。好久没有管理数据库，都快忘记了。现在来复习一下。","text":"单表已经无法满足我们的需求了，总不能把所有的数据字段都放在一个表撒，所以分表就是必须的，关联查询，经常会用到。就比如公司最近的业务就是一个主表，存储状态数据。所有的相关数据分布在好几张表内，如何建立有效高效的查询，就非常必要了。好久没有管理数据库，都快忘记了。现在来复习一下。 select 语句由于join是在select内使用的，我们还需要来观察一下select的基本格式： SELECT [ALL | DISTINCT | DISTINCTROW ] [HIGH_PRIORITY] [STRAIGHT_JOIN] [SQL_SMALL_RESULT] [SQL_BIG_RESULT] [SQL_BUFFER_RESULT] [SQL_CACHE | SQL_NO_CACHE] [SQL_CALC_FOUND_ROWS] select_expr [, select_expr ...] [FROM table_references [PARTITION partition_list] [WHERE where_condition] [GROUP BY &#123;col_name | expr | position&#125; [ASC | DESC], ... [WITH ROLLUP]] [HAVING where_condition] [ORDER BY &#123;col_name | expr | position&#125; [ASC | DESC], ...] [LIMIT &#123;[offset,] row_count | row_count OFFSET offset&#125;] [PROCEDURE procedure_name(argument_list)] [INTO OUTFILE 'file_name' [CHARACTER SET charset_name] export_options | INTO DUMPFILE 'file_name' | INTO var_name [, var_name]] [FOR UPDATE | LOCK IN SHARE MODE]] 简单地说，select语句就是： select what from which_table where conditon; 也就是上面语句中的 table_references。对于表的引用，可能是一个，也可能是多个。 table_references对于 表的引用， 可能有多种形式。 table_references: escaped_table_reference [, escaped_table_reference] ...escaped_table_reference: table_reference | &#123; OJ table_reference &#125;table_reference: table_factor | join_tabletable_factor: tbl_name [PARTITION (partition_names)] [[AS] alias] [index_hint_list] | table_subquery [AS] alias | ( table_references )join_table: table_reference [INNER | CROSS] JOIN table_factor [join_condition] | table_reference STRAIGHT_JOIN table_factor | table_reference STRAIGHT_JOIN table_factor ON conditional_expr | table_reference &#123;LEFT|RIGHT&#125; [OUTER] JOIN table_reference join_condition | table_reference NATURAL [&#123;LEFT|RIGHT&#125; [OUTER]] JOIN table_factorjoin_condition: ON conditional_expr | USING (column_list)index_hint_list: index_hint [, index_hint] ...index_hint: USE &#123;INDEX|KEY&#125; [FOR &#123;JOIN|ORDER BY|GROUP BY&#125;] ([index_list]) | IGNORE &#123;INDEX|KEY&#125; [FOR &#123;JOIN|ORDER BY|GROUP BY&#125;] (index_list) | FORCE &#123;INDEX|KEY&#125; [FOR &#123;JOIN|ORDER BY|GROUP BY&#125;] (index_list)index_list: index_name [, index_name] ... 一个表引用，也被称为 join 表达式。 一个表引用（当引用的是分区表的时候）可能会包含一个 PARTITION 选项，这包括一个 逗号分隔的分区 列表，子分区，或者两者皆有。这个选项跟随在表的后面，但在别名之前。这个选项的影响是，数据只会从列出的分区或子分区内选出。没有列出的表数据不会去查询。 table_factor的语法在标准SQL的基础上在MySQL中进行了扩展。标准的SQL只接受 table_reference，而不接受在括号内的 table_reference 列表。 这是一个保守的扩展，处于 列表中的逗号 都被认为是一个 inner join。如： SELECT * FROM t1 LEFT JOIN (t2, t3, t4) ON (t2.a = t1.a AND t3.b = t1.b AND t4.c = t1.c) 等于： SELECT * FROM t1 LEFT JOIN (t2 CROSS JOIN t3 CROSS JOIN t4) ON (t2.a = t1.a AND t3.b = t1.b AND t4.c = t1.c) 在MySql中，JOIN, CROSS JOIN, INNER JOIN语法上是相同的，可以相互替换。标准的SQL内就是不相等的，INNER JOIN会与一个ON语句配合使用，CROSS JOIN在其他情况下使用。 通常，如果 join 表达式内 只有 inner join操作，那么括号可以忽略。MySQL支持嵌套Join，嵌套索引的优化。 索引提示可以用来指定 MySQL 的优化器怎么样利用 索引。更多信息查看 索引提示。 优化器提示和 optimizer_switch 系统变量是另外影响优化器使用索引的方法。查看 8.9.3 优化提示 8.9.2 优化开关 接下来的列表描述了编写 joins 要考虑到的因素： 使用别名， as 可以省略 SELECT t1.name, t2.salary FROM employee AS t1 INNER JOIN info AS t2 ON t1.name = t2.name;SELECT t1.name, t2.salary FROM employee t1 INNER JOIN info t2 ON t1.name = t2.name; table_subquery在From语句中被看做一个 派成表 或子查询。Section 13.2.10.8, “Derived Tables”。这样的查询必须要有一个别名，作为结果表名称。比如： SELECT * FROM (SELECT 1, 2, 3) AS t1; INNER JOIN 与, 在没有 join 条件的时候是相等的，都会在指定的表上产生一个 笛卡尔积 结果集（每个表的每一行都会与其他表的任何一行进行 JOIN）。 然而，, 的优先级小于 INNER JOIN, CROSS JOIN, LEFT JOIN,等。如果你有Join条件的时候，混合使用 逗号 和其他 Join 类型，一个类似 Unknown column ‘col_name’ in ‘on clause’ 错误就可能会出现。我们后面会看看怎么样处理这样的信息。 位于 ON 后的 conditional_expr 可以是任何 WHERE 语句内可用的表达式。通常，ON 语句用来表示怎么样JOIN表，而WHERE用来限制包括在结果中的行。 在LEFT JOIN中，在 ON 或 USING 部分 在右表中，没有匹配的行，那么，右表对应的那一行将会返回全是NULL。可以用这个事实来查找在表中在另外一个表内不重复的行。 SELECT left_tbl.* FROM left_tbl LEFT JOIN right_tbl ON left_tbl.id = right_tbl.id WHERE right_tbl.id IS NULL; 这个例子寻找在 left_tbl中，对应 id 在右表中 不存在的记录。 参考Outer Join 优化 USING(column_list语句列出了在join的表内必须都包含的列，如果 表a, b都包含有列 c1, c2, c3，下面的语句会比较两个表中对应的列。 两个表的NATURAL [LEFT] JOIN被定义来语法上与 一个 含有 USING（包含两表中所有列）的 INNER JOIN 或 LEFT JOIN。 RIGHT JOIN与 LEFT JOIN工作一样，但为了兼容性，建议一直使用 LEFT JOIN。 { OJ ... }语法只是为了与ODBC兼容。大括号是应该直接写出。 SELECT left_tbl.* FROM &#123; OJ left_tbl LEFT OUTER JOIN right_tbl ON left_tbl.id = right_tbl.id &#125; WHERE right_tbl.id IS NULL; 可以和其他JOIN类型一起使用 { OJ ... }，比如INNER JOIN 和 OUTTER JOIN。这会帮助与其他一些第三方库的兼容，但这并不是官方的ODBC语法。 STRAIGHT_JOIN与JOIN类似，例外的是左表总是先于右表读取。这在很少的情况下会用到，这种情况下，join 优化器会按序处理表。 一些例子： SELECT * FROM table1, table2;SELECT * FROM table1 INNER JOIN table2 ON table1.id = table2.id;SELECT * FROM table1 LEFT JOIN table2 ON table1.id = table2.id;SELECT * FROM table1 LEFT JOIN table2 USING (id);SELECT * FROM table1 LEFT JOIN table2 ON table1.id = table2.id LEFT JOIN table3 ON table2.id = table3.id; Natural joins 和使用了 USING的join，包括 Outer join 变量，根据 SQL：2003标准处理。 NATURALJoin的重复行不会出现。 CREATE TABLE t1 (i INT, j INT);CREATE TABLE t2 (k INT, j INT);INSERT INTO t1 VALUES(1, 1);INSERT INTO t2 VALUES(1, 1);SELECT * FROM t1 NATURAL JOIN t2;SELECT * FROM t1 JOIN t2 USING (j); 输出结果如下： +------+------+------+| j | i | k |+------+------+------+| 1 | 1 | 1 |+------+------+------++------+------+------+| j | i | k |+------+------+------+| 1 | 1 | 1 |+------+------+------+ 在第一个select语句中，j 在两个表中都有，所以其成为了一个 join 列，根据 标准SQL，其在结果集内只出现一次。类似，在第二个select中，j 是一个 USING 中的列，其也只会出现一次。 冗余的列消除了，列顺序根据标准SQL，如下产生： 第一步，根据在第一个表中出现的顺序来排序共有的列。 第二步，第一个表中独有的列。 第三步，第二个表中独有的列。 两个共有的列合并为一列通过联合操作来定义 。这就是说，对于 t1.a 与 t2.a 在单个结果列中的定义是 a = COALESE(t1.a, t2.a)： COALESCE(x, y) = (CASE WHEN x IS NOT NULL THEN x ELSE y END) 如果 join操作是其他类型的join，结果列是指定join表的所有列的集合。 COALESCE操作的一个后果就是，对于 outer join，如果其中一个表的列总是NULL的话，它总是会包含 非NULL的那一列。如果两个表中的这一列都不为空，或者都为空，其值是相同的，哪个值作为结果其实不重要。一个简单的的解释这个情况的办法是，把一个 outer join 的 合并列 看作是一个 Join 操作的 inner 表的公共列。假设表 t1(a, b) 和 表 t2(a, c)有以下内容： t1 t2---- ----1 x 2 z2 y 3 w 下面这个join的结果是，其中，列 a 包含的是 t1.a的值： ysql&gt; SELECT * FROM t1 NATURAL LEFT JOIN t2;+------+------+------+| a | b | c |+------+------+------+| 1 | x | NULL || 2 | y | z |+------+------+------+ 而对于下面这个： mysql&gt; SELECT * FROM t1 NATURAL RIGHT JOIN t2;+------+------+------+| a | c | b |+------+------+------+| 2 | z | y || 3 | w | NULL |+------+------+------+ 其包含的是 t2.a 的值。 我们把他与 JOIN ... ON 相比较： mysql&gt; SELECT * FROM t1 LEFT JOIN t2 ON (t1.a = t2.a);+------+------+------+------+| a | b | a | c |+------+------+------+------+| 1 | x | NULL | NULL || 2 | y | 2 | z |+------+------+------+------+mysql&gt; SELECT * FROM t1 RIGHT JOIN t2 ON (t1.a = t2.a);+------+------+------+------+| a | b | a | c |+------+------+------+------+| 2 | y | 2 | z || NULL | NULL | 3 | w |+------+------+------+------+ USING 语句可以被 ON 语句重写。然而，尽管他们很相似，但他们并不总是一样。比如下面这两个： a LEFT JOIN b USING (c1, c2, c3)a LEFT JOIN b ON a.c1 = b.c1 AND a.c2 = b.c2 AND a.c3 = b.c3 如果我们想要判断哪个满足 join 条件，两者语法上是一致的。 但如果我们是想要决定 select * 会显示哪些列的时候，这就不一样了。USING 操作选择列中 联合 后的值，ON 会显示表中所有的列。对于 USING JOIN，SELECT * 会选择这些值： COALESCE(a.c1, b.c1), COALESCE(a.c2, b.c2), COALESCE(a.c3, b.c3) 而对于 ON： a.c1, a.c2, a.c3, b.c1, b.c2, b.c3 在 inner join中，COALESCE(a.c1, b.c1) 与 a.c1 或 b.c1 相似，因为两者值是相同的。对于 outer join（如 LEFT JOIN），其中有一个值可能是 NULL，这列将会被忽略。 ON 只能引用其操作数。 CREATE TABLE t1 (i1 INT);CREATE TABLE t2 (i2 INT);CREATE TABLE t3 (i3 INT);SELECT * FROM t1 JOIN t2 ON (i1 = i3) JOIN t3; 这将会出现一个错误 Unknown column ‘i3’ in ‘on clause’ ，因为 I3 位于表 t3内，其并不是 ON 的操作数，因为这样写： SELECT * FROM t1 JOIN t2 JOIN t3 ON (i1 = i3); JOIN 的优先级高于 ,，所以 t1, t2 JOIN t3 会被 预编译为 t1, (t2 join t3)，而不是 ((t1, t2) JOIN t3。这也会影响 ON 语句哦。 CREATE TABLE t1 (i1 INT, j1 INT);CREATE TABLE t2 (i2 INT, j2 INT);CREATE TABLE t3 (i3 INT, j3 INT);INSERT INTO t1 VALUES(1, 1);INSERT INTO t2 VALUES(1, 1);INSERT INTO t3 VALUES(1, 1);SELECT * FROM t1, t2 JOIN t3 ON (t1.i1 = t3.i3); 很明显，上面的语句也会出现一个错误。Unknown column ‘t1.i1’ in ‘on clause’ 。 为了正确的执行语句，我们应该这样做： SELECT * FROM (t1, t2) JOIN t3 ON (t1.i1 = t3.i3); 用 括号把先前的两个表给包围起来。 SELECT * FROM t1 JOIN t2 JOIN t3 ON (t1.i1 = t3.i3); 避免使用 逗号 操作符。 UPDATEupdate 也支持 table_reference 这样的形式来指定关联表。 UPDATE [LOW_PRIORITY] [IGNORE] table_reference SET assignment_list [WHERE where_condition] [ORDER BY ...] [LIMIT row_count]value: &#123;expr | DEFAULT&#125;assignment: col_name = valueassignment_list: assignment [, assignment] ... update sm_com_register_applicationstatus a join `v_sm_company` b on a.com_name = b.qymc set a.status='5', a.`is_auto_enter` ='1' where a.status='14';","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://gowa2017.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://gowa2017.github.io/tags/MySQL/"}],"keywords":[{"name":"MySQL","slug":"MySQL","permalink":"https://gowa2017.github.io/categories/MySQL/"}]},{"title":"安卓被强杀后台恢复时候崩溃的解决办法","slug":"安卓被强杀后台恢复时候崩溃的解决办法","date":"2018-06-18T03:50:35.000Z","updated":"2018-06-18T03:50:35.000Z","comments":true,"path":"Android/安卓被强杀后台恢复时候崩溃的解决办法.html","link":"","permalink":"https://gowa2017.github.io/Android/安卓被强杀后台恢复时候崩溃的解决办法.html","excerpt":"业务场景是这样的，用户在登录的时候，登录成功后会返回用户相当信息。当然，这个用户信息就放在了一个单例 的userManager里面。所有的Manager都是在Application建立的时候进行注册的。现在的问题就是，如果进入后台模式，再重新进入的话，很多基于用户ID的查询显示都会出现NPE错误。因为userManager中保存用户信息的变量已经被重新回收初始化了。","text":"业务场景是这样的，用户在登录的时候，登录成功后会返回用户相当信息。当然，这个用户信息就放在了一个单例 的userManager里面。所有的Manager都是在Application建立的时候进行注册的。现在的问题就是，如果进入后台模式，再重新进入的话，很多基于用户ID的查询显示都会出现NPE错误。因为userManager中保存用户信息的变量已经被重新回收初始化了。 问题在我们三userManage中，变量userInfo，是在 Login成功后才进行初始化的，我觉得应该更加健壮一些，应该在编译的时候就进行一下构造，这样的话，就不会出现调用其方法的时候，出现NPE错误。 后台回收app后发生了什么后台回收了app后，所有的相关资料都已经不存在于内存，但是，我们的任务，内存中的回退栈，并没有回收。所以我们还是能回到上一次我们离开时的界面的，但这个时候app进程其实已经被杀掉了。那么，这个应用进程内的所有内存信息，肯定也是没有了的。 默认情况下，安卓会保存activity的状态信息，进行恢复，但是有的信息它 是无法保存的。所以才会出现NPE错误。 在后台回收了app后，我们重新回到上次离开的地方时，系统会再次派生一个进程，建立application，但是却不会重新开始一个正常的流程。 我们现在要做的就是在回到 离开时 activity的时候，判断app是否是被强杀的，如果 是，那么就重新走一次流程。 任务与回退栈一个任务是一系列在业务上相关的 activity的集合，activity以先入后出的形式进行组织。 一个App可能会涉及多个任务。 这里我们利用到了两个属性：activity在 清单文件中的 launchMode 与 intent的 FLAG_ACTIVITY_CLEAR_TOP标志。 如果一个activity的 启动模式是 singleTask，那么，这个activity在初始化的时候会放在一个新任务的底部，如果这个activity已经存在一个任务中了，则不会新初始化，只会调用 activity 的 onNewIntent() 方法。 而 intent 的 FLAG_ACTIVITY_CLEAR_TOP则是会将指定的 activity放到栈的顶部，把其上的所有内容回收。 所以我们的思路是，把一个不基于任务可能出现意外错误的 activity设置为 singleTask ，然后，每次当检测到强杀的时候，就直接转到这个 activity，从这个activity开始继续下一步操作。这样，系统就会放弃 这个 activity以上的所有activity。 具体做法， 先在 application 中设置记录状态的变量。 建立一个 BaseActivity 类，所有的activity都继承这个类。 SplashActivity建立时设置 app 状态为1。进入 HomeActivity（singleTask模式）。 在 BaseActivity 在OnCreate中，检测app状态，如果状态不正确，启动 HomeActivity。 这样，所有的回收后的Activity在恢复时都会进行状态检测，决定是否要跳转到HomeActivity。 我们的启动流程SplashActivity --&gt; LoginActivity --&gt; MainActivity --&gt; OtherActivity 其中把 LoginActivity 设置为 singleTask，在BaseActivity中跳转到它的时候，为intent设置 FLAG_ACTIVITY_CLEAR_TOP标志。","categories":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/tags/Java/"},{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"}],"keywords":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}]},{"title":"android中的进程及内存管理","slug":"android中的进程及内存管理","date":"2018-06-12T04:46:17.000Z","updated":"2018-06-12T04:46:17.000Z","comments":true,"path":"Android/android中的进程及内存管理.html","link":"","permalink":"https://gowa2017.github.io/Android/android中的进程及内存管理.html","excerpt":"其实以为，安卓只需要在界面上进行了解就行了，其实不然。大多数时候，我们都是在JAVA进行业务逻辑的处理和数据的处理，与显示层其实没有什么太大的关系。更容易让我们忽略的是，如果对于内存管理，生命周期没有一定了解的话，总是会出现很多莫名其妙的问题。比如，基于网络获取的数据给存储到了 View或者 Activity内，那么，在安卓把它进行回收了的时候，就总是会出现 NPE 错误了。","text":"其实以为，安卓只需要在界面上进行了解就行了，其实不然。大多数时候，我们都是在JAVA进行业务逻辑的处理和数据的处理，与显示层其实没有什么太大的关系。更容易让我们忽略的是，如果对于内存管理，生命周期没有一定了解的话，总是会出现很多莫名其妙的问题。比如，基于网络获取的数据给存储到了 View或者 Activity内，那么，在安卓把它进行回收了的时候，就总是会出现 NPE 错误了。所以有必要对此进行一个了解及记录。 进程来自安卓官方的文档，开宗明义的就描述了，安卓是一个什么样的系统。应用基础 一文中的描述如下： Android 操作系统是一种多用户 Linux 系统，其中的每个应用都是一个不同的用户； 默认情况下，系统会为每个应用分配一个唯一的 Linux 用户 ID（该 ID 仅由系统使用，应用并不知晓）。系统为应用中的所有文件设置权限，使得只有分配给该应用的用户 ID 才能访问这些文件； 每个进程都具有自己的虚拟机 (VM)，因此应用代码是在与其他应用隔离的环境中运行； 默认情况下，每个应用都在其自己的 Linux 进程内运行。Android 会在需要执行任何应用组件时启动该进程，然后在不再需要该进程或系统必须为其他应用恢复内存时关闭该进程。 上面的描述说明，安卓，首先其是一个Linux系统，并且，利用安卓的用户权限管理机制为每个应用赋予一个不同的用户。每个应用，有自己的进程，有自己的内存空间及虚拟机。对于应用的进程。 在 进程与应用生命周期一文中也描述了一些很恼火的问题。 进程多数情况下，每个应用在其自己的Linux进程内运行。这个进程在应用的某些代码需要运行的时候建立，只有其应用不需要，或者系统需要释放内存来供其他应用使用的时候会结束。 一个不太寻常和安卓的基础特征是，应用进程的生命周期不是直接由其自己控制的。系统通过一系列的因素来决定其生命周期，如系统已知此应用的运行部分，对用户的重要程度，及系统有多少内存可用。 开发者需要明白各个组件（Activity，Service，BroadcastReceiver）是怎么样影响应用的生命周期的。不正确的使用这些组件可能会导致应用在执行重要活动的时候被系统给KIll 一个常见的进程生命周期Bug是 BroadcastReceiver 在其 BroadcastReceiver.onReceive() 方法中收到一个 intent 时启动了一个新的线程，然后就从方法中返回了。其返回后，系统就会认为，BroadcastReceiver 不再活跃，其就会将此进程标记为不再需要的（除非有其他应用组件还是活跃的）。所以，系统可能会在将来的某个时候就释放内存，同时，也会结束派生出来的线程。典型的解决办法是从BroadcaseReceiver内调度一个JobService，这样系统就会知道依然有活跃的任务存在。 为了确定哪个进程在内存低的时候被Kill，安卓会把每个进程放到一个 重要性等级中，其参考依据是应用进程中运行的组件及组件状态。下面是重要级别列表（从高至低）： 前台进程：当前用户正在交互的进程。很多组件会导致进程被认为是前台的。下面的任一条件满足，应用进程就会被认为是前台的： 运行一个屏幕最顶部与用户正在交互的 Activity（onResume()被调用）。BroadcastReceiver 正在运行（执行 BroadcastReceiver.onReceive()中）有一个Sevice并且在执行其中一个回调函数的代码。（Service.onCreate(), Service.onStart(), or Service.onDestroy()） 系统中这样的进程应该只有少数几个，只有在内存到达连这些进程都不能继续运行的时候才会杀掉这种进程。通常，在这个时候，系统已经到了一个 内存换页状态，所以需要这个杀掉进程的动作来保证用户交互的响应性。 可见进程：在做一些用户可以感受到的事情的进程，杀掉这样的进程对用户来说体验不好。满足下面条件的进程被认为是可见的： 运行一个用户可见，但不在前台的 Activity，（如调用了 onPause()方法）。这是有可能发生的，比如前台进程是一个对话框，而其允许先前的Activity在其后面。有一个 Service 以前台服务运行，通过 Service.startForeground()执行（这个方法会请求系统向对待用户敏感事件一样对待，或者向对用户可见一样）。其内用一个系统使用的，对用户来说能感受到的服务，比如 Live wallpaper，输入法服务等。 服务进程： 此进程内包含一个已经调用了startService() 的 Service。虽然这些过程对用户来说不是直接可见的，但他们通常在做用户关心的事情（如后台网络数据上传或下载），所以系统会保持这样的进程运行，除非位于其上的两个类型进程没有足够的内存了。长时间运行（例如30分钟或更长时间）的服务可能把重要性降级，以允许它们的进程下降到下面描述的缓存的LRU列表。 这有助于避免由于内存泄漏或其他问题而长时间运行的服务消耗大量内存，导致系统无法有效使用缓存进程。 缓存进程：当前不需要的进程，系统想什么干掉他就什么时候干掉。在正常运行的系统中，这些是内存管理中唯一涉及的过程：运行良好的系统将始终有多个高速缓存的进程可用（以便在应用程序之间进行更高效的切换），并根据需要定期清除最旧的进程。 只有在非常危急的情况下（也就是不希望出现的情况），系统才能达到所有高速缓存进程都被终止的程度，并且它必须开始查杀服务进程。这些进程通常包含一个或多个用户当前不可见的Activity实例（onStop（）方法已被调用并返回）。 如果他们正确地实施了他们的活动生命周期（请参阅活动以获取更多详细信息），那么当系统终止此类流程时，它不会影响用户在返回到该应用程序时的体验：当相关活动重新创建时，它可以恢复先前保存的状态 一个新的过程。 任务和回退栈原文：任务和返回栈 在用户执行一个特定的任务的时候，可能会和很多的 Activity 交互，这一系列的 Activity 就是 任务。而任务的具体实现形式，在安卓内就叫 回退栈。 以 先入后出 的形式进行组织。 设备主屏幕是大多数任务的起点。当用户触摸应用启动器中的图标（或主屏幕上的快捷方式）时，该应用的任务将出现在前台。 如果应用不存在任务（应用最近未曾使用），则会创建一个新任务，并且该应用的“主”Activity 将作为堆栈中的根 Activity 打开。 当前 Activity 启动另一个 Activity 时，该新 Activity 会被推送到堆栈顶部，成为焦点所在。 前一个 Activity 仍保留在堆栈中，但是处于停止状态。Activity 停止时，系统会保持其用户界面的当前状态。 用户按“返回”按钮时，当前 Activity 会从堆栈顶部弹出（Activity 被销毁），而前一个 Activity 恢复执行（恢复其 UI 的前一状态）。 堆栈中的 Activity 永远不会重新排列，仅推入和弹出堆栈：由当前 Activity 启动时推入堆栈；用户使用“返回”按钮退出时弹出堆栈。 因此，返回栈以“后进先出”对象结构运行。 图 1 通过时间线显示 Activity 之间的进度以及每个时间点的当前返回栈，直观呈现了这种行为。 如果用户继续按“返回”，堆栈中的相应 Activity 就会弹出，以显示前一个 Activity，直到用户返回主屏幕为止（或者，返回任务开始时正在运行的任意 Activity）。 当所有 Activity 均从堆栈中移除后，任务即不复存在。 任务是一个有机整体，当用户开始新任务或通过“主页”按钮转到主屏幕时，可以移动到“后台”。 尽管在后台时，该任务中的所有 Activity 全部停止，但是任务的返回栈仍旧不变，也就是说，当另一个任务发生时，该任务仅仅失去焦点而已，如图 2 中所示。然后，任务可以返回到“前台”，用户就能够回到离开时的状态。 例如，假设当前任务（任务 A）的堆栈中有三个 Activity，即当前 Activity 下方还有两个 Activity。 用户先按“主页”按钮，然后从应用启动器启动新应用。 显示主屏幕时，任务 A 进入后台。新应用启动时，系统会使用自己的 Activity 堆栈为该应用启动一个任务（任务 B）。与该应用交互之后，用户再次返回主屏幕并选择最初启动任务 A 的应用。现在，任务 A 出现在前台，其堆栈中的所有三个 Activity 保持不变，而位于堆栈顶部的 Activity 则会恢复执行。 此时，用户还可以通过转到主屏幕并选择启动该任务的应用图标（或者，通过从概览屏幕选择该应用的任务）切换回任务 B。这是 Android 系统中的一个多任务示例。 注：后台可以同时运行多个任务。但是，如果用户同时运行多个后台任务，则系统可能会开始销毁后台 Activity，以回收内存资源，从而导致 Activity 状态丢失。请参阅下面有关 Activity 状态的部分。 由于返回栈中的 Activity 永远不会重新排列，因此如果应用允许用户从多个 Activity 中启动特定 Activity，则会创建该 Activity 的新实例并推入堆栈中（而不是将 Activity 的任一先前实例置于顶部）。 因此，应用中的一个 Activity 可能会多次实例化（即使 Activity 来自不同的任务），如图 3 所示。因此，如果用户使用“返回”按钮向后导航，则会按 Activity 每个实例的打开顺序显示这些实例（每个实例的 UI 状态各不相同）。 但是，如果您不希望 Activity 多次实例化，则可修改此行为。 具体操作方法将在后面的管理任务部分中讨论。 Activity 和任务的默认行为总结如下： 当 Activity A 启动 Activity B 时，Activity A 将会停止，但系统会保留其状态（例如，滚动位置和已输入表单中的文本）。如果用户在处于 Activity B 时按“返回”按钮，则 Activity A 将恢复其状态，继续执行。 用户通过按“主页”按钮离开任务时，当前 Activity 将停止且其任务会进入后台。 系统将保留任务中每个 Activity 的状态。如果用户稍后通过选择开始任务的启动器图标来恢复任务，则任务将出现在前台并恢复执行堆栈顶部的 Activity。 如果用户按“返回”按钮，则当前 Activity 会从堆栈弹出并被销毁。 堆栈中的前一个 Activity 恢复执行。销毁 Activity 时，系统不会保留该 Activity 的状态。 即使来自其他任务，Activity 也可以多次实例化。 保存 Activity 状态正如上文所述，当 Activity 停止时，系统的默认行为会保留其状态。 这样一来，当用户导航回到上一个 Activity 时，其用户界面与用户离开时一样。 但是，在 Activity 被销毁且必须重建时，您可以而且应当主动使用回调方法保留 Activity 的状态。 系统停止您的一个 Activity 时（例如，新 Activity 启动或任务转到前台），如果系统需要回收系统内存资源，则可能会完全销毁该 Activity。 发生这种情况时，有关该 Activity 状态的信息将会丢失。如果发生这种情况，系统仍会知道该 Activity 存在于返回栈中，但是当该 Activity 被置于堆栈顶部时，系统一定会重建 Activity（而不是恢复 Activity）。 为了避免用户的工作丢失，您应主动通过在 Activity 中实现 onSaveInstanceState() 回调方法来保留工作。 如需了解有关如何保存 Activity 状态的详细信息，请参阅 Activity 文档。 管理任务Android 管理任务和返回栈的方式（如上所述，即：将所有连续启动的 Activity 放入同一任务和“后进先出”堆栈中）非常适用于大多数应用，而您不必担心 Activity 如何与任务关联或者如何存在于返回栈中。 但是，您可能会决定要中断正常行为。 也许您希望应用中的 Activity 在启动时开始新任务（而不是放置在当前任务中）；或者，当启动 Activity 时，您希望将其现有实例上移一层（而不是在返回栈的顶部创建新实例）；或者，您希望在用户离开任务时，清除返回栈中除根 Activity 以外的所有其他 Activity。 通过使用 清单文件元素中的属性和传递给 startActivity() 的 Intent 中的标志，您可以执行所有这些操作以及其他操作。 在这一方面，您可以使用的主要 属性包括： taskAffinity launchMode allowTaskReparenting clearTaskOnLaunch alwaysRetainTaskState finishOnTaskLaunch 您可以使用的主要 Intent 标志包括： FLAG_ACTIVITY_NEW_TASK FLAG_ACTIVITY_CLEAR_TOP FLAG_ACTIVITY_SINGLE_TOP 在下文中，您将了解如何使用这些清单文件属性和 Intent 标志定义 Activity 与任务的关联方式，以及 Activity 在返回栈中的行为方式。 此外，我们还单独介绍了有关如何在概览屏幕中显示和管理任务与 Activity 的注意事项。 如需了解详细信息，请参阅概览屏幕。 通常，您应该允许系统定义任务和 Activity 在概览屏幕中的显示方法，并且无需修改此行为。 定义启动模式启动模式允许您定义 Activity 的新实例如何与当前任务关联。 您可以通过两种方法定义不同的启动模式： 使用清单文件在清单文件中声明 Activity 时，您可以指定 Activity 在启动时应该如何与任务关联。 使用 Intent 标志调用 startActivity() 时，可以在 Intent 中加入一个标志，用于声明新 Activity 如何（或是否）与当前任务关联。 因此，如果 Activity A 启动 Activity B，则 Activity B 可以在其清单文件中定义它应该如何与当前任务关联（如果可能），并且 Activity A 还可以请求 Activity B 应该如何与当前任务关联。如果这两个 Activity 均定义 Activity B 应该如何与任务关联，则 Activity A 的请求（如 Intent 中所定义）优先级要高于 Activity B 的请求（如其清单文件中所定义）。 注：某些适用于清单文件的启动模式不可用作 Intent 标志，同样，某些可用作 Intent 标志的启动模式无法在清单文件中定义。 使用清单文件在清单文件中声明 Activity 时，您可以使用 元素的 launchMode 属性指定 Activity 应该如何与任务关联。 launchMode 属性指定有关应如何将 Activity 启动到任务中的指令。您可以分配给 launchMode 属性的启动模式共有四种： “standard”（默认模式）默认。系统在启动 Activity 的任务中创建 Activity 的新实例并向其传送 Intent。Activity 可以多次实例化，而每个实例均可属于不同的任务，并且一个任务可以拥有多个实例。 “singleTop”如果当前任务的顶部已存在 Activity 的一个实例，则系统会通过调用该实例的 onNewIntent() 方法向其传送 Intent，而不是创建 Activity 的新实例。Activity 可以多次实例化，而每个实例均可属于不同的任务，并且一个任务可以拥有多个实例（但前提是位于返回栈顶部的 Activity 并不是 Activity 的现有实例）。例如，假设任务的返回栈包含根 Activity A 以及 Activity B、C 和位于顶部的 D（堆栈是 A-B-C-D；D 位于顶部）。收到针对 D 类 Activity 的 Intent。如果 D 具有默认的 “standard” 启动模式，则会启动该类的新实例，且堆栈会变成 A-B-C-D-D。但是，如果 D 的启动模式是 “singleTop”，则 D 的现有实例会通过 onNewIntent() 接收 Intent，因为它位于堆栈的顶部；而堆栈仍为 A-B-C-D。但是，如果收到针对 B 类 Activity 的 Intent，则会向堆栈添加 B 的新实例，即便其启动模式为 “singleTop” 也是如此。 注：为某个 Activity 创建新实例时，用户可以按“返回”按钮返回到前一个 Activity。 但是，当 Activity 的现有实例处理新 Intent 时，则在新 Intent 到达 onNewIntent() 之前，用户无法按“返回”按钮返回到 Activity 的状态。 “singleTask”系统创建新任务并实例化位于新任务底部的 Activity。但是，如果该 Activity 的一个实例已存在于一个单独的任务中，则系统会通过调用现有实例的 onNewIntent() 方法向其传送 Intent，而不是创建新实例。一次只能存在 Activity 的一个实例。注：尽管 Activity 在新任务中启动，但是用户按“返回”按钮仍会返回到前一个 Activity。 “singleInstance”.与 “singleTask” 相同，只是系统不会将任何其他 Activity 启动到包含实例的任务中。该 Activity 始终是其任务唯一仅有的成员；由此 Activity 启动的任何 Activity 均在单独的任务中打开。我们再来看另一示例，Android 浏览器应用声明网络浏览器 Activity 应始终在其自己的任务中打开（通过在 元素中指定 singleTask 启动模式）。这意味着，如果您的应用发出打开 Android 浏览器的 Intent，则其 Activity 与您的应用位于不同的任务中。相反，系统会为浏览器启动新任务，或者如果浏览器已有任务正在后台运行，则会将该任务上移一层以处理新 Intent。 无论 Activity 是在新任务中启动，还是在与启动 Activity 相同的任务中启动，用户按“返回”按钮始终会转到前一个 Activity。 但是，如果启动指定 singleTask 启动模式的 Activity，则当某后台任务中存在该 Activity 的实例时，整个任务都会转移到前台。此时，返回栈包括上移到堆栈顶部的任务中的所有 Activity。 图 4 显示了这种情况。 如需了解有关在清单文件中使用启动模式的详细信息，请参阅 元素文档，其中更详细地讨论了 launchMode 属性和可接受的值。 注：使用 launchMode 属性为 Activity 指定的行为可由 Intent 附带的 Activity 启动标志替代，下文将对此进行讨论。 使用 Intent 标志启动 Activity 时，您可以通过在传递给 startActivity() 的 Intent 中加入相应的标志，修改 Activity 与其任务的默认关联方式。可用于修改默认行为的标志包括： FLAG_ACTIVITY_NEW_TASK在新任务中启动 Activity。如果已为正在启动的 Activity 运行任务，则该任务会转到前台并恢复其最后状态，同时 Activity 会在 onNewIntent() 中收到新 Intent。正如前文所述，这会产生与 “singleTask”launchMode 值相同的行为。 FLAG_ACTIVITY_SINGLE_TOP如果正在启动的 Activity 是当前 Activity（位于返回栈的顶部），则 现有实例会接收对 onNewIntent() 的调用，而不是创建 Activity 的新实例。正如前文所述，这会产生与 “singleTop”launchMode 值相同的行为。 FLAG_ACTIVITY_CLEAR_TOP如果正在启动的 Activity 已在当前任务中运行，则会销毁当前任务顶部的所有 Activity，并通过 onNewIntent() 将此 Intent 传递给 Activity 已恢复的实例（现在位于顶部），而不是启动该 Activity 的新实例。产生这种行为的 launchMode 属性没有值。 FLAG_ACTIVITY_CLEAR_TOP 通常与 FLAG_ACTIVITY_NEW_TASK 结合使用。一起使用时，通过这些标志，可以找到其他任务中的现有 Activity，并将其放入可从中响应 Intent 的位置。 注：如果指定 Activity 的启动模式为 “standard”，则该 Activity 也会从堆栈中移除，并在其位置启动一个新实例，以便处理传入的 Intent。 这是因为当启动模式为 “standard” 时，将始终为新 Intent 创建新实例。 处理关联任务和返回栈应用通常包含多个 Activity。每个 Activity 均应围绕用户可以执行的特定操作设计，并且能够启动其他 Activity。 例如，电子邮件应用可能有一个 Activity 显示新邮件的列表。用户选择某邮件时，会打开一个新 Activity 以查看该邮件。 一个 Activity 甚至可以启动设备上其他应用中存在的 Activity。例如，如果应用想要发送电子邮件，则可将 Intent 定义为执行“发送”操作并加入一些数据，如电子邮件地址和电子邮件。 然后，系统将打开其他应用中声明自己处理此类 Intent 的 Activity。在这种情况下，Intent 是要发送电子邮件，因此将启动电子邮件应用的“撰写”Activity（如果多个 Activity 支持相同 Intent，则系统会让用户选择要使用的 Activity）。发送电子邮件时，Activity 将恢复，看起来好像电子邮件 Activity 是您的应用的一部分。 即使这两个 Activity 可能来自不同的应用，但是 Android 仍会将 Activity 保留在相同的任务中，以维护这种无缝的用户体验。 任务是指在执行特定作业时与用户交互的一系列 Activity。 这些 Activity 按照各自的打开顺序排列在堆栈（即返回栈）中。 设备主屏幕是大多数任务的起点。当用户触摸应用启动器中的图标（或主屏幕上的快捷方式）时，该应用的任务将出现在前台。 如果应用不存在任务（应用最近未曾使用），则会创建一个新任务，并且该应用的“主”Activity 将作为堆栈中的根 Activity 打开。 当前 Activity 启动另一个 Activity 时，该新 Activity 会被推送到堆栈顶部，成为焦点所在。 前一个 Activity 仍保留在堆栈中，但是处于停止状态。Activity 停止时，系统会保持其用户界面的当前状态。 用户按“返回”按钮时，当前 Activity 会从堆栈顶部弹出（Activity 被销毁），而前一个 Activity 恢复执行（恢复其 UI 的前一状态）。 堆栈中的 Activity 永远不会重新排列，仅推入和弹出堆栈：由当前 Activity 启动时推入堆栈；用户使用“返回”按钮退出时弹出堆栈。 因此，返回栈以“后进先出”对象结构运行。 图 1 通过时间线显示 Activity 之间的进度以及每个时间点的当前返回栈，直观呈现了这种行为。 图 1. 显示任务中的每个新 Activity 如何向返回栈添加项目。 用户按“返回”按钮时，当前 Activity 随即被销毁，而前一个 Activity 恢复执行。 如果用户继续按“返回”，堆栈中的相应 Activity 就会弹出，以显示前一个 Activity，直到用户返回主屏幕为止（或者，返回任务开始时正在运行的任意 Activity）。 当所有 Activity 均从堆栈中移除后，任务即不复存在。 图 2. 两个任务：任务 B 在前台接收用户交互，而任务 A 则在后台等待恢复。 图 3. 一个 Activity 将多次实例化。 任务是一个有机整体，当用户开始新任务或通过“主页”按钮转到主屏幕时，可以移动到“后台”。 尽管在后台时，该任务中的所有 Activity 全部停止，但是任务的返回栈仍旧不变，也就是说，当另一个任务发生时，该任务仅仅失去焦点而已，如图 2 中所示。然后，任务可以返回到“前台”，用户就能够回到离开时的状态。 例如，假设当前任务（任务 A）的堆栈中有三个 Activity，即当前 Activity 下方还有两个 Activity。 用户先按“主页”按钮，然后从应用启动器启动新应用。 显示主屏幕时，任务 A 进入后台。新应用启动时，系统会使用自己的 Activity 堆栈为该应用启动一个任务（任务 B）。与该应用交互之后，用户再次返回主屏幕并选择最初启动任务 A 的应用。现在，任务 A 出现在前台，其堆栈中的所有三个 Activity 保持不变，而位于堆栈顶部的 Activity 则会恢复执行。 此时，用户还可以通过转到主屏幕并选择启动该任务的应用图标（或者，通过从概览屏幕选择该应用的任务）切换回任务 B。这是 Android 系统中的一个多任务示例。 注：后台可以同时运行多个任务。但是，如果用户同时运行多个后台任务，则系统可能会开始销毁后台 Activity，以回收内存资源，从而导致 Activity 状态丢失。请参阅下面有关 Activity 状态的部分。 由于返回栈中的 Activity 永远不会重新排列，因此如果应用允许用户从多个 Activity 中启动特定 Activity，则会创建该 Activity 的新实例并推入堆栈中（而不是将 Activity 的任一先前实例置于顶部）。 因此，应用中的一个 Activity 可能会多次实例化（即使 Activity 来自不同的任务），如图 3 所示。因此，如果用户使用“返回”按钮向后导航，则会按 Activity 每个实例的打开顺序显示这些实例（每个实例的 UI 状态各不相同）。 但是，如果您不希望 Activity 多次实例化，则可修改此行为。 具体操作方法将在后面的管理任务部分中讨论。 Activity 和任务的默认行为总结如下： 当 Activity A 启动 Activity B 时，Activity A 将会停止，但系统会保留其状态（例如，滚动位置和已输入表单中的文本）。如果用户在处于 Activity B 时按“返回”按钮，则 Activity A 将恢复其状态，继续执行。用户通过按“主页”按钮离开任务时，当前 Activity 将停止且其任务会进入后台。 系统将保留任务中每个 Activity 的状态。如果用户稍后通过选择开始任务的启动器图标来恢复任务，则任务将出现在前台并恢复执行堆栈顶部的 Activity。如果用户按“返回”按钮，则当前 Activity 会从堆栈弹出并被销毁。 堆栈中的前一个 Activity 恢复执行。销毁 Activity 时，系统不会保留该 Activity 的状态。即使来自其他任务，Activity 也可以多次实例化。导航设计 如需了解有关 Android 应用导航工作方式的详细信息，请阅读 Android 设计的导航指南。 保存 Activity 状态正如上文所述，当 Activity 停止时，系统的默认行为会保留其状态。 这样一来，当用户导航回到上一个 Activity 时，其用户界面与用户离开时一样。 但是，在 Activity 被销毁且必须重建时，您可以而且应当主动使用回调方法保留 Activity 的状态。 系统停止您的一个 Activity 时（例如，新 Activity 启动或任务转到前台），如果系统需要回收系统内存资源，则可能会完全销毁该 Activity。 发生这种情况时，有关该 Activity 状态的信息将会丢失。如果发生这种情况，系统仍会知道该 Activity 存在于返回栈中，但是当该 Activity 被置于堆栈顶部时，系统一定会重建 Activity（而不是恢复 Activity）。 为了避免用户的工作丢失，您应主动通过在 Activity 中实现 onSaveInstanceState() 回调方法来保留工作。 如需了解有关如何保存 Activity 状态的详细信息，请参阅 Activity 文档。 管理任务Android 管理任务和返回栈的方式（如上所述，即：将所有连续启动的 Activity 放入同一任务和“后进先出”堆栈中）非常适用于大多数应用，而您不必担心 Activity 如何与任务关联或者如何存在于返回栈中。 但是，您可能会决定要中断正常行为。 也许您希望应用中的 Activity 在启动时开始新任务（而不是放置在当前任务中）；或者，当启动 Activity 时，您希望将其现有实例上移一层（而不是在返回栈的顶部创建新实例）；或者，您希望在用户离开任务时，清除返回栈中除根 Activity 以外的所有其他 Activity。 通过使用 清单文件元素中的属性和传递给 startActivity() 的 Intent 中的标志，您可以执行所有这些操作以及其他操作。 在这一方面，您可以使用的主要 属性包括： taskAffinitylaunchModeallowTaskReparentingclearTaskOnLaunchalwaysRetainTaskStatefinishOnTaskLaunch您可以使用的主要 Intent 标志包括： FLAG_ACTIVITY_NEW_TASKFLAG_ACTIVITY_CLEAR_TOPFLAG_ACTIVITY_SINGLE_TOP在下文中，您将了解如何使用这些清单文件属性和 Intent 标志定义 Activity 与任务的关联方式，以及 Activity 在返回栈中的行为方式。 此外，我们还单独介绍了有关如何在概览屏幕中显示和管理任务与 Activity 的注意事项。 如需了解详细信息，请参阅概览屏幕。 通常，您应该允许系统定义任务和 Activity 在概览屏幕中的显示方法，并且无需修改此行为。 注意：大多数应用都不得中断 Activity 和任务的默认行为： 如果确定您的 Activity 必须修改默认行为，当使用“返回”按钮从其他 Activity 和任务导航回到该 Activity 时，请务必要谨慎并确保在启动期间测试该 Activity 的可用性。请确保测试导航行为是否有可能与用户的预期行为冲突。 定义启动模式启动模式允许您定义 Activity 的新实例如何与当前任务关联。 您可以通过两种方法定义不同的启动模式： 使用清单文件在清单文件中声明 Activity 时，您可以指定 Activity 在启动时应该如何与任务关联。 使用 Intent 标志调用 startActivity() 时，可以在 Intent 中加入一个标志，用于声明新 Activity 如何（或是否）与当前任务关联。 因此，如果 Activity A 启动 Activity B，则 Activity B 可以在其清单文件中定义它应该如何与当前任务关联（如果可能），并且 Activity A 还可以请求 Activity B 应该如何与当前任务关联。如果这两个 Activity 均定义 Activity B 应该如何与任务关联，则 Activity A 的请求（如 Intent 中所定义）优先级要高于 Activity B 的请求（如其清单文件中所定义）。 注：某些适用于清单文件的启动模式不可用作 Intent 标志，同样，某些可用作 Intent 标志的启动模式无法在清单文件中定义。 使用清单文件在清单文件中声明 Activity 时，您可以使用 元素的 launchMode 属性指定 Activity 应该如何与任务关联。 launchMode 属性指定有关应如何将 Activity 启动到任务中的指令。您可以分配给 launchMode 属性的启动模式共有四种： “standard”（默认模式）默认。系统在启动 Activity 的任务中创建 Activity 的新实例并向其传送 Intent。Activity 可以多次实例化，而每个实例均可属于不同的任务，并且一个任务可以拥有多个实例。“singleTop”如果当前任务的顶部已存在 Activity 的一个实例，则系统会通过调用该实例的 onNewIntent() 方法向其传送 Intent，而不是创建 Activity 的新实例。Activity 可以多次实例化，而每个实例均可属于不同的任务，并且一个任务可以拥有多个实例（但前提是位于返回栈顶部的 Activity 并不是 Activity 的现有实例）。例如，假设任务的返回栈包含根 Activity A 以及 Activity B、C 和位于顶部的 D（堆栈是 A-B-C-D；D 位于顶部）。收到针对 D 类 Activity 的 Intent。如果 D 具有默认的 “standard” 启动模式，则会启动该类的新实例，且堆栈会变成 A-B-C-D-D。但是，如果 D 的启动模式是 “singleTop”，则 D 的现有实例会通过 onNewIntent() 接收 Intent，因为它位于堆栈的顶部；而堆栈仍为 A-B-C-D。但是，如果收到针对 B 类 Activity 的 Intent，则会向堆栈添加 B 的新实例，即便其启动模式为 “singleTop” 也是如此。 注：为某个 Activity 创建新实例时，用户可以按“返回”按钮返回到前一个 Activity。 但是，当 Activity 的现有实例处理新 Intent 时，则在新 Intent 到达 onNewIntent() 之前，用户无法按“返回”按钮返回到 Activity 的状态。 “singleTask”系统创建新任务并实例化位于新任务底部的 Activity。但是，如果该 Activity 的一个实例已存在于一个单独的任务中，则系统会通过调用现有实例的 onNewIntent() 方法向其传送 Intent，而不是创建新实例。一次只能存在 Activity 的一个实例。注：尽管 Activity 在新任务中启动，但是用户按“返回”按钮仍会返回到前一个 Activity。 “singleInstance”.与 “singleTask” 相同，只是系统不会将任何其他 Activity 启动到包含实例的任务中。该 Activity 始终是其任务唯一仅有的成员；由此 Activity 启动的任何 Activity 均在单独的任务中打开。我们再来看另一示例，Android 浏览器应用声明网络浏览器 Activity 应始终在其自己的任务中打开（通过在 元素中指定 singleTask 启动模式）。这意味着，如果您的应用发出打开 Android 浏览器的 Intent，则其 Activity 与您的应用位于不同的任务中。相反，系统会为浏览器启动新任务，或者如果浏览器已有任务正在后台运行，则会将该任务上移一层以处理新 Intent。 无论 Activity 是在新任务中启动，还是在与启动 Activity 相同的任务中启动，用户按“返回”按钮始终会转到前一个 Activity。 但是，如果启动指定 singleTask 启动模式的 Activity，则当某后台任务中存在该 Activity 的实例时，整个任务都会转移到前台。此时，返回栈包括上移到堆栈顶部的任务中的所有 Activity。 图 4 显示了这种情况。 图 4. 显示如何将启动模式为“singleTask”的 Activity 添加到返回栈。 如果 Activity 已经是某个拥有自己的返回栈的后台任务的一部分，则整个返回栈也会上移到当前任务的顶部。 如需了解有关在清单文件中使用启动模式的详细信息，请参阅 元素文档，其中更详细地讨论了 launchMode 属性和可接受的值。 注：使用 launchMode 属性为 Activity 指定的行为可由 Intent 附带的 Activity 启动标志替代，下文将对此进行讨论。 使用 Intent 标志启动 Activity 时，您可以通过在传递给 startActivity() 的 Intent 中加入相应的标志，修改 Activity 与其任务的默认关联方式。可用于修改默认行为的标志包括： FLAG_ACTIVITY_NEW_TASK在新任务中启动 Activity。如果已为正在启动的 Activity 运行任务，则该任务会转到前台并恢复其最后状态，同时 Activity 会在 onNewIntent() 中收到新 Intent。正如前文所述，这会产生与 “singleTask”launchMode 值相同的行为。 FLAG_ACTIVITY_SINGLE_TOP如果正在启动的 Activity 是当前 Activity（位于返回栈的顶部），则 现有实例会接收对 onNewIntent() 的调用，而不是创建 Activity 的新实例。正如前文所述，这会产生与 “singleTop”launchMode 值相同的行为。 FLAG_ACTIVITY_CLEAR_TOP如果正在启动的 Activity 已在当前任务中运行，则会销毁当前任务顶部的所有 Activity，并通过 onNewIntent() 将此 Intent 传递给 Activity 已恢复的实例（现在位于顶部），而不是启动该 Activity 的新实例。产生这种行为的 launchMode 属性没有值。 FLAG_ACTIVITY_CLEAR_TOP 通常与 FLAG_ACTIVITY_NEW_TASK 结合使用。一起使用时，通过这些标志，可以找到其他任务中的现有 Activity，并将其放入可从中响应 Intent 的位置。 注：如果指定 Activity 的启动模式为 “standard”，则该 Activity 也会从堆栈中移除，并在其位置启动一个新实例，以便处理传入的 Intent。 这是因为当启动模式为 “standard” 时，将始终为新 Intent 创建新实例。 处理关联“关联”指示 Activity 优先属于哪个任务。默认情况下，同一应用中的所有 Activity 彼此关联。 因此，默认情况下，同一应用中的所有 Activity 优先位于相同任务中。 不过，您可以修改 Activity 的默认关联。 在不同应用中定义的 Activity 可以共享关联，或者可为在同一应用中定义的 Activity 分配不同的任务关联。 可以使用 元素的 taskAffinity 属性修改任何给定 Activity 的关联。 taskAffinity 属性取字符串值，该值必须不同于在 元素中声明的默认软件包名称，因为系统使用该名称标识应用的默认任务关联。 在两种情况下，关联会起作用： 启动 Activity 的 Intent 包含 FLAG_ACTIVITY_NEW_TASK 标志。默认情况下，新 Activity 会启动到调用 startActivity() 的 Activity 任务中。它将推入与调用方相同的返回栈。 但是，如果传递给 startActivity() 的 Intent 包含 FLAG_ACTIVITY_NEW_TASK 标志，则系统会寻找其他任务来储存新 Activity。这通常是新任务，但未做强制要求。 如果现有任务与新 Activity 具有相同关联，则会将 Activity 启动到该任务中。 否则，将开始新任务。 如果此标志导致 Activity 开始新任务，且用户按“主页”按钮离开，则必须为用户提供导航回任务的方式。 有些实体（如通知管理器）始终在外部任务中启动 Activity，而从不作为其自身的一部分启动 Activity，因此它们始终将 FLAG_ACTIVITY_NEW_TASK 放入传递给 startActivity() 的 Intent 中。请注意，如果 Activity 能够由可以使用此标志的外部实体调用，则用户可以通过独立方式返回到启动的任务，例如，使用启动器图标（任务的根 Activity 具有 CATEGORY_LAUNCHER Intent 过滤器；请参阅下面的启动任务部分）。 Activity 将其 allowTaskReparenting 属性设置为 “true”。在这种情况下，Activity 可以从其启动的任务移动到与其具有关联的任务（如果该任务出现在前台）。 例如，假设将报告所选城市天气状况的 Activity 定义为旅行应用的一部分。 它与同一应用中的其他 Activity 具有相同的关联（默认应用关联），并允许利用此属性重定父级。当您的一个 Activity 启动天气预报 Activity 时，它最初所属的任务与您的 Activity 相同。 但是，当旅行应用的任务出现在前台时，系统会将天气预报 Activity 重新分配给该任务并显示在其中。 提示：如果从用户的角度来看，一个 .apk 文件包含多个“应用”，则您可能需要使用 taskAffinity 属性将不同关联分配给与每个“应用”相关的 Activity。 清理返回栈如果用户长时间离开任务，则系统会清除所有 Activity 的任务，根 Activity 除外。 当用户再次返回到任务时，仅恢复根 Activity。系统这样做的原因是，经过很长一段时间后，用户可能已经放弃之前执行的操作，返回到任务是要开始执行新的操作。 您可以使用下列几个 Activity 属性修改此行为： alwaysRetainTaskState如果在任务的根 Activity 中将此属性设置为 “true”，则不会发生刚才所述的默认行为。即使在很长一段时间后，任务仍将所有 Activity 保留在其堆栈中。 clearTaskOnLaunch如果在任务的根 Activity 中将此属性设置为 “true”，则每当用户离开任务然后返回时，系统都会将堆栈清除到只剩下根 Activity。 换而言之，它与 alwaysRetainTaskState 正好相反。 即使只离开任务片刻时间，用户也始终会返回到任务的初始状态。 finishOnTaskLaunch此属性类似于 clearTaskOnLaunch，但它对单个 Activity 起作用，而非整个任务。 此外，它还有可能会导致任何 Activity 停止，包括根 Activity。 设置为 “true” 时，Activity 仍是任务的一部分，但是仅限于当前会话。如果用户离开然后返回任务，则任务将不复存在。启动任务通过为 Activity 提供一个以 “android.intent.action.MAIN” 为指定操作、以 “android.intent.category.LAUNCHER” 为指定类别的 Intent 过滤器，您可以将 Activity 设置为任务的入口点。 例如： &lt;activity ... &gt; &lt;intent-filter ... &gt; &lt;action android:name=\"android.intent.action.MAIN\" /&gt; &lt;category android:name=\"android.intent.category.LAUNCHER\" /&gt; &lt;/intent-filter&gt; ...&lt;/activity&gt; 此类 Intent 过滤器会使 Activity 的图标和标签显示在应用启动器中，让用户能够启动 Activity 并在启动之后随时返回到创建的任务中。 第二个功能非常重要：用户必须能够在离开任务后，再使用此 Activity 启动器返回该任务。 因此，只有在 Activity 具有 ACTION_MAIN 和 CATEGORY_LAUNCHER 过滤器时，才应该使用将 Activity 标记为“始终启动任务”的两种启动模式，即 “singleTask” 和 “singleInstance”。例如，我们可以想像一下如果缺少过滤器会发生什么情况： Intent 启动一个 “singleTask” Activity，从而启动一个新任务，并且用户花了些时间处理该任务。然后，用户按“主页”按钮。 任务现已发送到后台，而且不可见。现在，用户无法返回到任务，因为该任务未显示在应用启动器中。 如果您并不想用户能够返回到 Activity，对于这些情况，请将 元素的 finishOnTaskLaunch 设置为 “true”（请参阅清理堆栈）。 有关如何在概览屏幕中显示和管理任务与 Activity 的更多信息，请参阅概览屏幕。","categories":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/tags/Java/"},{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"}],"keywords":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}]},{"title":"Word-OOXML中的尺寸单位","slug":"Word-OOXML中的尺寸单位","date":"2018-06-08T01:42:39.000Z","updated":"2018-06-08T01:42:39.000Z","comments":true,"path":"Java/Word-OOXML中的尺寸单位.html","link":"","permalink":"https://gowa2017.github.io/Java/Word-OOXML中的尺寸单位.html","excerpt":"国际纸长标准 ISO 216 A4 （210 297mm，8.3 11.7in)，在word中档中的表示如下: 原文：https://startbigthinksmall.wordpress.com/2010/01/04/points-inches-and-emus-measuring-units-in-office-open-xml/ // pageSize: with and height in 20th of a point&lt;w:pgSz w:w=\"11906\" w:h=\"16838\"/&gt; 为什么会是这么巨大的值呢？因为其使用的单位是不同的。 对于上面我说到的 A4 纸张标准表示几个单位表示如下： 宽，高 Twip(1/20Pt) Point(1/72 Inch) Inch Cm（2.54*Inch） 缇 点 英寸 厘米 宽度 11906 595.3 8.27 21.0 高度 16838 841.9 11.69 29.7","text":"国际纸长标准 ISO 216 A4 （210 297mm，8.3 11.7in)，在word中档中的表示如下: 原文：https://startbigthinksmall.wordpress.com/2010/01/04/points-inches-and-emus-measuring-units-in-office-open-xml/ // pageSize: with and height in 20th of a point&lt;w:pgSz w:w=\"11906\" w:h=\"16838\"/&gt; 为什么会是这么巨大的值呢？因为其使用的单位是不同的。 对于上面我说到的 A4 纸张标准表示几个单位表示如下： 宽，高 Twip(1/20Pt) Point(1/72 Inch) Inch Cm（2.54*Inch） 缇 点 英寸 厘米 宽度 11906 595.3 8.27 21.0 高度 16838 841.9 11.69 29.7 单位对于 WordProcessingML 文件，其的DPI是 72。 halp-points常用来指定字体大小，12pt 的字体大小，等于 24 half points。 // run properties&lt;w:rPr&gt; // size value in half-points &lt;w:sz w:val=\"24\"/&gt;&lt;/w:rPr&gt; 1/50百分点用来在某些地方进行相对测量。用下面的表格例子来说明： &lt;w:tbl&gt; &lt;w:tblPr&gt; &lt;!-- table width in 50th of a percent --&gt; &lt;w:tblW w:w=\"2500\" w:type=\"pct\"/&gt; &lt;/w:tblPr&gt; &lt;w:tblGrid/&gt; &lt;w:tr&gt; &lt;w:tc&gt; &lt;w:p&gt; &lt;w:r&gt; &lt;w:t&gt;Hello, World!&lt;/w:t&gt; &lt;/w:r&gt; &lt;/w:p&gt; &lt;/w:tc&gt; &lt;/w:tr&gt;&lt;/w:tbl&gt; 上面的表格将会占据可用宽度的 50%.如果想用 1/20点，也就是 dxa（缇）来表示，要设置 w:type=dxa。 EMU(English Metric Unit)在基于矢量的绘制和图片的时候，EMU常用来进行描述坐标。EMU是 厘米 和 英寸的桥梁。1Inch = 914400 EMUs，1cm = 360000 EMUs。 加入我们要在一个表格内插入图片： &lt;w:tcW w:w=\"2410\" w:type=\"dxa\"/&gt; 宽 Twip(1/20Pt) Point(1/72 Inch) Inch Cm（2.54*Inch） EMU 缇 点 英寸 厘米 英寸*914400 宽度 2410 120.5 1.57361 1530350 计算方法： 2410 * 914400 / 20 /72 = 1530350 或者 直接： 2140 * 635 = 1530350 就是说 1 dxa = 653 EMU A4纸的像素和分辨率A4纸的尺寸是 210mm * 297 mm， 1 英寸 = 2.54 cm。 根据分辨率来得出常用的尺寸： 当分辨率是72像素/英寸时，A4纸像素长宽分别是842×595；当分辨率是120像素/英寸时，A4纸像素长宽分别是2105×1487；当分辨率是150像素/英寸时，A4纸像素长宽分别是1754×1240；当分辨率是300像素/英寸时，A4纸像素长宽分别是3508×2479； 现在我们一般 用的是 300dpi的这样。 POI内的实现 public static final int EMU_PER_PIXEL = 9525; public static final int EMU_PER_POINT = 12700; public static final int EMU_PER_CENTIMETER = 360000; public static final int MASTER_DPI = 576; public static final int PIXEL_DPI = 96; public static final int POINT_DPI = 72; public static final float DEFAULT_CHARACTER_WIDTH = 7.0017F; public static final int EMU_PER_CHARACTER = 66691;","categories":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/tags/Java/"},{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"},{"name":"word","slug":"word","permalink":"https://gowa2017.github.io/tags/word/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}]},{"title":"Java中的定时器Timer与TimerTask","slug":"Java中的定时器Timer与TimerTask","date":"2018-06-07T05:48:30.000Z","updated":"2018-06-07T05:48:30.000Z","comments":true,"path":"Java/Java中的定时器Timer与TimerTask.html","link":"","permalink":"https://gowa2017.github.io/Java/Java中的定时器Timer与TimerTask.html","excerpt":"","text":"定时器在我们需要循环执行，或者指定时间执行某个任务的时候非常的有用，所以Java其自身也提供了相应的类来实现这些功能。Java的 java.util 包内包含了 Timer, TimerTask。 简介从命令上就可以看出，Timer 是一个定时器，其实质是单独开了一个线程来进行计时。 TimerTask是一个任务，其本质，是一个实现了 Runnable 接口的抽象类。其只定义了一个抽象方法 run()，所以我们在使用的时候，实现这个run()方法就行了。 我们主要关注的是，Timer的冲个调度方法： public void schedule(TimerTask task, long delay);public void schedule(TimerTask task, Date time);public void schedule(TimerTask task, long delay, long period);public void schedule(TimerTask task, long delay, long period); 其方便代表的意思是： 指定延迟delay ms 后执行 task。 在指定时间 time 时 执行 task。 指定延迟delay ms 后，每 period ms 执行一次 task 任务 在指定时间 time 时 延迟 delay ms 执行 task，之后每 period ms 执行一次任务。 实例我们要实现一个模拟用户在线学习的功能，每个10秒钟，就给他增加学习时间： new Timer().schedule(new TimerTask() &#123; @Override public void run() &#123; addLearnTime(); &#125;&#125;,10000,10000); 就是这么简单。","categories":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/tags/Java/"},{"name":"android","slug":"android","permalink":"https://gowa2017.github.io/tags/android/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}]},{"title":"Java的接口与抽象类(Interface与Abstarct-Class)","slug":"Java的接口与抽象类(Interface与Abstarct-Class)","date":"2018-06-01T01:10:15.000Z","updated":"2018-06-01T01:10:15.000Z","comments":true,"path":"Java/Java的接口与抽象类(Interface与Abstarct-Class).html","link":"","permalink":"https://gowa2017.github.io/Java/Java的接口与抽象类(Interface与Abstarct-Class).html","excerpt":"","text":"在Java中感觉接口与抽象类非常的相似，但其实应该是有区别的，不然的话何必要设计出这两个东西来呢，所以呢仔细看了一下官方的文档，了解一下细节。 接口Interface在Java编程语言中，接口是一个引用类型，类似于一个类，它只能包含常量，方法签名，缺省方法，静态方法和嵌套类型。 方法体只存在于默认方法和静态方法中。 接口不能被实例化 - 它们只能由类实现或由其他接口扩展。 定义一个接口就和定义一个类相似： public interface OperateCar &#123; // constant declarations, if any // method signatures // An enum with values RIGHT, LEFT int turn(Direction direction, double radius, double startSpeed, double endSpeed); int changeLanes(Direction direction, double startSpeed, double endSpeed); int signalTurn(Direction direction, boolean signalOn); int getRadarFront(double distanceToCar, double speedOfCar); int getRadarRear(double distanceToCar, double speedOfCar); ...... // more method signatures&#125; 接口内的方法，只有签名，而没有方法体。 接口，只是方法的集合。任何实现了接口所定义方法的类或对象，都课被当做那个接口使用。还一个可实例化的类实现了一个接口，那么其应该为接口内的所有方法提供一个方法体。 例如，下面这个类就实现了上述的接口： public class OperateBMW760i implements OperateCar &#123; // the OperateCar method signatures, with implementation -- // for example: int signalTurn(Direction direction, boolean signalOn) &#123; // code to turn BMW's LEFT turn indicator lights on // code to turn BMW's LEFT turn indicator lights off // code to turn BMW's RIGHT turn indicator lights on // code to turn BMW's RIGHT turn indicator lights off &#125; // other members, as needed -- for example, helper classes not // visible to clients of the interface&#125; 在上面的机器人汽车示例中，实施接口的是汽车制造商。 当然，雪佛兰的实施将与丰田的实施大不相同，但两家制造商将坚持相同的接口。 作为接口客户的指导制造商将构建使用汽车位置GPS数据，数字街道地图和交通数据来驱动汽车的系统。 这样做时，指导系统将调用接口方法：转弯，改变车道，制动，加速等等。 抽象类Abstract Class抽象类的定义很简单，其实就是一个声明为 abstract的类，其可能，也可能不包含抽象方法。抽象类不能被实例化，但他们可以作为其他类的超类。 抽象方法就是由关键字 abstract 修饰 的方法。其也不会有方法体： abstract void moveTo(double deltaX, double deltaY); 如果一个类包含了抽象方法，那么它自己必须是 abstract的。 public abstract class GraphicObject &#123; // declare fields // declare nonabstract methods abstract void draw();&#125; 当一个抽象类被继承的时候，子类通常会提供所有抽象方法的实现。如果没有的话，子类也必须声明为 abstract。 接口中没有被声明为 defalut, static的方法是 隐式 抽象的，所以 abstract 关键字没有被用来修饰接口方法。 比较抽象类和接口非常的相似。我们不能实例化他们，他们可能包含了有实现或没有实现的方法。 然而，对于抽象类，可以定义 非 statis, final 的字段，可以定义 public protected private 约束的方法。 对于接口，所有的字段都自动是 public,statis,final的，所有声明的方法都是 public的。此外，我们只能扩展一个（抽象）类，不论其是否是抽象的，而我们可以实现任意数量的接口。 怎么选择抽象类还是接口？ 以下情况考虑使用抽象类： 在几个非常相关的类间共享代码 希望扩展抽象类的类有很多公共的方法和字段，或者需要不止是 public 的修饰符。 想声明非static, final的字段。这允许我们定义用来访问和修改这个对象的状态。 以下情况考虑使用接口： 期望不相关的类实现我们的接口。例如，接口 Comparable, Cloneable 想要对一个具体的数据类型指定行为，但是并不在乎谁实现了它的行为。 想要利用类型的多重继承优势。 JDK中一个抽象类的例子是 AbstractMap，其是 集合框架 的一部分。其子类（HashMap, TreeMap, ConcurrentHashMap）共享很多方法（如 get, put, containsKey, containsValue）。 JDK中一个实现了多个接口的例子就是 HashMap，其实现了接口 Serializable, Cloneable, Map。通过阅读这些接口列表，我们可以推端一个 HaspMap的实例可以被克隆，序列化（可以被转换为一个字节流），并且拥有 map 的功能。此外，Map接口已经被增强了，提供了很多默认方法如 merge, forEach。 很多库使用了 抽象类和接口。HaspMap 实现了几个接口，但也扩展了抽象类AbstractMap。","categories":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/tags/Java/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}]},{"title":"关于Java操纵word文书","slug":"关于Java操纵word文书","date":"2018-05-18T00:57:47.000Z","updated":"2018-05-18T00:57:47.000Z","comments":true,"path":"Java/关于Java操纵word文书.html","link":"","permalink":"https://gowa2017.github.io/Java/关于Java操纵word文书.html","excerpt":"","text":"公司做的业务需要为各部门生成其所需要的执法文书，或者是存档表单打印出来，纸质存档。但是涉及到会有图片，而且是数量类型是不定的这种情况。不能不来研究一下图片是怎么操作的了。 前言我们其实知道，word2007的 docx 格式，其实是一个xml文件的压缩包，操作 docx文档，其实就是操作那些xml文件。那么，我们需要明白的是，对于docx文档中的 xml 文件，在我们所使用的工具库内的表现形式是什么样的。 图片表示图片是以 DrawingML 形式进行保存的。这包括三个部分： 指定一个基本图片 对图标附加属性 转换图片 指定基本图片通过使用图片元素pic，可以将图片插入到演示文档中，该图片元素类似于形状元素，但包含一些关键区别，可以更加完整地存储图片信息。这个基本的图片元素应该包含blipfill和一些基本的非可视图片属性。 &lt;p:pic&gt; &lt;p:nvPicPr&gt; &lt;p:cNvPr id=\"4\" name=\"St_Patrick's_Day.jpg\"/&gt; &lt;p:cNvPicPr&gt; &lt;a:picLocks noChangeAspect=\"1\"/&gt; &lt;/p:cNvPicPr&gt; &lt;p:nvPr/&gt; &lt;/p:nvPicPr&gt; &lt;p:blipFill&gt; &lt;a:blip r:embed=\"rId2\"/&gt; &lt;a:stretch&gt; &lt;a:fillRect/&gt; &lt;/a:stretch&gt; &lt;/p:blipFill&gt; &lt;p:spPr&gt; &lt;a:xfrm&gt; &lt;a:off x=\"1346200\" y=\"914400\"/&gt; &lt;a:ext cx=\"3657600\" cy=\"2743200\"/&gt; &lt;/a:xfrm&gt; &lt;a:prstGeom prst=\"rect\"&gt; &lt;a:avLst/&gt; &lt;/a:prstGeom&gt; &lt;a:noFill/&gt; &lt;a:ln&gt; &lt;a:noFill/&gt; &lt;/a:ln&gt; &lt;/p:spPr&gt; &lt;/p:pic&gt; 附加属性现在已经指定了基本图片，我们可以继续使用更复杂的属性，例如重新着色选项和图片描述。 在下面的图片中，请注意曾经是绿色的图片已被重新着色为紫色。 这可以通过使用双色调元素来完成，这允许设置两种基色以用于重新着色整个图片。 第一个用于处理图片较暗的区域，第二个用于处理较亮的区域。 我们可以在下面看到黑色（＃000000）确实用于较暗的区域，而accent4（在这种情况下为紫色）用于较亮的区域。 &lt;p:pic&gt; &lt;p:nvPicPr&gt; &lt;p:cNvPr id=\"4\" name=\"St_Patrick's_Day.jpg\" descr=\"This is a Saint Patrick's day picture\"/&gt; &lt;p:cNvPicPr&gt; &lt;a:picLocks noChangeAspect=\"1\"/&gt; &lt;/p:cNvPicPr&gt; &lt;p:nvPr/&gt; &lt;/p:nvPicPr&gt; &lt;p:blipFill&gt; &lt;a:blip r:embed=\"rId2\"&gt; &lt;a:duotone&gt; &lt;a:srgbClr val=\"000000\"/&gt; &lt;a:schemeClr val=\"accent4\"/&gt; &lt;/a:duotone&gt; &lt;/a:blip&gt; &lt;a:stretch&gt; &lt;a:fillRect/&gt; &lt;/a:stretch&gt;&lt;p:spPr&gt; &lt;a:xfrm&gt; &lt;a:off x=\"1346200\" y=\"914400\"/&gt; &lt;a:ext cx=\"3657600\" cy=\"2743200\"/&gt; &lt;/a:xfrm&gt; &lt;a:prstGeom prst=\"rect\"&gt; &lt;a:avLst/&gt; &lt;/a:prstGeom&gt; &lt;a:noFill/&gt; &lt;a:ln&gt; &lt;a:noFill/&gt; &lt;/a:ln&gt; &lt;/p:spPr&gt; &lt;/p:pic&gt; 转换图片现在已经指定了基本属性和附加图片属性，我们可以开始合并形状属性。 下面是与上面描述的相同的图片，应用了3D相机透视图以及简单阴影和白色轮廓。 这些形状属性与可应用于形状元素的形状属性相同。 这里可以看到一幅特定图片的差异，图片边框。 它不是边界向内和向外扩展，而只是向外扩展。 &lt;p:pic&gt; &lt;p:nvPicPr&gt; &lt;p:cNvPr id=\"4\" name=\"St_Patrick's_Day.jpg\" descr=\"This is a Saint Patrick's day picture\"/&gt; &lt;p:cNvPicPr&gt; &lt;a:picLocks noChangeAspect=\"1\"/&gt; &lt;/p:cNvPicPr&gt; &lt;p:nvPr/&gt; &lt;/p:nvPicPr&gt; &lt;p:blipFill&gt; &lt;a:blip r:embed=\"rId2\"&gt; &lt;a:duotone&gt; &lt;a:srgbClr val=\"000000\"/&gt; &lt;a:schemeClr val=\"accent4\"/&gt; &lt;/a:duotone&gt; &lt;/a:blip&gt; &lt;a:stretch&gt; &lt;a:fillRect/&gt; &lt;/a:stretch&gt; &lt;/p:blipFill&gt; &lt;p:spPr&gt; &lt;a:xfrm&gt; &lt;a:off x=\"1346200\" y=\"914400\"/&gt; &lt;a:ext cx=\"3657600\" cy=\"2743200\"/&gt; &lt;/a:xfrm&gt; &lt;a:prstGeom prst=\"rect\"&gt; &lt;a:avLst/&gt; &lt;/a:prstGeom&gt; &lt;a:noFill/&gt; &lt;a:ln w=\"57150\"&gt; &lt;a:solidFill&gt; &lt;a:schemeClr val=\"bg1\"/&gt; &lt;/a:solidFill&gt; &lt;/a:ln&gt; &lt;a:effectLst&gt; &lt;a:outerShdw blurRad=\"50800\" dist=\"50800\" dir=\"2700000\" algn=\"tl\" rotWithShape=\"0\"&gt; &lt;a:srgbClr val=\"7D7D7D\"&gt; &lt;a:alpha val=\"65000\"/&gt; &lt;/a:srgbClr&gt; &lt;/a:outerShdw&gt; &lt;/a:effectLst&gt; &lt;a:scene3d&gt; &lt;a:camera prst=\"perspectiveRelaxedModerately\"/&gt; &lt;a:lightRig rig=\"threePt\" dir=\"t\"&gt; &lt;a:rot lat=\"0\" lon=\"0\" rev=\"18900000\"/&gt; &lt;/a:lightRig&gt; &lt;/a:scene3d&gt; &lt;/p:spPr&gt; &lt;/p:pic&gt; POI插入图片在POI中，是把图片信息存储在一个 ByteArrayInputStream中的，我们要做的，就是把这个信息添加到 文件内，然后在 main document part内展出 出来，据说官方的poi少了一个展示的过程，所以我们需要手动进行添加。 获取 byte[]我们的图片大多是从网络读取，所以参考了一下网上利用 HttpUrlConnection 来获取图片的操作，但是还有更好更方便的后面再研究了： public static byte[] getImageFromURL(String urlPath) &#123; System.out.println(urlPath); byte[] data = null; InputStream is = null; HttpURLConnection conn = null; try &#123; URL url = new URL(urlPath); conn = (HttpURLConnection) url.openConnection(); conn.setDoInput(true); // conn.setDoOutput(true); conn.setRequestMethod(\"GET\"); conn.setConnectTimeout(6000); is = conn.getInputStream(); if (conn.getResponseCode() == 200) &#123; data = readInputStream(is); &#125; else &#123; data = null; &#125; &#125; catch (MalformedURLException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; if (is != null) &#123; is.close(); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; conn.disconnect(); &#125; return data; 添加图片到xml包我们只要清楚，word的文档主要是在 document.xml内显示，然后其最常用的块级别的元素就是 Paragraph -&gt; Run -&gt; Text。这样。 XWPFDocumet本身，提供了一个将二进制序列存储到包内的方法： public String addPictureData(byte[] pictureData, int format) throws InvalidFormatException {这会返回一个ID。我们前面说过，POI似乎添加了后不能直接显示，还需要在文档的 xml 内插入对应的代码。这个没有什么接口，就只能才采用非常基本的方式了： public void createPicture(XWPFRun run, String blipId, int id, int width, int height) &#123; final int EMU = 9525; width *= EMU; height *= EMU; //String blipId = getAllPictures().get(id).getPackageRelationship().getId(); CTInline inline = run.getCTR().addNewDrawing().addNewInline(); String picXml = \"\" + \"&lt;a:graphic xmlns:a=\\\"http://schemas.openxmlformats.org/drawingml/2006/main\\\"&gt;\" + \" &lt;a:graphicData uri=\\\"http://schemas.openxmlformats.org/drawingml/2006/picture\\\"&gt;\" + \" &lt;pic:pic xmlns:pic=\\\"http://schemas.openxmlformats.org/drawingml/2006/picture\\\"&gt;\" + \" &lt;pic:nvPicPr&gt;\" + \" &lt;pic:cNvPr id=\\\"\" + id + \"\\\" name=\\\"Generated\\\"/&gt;\" + \" &lt;pic:cNvPicPr/&gt;\" + \" &lt;/pic:nvPicPr&gt;\" + \" &lt;pic:blipFill&gt;\" + \" &lt;a:blip r:embed=\\\"\" + blipId + \"\\\" xmlns:r=\\\"http://schemas.openxmlformats.org/officeDocument/2006/relationships\\\"/&gt;\" + \" &lt;a:stretch&gt;\" + \" &lt;a:fillRect/&gt;\" + \" &lt;/a:stretch&gt;\" + \" &lt;/pic:blipFill&gt;\" + \" &lt;pic:spPr&gt;\" + \" &lt;a:xfrm&gt;\" + \" &lt;a:off x=\\\"0\\\" y=\\\"0\\\"/&gt;\" + \" &lt;a:ext cx=\\\"\" + width + \"\\\" cy=\\\"\" + height + \"\\\"/&gt;\" + \" &lt;/a:xfrm&gt;\" + \" &lt;a:prstGeom prst=\\\"rect\\\"&gt;\" + \" &lt;a:avLst/&gt;\" + \" &lt;/a:prstGeom&gt;\" + \" &lt;/pic:spPr&gt;\" + \" &lt;/pic:pic&gt;\" + \" &lt;/a:graphicData&gt;\" + \"&lt;/a:graphic&gt;\"; //CTGraphicalObjectData graphicData = inline.addNewGraphic().addNewGraphicData(); XmlToken xmlToken = null; try &#123; xmlToken = XmlToken.Factory.parse(picXml); &#125; catch (XmlException xe) &#123; xe.printStackTrace(); &#125; inline.set(xmlToken); //graphicData.set(xmlToken); inline.setDistT(0); inline.setDistB(0); inline.setDistL(0); inline.setDistR(0); CTPositiveSize2D extent = inline.addNewExtent(); extent.setCx(width); extent.setCy(height); CTNonVisualDrawingProps docPr = inline.addNewDocPr(); docPr.setId(id); docPr.setName(\"Picture \" + id); docPr.setDescr(\"Generated\"); &#125; 这个方法，会在 run 内插入 上面代码中的 xml 内容。我们的图片才会正常的显示，其实当我们拿到了二进制的序列后，只需要两步即可： public void addPic(byte[] data) &#123; XWPFParagraph p = this.createParagraph(); XWPFRun r = p.createRun(); try &#123; //将数据添加到包内 String id = p.getDocument().addPictureData(data, Document.PICTURE_TYPE_PNG); // documents.xml内写入代码 createPicture(r, id, this.getNextPicNameNumber(Document.PICTURE_TYPE_PNG), 600, 600); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;&#125; 操纵表格首先要明白的是，tbl 是一个块级别的元素。tbl 有 行 tr 与 与 单元格 tc。tbl 有 一个虚拟的网格列概念。tc 通过 占据 网格列来获取宽度。 对于需要动态写入表格的时候，如果是带表头的表格，且是文档中的第一个表，我们可以如下操作： XWPFTable t = new CustomXWPFDocument().getTables().get(0);XWPFTableRow row = t.createRow();XWPFTableCell cell = row.getCell(0);cell.setText(\"第二行第一列\"); 再看看，我们的文件是否已经OK了。 有几个坑，是踩过的。对于word中的表格来说，其对齐是分两部分来设置的。 单元格 cell 设置 垂直对齐，而水平对齐，是在 Paragraph中来设置，所以如果要让一个单元格中的元素居中我们必须： cell.setVerticalAlignment(XWPFTableCell.XWPFVertAlign.CENTER); for (int k = 0; k &lt; cell.getParagraphs().size(); k++) &#123; XWPFParagraph paragraph = cell.getParagraphs().get(k); paragraph.setAlignment(ParagraphAlignment.CENTER); &#125; inline图片的显示在采用上节所说的方法添加图片到表格中内，出现了表格就显示了一行的情况，实在是百思不得其解。后面把文档打开了观察，原来我们是把元素设置了居中的，图片被居中上部的内容挡住了，即使没有内容但是我们设置了居中，就是会被挡住。 最后采用的方法，是移除了其中所有的段落： for (int i = 0; i &lt; cell.getParagraphs.size();i ++)&#123; cell.removeParagraph(i);&#125; 重新添加段落 run 后正常的。","categories":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/tags/Java/"},{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"},{"name":"word","slug":"word","permalink":"https://gowa2017.github.io/tags/word/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}]},{"title":"word2007文档格式","slug":"word2007文档格式","date":"2018-05-16T15:10:53.000Z","updated":"2018-05-16T15:10:53.000Z","comments":true,"path":"Java/word2007文档格式.html","link":"","permalink":"https://gowa2017.github.io/Java/word2007文档格式.html","excerpt":"对于文书来说，有很多需要生成的，一直以来用的是POI，但是似乎对文档的控制粒度粗了一下，所以潜心下来看一下怎么样操作docx4j。","text":"对于文书来说，有很多需要生成的，一直以来用的是POI，但是似乎对文档的控制粒度粗了一下，所以潜心下来看一下怎么样操作docx4j。 word文档格式对于2007版本的word格式后缀是 docx，这其实是一个zip有所的xml文件包。docx4j其实就是用java对象，来表示及引用这个包内的各个parts。这就不能不介绍一些存在于其中的概念了。 一个比较好的方式是把docx文档上传到 http://webapp.docx4java.org ，然后查看其中的 partList。 每个 part 通常是 XML，但也有可能不是（比如一个 image part）。 所有的 parts 形成了一棵树，如果某个 part 有 child，其必须有一个相关的 part 来标识。 包含主要文档主要文本的 part 叫做 Main Document Part。每个part都有一个名字，Main Document Part 通常叫做 /word/document.xml。 如果文档有 头部，Main Document Part会有一个 头部子part，这可以通过 Main Document Part 中的 关系来描述。 更详细的介绍可以参考文档 OpenXML。 Stories(翻译为节？）每个 WordprocessingML 由 一系列的 stories(节)组成。每个 story 都代表了 文档中的 一个文本区域。有如下 区域 ： comment, endnote, footer, footnote, frame, glossary document, header, main story, subdocument, text box。 除了一个例外（一个 glossary document），文档中的所有 stories 利用 一些通用的属性来表示每 个 sotry的内容。这些属性包括 字体信息，风格定义，数组定义，及文档设置等。 文档基本结构一个 最简单 的 WordprocessingML 文档的 main document story 由下面的XML元素组成： document — WordprocessingML main document part 的根 元素，它定义了 main document story body — 组成 main story 的 块-级别 结构集合的容器。 p — 一个段落 r — 一个 run t — 一个文本范围 一个 run 表示 story 中 具有共同属性集的文本区域. WordprocessingML 文档中的文本必须包含在 一个或多个 run 内。一个 paragraph 是一个或多个 run 以一个单元显示的集合。 run必须包含在 paragraph内。 看看下面最简单的一个例子： &lt;?xml version=\"1.0\"?&gt; &lt;w:document xmlns:w=\"...\"&gt; &lt;w:body&gt; &lt;w:p&gt; &lt;w:r&gt; &lt;w:t&gt;Hello, world.&lt;/w:t&gt; &lt;/w:r&gt; &lt;/w:p&gt; &lt;/w:body&gt; &lt;/w:document&gt; ParagraphsWordprocessingML 文档内最基本的 块级别内容单元就是 paragraphs，其使用 p 元素来存储。一个 paragraph 定义了以一个新行开始的分隔区域。其可以包含三类信息：可选的 段落属性，内联的内容（典型的是runs），及可选的用来比较两个文档内容的版本 IDs。 考虑一个内容居中的段落片段 The quick brown fox jumped …。段落内所有的文本都使用 斜体，段落内容拥有 排版居中属性，段落中的每个 run都存储了这个斜体属性，例如： &lt;w:p&gt; &lt;w:pPr&gt; &lt;w:jc w:val=\"center\"/&gt; &lt;w:rPr&gt; &lt;w:i/&gt; &lt;/w:rPr&gt; &lt;/w:pPr&gt; &lt;w:r&gt; &lt;w:rPr&gt; &lt;w:i/&gt; &lt;/w:rPr&gt; &lt;w:t&gt;The &lt;/w:r&gt; &lt;/w:p&gt;``` &gt; 每个run都指定了其内容的字符格式信息，而 段落指定了段落级别的格式信息（居中排版）。也要注意到，开头和结尾的空白字符在XML中不重要，想要指定空白的话，通过 **xml:space** 元素来指定。段落的属性通过 **pPr** 元素来指定。段落属性的例子如 **对齐，加粗，连字符，缩进，行间距，阴影，文字方向，及窗口/孤儿控制**。还要注意的是，一个 **pPr**元素可能会包含一系列的 *run* 属性--这些属性被应用到包含 *glyph* （这个是一个段落标记，不是整个段落）的这个*run*。## Runs文档层级的下一个级别就是 *run*，其定义了具有共同属性的文本区域，通过 *r* 元素来表示。*r* 元素允许生产者结合 *breaks, styles, or formatting properties 及对run 内的所有部分应用同样的信息。*跟 段落一样，run 也可以拥有属性。*r* 元素内的所有元素都有他们自己的属性，这通过一个可选的 *rPr* run属性元素来控制，但它必须是 *r* 元素的第一个 子元素。 按照顺序，*rPr*元素是一系列属性元素的容器，其会被应用在*ｒ*元素剩余子元素。例如，rPr容器元素中的元素允许使用者控制下列t元素中的文本是粗体，下划线还是可见文本。运行属性的一些示例是粗体，边框，字体样式，颜色，字体，字体大小，斜体，字距调整，禁用拼写/语法检查，底纹，小写字母，删除线，文本方向和下划线。```xml &lt;w:r&gt; &lt;w:rPr&gt;&lt;w:b/&gt; &lt;w:i/&gt; &lt;/w:rPr&gt; &lt;w:t&gt;quick&lt;/w:t&gt; &lt;/w:r&gt; 该运行在其运行内容中指定了两个格式化属性：粗体和斜体。这些属性因此适用于此运行中的所有内容。 生产者可以将运行分解成任意数量的较小运行，只要每个较小的运行使用同一组属性，而不更改文档的内容。 考虑下面的 WordprocessingML 文档，一个高效的生产者可以选择使用两次运行来输出这个内容，如下所示： &lt;w:r&gt;&lt;w:t xml:space=\"preserve\"&gt;only one word is &lt;/w:t&gt;&lt;/w:r&gt; &lt;w:r&gt; &lt;w:rPr&gt; &lt;w:i/&gt; &lt;w:rPr&gt; &lt;w:t&gt;emphasized&lt;/w:t&gt; &lt;/w:r&gt; 但是，效率较低的生产者可能会使用四次运行，如下所示： &lt;w:r&gt; &lt;w:t&gt;only one&lt;/w:t&gt;&lt;/w:r&gt; &lt;w:r&gt;&lt;w:t xml:space=\"preserve\"&gt; word is &lt;/w:t&gt; &lt;/w:r&gt; &lt;w:r&gt; &lt;w:rPr&gt; &lt;w:i/&gt; &lt;w:rPr&gt; &lt;w:t&gt;empha&lt;/w:t&gt; &lt;/w:r&gt; &lt;w:r&gt; &lt;w:rPr&gt; &lt;w:i/&gt; &lt;w:rPr&gt; &lt;w:t&gt;sized&lt;/w:t&gt; &lt;/w:r&gt; 尽管后面的例子使用四次而不是两次，但应用于每个文本区域的净运行信息是相同的，并且两者同样有效。 当然，可能需要打破运行。例如，该运行中仅有一些文本的属性发生更改，要求将更改的部分放入自己的运行中。另一个例子涉及将某种标记插入现有运行的中间。这需要运行分解成两个，并在它们之间插入标记。 下面的 run 有两个句子： &lt;w:r&gt;&lt;w:t&gt;Hello, world. How are you, today?&lt;/w:t&gt;&lt;/w:r&gt; 如果前两个单词用粗体显示，则需要将运行分解为两次运行以存储格式，如下所示： &lt;w:r&gt; &lt;w:rPr&gt; &lt;w:b/&gt; &lt;/w:rPr&gt;&lt;w:t xml:space=\"preserve\"&gt;Hello, world. &lt;/w:t&gt; &lt;/w:r&gt; &lt;w:r&gt; &lt;w:t&gt;How are you, today?&lt;/w:t&gt;&lt;/w:r&gt; 除文本外，运行还可以包含多种文本内容（§2.4.3）运行也可以包含一组用于文档“合并和比较”的修订ID。 Run Content此层次结构的最低级别是运行内容，即可以存储在文档的单个运行中的内容,WordprocessingML run 的内容包括： 文本 删除的文字 软线断裂 域代码 删除的域代码 脚注/尾注引用标记简单字段 页码 标签 Ruby文本 DrawingML内容 嵌入对象 图片 Headers and Footers页眉和页脚引用了 文本，图形，或数据（如页码，日期，文本标题等等），他们可能会在WordprocessingML中每页的顶或底部出现。 页眉出现在顶部（在 页内 main document content 的上方），页脚出现在其下面。 因为 WordprocessingML 是一个 基于流的格式，页眉和页脚通过通过文档特定节中所有页的页眉或页脚来应用。 Header PartWordprocessingML 的页眉信息存储在 header part，其在 Main Document part 或 Glossary Document part内以关联Id引用，关联类型是 http://schemas.openxmlformats.org/wordprocessingml/2006/header and has a content8 type of vnd-openxmlformats.officedocument.wordprocessingml-header+xml。 Footer Part同上，类型不同：http://schemas.openxmlformats.org/wordprocessingml/2006/footer and has a content13 type of vnd-openxmlformats.officedocument.wordprocessingml-footer+xml Headers and Footers如上所述，页眉和页脚信息会存在在 docx 包内的一个或多个 header/footer part内。 hdr元素为文档定义了单个标题，而ftr元素为其定义了单个页脚文件。 页眉和页脚只是WordprocessingML中的另一个文档 story。 在header/footer 的根元素内，元素的内容和 body 元素的内容相似，同时包含了去引用的 块级别-标记 —这种标记在 WordprocessingML 中与 段落元素平级。 文档每节都可能有三种不同类型的页眉和页脚。 First page header/footer Odd page header/footer Even page header/footer 表格WordprocessingML中另一种块级别的内容，表格，是按行和列排列的一组段落（和其他块级内容）。 简介WordprocessingML中的表格通过tbl元素定义，类似于HTML 标签。 表格元素指定文档中存在的表格的位置。 tbl元素具有两个定义其属性的元素：tblPr，它定义了表格范围属性（如样式和宽度）以及定义表格网格布局的tblGrid。 tbl元素还可以包含任意非零数量的行，其中每行都用tr元素指定。 每个tr元素可以包含任意非零数目的单元格，其中每个单元格都用tc元素指定。 考虑一个空的单细胞表（即：一行一列的表）和所有边上的1点边框： &lt;w:tbl&gt; &lt;w:tblPr&gt; &lt;w:tblW w:w=\"5000\" w:type=\"pct\"/&gt; &lt;w:tblBorders&gt; &lt;w:top w:val=\"single\" w:sz=\"4\" w:space=\"0\" w:color=\"auto\"/&gt; &lt;w:left w:val=\"single\" w:sz=\"4 w:space=\"0\" w:color=\"auto\"/&gt; &lt;w:bottom w:val=\"single\" w:sz=\"4\" w:space=\"0\" w:color=\"auto\"/&gt; &lt;w:right w:val=\"single\" w:sz=\"4\" w:space=\"0\" w:color=\"auto\"/&gt; &lt;/w:tblBorders&gt; &lt;/w:tblPr&gt; &lt;w:tblGrid&gt; &lt;w:gridCol w:w=\"10296\"/&gt; &lt;/w:tblGrid&gt; &lt;w:tr&gt; &lt;w:tc&gt; &lt;w:tcPr&gt; &lt;w:tcW w:w=\"0\" w:type=\"auto\"/&gt; &lt;/w:tcPr&gt; &lt;w:p/&gt; &lt;/w:tc&gt; &lt;/w:tr&gt; &lt;/w:tbl&gt; 上面这个表格指定了一个表格范围内的属性———— 100%页宽（tblW的 type 属性在 w 属性内的 宽度值 应该怎么解释———— pct 表示一个百分点的 50分之一）及表格的边框 tblBorders，tblGrid定义了一系列垂直共享的边缘，还有一个单行。 表格属性tblPr元素定义了表格范围内的属性，应用于表内每行和单元格的属性。 可以在tblPr元素的定义中找到完整的表格范围属性集。 考虑一个一行两列的简单表： &lt;w:tbl&gt;&lt;w:tblPr&gt;&lt;w:tblW w:w=\"0\" w:type=\"auto\"/&gt;&lt;w:tblBorders&gt;&lt;w:top w:val=\"single\" w:sz=\"4\" w:space=\"0\" w:color=\"auto\"/&gt;&lt;w:left w:val=\"single\" w:sz=\"4 w:space=\"0\" w:color=\"auto\"/&gt;&lt;w:bottom w:val=\"single\" w:sz=\"4\" w:space=\"0\" w:color=\"auto\"/&gt;&lt;w:right w:val=\"single\" w:sz=\"4\" w:space=\"0\" w:color=\"auto\"/&gt;&lt;w:insideH w:val=\"single\" w:sz=\"4\" w:space=\"0\" w:color=\"auto\"/&gt;&lt;w:insideV w:val=\"single\" w:sz=\"4\" w:space=\"0\" w:color=\"auto\"/&gt;&lt;/w:tblBorders&gt;&lt;/w:tblPr&gt;&lt;w:tblGrid&gt;...&lt;/w:tblGrid&gt;&lt;w:tr&gt;...&lt;/w:tr&gt;&lt;/w:tbl&gt; 在这个例子中，tblW元素定义了表格的总宽度，在这种情况下，该表格被设置为auto，它指定表的大小应该适合其内容。 tblBorders元素指定每个元素的表格边框，并在顶部，左侧，底部，右侧和水平内部指定一个点边框垂直边框。 通过指定表格，可以在单个行的基础上覆盖表格范围内的属性。 Table Grid（网格）tblGrid元素定义表格的网格。 表中的所有列（包括行之前和之后的空格）引用此网格。 每个gridCol在表格布局中定义单个网格列，用于定义表格中垂直线的存在。 tblGrid元素可以包含任意数量的gridCol元素，其中每个gridCol元素代表表格中的一个网格列并定义单个网格条目。 如下所述，当单元格布置在此表格中时，将强制所有单元格对齐由此网格定义的共享列边缘。 回到先前的那个 ‘一个单元格的表’ 例子，这个只有一列，列宽为 10296 （单位是1/20打印点）。这种单位（1/20 打印点，缇）常在 WordprocessingML中使用，然后转换成 1/1440 英寸（1/20 打印点，1点是1/72 英寸）。 &lt;w:tblGrid&gt; &lt;w:gridCol w:w=\"10296\"/&gt;&lt;/w:tblGrid&gt; 考虑一个复杂的表格，有两行两列，但是列不是对齐的。 该表格通过将单元布置在由三个表格网格列组成的表格网格上来表示，每个网格列表示表格中的逻辑垂直列： 虚线表示每个表格网格列的虚拟垂直延续，可以用WordprocessingML代码表示： &lt;w:tblGrid&gt; &lt;w:gridCol w:w=\"2952\"/&gt; &lt;w:gridCol w:w=\"4416\"/&gt; &lt;w:gridCol w:w=\"1488\"/&gt; &lt;/w:tblGrid&gt; &lt;w:tr&gt; &lt;w:tc&gt; &lt;w:tcPr&gt; &lt;w:tcW w:w=\"7368\" w:type=\"dxa\"/&gt; &lt;w:gridSpan w:val=‛2‛/&gt; &lt;/w:tcPr&gt; &lt;w:p/&gt; &lt;/w:tc&gt; &lt;w:tc&gt; &lt;w:tcPr&gt; &lt;w:tcW w:w=\"1488\" w:type=\"dxa\"/&gt; &lt;/w:tcPr&gt; &lt;w:p/&gt; &lt;/w:tc&gt; &lt;/w:tr&gt; &lt;w:tr&gt; &lt;w:tc&gt; &lt;w:tcPr&gt; &lt;w:tcW w:w=\"2952\" w:type=\"dxa\"/&gt; &lt;/w:tcPr&gt; &lt;w:p/&gt; &lt;/w:tc&gt; &lt;w:tc&gt; &lt;w:tcPr&gt; &lt;w:tcW w:w=\"5904\" w:type=\"dxa\"/&gt; &lt;w:gridSpan w:val=‛2‛/&gt; &lt;/w:tcPr&gt; &lt;w:p/&gt; &lt;/w:tc&gt; &lt;/w:tr&gt; 需要注意的是每个没有跨越 grid 列（比如，跨越两个相邻的 垂直线）的格子必须通过提供 gridSpan 元素并指定一个值来确定此格子会跨越多少个 grid columns。每个 gridCol表示一个共享的 列（格子可以捕捉），虽然其没有一个可视的显示。 表格行与单元格表格行用 tr 元素来定义，这和 HTML &lt;tr&gt;标记类似。tr 元素表现得像是一行单元格的容器。 tr 有一个用于格式化的子元素，trPr，它定义了 行的属性（比如行的宽度），以及其是否能跨页。每个属性，通过单独的 trPr 元素来定义 。同样，表格行可以包含两种类型的内容：自定义标记（自定义的XML或结构化的文档标签）与单元格。 行中的单元格通过 tc 来定义，其包含了表格的内容，与HTML的 &lt;td&gt;类似。 tc 有子元素用于格式化 tcPr，同样每个属性用一个 tcPr 独立定义。每个单元格可以包含任何有效的 块级别 内容，允许在单元格内嵌套段落和表格。 下面的例子中，tcW 定义了列的宽度，属性 w 的值单位是 twips（缇，1/20打印点）。这里，单元格的宽度是 8856 单位，其中，单位通过 type 属性来定义， dxa 表示单位是 缇。 &lt;w:tr&gt; &lt;w:tc&gt; &lt;w:tcPr&gt; &lt;w:tcW w:w=\"8856\" w:type=\"dxa\"/&gt; &lt;/w:tcPr&gt; &lt;w:p/&gt; &lt;/w:tc&gt; &lt;/w:tr&gt; tc 元素包含了单元格的内容，这个例子中是空的。 考虑一个包含 Hello world 的单元格。 Hello world 其可以这样表示： &lt;w:tr&gt; &lt;w:tc&gt; &lt;w:tcPr&gt; &lt;w:tcW w:w=\"1770\" w:type=\"dxa\"/&gt; &lt;/w:tcPr&gt; &lt;w:p&gt; &lt;w:r&gt; &lt;w:t&gt;Hello, World&lt;/w:t&gt; &lt;/w:r&gt; &lt;/w:p&gt; &lt;/w:tc&gt; &lt;/w:tr&gt; 在行和单元格级别，其属性必须指定 行和列 在 表的网格中是怎么放置的。 trPr 元素包含了行在开始前或结束后要忽略的网格数，这通过 gridBefore, gridAfter 元素来指定，这允许行在网格中的不同列处开始，同时 wBefore/wAfter元素指定了 前导/拖尾的空白。 tcPr 通过 gridSpan 元素来指定单元格跨越了多多少网格，tcW 用来指定单元格的宽度。 在前面的那个有两行和两个不同尺寸单元格的例子中，应该用三个网格列来进行表示（每个用垂直线分隔）。考虑第一行的如下表示： &lt;w:tr&gt; ... &lt;w:tc&gt; &lt;w:tcPr&gt; &lt;w:tcW w:w=\"5145\" w:type=\"dxa\" /&gt; &lt;w:gridSpan w:val=\"2\" /&gt; &lt;/w:tcPr&gt; &lt;w:p /&gt; &lt;/w:tc&gt; &lt;w:tc&gt; &lt;w:tcPr&gt; &lt;w:tcW w:w=\"2145\" w:type=\"dxa\" /&gt; &lt;/w:tcPr&gt; &lt;w:p/&gt; &lt;/w:tc&gt; &lt;/w:tr&gt; gridSpan 表示 单元格跨越了多少列。 要注意，表中的所有宽度都是首选宽度————因为表格总是要去满足 网格的需求，相互冲突的属性必须通过在一个指定的 manner 中重写首选宽度来解决。 表格布局 table layout表格以一系列的属性表示： 表级别的属性（如 首选宽度） 表网格列 行级别属性 单元格级别属性 为了控制这些属性，使用了下面的逻辑，这根据表的类型而定。 固定宽度表格这种表格不会根据内容而改变尺寸。这这种表格中，表格信息在下面的方式中使用： 表网格用来创建共享列，他们的初始宽度通过 tblGrid 元素来定义。 表的总宽度通过 tblW 属性来定义————如果设置为 auto or nil，那么其宽度通过 行和 单元格的信息来指定。 读取第一行会跳过此行开始前的初始网格单元数。要跳过的网格列宽度通过 wBefore属性来设置。 第一个单元格被放在网格中，通过 gridSpan设置的跨越网格列数宽度基于 tcW属性设置。 剩下的单元格被放入网格中。 在每个步骤中，如果单元格需求的宽度超过了表的宽度，那么每个嘿格列都会减少尺寸来适应表格宽度。 如果网格超出（如 tblGrid 指定了三个网格列，但是第二个单元格却使用了 gridSpan=4），网格会以一个默认的值来新建一个网格列。 对于每个接下来的行，单元格被放在网格中，每个网格列会被调整到所请求的最大值，这通过在 结束的那个单元格上增加宽度来实现。 自适应表格走完上面的步骤后会计算最大或者最小的宽度，调整网格列来进行适应。 最小的网格列宽，就是只跨越一个网格列的，内容最端的单元格宽度。 对于跨越多个网格列的单元阁，会增加所有网格列的宽度来适应其最小宽度 如果网格列中的单元格拥有首选宽度，第一个这种宽度会覆盖网格列内容宽度的最大宽度。 将单元格中的文本放到表格中，检查每个单元格内容的最小内容宽度。如果一个单元格的最小内容宽度超出了单元格当前的宽度，按下面的方式进行覆盖： 首先，通过缩小所有其他网格列的宽度（直到其最小宽度）来重新设置当前列宽。那么这个单元格的宽度会边到其最小值和 最大值内。 接着，重写首选的表格宽度，直到到达页宽。最后，如果需要的话在每个单元格内容内增加换行符。 复杂表格例子最好的演示就是通过例子来展示。 如上所述，单元格可以被水平合并。 垂直合并单元格可以通过 tcPr 的 vmerge 元素来指定单元格对行的合并。 First cell, first row Last cell, first row First cell, second row Last cell, second row 我们想要下面这样的效果： First cell, first row Last cell, first row Last cell, second row First cell, second row WordprocessingML 是这样表示的： &lt;w:tr&gt; &lt;w:tc&gt; &lt;w:p&gt; &lt;w:r&gt; &lt;w:t&gt;First cell, first row&lt;/w:t&gt; &lt;/w:r&gt; &lt;/w:p&gt; &lt;/w:tc&gt; &lt;w:tc&gt; &lt;w:tcPr&gt; &lt;w:vmerge w:val=\"restart\"/&gt; &lt;/w:tcPr&gt; &lt;w:p&gt; &lt;w:r&gt; &lt;w:t&gt;Last cell, first row&lt;/w:t&gt; &lt;/w:r&gt; &lt;/w:p&gt; &lt;w:p&gt; &lt;w:r&gt; &lt;w:t&gt;Last cell, second row&lt;/w:t&gt; &lt;/w:r&gt; &lt;/w:p&gt; &lt;/w:tc&gt; &lt;/w:tr&gt;&lt;w:tr&gt; &lt;w:tc&gt; &lt;w:p&gt; &lt;w:r&gt; &lt;w:t&gt;First cell, second row&lt;/w:t&gt; &lt;/w:r&gt; &lt;/w:p&gt; &lt;/w:tc&gt; &lt;w:tc&gt; &lt;w:tcPr&gt; &lt;w:vmerge/&gt; &lt;/w:tcPr&gt; &lt;w:p/&gt; &lt;/w:tc&gt; &lt;/w:tr&gt; vmerge 的值 restart,restarts开始一个合并区域，而没有值的单元格就会被合并到上面的一个。","categories":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/tags/Java/"},{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"},{"name":"docx4j","slug":"docx4j","permalink":"https://gowa2017.github.io/tags/docx4j/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}]},{"title":"Git命令-stash","slug":"Git命令-stash","date":"2018-05-15T03:18:14.000Z","updated":"2018-05-15T03:18:14.000Z","comments":true,"path":"Git/Git命令-stash.html","link":"","permalink":"https://gowa2017.github.io/Git/Git命令-stash.html","excerpt":"事情是这样的，用git在版本管理，经常是切换到其他分支去开发新功能。但是，经常有些BUG需要修补，而新功能某些文件没有进行跟踪就 stash了。等到我过几天回去再修改了些文件。又stash了。反正，问题就是，我用stash把我修改过的东西，覆盖回来了。产生冲突，很恶心。所以不能不仔细看一下这个到底是个什么原因，有什么办法来解决没有？","text":"事情是这样的，用git在版本管理，经常是切换到其他分支去开发新功能。但是，经常有些BUG需要修补，而新功能某些文件没有进行跟踪就 stash了。等到我过几天回去再修改了些文件。又stash了。反正，问题就是，我用stash把我修改过的东西，覆盖回来了。产生冲突，很恶心。所以不能不仔细看一下这个到底是个什么原因，有什么办法来解决没有？ 储藏与清理有时，当你在项目的一部分上已经工作一段时间后，所有东西都进入了混乱的状态，而这时你想要切换到另一个分支做一点别的事情。 问题是，你不想仅仅因为过会儿回到这一点而为做了一半的工作创建一次提交。 针对这个问题的答案是 git stash 命令。 储藏会处理工作目录的脏的状态 - 即，修改的跟踪文件与暂存改动 - 然后将未完成的修改保存到一个栈上，而你可以在任何时候重新应用这些改动。 储藏工作为了演示，进入项目并改动几个文件，然后可能暂存其中的一个改动。 如果运行 git status，可以看到有改动的状态： $ git statusChanges to be committed: (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) modified: index.htmlChanges not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: lib/simplegit.rb 现在想要切换分支，但是还不想要提交之前的工作；所以储藏修改。 将新的储藏推送到栈上，运行 git stash或 git stash save： $ git stashSaved working directory and index state \\ &quot;WIP on master: 049d078 added the index file&quot;HEAD is now at 049d078 added the index file(To restore them type &quot;git stash apply&quot;) 工作目录是干净的了： $ git status# On branch masternothing to commit, working directory clean 在这时，你能够轻易地切换分支并在其他地方工作；你的修改被存储在栈上。 要查看储藏的东西，可以使用 git stash list： $ git stash liststash@&#123;0&#125;: WIP on master: 049d078 added the index filestash@&#123;1&#125;: WIP on master: c264051 Revert &quot;added file_size&quot;stash@&#123;2&#125;: WIP on master: 21d80a5 added number to log 在本例中，有两个之前做的储藏，所以你接触到了三个不同的储藏工作。 可以通过原来 stash 命令的帮助提示中的命令将你刚刚储藏的工作重新应用：git stash apply。 如果想要应用其中一个更旧的储藏，可以通过名字指定它，像这样：git stash apply stash@{2}。 如果不指定一个储藏，Git 认为指定的是最近的储藏： $ git stash apply# On branch master# Changed but not updated:# (use &quot;git add &lt;file&gt;...&quot; to update what will be committed)## modified: index.html# modified: lib/simplegit.rb# 可以看到 Git 重新修改了当你保存储藏时撤消的文件。 在本例中，当尝试应用储藏时有一个干净的工作目录，并且尝试将它应用在保存它时所在的分支；但是有一个干净的工作目录与应用在同一分支并不是成功应用储藏的充分必要条件。 可以在一个分支上保存一个储藏，切换到另一个分支，然后尝试重新应用这些修改。 当应用储藏时工作目录中也可以有修改与未提交的文件 - 如果有任何东西不能干净地应用，Git 会产生合并冲突。 文件的改动被重新应用了，但是之前暂存的文件却没有重新暂存。 想要那样的话，必须使用 —index 选项来运行 git stash apply 命令，来尝试重新应用暂存的修改。 如果已经那样做了，那么你将回到原来的位置： $ git stash apply --index# On branch master# Changes to be committed:# (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage)## modified: index.html## Changed but not updated:# (use &quot;git add &lt;file&gt;...&quot; to update what will be committed)## modified: lib/simplegit.rb# 应用选项只会尝试应用暂存的工作 - 在堆栈上还有它。 可以运行 git stash drop加上将要移除的储藏的名字来移除它： $ git stash liststash@&#123;0&#125;: WIP on master: 049d078 added the index filestash@&#123;1&#125;: WIP on master: c264051 Revert &quot;added file_size&quot;stash@&#123;2&#125;: WIP on master: 21d80a5 added number to log $ git stash drop stash@&#123;0&#125;Dropped stash@&#123;0&#125; (364e91f3f268f0900bc3ee613f9f733e82aaed43) 也可以运行 git stash pop来应用储藏然后立即从栈上扔掉它。 创造性的储藏有几个储藏的变种可能也很有用。 第一个非常流行的选项是 stash save 命令的 —keep-index 选项。 它告诉 Git 不要储藏任何你通过 git add 命令已暂存的东西。 当你做了几个改动并只想提交其中的一部分，过一会儿再回来处理剩余改动时，这个功能会很有用。 $ git status -sM index.html M lib/simplegit.rb $ git stash --keep-indexSaved working directory and index state WIP on master: 1b65b17 added the index fileHEAD is now at 1b65b17 added the index file $ git status -sM index.html 另一个经常使用储藏来做的事情是像储藏跟踪文件一样储藏未跟踪文件。 默认情况下，git stash只会储藏已经在索引中的文件。 如果指定 —include-untracked 或 -u 标记，Git 也会储藏任何创建的未跟踪文件。 $ git status -sM index.html M lib/simplegit.rb?? new-file.txt $ git stash -uSaved working directory and index state WIP on master: 1b65b17 added the index fileHEAD is now at 1b65b17 added the index file $ git status -s$ 最终，如果指定了 —patch 标记，Git 不会储藏所有修改过的任何东西，但是会交互式地提示哪些改动想要储藏、哪些改动需要保存在工作目录中。 $ git stash --patchdiff --git a/lib/simplegit.rb b/lib/simplegit.rbindex 66d332e..8bb5674 100644--- a/lib/simplegit.rb+++ b/lib/simplegit.rb@@ -16,6 +16,10 @@ class SimpleGit return `#&#123;git_cmd&#125; 2&gt;&amp;1`.chomp end end++ def show(treeish = &apos;master&apos;)+ command(&quot;git show #&#123;treeish&#125;&quot;)+ end end testStash this hunk [y,n,q,a,d,/,e,?]? ySaved working directory and index state WIP on master: 1b65b17 added the index file 从储藏创建一个分支如果储藏了一些工作，将它留在那儿了一会儿，然后继续在储藏的分支上工作，在重新应用工作时可能会有问题。 如果应用尝试修改刚刚修改的文件，你会得到一个合并冲突并不得不解决它。 如果想要一个轻松的方式来再次测试储藏的改动，可以运行 git stash branch 创建一个新分支，检出储藏工作时所在的提交，重新在那应用工作，然后在应用成功后扔掉储藏： $ git stash branch testchangesSwitched to a new branch &quot;testchanges&quot;# On branch testchanges# Changes to be committed:# (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage)## modified: index.html## Changed but not updated:# (use &quot;git add &lt;file&gt;...&quot; to update what will be committed)## modified: lib/simplegit.rb#Dropped refs/stash@&#123;0&#125; (f0dfc4d5dc332d1cee34a634182e168c4efc3359) 这是在新分支轻松恢复储藏工作并继续工作的一个很不错的途径。 清理工作目录对于工作目录中一些工作或文件，你想做的也许不是储藏而是移除。 git clean 命令会帮你做这些事。 有一些通用的原因比如说为了移除由合并或外部工具生成的东西，或是为了运行一个干净的构建而移除之前构建的残留。 你需要谨慎地使用这个命令，因为它被设计为从工作目录中移除未被追踪的文件。 如果你改变主意了，你也不一定能找回来那些文件的内容。 一个更安全的选项是运行 git stash —all 来移除每一样东西并存放在栈中。 你可以使用git clean命令去除冗余文件或者清理工作目录。 使用git clean -f -d命令来移除工作目录中所有未追踪的文件以及空的子目录。 -f 意味着 强制 或 “确定移除”。 如果只是想要看看它会做什么，可以使用 -n 选项来运行命令，这意味着 “做一次演习然后告诉你 将要 移除什么”。 $ git clean -d -nWould remove test.oWould remove tmp/ 默认情况下，git clean 命令只会移除没有忽略的未跟踪文件。 任何与 .gitiignore 或其他忽略文件中的模式匹配的文件都不会被移除。 如果你也想要移除那些文件，例如为了做一次完全干净的构建而移除所有由构建生成的 .o 文件，可以给 clean 命令增加一个 -x 选项。 $ git status -s M lib/simplegit.rb?? build.TMP?? tmp/$ git clean -n -dWould remove build.TMPWould remove tmp/$ git clean -n -d -xWould remove build.TMPWould remove test.oWould remove tmp/ 如果不知道 git clean 命令将会做什么，在将 -n 改为 -f 来真正做之前总是先用 -n 来运行它做双重检查。 另一个小心处理过程的方式是使用 -i 或 “interactive” 标记来运行它。 这将会以交互模式运行 clean 命令。 $ git clean -x -iWould remove the following items: build.TMP test.o*** Commands *** 1: clean 2: filter by pattern 3: select by numbers 4: ask each 5: quit 6: helpWhat now&gt;","categories":[{"name":"Git","slug":"Git","permalink":"https://gowa2017.github.io/categories/Git/"}],"tags":[{"name":"编程","slug":"编程","permalink":"https://gowa2017.github.io/tags/编程/"},{"name":"Git","slug":"Git","permalink":"https://gowa2017.github.io/tags/Git/"}],"keywords":[{"name":"Git","slug":"Git","permalink":"https://gowa2017.github.io/categories/Git/"}]},{"title":"进程和线程概念览","slug":"进程和线程概念览","date":"2018-05-08T14:49:37.000Z","updated":"2018-05-08T14:49:37.000Z","comments":true,"path":"Android/进程和线程概念览.html","link":"","permalink":"https://gowa2017.github.io/Android/进程和线程概念览.html","excerpt":"当某个应用组件启动且该应用没有运行其他任何组件时，Android 系统会使用单个执行线程为应用启动新的 Linux 进程。默认情况下，同一应用的所有组件在相同的进程和线程（称为“主”线程）中运行。 如果某个应用组件启动且该应用已存在进程（因为存在该应用的其他组件），则该组件会在此进程内启动并使用相同的执行线程。 但是，您可以安排应用中的其他组件在单独的进程中运行，并为任何进程创建额外的线程。 本文档介绍进程和线程在 Android 应用中的工作方式。","text":"当某个应用组件启动且该应用没有运行其他任何组件时，Android 系统会使用单个执行线程为应用启动新的 Linux 进程。默认情况下，同一应用的所有组件在相同的进程和线程（称为“主”线程）中运行。 如果某个应用组件启动且该应用已存在进程（因为存在该应用的其他组件），则该组件会在此进程内启动并使用相同的执行线程。 但是，您可以安排应用中的其他组件在单独的进程中运行，并为任何进程创建额外的线程。 本文档介绍进程和线程在 Android 应用中的工作方式。文章来源：安卓官方API GUIDES` 进程默认情况下，同一应用的所有组件均在相同的进程中运行，且大多数应用都不会改变这一点。 但是，如果您发现需要控制某个组件所属的进程，则可在清单文件中执行此操作。 各类组件元素的清单文件条目—、、 和 —均支持 android:process 属性，此属性可以指定该组件应在哪个进程运行。您可以设置此属性，使每个组件均在各自的进程中运行，或者使一些组件共享一个进程，而其他组件则不共享。 此外，您还可以设置 android:process，使不同应用的组件在相同的进程中运行，但前提是这些应用共享相同的 Linux 用户 ID 并使用相同的证书进行签署。 此外， 元素还支持 android:process 属性，以设置适用于所有组件的默认值。 如果内存不足，而其他为用户提供更紧急服务的进程又需要内存时，Android 可能会决定在某一时刻关闭某一进程。在被终止进程中运行的应用组件也会随之销毁。 当这些组件需要再次运行时，系统将为它们重启进程。 决定终止哪个进程时，Android 系统将权衡它们对用户的相对重要程度。例如，相对于托管可见 Activity 的进程而言，它更有可能关闭托管屏幕上不再可见的 Activity 的进程。 因此，是否终止某个进程的决定取决于该进程中所运行组件的状态。 下面，我们介绍决定终止进程所用的规则。 进程生命周期Android 系统将尽量长时间地保持应用进程，但为了新建进程或运行更重要的进程，最终需要移除旧进程来回收内存。 为了确定保留或终止哪些进程，系统会根据进程中正在运行的组件以及这些组件的状态，将每个进程放入“重要性层次结构”中。 必要时，系统会首先消除重要性最低的进程，然后是重要性略逊的进程，依此类推，以回收系统资源。 重要性层次结构一共有 5 级。以下列表按照重要程度列出了各类进程（第一个进程最重要，将是最后一个被终止的进程）： 前台进程用户当前操作所必需的进程。如果一个进程满足以下任一条件，即视为前台进程： 托管用户正在交互的 Activity（已调用 Activity 的 onResume() 方法） 托管某个 Service，后者绑定到用户正在交互的 Activity 托管正在“前台”运行的 Service（服务已调用 startForeground()） 托管正执行一个生命周期回调的 Service（onCreate()、onStart() 或 onDestroy()） 托管正执行其 onReceive() 方法的 BroadcastReceiver通常，在任意给定时间前台进程都为数不多。只有在内存不足以支持它们同时继续运行这一万不得已的情况下，系统才会终止它们。 此时，设备往往已达到内存分页状态，因此需要终止一些前台进程来确保用户界面正常响应。 可见进程没有任何前台组件、但仍会影响用户在屏幕上所见内容的进程。 如果一个进程满足以下任一条件，即视为可见进程： 托管不在前台、但仍对用户可见的 Activity（已调用其 onPause() 方法）。例如，如果前台 Activity 启动了一个对话框，允许在其后显示上一 Activity，则有可能会发生这种情况。 托管绑定到可见（或前台）Activity 的 Service。可见进程被视为是极其重要的进程，除非为了维持所有前台进程同时运行而必须终止，否则系统不会终止这些进程。 服务进程正在运行已使用 startService() 方法启动的服务且不属于上述两个更高类别进程的进程。尽管服务进程与用户所见内容没有直接关联，但是它们通常在执行一些用户关心的操作（例如，在后台播放音乐或从网络下载数据）。因此，除非内存不足以维持所有前台进程和可见进程同时运行，否则系统会让服务进程保持运行状态。 后台进程包含目前对用户不可见的 Activity 的进程（已调用 Activity 的 onStop() 方法）。这些进程对用户体验没有直接影响，系统可能随时终止它们，以回收内存供前台进程、可见进程或服务进程使用。 通常会有很多后台进程在运行，因此它们会保存在 LRU （最近最少使用）列表中，以确保包含用户最近查看的 Activity 的进程最后一个被终止。如果某个 Activity 正确实现了生命周期方法，并保存了其当前状态，则终止其进程不会对用户体验产生明显影响，因为当用户导航回该 Activity 时，Activity 会恢复其所有可见状态。 有关保存和恢复状态的信息，请参阅 Activity文档。 空进程不含任何活动应用组件的进程。保留这种进程的的唯一目的是用作缓存，以缩短下次在其中运行组件所需的启动时间。 为使总体系统资源在进程缓存和底层内核缓存之间保持平衡，系统往往会终止这些进程。 根据进程中当前活动组件的重要程度，Android 会将进程评定为它可能达到的最高级别。例如，如果某进程托管着服务和可见 Activity，则会将此进程评定为可见进程，而不是服务进程。 此外，一个进程的级别可能会因其他进程对它的依赖而有所提高，即服务于另一进程的进程其级别永远不会低于其所服务的进程。 例如，如果进程 A 中的内容提供程序为进程 B 中的客户端提供服务，或者如果进程 A 中的服务绑定到进程 B 中的组件，则进程 A 始终被视为至少与进程 B 同样重要。 由于运行服务的进程其级别高于托管后台 Activity 的进程，因此启动长时间运行操作的 Activity 最好为该操作启动服务，而不是简单地创建工作线程，当操作有可能比 Activity 更加持久时尤要如此。例如，正在将图片上传到网站的 Activity 应该启动服务来执行上传，这样一来，即使用户退出 Activity，仍可在后台继续执行上传操作。使用服务可以保证，无论 Activity 发生什么情况，该操作至少具备“服务进程”优先级。 同理，广播接收器也应使用服务，而不是简单地将耗时冗长的操作放入线程中。 线程应用启动时，系统会为应用创建一个名为“主线程”的执行线程。 此线程非常重要，因为它负责将事件分派给相应的用户界面小部件，其中包括绘图事件。 此外，它也是应用与 Android UI 工具包组件（来自 android.widget 和 android.view 软件包的组件）进行交互的线程。因此，主线程有时也称为 UI 线程。 系统不会为每个组件实例创建单独的线程。运行于同一进程的所有组件均在 UI 线程中实例化，并且对每个组件的系统调用均由该线程进行分派。 因此，响应系统回调的方法（例如，报告用户操作的 onKeyDown() 或生命周期回调方法）始终在进程的 UI 线程中运行。 例如，当用户触摸屏幕上的按钮时，应用的 UI 线程会将触摸事件分派给小部件，而小部件反过来又设置其按下状态，并将失效请求发布到事件队列中。 UI 线程从队列中取消该请求并通知小部件应该重绘自身。 在应用执行繁重的任务以响应用户交互时，除非正确实现应用，否则这种单线程模式可能会导致性能低下。 具体地讲，如果 UI 线程需要处理所有任务，则执行耗时很长的操作（例如，网络访问或数据库查询）将会阻塞整个 UI。 一旦线程被阻塞，将无法分派任何事件，包括绘图事件。 从用户的角度来看，应用显示为挂起。 更糟糕的是，如果 UI 线程被阻塞超过几秒钟时间（目前大约是 5 秒钟），用户就会看到一个让人厌烦的“应用无响应”(ANR) 对话框。如果引起用户不满，他们可能就会决定退出并卸载此应用。 此外，Android UI 工具包并非线程安全工具包。因此，您不得通过工作线程操纵 UI，而只能通过 UI 线程操纵用户界面。 因此，Android 的单线程模式必须遵守两条规则： 不要阻塞 UI 线程 不要在 UI 线程之外访问 Android UI 工具包 工作线程根据上述单线程模式，要保证应用 UI 的响应能力，关键是不能阻塞 UI 线程。 如果执行的操作不能很快完成，则应确保它们在单独的线程（“后台”或“工作”线程）中运行。 例如，以下代码演示了一个点击侦听器从单独的线程下载图像并将其显示在 ImageView 中： public void onClick(View v) &#123; new Thread(new Runnable() &#123; public void run() &#123; Bitmap b = loadImageFromNetwork(\"http://example.com/image.png\"); mImageView.setImageBitmap(b); &#125; &#125;).start();&#125; 乍看起来，这段代码似乎运行良好，因为它创建了一个新线程来处理网络操作。 但是，它违反了单线程模式的第二条规则：不要在 UI 线程之外访问 Android UI 工具包 — 此示例从工作线程（而不是 UI 线程）修改了 ImageView。 这可能导致出现不明确、不可预见的行为，但要跟踪此行为困难而又费时。 为解决此问题，Android 提供了几种途径来从其他线程访问 UI 线程。 以下列出了几种有用的方法： Activity.runOnUiThread(Runnable) View.post(Runnable) View.postDelayed(Runnable, long) 例如，您可以通过使用 View.post(Runnable) 方法修复上述代码： public void onClick(View v) { new Thread(new Runnable() { public void run() { final Bitmap bitmap = loadImageFromNetwork(“http://example.com/image.png“); mImageView.post(new Runnable() { public void run() { mImageView.setImageBitmap(bitmap); } }); } }).start();} 现在，上述实现属于线程安全型：在单独的线程中完成网络操作，而在 UI 线程中操纵 ImageView。 但是，随着操作日趋复杂，这类代码也会变得复杂且难以维护。 要通过工作线程处理更复杂的交互，可以考虑在工作线程中使用 Handler 处理来自 UI 线程的消息。当然，最好的解决方案或许是扩展 AsyncTask 类，此类简化了与 UI 进行交互所需执行的工作线程任务。 使用 AsyncTaskAsyncTask 允许对用户界面执行异步操作。 它会先阻塞工作线程中的操作，然后在 UI 线程中发布结果，而无需您亲自处理线程和/或处理程序。 要使用它，必须创建 AsyncTask 的子类并实现 doInBackground() 回调方法，该方法将在后台线程池中运行。 要更新 UI，应该实现 onPostExecute() 以传递 doInBackground() 返回的结果并在 UI 线程中运行，以便您安全地更新 UI。 稍后，您可以通过从 UI 线程调用 execute() 来运行任务。 例如，您可以通过以下方式使用 AsyncTask 来实现上述示例： public void onClick(View v) &#123; new DownloadImageTask().execute(\"http://example.com/image.png\");&#125;private class DownloadImageTask extends AsyncTask&lt;String, Void, Bitmap&gt; &#123; /** The system calls this to perform work in a worker thread and * delivers it the parameters given to AsyncTask.execute() */ protected Bitmap doInBackground(String... urls) &#123; return loadImageFromNetwork(urls[0]); &#125; /** The system calls this to perform work in the UI thread and delivers * the result from doInBackground() */ protected void onPostExecute(Bitmap result) &#123; mImageView.setImageBitmap(result); &#125;&#125; 现在 UI 是安全的，代码也得到简化，因为任务分解成了两部分：一部分应在工作线程内完成，另一部分应在 UI 线程内完成。 下面简要概述了 AsyncTask 的工作方法，但要全面了解如何使用此类，您应阅读 AsyncTask 参考文档： 可以使用泛型指定参数类型、进度值和任务最终值 方法 doInBackground() 会在工作线程上自动执行 onPreExecute()、onPostExecute() 和 onProgressUpdate() 均在 UI 线程中调用 doInBackground() 返回的值将发送到 onPostExecute() 您可以随时在 doInBackground() 中调用publishProgress()，以在 UI 线程中执行 onProgressUpdate() 您可以随时取消任何线程中的任务 注意：使用工作线程时可能会遇到另一个问题，即：运行时配置变更（例如，用户更改了屏幕方向）导致 Activity 意外重启，这可能会销毁工作线程。 要了解如何在这种重启情况下坚持执行任务，以及如何在 Activity 被销毁时正确地取消任务，请参阅书架示例应用的源代码。 线程安全方法在某些情况下，您实现的方法可能会从多个线程调用，因此编写这些方法时必须确保其满足线程安全的要求。 这一点主要适用于可以远程调用的方法，如绑定服务中的方法。如果对 IBinder 中所实现方法的调用源自运行 IBinder 的同一进程，则该方法在调用方的线程中执行。但是，如果调用源自其他进程，则该方法将在从线程池选择的某个线程中执行（而不是在进程的 UI 线程中执行），线程池由系统在与 IBinder 相同的进程中维护。 例如，即使服务的 onBind() 方法将从服务进程的 UI 线程调用，在 onBind() 返回的对象中实现的方法（例如，实现 RPC 方法的子类）仍会从线程池中的线程调用。 由于一个服务可以有多个客户端，因此可能会有多个池线程在同一时间使用同一 IBinder 方法。因此，IBinder 方法必须实现为线程安全方法。 同样，内容提供程序也可接收来自其他进程的数据请求。尽管 ContentResolver 和 ContentProvider 类隐藏了如何管理进程间通信的细节，但响应这些请求的 ContentProvider 方法（query()、insert()、delete()、update() 和 getType() 方法）将从内容提供程序所在进程的线程池中调用，而不是从进程的 UI 线程调用。 由于这些方法可能会同时从任意数量的线程调用，因此它们也必须实现为线程安全方法。 进程间通信Android 利用远程过程调用 (RPC) 提供了一种进程间通信 (IPC) 机制，通过这种机制，由 Activity 或其他应用组件调用的方法将（在其他进程中）远程执行，而所有结果将返回给调用方。 这就要求把方法调用及其数据分解至操作系统可以识别的程度，并将其从本地进程和地址空间传输至远程进程和地址空间，然后在远程进程中重新组装并执行该调用。 然后，返回值将沿相反方向传输回来。 Android 提供了执行这些 IPC 事务所需的全部代码，因此您只需集中精力定义和实现 RPC 编程接口即可。 要执行 IPC，必须使用 bindService() 将应用绑定到服务上。如需了解详细信息，请参阅服务开发者指南。","categories":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"},{"name":"java","slug":"java","permalink":"https://gowa2017.github.io/tags/java/"}],"keywords":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}]},{"title":"Android中的线程","slug":"android中的线程","date":"2018-05-08T12:54:07.000Z","updated":"2018-05-08T12:54:07.000Z","comments":true,"path":"Android/android中的线程.html","link":"","permalink":"https://gowa2017.github.io/Android/android中的线程.html","excerpt":"","text":"这文章是逐渐进行总结的，一直以来对于Java并不是很理解。参考了以前曾了解过的POSIX的线程机制来进行对比和印证一下。JAVA是在VM内执行代码的，其实也和在真实机器内类似，很多东西在概念上是相似的。 进程按 POSIX 的定义，以前来说，进程是内核最小的调度实体，不过在后面，已经可以到线程了。通过把线程调度在不同的CPU上来实现并行的运算。关于多进程还是多线程，优劣各有不同。线程概念的提出，在于当在新建进程的时候，fork 的代价太高昂，而且有很多东西资源本来是可以共享的。但随线程而来的，则是对于内存资源共享的竞争性。于是就出现了很多的同步进制，如 文件锁，记录锁，信号量等等。 线程同一进程中的线程，共享所有的资源。也就是说，对于进程内的内存有相同的访问权限。所以在修改一个大家都能访问的资源的时候，一定要小心，而且因此而来的竞争条件也会让我们很头疼。但其更轻量，速度更快，效率更高。 Runnable接口Runnable接口类可以被任何其实例想用来被一个 线程执行的类实现。这个类必须定义一个没有参数的方法 run()。 这个接口设计用来 给那些想要在活跃时执行代码的对象提供一个通用的协议。比如，Runnable被类Thread实现。活跃 指的是一个线程已经开始，且没有被停止。 Runnable也提供了对于非Thread子类变得活跃的方式。 对于这样不是 Thread 子类，但实现了Runnable接口的类，可以通过 1、实例化一个Thread实例；2、把自己传递过去。大多数情况下，如果我们只是想覆盖run()方法，而没有其他的Thread方法。这很重要，一个类如果不是想要修改或者功能的时候，就不应该继承出一个子类来。 run()当一个实现了Runnable接口的对象用来建立一个线程时，启动这个线程会调用这个对象的 run 方法。 JAVA中的thread类thread是一个实现了 runnable 接口的类。一个 thread 是程序中的一个执行线程。Java VM允许一个应用有多个线程并发执行。 每个线程都有一个优先级。高优线级的线程会更容易被调度执行。每个线程都可能是或可能不是一个守护线程。当在线程内执行的代码创建新的 Thread 对象时，新线程和这个创建它的线程有相同的优先级，而且只有当创建它的线程是守护线程时，它才会成为守护线程。 当一个JAVA虚拟机启动的时候，通常会有一个非守护线程（这个线程典型的会调用特定类中的 main() 方法）。JAVA VM会在下面几种情况下中止执行这个线程： Runtime的exit()方法被调用，并且安全管理运行这个操作发生。 所有非守护线程都消亡，不管是从run()方法返回还是抛出一个run()方法外抛出一个违例。 有两种狠狠阿拉丁建立一个新线程。1、声明一个Thread 的子类 这个子类要重写Thread的run()方法。这个子类的实例就可以被分配和执行。例如，一个计算三次方大于一个指定值的类可以如下： class PrimeThread extends Thread &#123; long minPrime; PrimeThread(long minPrime) &#123; this.minPrime = minPrime; &#125; public void run() &#123; // compute primes larger than minPrime .... &#125;&#125; 接下来的代码就会建立一个线程并执行： PrimeThread p = new PrimeThread(143);p.start(); 另外一个建立线程的方法就是声明一个实现 Runnable 接口的类。这个类实现了 run() 方法。这个类的实例可以被分配，然后在作为 Thread参数来建立，接着执行。上面的例子可以这样改写： class PrimeRun implements Runnable &#123; long minPrime; PrimeRun(long minPrime)&#123; this.minPrime = minPrime; &#125; public void run() &#123; // compute primes larger than minPrime . . . &#125; 下面的代码同样这建立一个线程并执行： PrimeRun p = new PrimeRun(143);new Thread(p).start(); 每个线程都有一个名字。多个线程可能有相同的名字。当一个线程被创建时没有指定名字，会自动生成一个新名字。 在这个类中，传递一个 null 参数到构造器或方法将会导致一个 NullPointerException违例。 Handler 一个 Handler 允许我们 发送和处理与 一个进程的 MessageQueue相关联的 Message 和 Runnable对象。每个 Handler 实例都与一个 线程和线程的 消息队列相关联。当建立一个新 Handler 时，这是到线程/线程消息队列的的边界————从这个时候起，它就会递送消息和runnable到这个消息队列并执行，直到它们离开消息队列。 有两个主要的用法：1、在将来的某个时刻调度消息和runnable来执行; 2、入队一个你所有用但会在另外一个线程执行的动作。 调度消息要与 post(Runnable), postAtTime(Runnable, long), postDelayed(Runnable, Object, long), sendEmptyMessage(int), sendMessage(Message), sendMessageAtTime(Message, long), and sendMessageDelayed(Message, long)配合使用。post版本允许将被消息队列调用的Runnable对象在收到时就入队；sendMessage版本允许将一个 包含 一系列数据的Message对象被 Handler的 handleMessage(Message)方法处理（需要实现Handler的子类）。 当 post 或者 发送信息到 Handler时，你可以允许消息队列在在准备好时就处理信息，或指定一个延迟时间，或指定一个绝对时间。后面两种方式可以用来实现 超时，定时和其他基于时间的行为。 当你的应用建立了一个过程时，主线程专注于运行一个关于管理最顶层应用对象（activity, broadcast接收者等等）和他们建立的任何窗口的消息队列。我们可以创建我们自己的线程，然后通过一个Handler和主线程通信。这通过在我们创建的新线程对调用 post, sendMessage方法。对应的Runnable和 Message会在Handler的消息队列被调度，并在合适的时间处理。 AsyncTask AsyncTask 让我们可以完全又简单的使用UI线程。这个类允许我们在后台执行操作然后在UI程公布结果，在这过程中我们不用操作线程或handler。 AsyncTask设计来作为Thread, Handler的辅助，其并不想产生一个线程框架。AsyncTask经常被用来进行比较短的操作（最多几秒种）。如果需要的时候长时间运行的线程，强烈建议使用 java.util.concurrent包提供的API，比如Executor, ThreadPoolExecutor, FutureTask。 一个异步任务被一个在后台线程运行，然后结果公布在UI线程的计算定义。一个异步任务有三个一般参数，Params, Progress, Result和四个步骤 onPreExecute, doInBackground, onProgressUpdate, onPostExecute。 使用AsyncTask必须通过子类使用，子类最少会重写一个方法doInBackgroud(Params ...))，通常也会重写 onPostExecute(Result)。 一个例子： private class DownloadFilesTask extends AsyncTask&lt;URL, Integer, Long&gt; &#123; protected Long doInBackground(URL... urls) &#123; int count = urls.length; long totalSize = 0; for (int i = 0; i &lt; count; i++) &#123; totalSize += Downloader.downloadFile(urls[i]); publishProgress((int) ((i / (float) count) * 100)); // Escape early if cancel() is called if (isCancelled()) break; &#125; return totalSize; &#125; protected void onProgressUpdate(Integer... progress) &#123; setProgressPercent(progress[0]); &#125; protected void onPostExecute(Long result) &#123; showDialog(\"Downloaded \" + result + \" bytes\"); &#125;&#125; 一旦建立后，一个任务就会很容易的被执行： new DownloadFilesTask().execute(url1, url2, url3); AsyncTask的一般类型 Params 发送给任务的参数类型。 Progress 在后台计算时显示的进度单元类型。 Result 后台计算的结果类型。 一般来说三个参数类型都会用到，如果其中一个不会用到，简单的使用类型 Void: private class MyTask extends AsyncTask&lt;Void, Void, Void&gt; &#123;....&#125; 4个步骤当一个异步任务执行的时候，会经历四个步骤： onPreExecute() 这个方法在任务没有执行前，在主线程中调用。常常用来设置任务，具体来说，比如在用户的UI上显示一个进度条。 doInBackgroud(Params …) 当onPreExecute()执行完毕后，这个方法会在后台现程立刻执行。这个步骤用来进行背景计算，有可能会花很长时间。异步任务的类型会被传递给这个步骤。计算的结果必须通过这个步骤返回，然后传递给最后一个步骤。这个步骤可以使用 publishProgress(Progress...)来显示更多进度信息。这些进度信息值会在主线程公布，在onProgressUpdate(Progress...)步骤中进行。 onProgressUpdate(Progress …) 在调用publishProgress(Progress ...)后会在主线程中调用这个方法。这个执行的时间是未定义 。这个用来显示后台任务的一些进度信息。具体点说，就是可以用来显示一个进度栏或在一个文本区域内显示日志。 onPostExecute(Result) 后台计算结束后在主线程中调用。后台计算的结果以参数的形式传递到这个方法。 取消一个任务通过 cancel(boolean)可以在任何时候取消一个任务。调用这个方法会让后续对isCancelled()的调用返回 true。然后，在doInBackgroud(Object[])返回后，将不再调用 onPostExecute(Object)，而是调用 onCancelled(Object)。为了保证一个任务进可能快的取消，应该在 doInBackgroud(Object[])内间段性的检查 isCancelled()的返回值（如果可能的话）。 线程规则为了这个类正常的工作，有些线程规则必须需要遵守。 AsyncTask类必须在UI线程加载。 任务实例必须在UI线程创建 execute(Params …)必须在UI线程调用。 不要手动调用 四个步骤 方法。 任务只能执行一次（重复执行会抛出违例）。 内存观察AsyncTask保证所有的回调函数都是同步的。下面的操作不需要显式的淘汰赛部就是安全的。 在构建器或onPreExecute()内设置成员字段，并在doInBackgroud(Params ...)内引用。 在doInBackgroud(Params ...)内设置成员字段后，在onProgressUpdate(Progress ...), onPostExecute(Result)内引用。 执行顺序初次介绍的时候，AsyncTask在一个后台线程内序列执行。从DONUT版本开始，这改变到允许在一个线程池内执行，允许多个任务并发操作。从HONEYCOMB开始，所有的任务在一个线程内执行，用来避免因为并发执行的很多错误。 访问UI线程方法Activity.runOnUiThread(Runnable)void runOnUiThread (Runnable action) 在UI线程内运行指定的动作。如果当前线程是UI线程，这个动作会被立刻执行。如果不是，这个动作会被post到UI线程的事件队列 View.post(Runnable)boolean post (Runnable action) 将 Runnable添加到 消息队列。这个 action会在UI线程执行。 View.postDelayed(Runnable, long)同上，不过会延迟一点时间 long。","categories":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"},{"name":"thread","slug":"thread","permalink":"https://gowa2017.github.io/tags/thread/"}],"keywords":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}]},{"title":"安装开发常用知识记录","slug":"安装开发常用知识记录","date":"2018-05-08T05:38:20.000Z","updated":"2018-05-08T05:38:20.000Z","comments":true,"path":"Android/安装开发常用知识记录.html","link":"","permalink":"https://gowa2017.github.io/Android/安装开发常用知识记录.html","excerpt":"","text":"一些常用用的的组件等 PickerRecyclerViewAdapterPersistence","categories":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"}],"keywords":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}]},{"title":"RxJava2简介","slug":"RxJava2简介","date":"2018-05-07T18:14:29.000Z","updated":"2018-05-07T18:14:29.000Z","comments":true,"path":"RxJava/RxJava2简介.html","link":"","permalink":"https://gowa2017.github.io/RxJava/RxJava2简介.html","excerpt":"","text":"RxJava是 响应式扩展 的Java VM实现：采用观察者序列来组成异步和事件驱动的程序的一个库。 其扩展了 观察者模式 来支持 数据/事件的序列，并增加了操作符，这允许我们通过生命来组成序列，而不用担心底层的如 线程，同步，线程安全和并发数据结构等。 开始在 AS 中 加上 compile \"io.reactivex.rxjava2:rxjava:2.x.y\" 把 x, y 换成最新的版本号。 Hello World例子程序： package rxjava.examples;import io.reactivex.*;public class HelloWorld &#123; public static void main(String[] args) &#123; Flowable.just(\"Hello world\").subscribe(System.out::println); &#125;&#125; 如果我们使用的开发环境不支持 Java 8 的 lambdas，必须自己创建一个内部的 Consumer。 import io.reactivex.functions.Consumer;Flowable.just(\"Hello world\") .subscribe(new Consumer&lt;String&gt;() &#123; @Override public void accept(String s) &#123; System.out.println(s); &#125; &#125;); 基本类 io.reactivex.Flowable: 0..N flows, supporting Reactive-Streams and backpressure io.reactivex.Observable: 0..N flows, no backpressure, io.reactivex.Single: a flow of exactly 1 item or an error, io.reactivex.Completable: a flow without items but only a completion or error signal, io.reactivex.Maybe: a flow with no items, exactly one item or an error. 术语Upstream, downstreamRxJava中的数据流由 一个源，0个或多个中间步骤，随后是一个数据消费者或者结合步骤（这些步骤会通过某些方式来消费数据流） source.operator1().operator2().operator3().subscribe(consumer);source.flatMap(value -&gt; source.operator1().operator2().operator3()); 在这，如果我们把自己想象成 operator2，往左边看，直到source，这部分叫做 upstream。右边到 subscriber/consumer 之间的叫做 downstream。当每个元素写在单独一行的时候会更直观： source .operator1() .operator2() .operator3() .subscribe(consumer) 动作中的对象在RxJAVA文档中，emission, emits, item, event, signal, data","categories":[{"name":"RxJava","slug":"RxJava","permalink":"https://gowa2017.github.io/categories/RxJava/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/tags/Java/"},{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"},{"name":"RxJava","slug":"RxJava","permalink":"https://gowa2017.github.io/tags/RxJava/"}],"keywords":[{"name":"RxJava","slug":"RxJava","permalink":"https://gowa2017.github.io/categories/RxJava/"}]},{"title":"关于安卓权限的适配","slug":"关于安卓权限的适配","date":"2018-05-07T12:54:57.000Z","updated":"2018-05-07T12:54:57.000Z","comments":true,"path":"Android/关于安卓权限的适配.html","link":"","permalink":"https://gowa2017.github.io/Android/关于安卓权限的适配.html","excerpt":"","text":"问题是这样的，刚接触安卓变成，刚开始的时候app一切都正常的，但是突然有一个版本，就不能自动更新了，一点更新就崩溃。因为更新是使用网络上的一个库，实在是头疼。经过检查，才发现，原来是因为权限的问题。小米9，默认的权限获取手机存储是询问，但其实并不会询问，直接就是拒绝了。而手动给了存储权限后，更新就正常了。但是用户不会这么聪明的去查这些东西，肯定就知道一直崩溃崩溃。 权限适配自安卓6.0以后，情况有了变化。在之前的版本中，API23以前，权限写在AndroidManifest.xml文件中，然后安装的时候，就会提示权限，用户允许则安装，不允许，则不能安装。 6.0后，权限进行了分类两大类，敏感权限和普通权限，普通权限默认给予。而敏感权限，首先要在 AndroidManifest.xml中声明，然后在使用的时候，动态进行申请。默认的动态申请接口，在一些国产手机系统上被进行了截持，读取到你在 AndroidManifest.xml 内声明了敏感权限，给你返回 true，但是却不是真正的授权。就造成了我所遇到的情况。 所以现在解决的办法就是，适配6.0 或 把适配API降到 23以下。我们采用了后一种方法，因为当前用户量不是很大，毕竟适配起来的话比较恼火，虽然可喜的找到了这个项目，作者很强大。但是以后才用了。 问题如果我们选择适配API等级在23以下，即 在build.gradle中指定 targetSdkVersion level(leve &lt; 23)。那么在高版本的，API上的话，会是什么结果呢？ 是这样的对于没有适平配API23以上的APP，而又运行在 6.0以上的系统时，其采用以前的授权方式，即在安装时进行授权。 怎么适配？参考一下我上面提到的项目，是一个非常棒的项目哦。","categories":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"}],"keywords":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}]},{"title":"java中的数据结构","slug":"java中的数据结构","date":"2018-05-07T00:08:58.000Z","updated":"2018-05-07T00:08:58.000Z","comments":true,"path":"Java/java中的数据结构.html","link":"","permalink":"https://gowa2017.github.io/Java/java中的数据结构.html","excerpt":"","text":"java中实在是有太多的数据结构，谁叫它世界上最庞大复杂的语言呢，但其提供的东西，确实用起来很方便。比如List，Map，Set等等，但是很多时候对其内部并不是很了解，使用起来也不是很灵活。最简单的，我还不知道 Array 和ArrayList的区别。所以现在就来探究一下。 前言其实我对POSIX比较熟悉，ANSI C也比较了解，其中其实是没有什么数据结构的，基本类型，加上数组，结构体，联合等等，就是这么简单的语言。无论JAVA怎么复杂，也最终也要回到以内存来表示一个对象这个基础上来。 List, Map, Set 都是接口，凡实现了接口定义方法的，都可以认为是这种数据类型。 Array数组是一块连续的内存，其内的每个元素都是固定大小的，数组内的元素也是固定的。 我认为，JAVA中的对象数组，有点类似于 C 中的指针数组。都是对内存的引用。 数组是效率最快最高的，但是当我们要增加数组内的元素的时候怎么办？重新分配一块内存，然后把原数组内的所有元素复制过去，回收原来的内存，效率是非常低的。 ListList是一个扩展了Collection的接口类，凡是实现了其定义方法的，都可被称为一个List。常用的方法主要有add, set, get, addAll, clear, sort, remove等等。 ArrayListArrayList是一个实现了List接口的数组封装，我们可以这样理解，这个结构，内部是用数组来存储数据，然后封装一List所定义的方法。这样，我们就可以用List定义的方法来操作这个内部的数组。看代码： public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable transient Object[] elementData; // non-private to simplify nested class access 在我们动态添加元素，而数组空间不够的时候，一样需要重新分配内存并进行复制。 private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity);&#125; 当我们访问这个对象元素的时候，其实也是也数组的形式访问内部的那个数据数组elementData。 LinkedList上面的ArrayList 是使用 数组来保存内部数据，而LinkedList内部是使用双向链表来保存数据。只有这个区别而已。 private static class Node&lt;E&gt; &#123; E item; Node&lt;E&gt; next; Node&lt;E&gt; prev; Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) &#123; this.item = element; this.next = next; this.prev = prev; &#125;&#125; MapMap是一个接口，其提供了对键值这样类型数组的存储与访问，以及其他一些附加的操作。平时我不是很在意这个东西，但是在很多时候用起来才知道方便。 方法列表： boolean isEmpty(); 如果map内并无 键-值 对，返回 true。 int size(); 返回容量 boolean containsKey(Object); 返回map是否含有 Object 这个键。 boolean containsValue(Object); 返回map是否含有 Object 这个值。 V get(Object); 返回 Object 键对应的值。 V put(K, V); 把一个键值对 K, V 放进map。 V remove(Object); 从 map 内移除 Object 指定的键所引用的键值对。 void putAll(Map&lt;? extends K, ? extends V&gt; m); 把 m 内的所有键值对复制过来。 void clear(); 清空 Set&lt;K&gt; keySet(); 返回map 包含的所有 键 的Set。 Collection&lt;V&gt; values(); 返回 map 包含所有值的 Collection。 Set&lt;Map.Entry&lt;K, V&gt;&gt; entrySet(); 返回所有的键值对。 boolean equals(Object o); 与此map想比较是否相等。 int hashCode(); map的 hask值。 default V getOrDefault(Object key, V defaultValue); 返回键对应的值，如果map没有这个键，返回默认值。接口已实现的方法。 default void forEach(BiConsumer&lt;? super K, ? super V&gt; action); 对map中的每项进行对应的动作，直到遍历完map，或抛出了一个违例。接口实现的方法。 default void replaceAll(BiFunction&lt;? super K, ? super V, ? extends V&gt; function); 将map内所有项的值都替换为 该项，执行为指定的函数后的结果。接口实现的方法 default V putIfAbsent(K key, V value); 如果 键 key 还未与一个 值相关联（或与null 关联），把我们给定的 value 与 其相关联。返回此键值对项中的值。接口实现的方法 default boolean remove(Object key, Object value); 移除 已关联的 key, value 键值对。 接口实现的方法。 default boolean replace(K key, V oldValue, V newValue); 当 已存在 key, oldValue 关联的时候，把 oldValue 替换为 newValue。接口实现的方法。 default V replace(K key, V value); 当 key 与某些值关联时，将其值替换为 value 。 default V computeIfAbsent(K key,Function&lt;? super K, ? extends V&gt; mappingFunction) 如果 key 没有与任何值关联（或与null关联），使用 mappingFunction 计算出其值，然后放到 map内。 default V computeIfPresent(K key,BiFunction&lt;? super K, ? super V, ? extends V&gt; remappingFunction) 如果 key 当前的值不是 null，把 key 与 BiFunction 计算的值重新关联。 default V compute(K key,BiFunction&lt;? super K, ? super V, ? extends V&gt; remappingFunction) 为 key 与其当前关联的值 (或 null）重新计算一个 键值对。 default V merge(K key, V value,BiFunction&lt;? super V, ? super V, ? extends V&gt; remappingFunction) 如果 key 没有与任何值关联（或null），把它与 value 相关联。否则，把它与 BiFunction 的结果相关联；如果 BiFunction的结果为null，移除这个键。 HashMapHaspMap实现了Map接口： public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable &#123; 其真正保存数据的，也是一个 名为 table 的 Node 数组： transient Node&lt;K,V&gt;[] table; 只不过，其数组中的元素是一个Node，（单向）Hash链。 static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; 每个Node内，保存了键，值及下一个Node，加上自身的hash值。 当我们访问HashMap中元素的时候： public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125;final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) &#123; if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125; 其实先根据键 得出hash值，再得到hash链位置，然后通过遍历hash链来查找是否存在对应的键。","categories":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/tags/Java/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}]},{"title":"Java中使用JsonHelp来简化操作","slug":"Java中使用JsonHelp来简化操作","date":"2018-05-06T07:35:32.000Z","updated":"2018-05-06T07:35:32.000Z","comments":true,"path":"Android/Java中使用JsonHelp来简化操作.html","link":"","permalink":"https://gowa2017.github.io/Android/Java中使用JsonHelp来简化操作.html","excerpt":"Json为什么使用这个广我是不知道的，不过现在阶段公司在开发中大批量的都是使用Json来从服务端获取数据，也只有学习一下了。另外，值得一提的是以前，通过在Http地址中带上方法到接口去获取对应的信息，和在数据包内包含协议，究竟哪一个好，还真不知道","text":"Json为什么使用这个广我是不知道的，不过现在阶段公司在开发中大批量的都是使用Json来从服务端获取数据，也只有学习一下了。另外，值得一提的是以前，通过在Http地址中带上方法到接口去获取对应的信息，和在数据包内包含协议，究竟哪一个好，还真不知道 概述JsonHelp提供了很多方法来简化从Json对象到Java对象的转换，及其相逆的转换。我们来看一下。 JSONHelpertoJSONObject这个方法，会被Java 对象，转换为一个JSON对象。那JSON对象又是怎么样的？在安卓内部的JSONObject类中，我们可以看到，其实其只是一个Map。 private final LinkedHashMap&lt;String, Object&gt; nameValuePairs; 有点类似反射，获取当前类中的所有字段，找到注解的字段，获取字段的值，然后放到 JSON对象的 LinkedHashmap 中。 public static JSONObject toJSONObject(@NonNull Object object) &#123; JSONObject jsonObject = new JSONObject(); Class&lt;?&gt; currentClass = object.getClass(); while (currentClass != Object.class) &#123; Field[] fields = currentClass.getDeclaredFields(); for (Field field : fields) &#123; if (!field.isAccessible()) field.setAccessible(true); if (field.isAnnotationPresent(JsonTransparent.class)) &#123; // 忽略掉JsonTransparent注解的部分 continue; &#125; int modifiers = field.getModifiers(); if (Modifier.isFinal(modifiers) || Modifier.isStatic(modifiers)) &#123; // 忽略掉static 和 final 修饰的变量 continue; &#125; String fieldName; if (field.isAnnotationPresent(JsonField.class)) &#123; fieldName = field.getAnnotation(JsonField.class).value(); &#125; else &#123; fieldName = field.getName(); &#125; try &#123; Object value = getJsonObject(field.get(object)); if (value == null) &#123; continue; &#125; else &#123; jsonObject.put(fieldName, value); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; currentClass = currentClass.getSuperclass(); &#125; return jsonObject;&#125; toJSONArrayJSONArray是一个 List： private final List&lt;Object&gt; values; toJSONArray就是把一个对象列表逐个的放进去。 public static JSONArray toJSONArray(@NonNull List&lt;?&gt; datas) &#123; JSONArray jsonArray = new JSONArray(); for (Object object : datas) &#123; jsonArray.put(getJsonObject(object)); &#125; return jsonArray;&#125; getJsonObject这个方法将Java对象转换为JSON支持的类型。 toList将JSONArray转换为一个List。对于JSONArray中的每个元素，获取其值，转换为Java对象后放到列表内。 public static &lt;V&gt; List&lt;V&gt; toList(@NonNull JSONArray jsonArray, @NonNull Class&lt;V&gt; entityType) &#123; List&lt;V&gt; list = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; jsonArray.length(); i++) &#123; try &#123; V v; String json = jsonArray.getString(i); if (json.startsWith(\"&#123;\")) &#123; JSONObject jsonObject = new JSONObject(json); v = toObject(jsonObject, entityType); &#125; else &#123; v = (V) getJavaObject(json, entityType, null); &#125; if (v != null) &#123; list.add(v); &#125; else &#123; Log.d(\"json\", \"json序列化失败：\" + json); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; return list; &#125; initObjecttoObject把JSONObject转换为Java对象。 @Nullablepublic static &lt;V&gt; V toObject(@NonNull JSONObject jsonObject, @NonNull Class&lt;V&gt; entityType) &#123; V v; try &#123; v = entityType.newInstance(); initObject(jsonObject, v); &#125; catch (Exception e1) &#123; e1.printStackTrace(); v = null; &#125; return v;&#125; getJavaObjectgetCollectionClassJSONObject当我们获取数据，比如从网络获取的时候，其实获得的是JSON的字符串。查看了一下HttpRequester中的代码，在OnSuccess方法中，会把反馈回来的字符串建立一个JSON对象。 public void onSuccess(int statusCode, Header[] headers, String responseString) &#123; Logger.log(Logger.HTTP, TAG + \"-&gt;onSuccess()-&gt;code = \" + statusCode + \", content = \" + responseString); try &#123; JSONObject jsonObject = new JSONObject(responseString); int state = jsonObject.optInt(\"state\", 0); String msg = CodeConfig.getCodeTip(state); HttpRequester.this.onFinish(state, msg, jsonObject); &#125; catch (JSONException e) &#123; e.printStackTrace(); HttpRequester.this.onFinish(CodeConfig.CODE_FAIL, e.getMessage(), null); &#125;&#125; 当建立成JSON对象后，我们就可以做我们想做的操作了。对象本身就提供了很多方法来操作数据。 我们知道，JSON对象其实放数据的就是一个LinkedHashMap。我们所做的事情，其实都是对这个Map进行获取而且了。 我们最常用的，其实就是获取字符串我们来看一下optString这个方法。 public String optString(String name, String fallback) &#123; Object object = opt(name); String result = JSON.toString(object); return result != null ? result : fallback;&#125;public Object opt(String name) &#123; return nameValuePairs.get(name);&#125; 好简单不是，其实就是从Map内获取出获取键的值，然后把这个值转换成字符串返回。 但是我们从服务器返回的数据，有可能是一个列表，一个对象，或者一个复杂的对象结构。这个时候，就不能简单的从对象内获取字符串了。 总结总结以上流程，我们简单来归纳一下。当我们调用HttpRequester的时候，其返回的数据会被封装成JSONObject对象返回给调用进程。 接着，我们就可以从这个返回对象内获取我们想要的部分，然后根据对应的类，来转换成Java对象了。","categories":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"},{"name":"java","slug":"java","permalink":"https://gowa2017.github.io/tags/java/"}],"keywords":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}]},{"title":"开源项目分类汇总，更全更新可见","slug":"开源项目分类汇总，更全更新可见","date":"2018-04-12T01:05:00.000Z","updated":"2018-04-12T01:05:00.000Z","comments":true,"path":"Android/开源项目分类汇总，更全更新可见.html","link":"","permalink":"https://gowa2017.github.io/Android/开源项目分类汇总，更全更新可见.html","excerpt":"本文来自开源项目 android-open-projectandroid 开源项目分类汇总，更全更新可见 codekk.com Other: English Version, 繁體版, Website Version. 我们的微信公众号：codekk。二维码如下： 专注于 Android 开源分享、源码解析、框架设计、Android 内推。 我们的网站：www.codekk.com","text":"本文来自开源项目 android-open-projectandroid 开源项目分类汇总，更全更新可见 codekk.com Other: English Version, 繁體版, Website Version. 我们的微信公众号：codekk。二维码如下： 专注于 Android 开源分享、源码解析、框架设计、Android 内推。 我们的网站：www.codekk.com Android 开发调试效率数倍提升工具——开发助手 App 最新版，可从 Google Play、应用宝、360 手机助手里搜索”开发助手”下载，或通过网页下载：Google Play、应用宝、360 手机助手、本地下载Android 开源项目源码解析(Volley、UIL、Dagger、EventBus、插件化库等分析)Android 职位内部推荐(阿里、腾讯、百度、京东、滴滴、美团、58、华为、网易、魅族等)强大的 Android 开源项目搜索站欢迎大家推荐好的 Android 开源项目，开源项目添加到 Android 开源项目集合，可以得到更多朋友的关注和反馈，欢迎Star、Fork :) 关于我，欢迎关注 微博：Trinea&nbsp;&nbsp;&nbsp;&nbsp;主页：trinea.cn 更多：Android 开源库获取途径整理分享：&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 目前包括： Android 开源项目第一篇——个性化控件(View)篇&nbsp;&nbsp;包括ListView、ActionBar、Menu、ViewPager、Gallery、GridView、ImageView、ProgressBar、TextView、ScrollView、TimeView、TipView、FlipView、ColorPickView、GraphView、UI Style、其他Android 开源项目第二篇——工具库篇&nbsp;&nbsp;包括依赖注入、图片缓存、网络请求、数据库 ORM 工具包、Android 公共库、高版本向低版本兼容库、多媒体、事件总线、传感器、安全、插件化、文件、其他Android 开源项目第三篇——优秀项目篇&nbsp;&nbsp;比较有意思的完整的 Android 项目Android 开源项目第四篇——开发及测试工具篇&nbsp;&nbsp;包括开发效率工具、开发自测相关、测试工具、开发及编译环境、其他Android 开源项目第五篇——优秀个人和团体篇&nbsp;&nbsp;乐于分享并且有一些很不错的开源项目的个人和组织，包括 JakeWharton、Chris Banes、Koushik Dutta 等大牛 第一部分 个性化控件(View)主要介绍那些不错个性化的 View，包括 ListView、ActionBar、Menu、ViewPager、Gallery、GridView、ImageView、ProgressBar、TextView、ScrollView、TimeView、TipView、FlipView、ColorPickView、GraphView、UI Style 等等。 一、ListView android-pulltorefresh一个强大的拉动刷新开源项目，支持各种控件下拉刷新，ListView、ViewPager、WebView、ExpandableListView、GridView、ScrollView、Horizontal ScrollView、Fragment 上下左右拉动刷新，比下面 johannilsson 那个只支持 ListView 的强大的多。并且它实现的下拉刷新 ListView 在 item 不足一屏情况下也不会显示刷新提示，体验更好。项目地址：https://github.com/chrisbanes/Android-PullToRefreshDemo 地址：https://github.com/Trinea/TrineaDownload/blob/master/pull-to-refreshview-demo.apk?raw=trueAPP 示例：新浪微博各个页面 android-pulltorefresh-listview下拉刷新 ListView，这个被很多人使用的项目实际有不少 bug，推荐使用 android-Ultra-Pull-to-Refresh项目地址：https://github.com/johannilsson/android-pulltorefreshDemo 地址：https://github.com/Trinea/TrineaDownload/blob/master/pull-to-refresh-listview-demo.apk?raw=true android-Ultra-Pull-to-Refresh下拉刷新，第一个项目已经停止维护了，并且使用起来相对复杂，定制性也差。这个是替代和改良方案。这个继承于 ViewGroup 可以包含任何 View。功能甚至比 SwipeRefreshLayout 强大。使用起来非常简单。良好的设计，如果你想定制自己的 UI 样式，非常简单，就像给 ListView 加一个 Header View 那么简单。支持 API LEVEL &gt;= 8项目地址：https://github.com/liaohuqiu/android-Ultra-Pull-To-Refresh原理剖析文档：android-Ultra-Pull-to-RefreshDemo 地址：https://raw.githubusercontent.com/liaohuqiu/android-Ultra-Pull-To-Refresh/master/ptr-demo.apk效果图：http://srain-github.qiniudn.com/ultra-ptr/release-to-refresh.gifhttp://srain-github.qiniudn.com/ultra-ptr/auto-refresh.gifhttp://srain-github.qiniudn.com/ultra-ptr/store-house-string-array.gif Android-PullToRefreshRecyclerView支持下拉刷新的RecyclerView，同时支持滑动到底部自动加载数据、给RecyclerView添加Header。并且不更改原有RecyclerView的逻辑。项目地址：https://github.com/HomHomLin/Android-PullToRefreshRecyclerViewDemo地址：https://github.com/HomHomLin/Android-PullToRefreshRecyclerView/blob/master/sample.apk DragSortListView拖动排序的 ListView，同时支持 ListView 滑动 item 删除，各个 Item 高度不一、单选、复选、CursorAdapter 做为适配器、拖动背景变化等项目地址：https://github.com/bauerca/drag-sort-listviewDemo 地址：https://play.google.com/store/apps/details?id=com.mobeta.android.demodslvAPP 示例：Wordpress Android SwipeListView支持定义 ListView 左右滑动事件，支持左右滑动位移，支持定义动画时间项目地址：https://github.com/47deg/android-swipelistviewDemo 地址：https://play.google.com/store/apps/details?id=com.fortysevendeg.android.swipelistviewAPP 示例：微信 Android-SlidingLayout实现类似QQ、微信ListView和WebView的上拉下拉弹跳效果和iOS的ListView的果冻效果。兼容Android自带库和兼容库的所有View组件，包括RecyclerView、ListView、ScrollView以及WebView等等。项目地址：https://github.com/HomHomLin/SlidingLayout/。Demo地址：https://github.com/HomHomLin/SlidingLayout/tree/master/demo SlideAndDragListView支持ListView的Item的拖动排序、左右滑动事件，可自定义左右滑动显示文字、图标、位移，同时支持onItemClick、onItemLongClick等监听器，提供丰富的回调接口。项目地址：https://github.com/yydcdut/SlideAndDragListViewDemo 地址：https://github.com/yydcdut/SlideAndDragListView/blob/master/apk/sdlv.apk?raw=trueAPP 示例：Android 手机QQ 5.0效果图： Android-SwipeToDismiss滑动 Item 消失 ListView，支持 3.0 以下版本见：https://github.com/JakeWharton/SwipeToDismissNOA项目地址：https://github.com/romannurik/Android-SwipeToDismissDemo 地址：https://github.com/JakeWharton/SwipeToDismissNOA/SwipeToDismissNOA.apk/qr_code RecyclerViewSwipeDismiss轻量级支持 support-v7 中的 RecyclerView 的滑动删除(Swipe to dismiss)行为，不需要修改源代码，只要简单的绑定onTouchListener项目地址：https://github.com/CodeFalling/RecyclerViewSwipeDismiss效果图： QuickSideBar帮助快速查阅对应分组的侧边栏，可以配合任意列表，demo中给出配合RecyclerView(浮动分组使用stickyheadersrecyclerview)。项目地址：https://github.com/saiwu-bigkoo/Android-QuickSideBar效果图： async-expandable-list支持异步加载子列表的 ExpandableListView，包括CollectionView可以显示小标题的列表项目地址：https://github.com/Ericliu001/async-expandable-list 效果图： PinnedHeaderExpandableListView首先它是一个 ExpandableListView，但是它的头部可以固定，其次，在它的上面还有一个头部可以来回伸缩项目地址：https://github.com/singwhatiwanna/PinnedHeaderExpandableListView效果图：APP 示例：百度手机卫士垃圾清理界面 StickyListHeadersGroupName 滑动到顶端时会固定不动直到另外一个 GroupName 到达顶端的 ExpandListView，支持快速滑动，支持 Android2.3 及以上项目地址：https://github.com/emilsjolander/StickyListHeaders效果图：APP 示例：Android 4.0 联系人 pinned-section-listviewGroupName 滑动到顶端时会固定不动直到另外一个 GroupName 到达顶端的 ExpandListView项目地址：https://github.com/beworker/pinned-section-listview效果图： PinnedHeaderListViewGroupName 滑动到顶端时会固定不动直到另外一个 GroupName 到达顶端的 ExpandListView项目地址：https://github.com/JimiSmith/PinnedHeaderListView QuickReturnListView/ScrollView 的 header 或 footer，当向下滚动时消失，向上滚动时出现项目地址：https://github.com/lawloretienne/QuickReturnDemo 地址：https://play.google.com/store/apps/details?id=com.etiennelawlor.quickreturn QuickReturnHeaderListView/ScrollView 的 header 或 footer，当向下滚动时消失，向上滚动时出现项目地址：https://github.com/ManuelPeinado/QuickReturnHeaderDemo 地址：https://github.com/Trinea/TrineaDownload/blob/master/quick-return-header-demo.apk?raw=trueAPP 示例：google plus IndexableListViewListView 右侧会显示 item 首字母快捷索引，点击可快速滑动到某个 item项目地址：https://github.com/woozzu/IndexableListViewDemo 地址：https://github.com/Trinea/TrineaDownload/blob/master/indexable-listview.apk?raw=trueAPP 示例：微信通讯录、小米联系人 CustomFastScrollViewListView 快速滑动，同时屏幕中间 PopupWindows 显示滑动到的 item 内容或首字母项目地址：https://github.com/nolanlawson/CustomFastScrollViewDemo效果图： Android-ScrollBarPanelListView 滑动时固定的 Panel 指示显示在 scrollbar 旁边项目地址：https://github.com/rno/Android-ScrollBarPanel效果图： SlideExpandableListView用户点击 listView item 滑出固定区域，其他 item 的区域收缩项目地址：https://github.com/tjerkw/Android-SlideExpandableListViewDemo 地址：https://github.com/Trinea/TrineaDownload/blob/master/slide-expandable-listView-demo.apk?raw=true JazzyListViewListView 及 GridView item 以特殊动画效果进入屏幕，效果包括 grow、cards、curl、wave、flip、fly 等等项目地址：https://github.com/twotoasters/JazzyListViewDemo 地址：https://play.google.com/store/apps/details?id=com.twotoasters.jazzylistview.sample在线演示：http://lab.hakim.se/scroll-effects/ ListViewAnimations带 Item 显示动画的 ListView，动画包括底部飞入、其他方向斜飞入、下层飞入、渐变消失、滑动删除等项目地址：https://github.com/nhaarman/ListViewAnimationsDemo 地址：https://play.google.com/store/apps/details?id=com.haarman.listviewanimationsAPP 示例：Google plus、Google Now 卡片式进入、小米系统中应用商店、联系人、游戏中心、音乐、文件管理器的 ListView、Ultimate、Light Flow Lite、TreinVerkeer、Running Coach、Pearl Jam Lyrics、Calorie Chart、Car Hire、Super BART、DK FlashCards、Counter Plus、Voorlees Verhaaltjes 2.0 DevsmartLib-Android横向 ListView项目地址：https://github.com/dinocore1/DevsmartLib-AndroidDemo 地址：https://github.com/Trinea/TrineaDownload/blob/master/horizontal-listview-demo.apk?raw=true TwoWayView横向 ListView 的效果，继承自 AdapterView项目地址：https://github.com/lucasr/twoway-view HorizontalVariableListView支持 Item 宽度不一致的 ListView项目地址：https://github.com/sephiroth74/HorizontalVariableListView LinearListView用 LinearLayout 实现的 ListView，可解决多个 ListView 并存等问题。目前自己也有需要，等亲自尝试过后会再具体介绍项目地址：https://github.com/frankiesardo/LinearListView MultiChoiceAdapter支持多选的 ListView Adapter项目地址：https://github.com/ManuelPeinado/MultiChoiceAdapterDemo 地址：https://play.google.com/store/apps/details?id=com.manuelpeinado.multichoiceadapter.demo EnhancedListView支持横向滑动删除列表项以及撤销删除的 ListView，该项目的前身是SwipeToDismissUndoList项目地址：https://github.com/timroes/EnhancedListViewDemo 地址：https://play.google.com/store/apps/details?id=de.timroes.android.listviewdemo&amp;rdid=de.timroes.android.listviewdemo ListBuddies自动滚动的双列 ListView ，两个 ListView 滚动速度不一致，有视差效果项目地址：https://github.com/jpardogo/ListBuddiesDemo 地址：https://play.google.com/store/apps/details?id=com.jpardogo.android.listbuddies效果图： SwipeMenuListView针对 ListView item 的侧滑菜单项目地址：https://github.com/baoyongzhang/SwipeMenuListView效果图：APP 示例：手机 QQV5.0 PagingListView分页加载的 ListView。当滑动到 ListView 底部最后一个元素时，显示一个进度行，然后加载下一页数据，并显示。项目地址：https://github.com/nicolasjafelle/PagingListView PullZoomView支持下拉时 HeaderView 缩放的 ListView、ScrollView项目地址：https://github.com/Frank-Zhu/PullZoomView效果图： PullToZoomInListView滑动 ListView 时使其 HeaderView 跟随滑动缩放项目地址：https://github.com/matrixxun/PullToZoomInListView效果图： CalendarListview实现每个月一行日历效果的 ListView项目地址：https://github.com/traex/CalendarListview原理剖析文档：CalendarListview效果图： sticky-headers-recyclerviewGroupName 滑动到顶端时会固定不动直到另外一个 GroupName 到达顶端的 ListView，采用 support-v7 中的 RecyclerView 实现项目地址：https://github.com/timehop/sticky-headers-recyclerview PullSeparateListView到达顶部或底部继续拉动时，实现 Item 间的相互分离，两种模式：(1) 全部分离的模式，即屏幕内所有 Item 都会分离 (2)部分分离模式，以点击位置为分界点，部分 item 分离项目地址：https://github.com/chiemy/PullSeparateListView效果图： ExpandableLayoutHeader 和 Content Item 都可以展开的 ExpandableListview项目地址：https://github.com/traex/ExpandableLayout PagedHeadListView支持 paginated header 以及 material page indicator 的 ListView.项目地址：https://github.com/JorgeCastilloPrz/PagedHeadListView效果图： CustomSwipeListView支持左滑弹出自定义菜单，右滑删除且允许撤销，同时可以自定义滑动动画时间和滑动触发事件的时机等。项目地址：https://github.com/xyczero/Android-CustomSwipeListViewDemo 地址：Download here效果图： Pull-to-Refresh.Rentals-Android提供一个简单可以自定义的下拉刷新实现，Yalantis 出品。项目地址：https://github.com/Yalantis/Pull-to-Refresh.Rentals-Android效果图： ScrollerCalendar实现每行显示一年的 12 个月份的 RecyclerView 年历项目地址：https://github.com/guanchao/ScrollerCalendar效果图： ExtractWordView一个可以提取单词的 ListView,支持”放大镜”效果。项目地址：https://github.com/jcodeing/ExtractWordViewDemo 地址：Download here FlyRefresh支持 ListView, GridView, RecyclerView, ScrollView 的下拉刷新项目地址：https://github.com/race604/FlyRefresh效果图： MVCHelper实现下拉刷新，滚动底部自动加载更多，分页加载，自动切换显示网络失败布局，暂无数据布局，支持任意 view，真正的 MVC 架构支持切换主流下拉刷新框架 Android-PullToRefresh-Library,android-Ultra-Pull-To-Refresh-library，SwipeRefreshLayout项目地址：https://github.com/LuckyJayce/MVCHelperDemo 地址：https://github.com/LuckyJayce/MVCHelper/blob/master/raw/MVCHelper_Demo.apk?raw=true RecyclerViewSwipeDismiss支持滑动 Item 操作、点击展开、拖动排序、展开后拖动排序等特性的 RecyclerView项目地址：https://play.google.com/store/apps/details?id=com.h6ah4i.android.example.advrecyclerview视频：http://www.youtube.com/watch?feature=player_embedded&amp;v=S7cSwMArjUQ WaterDropListView模仿 iOS 下拉刷新“水滴”效果，支持下拉刷新和上拉加载项目地址：https://github.com/THEONE10211024/WaterDropListView效果图： PopupListView實現ListItem 點擊後置頂並可顯示客製化添加的item的內部View 的ListView项目地址：https://github.com/s8871404/PopupListViewDemo 地址：https://play.google.com/store/apps/details?id=com.baobomb.popuplistview_sample效果图： CircleRefreshLayout一个包含有趣的动画的自定义下拉刷新布局项目地址：https://github.com/tuesda/CircleRefreshLayout效果图： EasyRecyclerView一款简单易用的EasyRecyclerView1.提供EasyRecyclerView，不需要写太多RecyclerView的配置代码2.提供好一个可以适配单布局和多布局的RecyclerViewAdapter3.提供了分割线的实现类，只需要传入一个DrawableId项目地址：https://github.com/CaMnter/EasyRecyclerView CanRefresh可适配所有视图的下拉刷新上拉加载，并支持各种风格项目地址：https://github.com/canyinghao/CanRefresh效果图： NestRefreshLayout下拉刷新及加载更多控件，支持多种View，可以自定义Header和Footer由于实现了NestedScrollingChild和NestedScrollingParent所以与Support-Design兼容，可以配合CollapsingToolbarLayout使用项目地址：https://github.com/anzewei/NestRefreshLayoutDemo 地址：https://github.com/anzewei/NestRefreshLayout/blob/master/ext/sample-debug.apk?raw=true SnappingSwipingRecyclerView实现了类似微信读书首页的长按之后滑动删除的特效和动画项目地址:https://github.com/CarlLee/SnappingSwipingRecyclerView 二、ActionBar ActionBarSherlock为 Android 所有版本提供统一的 ActionBar，解决 4.0 以下 ActionBar 的适配问题项目地址：https://github.com/JakeWharton/ActionBarSherlockDemo 地址：https://play.google.com/store/apps/details?id=com.actionbarsherlock.sample.demos标签：兼容库, ActionBar ActionBar-PullToRefresh下拉刷新，ActionBar 出现加载中提示项目地址：https://github.com/chrisbanes/ActionBar-PullToRefreshDemo 地址：https://play.google.com/store/apps/details?id=uk.co.senab.actionbarpulltorefresh.samples.stockAPP 示例：Gmail，Google Plus，知乎等 FadingActionBarListView 向下滚动逐渐显现的 ActionBar项目地址：https://github.com/ManuelPeinado/FadingActionBarDemo 地址：https://play.google.com/store/apps/details?id=com.manuelpeinado.fadingactionbar.demoAPP 示例：google music，知乎 NotBoringActionBargoogle music 下拉收缩的 ActionBar项目地址：https://github.com/flavienlaurent/NotBoringActionBarDemo 地址：http://flavienlaurent.com/blog/2013/11/20/making-your-action-bar-not-boring/APP 示例：Google 音乐 RefreshActionItem带进度显示和刷新按钮的 ActionBar项目地址：https://github.com/ManuelPeinado/RefreshActionItemDemo 地址：https://play.google.com/store/apps/details?id=com.manuelpeinado.refreshactionitem.demoAPP 示例：The New York Times，DevAppsDirect GlassActionBar类似玻璃的有一定透明度的 ActionBar项目地址：https://github.com/ManuelPeinado/GlassActionBarDemo 地址：https://play.google.com/store/apps/details?id=com.manuelpeinado.glassactionbardemoAPP 示例：google music 三、Menu MenuDrawer滑出式菜单，通过拖动屏幕边缘滑出菜单，支持屏幕上下左右划出，支持当前 View 处于上下层，支持 Windows 边缘、ListView 边缘、ViewPager 变化划出菜单等。项目地址：https://github.com/SimonVT/android-menudrawerDemo 地址：http://simonvt.github.io/android-menudrawer/APP 示例：Gmail、Google Music 等大部分 google app SlidingMenu滑出式菜单，通过拖动屏幕边缘滑出菜单，支持屏幕左右划出，支持菜单 zoom、scale、slide up 三种动画样式出现。与 MenuDrawer 相比而言，SlidingMenu 支持菜单动画样式出现，MenuDrawer 支持菜单 view 处于内容的上下层项目地址：https://github.com/jfeinstein10/SlidingMenu原理剖析文档：SlidingMenuDemo 地址：https://play.google.com/store/apps/details?id=com.slidingmenu.exampleAPP 示例：Foursquare, LinkedIn, Zappos, Rdio, Evernote Food, Plume, VLC for Android, ESPN ScoreCenter, MLS MatchDay, 9GAG, Wunderlist 2, The Verge, MTG Familiar, Mantano Reader, Falcon Pro (BETA), MW3 Barracks ArcMenu支持类似 Path 的左下角动画旋转菜单及横向划出菜单、圆心弹出菜单项目地址：https://github.com/daCapricorn/ArcMenu效果图：https://dl.dropboxusercontent.com/u/11369687/preview1.pnghttps://dl.dropboxusercontent.com/u/11369687/raymenu.pngAPP 示例：Path android-satellite-menu类似 Path 的左下角动画旋转菜单项目地址：https://github.com/siyamed/android-satellite-menuDemo 地址：https://github.com/Trinea/TrineaDownload/blob/master/satellite-menu-demo.apk?raw=trueAPP 示例：Path radial-menu-widget圆形菜单，支持二级菜单项目地址：https://code.google.com/p/radial-menu-widget/效果图： Android Wheel Menu圆形旋转选取菜单项目地址：https://github.com/anupcowkur/Android-Wheel-Menu效果图： FoldingNavigationDrawer滑动并以折叠方式打开菜单项目地址：https://github.com/tibi1712/FoldingNavigationDrawer-AndroidDemo 地址：https://play.google.com/store/apps/details?id=com.ptr.folding.sample效果图： AndroidResideMenu仿 Dribbble 的边栏菜单项目地址：https://github.com/SpecialCyCi/AndroidResideMenu效果图： CircularFloatingActionMenu一个可定制的圆形的浮动菜单控件，类似于 Path 的圆形菜单。这个控件的可定制性更强，可以很容易的定制菜单出现消失时的动画，起始角度和半径。项目地址：https://github.com/oguzbilgener/CircularFloatingActionMenu原理剖析文档：CircularFloatingActionMenuDemo 地址：https://github.com/oguzbilgener/CircularFloatingActionMenu/tree/master/samples效果图： NavigationDrawerSINavigation Drawer 的一个简单实现，滑动并以折叠方式打开菜单项目地址：https://github.com/mmBs/NavigationDrawerSIDemo 地址：https://play.google.com/store/apps/details?id=mmbialas.pl.navigationdrawersi效果图：APP 示例：https://play.google.com/store/apps/details?id=mmbialas.pl.navigationdrawersi DragLayout使用 support.v4 包下的 ViewDragHelper 实现 QQ5.0 侧滑项目地址：https://github.com/BlueMor/DragLayout效果图： LDrawerMaterial Design 形式的展开折叠 Icon项目地址：https://github.com/ikimuhendis/LDrawer效果图： Floating Action Button悬浮的圆形菜单栏，支持组建滚动时自动隐藏及其他设置项目地址：https://github.com/shamanland/floating-action-button效果图： Side-Menu.Android分类侧滑菜单，Yalantis 出品。项目地址：https://github.com/Yalantis/Side-Menu.Android原理剖析文档：Side-Menu.Android效果图： Context-Menu.Android可以方便快速集成漂亮带有动画效果的上下文菜单，Yalantis出品。项目地址：https://github.com/Yalantis/Context-Menu.Android效果图： Droppy支持多种样式的下拉菜单项目地址：https://github.com/shehabic/Droppy MaterialDrawerMaterial Design 风格的导航抽屉，提供简便且强大的定制功能项目地址：https://github.com/mikepenz/MaterialDrawerDemo 地址：https://play.google.com/store/apps/details？id=com.mikepenz.materialdrawer.app效果图： SlideBottomPanel底部划出菜单，滑动时背景图透明度渐变，支持嵌套 LiewView 或 ScrollView项目地址：https://github.com/kingideayou/SlideBottomPanelDemo 地址：SlideBottomPanelDemo 下载效果图： FlowingDrawer带手势流动效果侧滑菜单项目地址：https://github.com/mxn21/FlowingDrawer效果图： FloatingActionMenu-Animation扩展FloatingActionMenu库，自定义菜单图标，动画滚动时项目地址: https://github.com/toanvc/FloatingActionMenu-Animation效果图: 四、ViewPager 、Gallery AdvancedPagerSlidingTabStrip一个完美兼容ViewPager的导航栏组件；可以自定义TabView；能动态加载Tab上的Icon图片； 能显示Tab的消息数量和提示小圆点；支持自定义为微博形式的可滑动tab。项目地址：https://github.com/HomHomLin/AdvancedPagerSlidingTabStrip。 ConvenientBanner通用的广告栏控件，让你轻松实现广告头效果。支持无限循环，可以设置自动翻页和时间(而且非常智能，手指触碰则暂停翻页，离开自动开始翻页。你也可以设置在界面onPause的时候不进行自动翻页，onResume之后继续自动翻页)，并且提供多种翻页特效。 对比其他广告栏控件，大多都需要对源码进行改动才能加载网络图片，或者帮你集成不是你所需要的图片缓存库。而这个库能让有代码洁癖的你欢喜，不需要对库源码进行修改你就可以使用任何你喜欢的网络图片库进行配合。项目地址：https://github.com/saiwu-bigkoo/Android-ConvenientBanner效果图： Android-ViewPagerIndicator配合 ViewPager 使用的 Indicator，支持各种位置和样式项目地址：https://github.com/JakeWharton/Android-ViewPagerIndicatorDemo 地址：https://play.google.com/store/apps/details?id=com.viewpagerindicator.sampleAPP 示例：太多了。。 JazzyViewPager支持 Fragment 切换动画的 ViewPager，动画包括转盘、淡入淡出、翻页、层叠、旋转、方块、翻转、放大缩小等，效果类似桌面左右切换的各种效果，不过桌面并非用 ViewPager 实现而已项目地址：https://github.com/jfeinstein10/JazzyViewPagerDemo 地址：https://github.com/jfeinstein10/JazzyViewPager/blob/master/JazzyViewPager.apk?raw=true JellyViewPager特殊切换动画的 ViewPager项目地址：https://github.com/chiemy/JellyViewPager效果图： Android-DirectionalViewPager支持横向和纵向(垂直)的 ViewPager项目地址：https://github.com/JakeWharton/Android-DirectionalViewPagerDemo 地址：https://market.android.com/details?id=com.directionalviewpager.sample FancyCoverFlow支持 Item 切换动画效果的类似 Gallery View项目地址：https://github.com/davidschreiber/FancyCoverFlowDemo 地址：https://play.google.com/store/apps/details?id=at.technikum.mti.fancycoverflow.samples效果图： AndroidTouchGallery支持双击或双指缩放的 Gallery(用 ViewPager 实现)，相比下面的 PhotoView，在被放大后依然能滑到下一个 item，并且支持直接从 url 和文件中获取图片，项目地址：https://github.com/Dreddik/AndroidTouchGalleryDemo 地址：https://github.com/Trinea/TrineaDownload/blob/master/touch-gallery-demo.apk?raw=trueAPP 示例：类似微信中查看聊天记录图片时可双击放大，并且放大情况下能正常左右滑动到前后图片 Android Auto Scroll ViewPagerAndroid 自动滚动 轮播循环的 ViewPager项目地址：https://github.com/Trinea/android-auto-scroll-view-pagerDemo 地址：https://play.google.com/store/apps/details?id=cn.trinea.android.demo文档介绍：http://www.trinea.cn/android/auto-scroll-view-pager/ Android PagerSlidingTabStrip配合 ViewPager 使用的 Indicator，支持 ViewPager Scroll 时 Indicator 联动项目地址：https://github.com/astuetz/PagerSlidingTabStrip原理剖析文档：Android PagerSlidingTabStripDemo 地址：https://play.google.com/store/apps/details?id=com.astuetz.viewpager.extensions.sample ViewPager3DViewPager3D 效果项目地址：https://github.com/inovex/ViewPager3D AnimaTabsview仿网易云音乐标签切换的动画,带透明小三角项目地址：https://github.com/wuyexiong/transparent-over-animtabsview在线演示：http://v.youku.com/v_show/id_XNzA4MjY5NjA0.html LoopingViewPager无限循环的 ViewPager项目地址：https://github.com/imbryk/LoopingViewPager android_page_curl翻书卷曲效果项目地址：https://github.com/harism/android_page_curl在线演示：https://www.youtube.com/watch?v=iwu7P5PCpswAPP 示例：iReader ViewPagerIndicator简化并实现 android 的 TabHost 效果，顶部滑动 tab，引导页，支持自定义 tab 样式,自定义滑动块样式和位置,自定义切换 tab 的过渡动画,子界面的预加载和界面缓存,设置界面是否可滑动项目地址：https://github.com/LuckyJayce/ViewPagerIndicator ScreenSlideIndicator轻量级的圆形 Indicadtor，位置可以自由调整，不会对 ViewPager 产生任何影响。项目地址：ScreenSlidePager效果图： SmartTabLayout自定义的 Tab title strip，基于 Google Samples 中的 android-SlidingTabBasic 项目，滑动时 Indicator 可平滑过渡。项目地址：https://github.com/ogaclejapan/SmartTabLayoutDemo 地址：https://play.google.com/store/apps/details?id=com.ogaclejapan.smarttablayout.demo效果图： AndroidImageSliderAndroid 图片滑动项目地址：https://github.com/daimajia/AndroidImageSlider效果图：App示例：https://github.com/daimajia/AndroidImageSlider/releases/download/v1.0.8/demo-1.0.8.apk RecyclerViewPager完全继承自 RecyclerView，可以自定义触发翻页的距离，可自定义翻页速度，支持垂直方向的 ViewPager，支持 Fragment。项目地址：RecyclerViewPager效果图： CircleIndicator轻量级ViewPager指示器,支持三种不同的模式项目地址：CircleIndicator效果图： EasySlidingTabs一款简单、易用的滑动标签页项目地址： https://github.com/CaMnter/EasySlidingTabs效果图： ParallaxViewPagerViewPager页面切换视差效果项目地址：https://github.com/ybq/ParallaxViewPager效果图： 五、GridView StaggeredGridView允许非对齐行的 GridView，类似 Pinterest 的瀑布流，并且跟 ListView 一样自带 View 缓存，继承自 ViewGroup项目地址：https://github.com/maurycyw/StaggeredGridViewDemo 地址：https://github.com/Trinea/TrineaDownload/blob/master/staggered-gridview-demo.apk?raw=trueAPP 示例：Pinterest 等 AndroidStaggeredGrid允许非对齐行的 GridView，类似 Pinterest 的瀑布流，继承自 AbsListView项目地址：https://github.com/etsy/AndroidStaggeredGridAPP 示例：Pinterest 等 PinterestLikeAdapterView允许非对齐行的 GridView，类似 Pinterest 的瀑布流，允许下拉刷新项目地址：https://github.com/GDG-Korea/PinterestLikeAdapterViewAPP 示例：Pinterest 等 DraggableGridViewItem 可拖动交换位置的 GridView，实际是自己继承 ViewGroup 实现，类似桌面的单屏效果，可屏幕自动上下滚动进行 Item 移动交换，多屏效果见下面 PagedDragDropGrid项目地址：https://github.com/thquinn/DraggableGridViewDemo 地址：https://github.com/thquinn/DraggableGridView/blob/master/bin/DraggableGridViewSample.apk?raw=true也可自定义item的宽高和每行的个数，同时修改了交换逻辑，当移动到另一个item时就进行交换，并删除滚动逻辑。项目地址：DraggableGridView效果图： DividedDraggableView一个带有分割区域的可拖动 view ,可屏幕自动上下滚动进行 Item 移动交换。项目地址：https://github.com/andyken/DividedDraggableView效果图： StickyGridHeadersGroupName 滑动到顶端时会固定不动直到另外一个 GroupName 到达顶端的 GridView项目地址：https://github.com/TonicArtos/StickyGridHeaders效果图： PagedDragDropGridItem 可拖动交换位置、拖动删除的自定义控件，实际是自己继承 ViewGroup 实现，类似桌面的多屏效果，可拖动到屏幕边缘，屏幕自动左右滚动进行 Item 移动交换，可拖动进行删除，单屏效果见上面 DraggableGridView项目地址：https://github.com/mrKlar/PagedDragDropGrid在线演示：http://youtu.be/FYTSRfthSuQ Android-DraggableGridViewPagerItem 可拖动交换位置的 GridView，实际是自己继承 ViewGroup 实现，类似桌面的多屏效果，可屏幕自动左右滚动进行 Item 移动交换，单屏效果见上面 DraggableGridView项目地址：https://github.com/zzhouj/Android-DraggableGridViewPagerDemo 地址：https://github.com/Trinea/trinea-download/blob/master/draggable-grid-viewpager-demo.apk?raw=true TwoWayGridView可横向滚动的 GridView项目地址：https://github.com/jess-anders/two-way-gridview PagingGridView分页加载的 GridView。当滑动到 GridView 底部最后一个行时，显示一个进度行，然后加载下一页数据，并显示。项目地址：https://github.com/nicolasjafelle/PagingGridView AsymmetricGridView一个支持跨行和跨列可变 Item 大小的 GridView项目地址：https://github.com/felipecsl/AsymmetricGridViewDemo 地址：https://play.google.com/store/apps/details?id=com.felipecsl.asymmetricgridview.app效果图： GridView with Header and Footer和ListView一样带头部和底部的GridView，用法和ListView一样项目地址：https://github.com/liaohuqiu/android-GridViewWithHeaderAndFooter效果图： 六、ImageView PhotoView支持双击或双指缩放的 ImageView，在 ViewPager 等 Scrolling view 中正常使用，相比上面的 AndroidTouchGallery，不仅支持 ViewPager，同时支持单个 ImageView项目地址：https://github.com/chrisbanes/PhotoView原理剖析文档：PhotoViewDemo 地址：https://play.google.com/store/apps/details?id=uk.co.senab.photoview.sampleAPP 示例：photup Fresco-ImageViewFresco-ImageView是一种Android平台的图像控件，底层是对Fresco的封装，可以异步加载网络图片、项目资源和本地图片，并且支持双指缩放、图片的基本处理以及Fresco的所有特性。项目地址：https://github.com/HomHomLin/FrescoImageView android-gif-drawable支持 gif 显示的 view，用 jni 实现的，编译生成 so 库后直接 xml 定义 view 即可，而且本身不依赖于其他开源项目所以相对下面的 ImageViewEx 简单的多项目地址：https://github.com/koral--/android-gif-drawable ImageViewEx支持 Gif 显示的 ImageView，依赖很多，编译过程很繁琐项目地址：https://github.com/frapontillo/ImageViewExDemo 地址：https://github.com/Trinea/TrineaDownload/blob/master/imageviewex-demo.apk?raw=true RoundedImageView带圆角的 ImageView项目地址：https://github.com/vinc3m1/RoundedImageView效果图： SelectableRoundedImageViewImageView 允许四个角的每一个有不同的半径值。也允许椭圆形、圆形的形状或者边项目地址：https://github.com/pungrue26/SelectableRoundedImageViewDemo 地址：https://play.google.com/store/apps/details?id=com.joooonho效果图： ColorArt根据图片的均色设置背景色显示文字和图片，类似 itune11 中效果项目地址：https://github.com/MichaelEvans/ColorArtDemo 地址：https://github.com/Trinea/TrineaDownload/blob/master/color-art-demo.apk?raw=true CircleImageView圆形的 ImageView项目地址：https://github.com/hdodenhof/CircleImageView效果图： ImageViewZoom支持放大和平移的 ImageView项目地址：https://github.com/sephiroth74/ImageViewZoomAPP 示例：https://play.google.com/store/apps/details?id=com.aviary.android.feather KenBurnsView实现 Ken Burns effect 效果，达到身临其境效果的 ImageView项目地址：https://github.com/flavioarfaria/KenBurnsView CustomShapeImageView各种形状的 ImageView, 相比上面的圆形 ImageView，多了更多形状项目地址：https://github.com/MostafaGazar/CustomShapeImageView效果图： Shape Image View可以自定义各种形状的 ImageView, 并且支持边框项目地址：https://github.com/siyamed/android-shape-imageview效果图：https://github.com/siyamed/android-shape-imageview/raw/master/images/all-samples.png TextDrawable一个用于生成带有文本或者字母的图片的轻量级库。扩展自 Drawable，因此可用于现有/自定义/网络等 ImageView 类，并且包含一个流接口用于创建 drawables 以及一个定制的 ColorGenerator项目地址：https://github.com/amulyakhare/TextDrawable效果图： android-smart-image-view可从 URL 或 contact address book 加载图片的 ImageView，支持缓存项目地址：https://github.com/loopj/android-smart-image-view PhotoView支持双指/双击缩放的ImageView,支持从一个PhotoView缩放到另外一个PhotoView(点击图片放大预览),相对于其他PhototView有更加平滑的缩放,平移的动画,并且支持所有的ScaleType,可以作为普通的ImageView使用项目地址：https://github.com/bm-x/PhotoView效果图： TextWithImageDrawable一个可以同时包含图片和文字的drawable,使用方式类似TextView和它的drawableLeft之类的方法,功能比较全面,可以代替TextView或是解决一些非得需要在ImageView中同时显示文字和图片的问题项目地址：https://github.com/wuseal/TextWithImageDrawable AnchorImageView一个可以锚点定位的ImageView(根据像素点)Demo中通过AnchorImageView简单的实现了一个课本点读的功能项目地址：https://github.com/jcodeing/AnchorImageViewDemo 地址：Download here 七、ProgressBar SmoothProgressBar水平进度条项目地址：https://github.com/castorflex/SmoothProgressBarDemo 地址：https://play.google.com/store/apps/details?id=fr.castorflex.android.smoothprogressbar.sample MaterialProgessBarMaterial Design 的进度条，支持 Android 4.0项目地址：https://github.com/DreaminginCodeZH/MaterialProgressBarDemo 地址：https://github.com/DreaminginCodeZH/MaterialProgressBar/blob/master/dist/sample.apk ProgressWheel支持进度显示的圆形 ProgressBar项目地址：https://github.com/Todd-Davies/ProgressWheelDemo 地址：https://github.com/Trinea/TrineaDownload/blob/master/progress-wheel-demo.apk?raw=true android-square-progressbar在图片周围显示进度项目地址：https://github.com/mrwonderman/android-square-progressbarDemo 地址：https://play.google.com/store/apps/details?id=net.yscs.android.square_progressbar_example效果图：APP 示例：square HoloCircularProgressBarAndroid4.1 时钟 App 样式项目地址：https://github.com/passsy/android-HoloCircularProgressBar效果图：APP 示例：Android4.1 时钟 App ProgressButton通过图钉的不同状态显示进度项目地址：https://github.com/f2prateek/progressbutton文档介绍：http://f2prateek.com/progressbutton/效果图： GoogleProgressBar类似 google 多个圆形卡片翻转的 progressBar项目地址：https://github.com/jpardogo/GoogleProgressBar效果图： TH-ProgressButton带圆形进度显示的按钮项目地址：https://github.com/torryharris/TH-ProgressButton效果图：https://raw.github.com/Vyshakh-K/TH-ProgressButton/master/screenshots/progressshot2.png NumberProgressBar带数字进度的进度条项目地址：https://github.com/daimajia/NumberProgressBar效果图： CircularProgressDrawable带圆形进度显示的进度条项目地址：https://github.com/Sefford/CircularProgressDrawable效果图： Android-RoundCornerProgressBarAndroid 圆角 ProgressBar，可自定义圆角颜色和半径，包括带 Icon 和不带 Icon 两种类型。项目地址：https://github.com/akexorcist/Android-RoundCornerProgressBar效果图： circular-progress-button带进度显示的 Button项目地址：https://github.com/dmytrodanylyk/circular-progress-button效果图： WaveView一个波纹效果的 View，可用来做 ProgressBar项目地址：https://github.com/john990/WaveViewDemo 地址：https://raw.github.com/john990/WaveView/master/screenshot%26apk/demo.unaligned.apk效果图： MaterialLoadingProgressBar抽取自 SwipeRefreshLayout 的 Material Design 进度指示器项目地址：https://github.com/lsjwzh/MaterialLoadingProgressBar效果图： MetaballLoadingA 2d metaball loading项目地址：https://github.com/dodola/MetaballLoading效果图：效果图： SectorProgressView一个圆形或环形的进度显示控件，用圆中扇形的角度大小来表示进度信息项目地址：https://github.com/timqi/SectorProgressViewDemo：apk download 效果图： CircularFillableLoaders一个可以用于闪屏或者其他地方加载的控件项目地址：https://github.com/lopspower/CircularFillableLoadersDemo地址：(https://play.google.com/store/apps/details?id=com.mikhaellopez.circularfillableloaderssample) 效果图： PinWheel一个旋转的大风车Dialog项目地址：https://github.com/codingWang/PinWheel效果图： ColorArcProgressBar一个可定制的圆形进度条，通过xml参数配置可实现QQ健康中步数的弧形进度显示、仪盘表显示速度、最常见的下载进度条等功能。项目地址：https://github.com/Shinelw/ColorArcProgressBar效果图： LoadingDrawable一些酷炫的android加载动画，可以与任何组件配合使用作为加载的组件或者ProgressBar。项目地址：https://github.com/dinuscxj/LoadingDrawable效果图： Android-SpinKitAndroid加载动画库项目地址：https://github.com/ybq/Android-SpinKit效果图： 八、TextView包括 TextView 及所有继承自 TextView 控件，如 EditText、Button、RadioButton android-flowtextview文字自动环绕其他 View 的 Layout项目地址：https://github.com/deano2390/FlowTextView效果图： Android Form EditText验证输入合法性的编辑框，支持输入、英文、ip、url 等多种正则验证项目地址：https://github.com/vekexasia/android-edittext-validatorDemo 地址：https://play.google.com/store/apps/details?id=com.andreabaccega.edittextformexample Emojicon支持 emojis 的 TextView 和 EditText项目地址：https://github.com/rockerhieu/emojicon文档介绍：http://rockerhieu.com/emojicon/ android-circlebuttonAndroid 圆形按钮，实际实现是继承自 ImageView项目地址：https://github.com/markushi/android-circlebuttonDemo 地址：https://github.com/markushi/android-circlebutton/blob/master/example/example.apk Segmented Radio Buttons for AndroidiOS’s segmented controls 的实现项目地址：https://github.com/vinc3m1/android-segmentedradiobuttonDemo 地址：https://github.com/thquinn/DraggableGridView/blob/master/bin/DraggableGridViewSample.apk?raw=true效果图： Chips EditText Library支持国家名字联想从而选择显示该国国旗的 EditText，实际就是通过 SpannableStringBuilder 实现项目地址：https://github.com/kpbird/chips-edittext-libraryDemo 地址：https://github.com/kpbird/chips-edittext-library/tree/master/ChipsEditTextDemo/bin AutoFitTextView可固定边界内容字体大小自适应的 TextView项目地址：https://github.com/grantland/android-autofittextview Shimmer for Android文字发淡光的 TextView项目地址：https://github.com/RomainPiel/Shimmer-android Titanic可以显示水位上升下降(不知道该怎么描述 囧)的 TextView项目地址：https://github.com/RomainPiel/Titanic效果图： android-iconify提供带 Icon 的 TextView,Menu,Button 等项目地址：https://github.com/JoanZapata/android-iconify Calligraphy让我们在 android 开发中使用自定义字体变得更加简单项目地址：https://github.com/chrisjenx/Calligraphy效果图： CreditsRoll类似星球大战字幕效果的 TextView项目地址：https://github.com/frakbot/CreditsRoll android-process-buton带加载或提交进度的 Button项目地址：https://github.com/dmytrodanylyk/android-process-buton FButton扁平化的 Button项目地址：https://github.com/hoang8f/android-flat-buttonDemo 地址：https://play.google.com/store/apps/details?id=info.hoang8f.fbutton.demo FloatingActionButton一个类似 Android 版 Google+浮动功能按钮的控件，可以响应 ListView 的滚动事件。当列表向上滚动的时候会自动显示，向下滚动的时候自动隐藏。项目地址：https://github.com/makovkastar/FloatingActionButtonDemo 地址：https://github.com/makovkastar/FloatingActionButton/tree/master/效果图： Android SaripaarAndroid 表单验证项目地址：https://github.com/ragunathjawahar/android-saripaar/ JumpingBeans文字像 Mexican beans 一样跳动项目地址：https://github.com/frakbot/JumpingBeansDemo 地址：http://play.google.com/store/apps/details?id=net.frakbot.jumpingbeans.demo效果图： FancyButtons一个不用图片就可以帮助我们创建出漂亮按钮的库。项目地址：https://github.com/medyo/fancybuttonsDemo 地址：https://github.com/medyo/fancybuttons/tree/master/samples效果图：https://raw.githubusercontent.com/medyo/fancybuttons/master/screenshots/fancy2.png Android-RobotoTextView一个实现了所有 Roboto 字体的 TextView，包括新出的 Roboto Slab 字体。项目地址：https://github.com/johnkil/Android-RobotoTextViewDemo 地址：http://play.google.com/store/apps/details?id=com.devspark.robototextviewDemo 项目：https://github.com/johnkil/Android-RobotoTextView/tree/master/robototextview-sample效果图： Android-WizardPager一个表单向导库项目地址：https://github.com/romannurik/android-wizardpagerDemo 项目：https://github.com/str4d/android-wizardpager/tree/textfield效果图： RippleView一个实现了 Android L 上才引入的点击按钮后出现水波纹效果的按钮项目地址：https://github.com/siriscac/RippleViewDemo 项目：https://github.com/siriscac/RippleView/tree/master/RippleViewExample效果图： RippleEffect一个实现 Material Design Ripple 效果的库，支持 Android API 9+以上版本。项目地址：https://github.com/traex/RippleEffectDemo 项目：https://github.com/traex/RippleEffect/tree/master/sample效果图： RippleCompat使用易于移植的方式为UI控件实现波纹效应，可以适配控件原背景及Palette支持。api简单，可自定义效果，兼容至Android API 7+。项目地址：https://github.com/desmond1121/RippleCompatDemo 项目：https://github.com/desmond1121/RippleCompat/tree/master/app效果图： palette效果： Android Floating Label Widgets包含一系列控件，这些控件特点是：有默认值，当值不为空时默认值浮动到上面变为提示项目地址：https://github.com/marvinlabs/android-floatinglabel-widgetsDemo 地址：https://play.google.com/store/apps/details?id=com.marvinlabs.widget.floatinglabel.demo在线演示：http://www.youtube.com/watch?v=hpZD9gJcRg0&amp;feature=youtu.be MaterialEditTextEditText 的 Material Design 实现。包含 Google Material Design Spec中的 UI 效果和一些新增特性。项目地址：https://github.com/rengwuxian/MaterialEditText MaterialEditText实现 Material Design 中 Ripple 效果线条背景的 EditText。直接替换原生 EditText 即可集成。项目地址：https://github.com/DreamingInCodeZH/MaterialEditText MultiActionTextView可以分别给 TextView 中的某几个字设置点击事件的 TextView项目地址：https://github.com/ajaysahani/MultiActionTextView效果图： ToggleButton状态切换的 Button，类似 iOS，用 View 实现项目地址：https://github.com/zcweng/ToggleButton效果图： SwitchButton状态切换的 Button，类似 iOS，拥有良好的用户界面项目地址：https://github.com/kyleduo/SwitchButton效果图： SlideSwitch状态切换的开关，可以设置为类似 IOS 的圆形，也可以设置为矩形，用 View 实现项目地址：https://github.com/Leaking/SlideSwitch效果图： ExpandableTextView可展开和收缩内容的 TextView。项目地址：https://github.com/Manabu-GT/ExpandableTextView效果图： TagCloudView(支持 SingleLine 模式的标签云)标签云效果，只需要一行代码即可设置为 SingleLine 模式，轻松实现知乎问题话题列表效果。SingleLine 模式时末尾文字及图片可自定义。项目地址：https://github.com/kingideayou/TagCloudView示例APK地址：https://github.com/kingideayou/TagCloudView/raw/master/apk/Demo.apkAPP示例：知乎效果图： BubbleTextViewAndroid Bubble View项目地址：https://github.com/dupengtao/BubbleTextView效果图： shadow-layoutAndroid Shadow Layout解决了CardView：1.不能画圆的阴影。2.设置阴影的位置。3.设置阴影颜色。项目地址：https://github.com/dmytrodanylyk/shadow-layout效果图： MoneyTextView一个支持加法运算的金额输入TextView项目地址：https://github.com/andyken/MoneyTextView效果图： 九、ScrollView Discrollview支持滚动时 Item 淡入淡出，平移，缩放效果的 ScrollView项目地址：https://github.com/flavienlaurent/discrollviewDemo 地址：https://github.com/flavienlaurent/discrollview/raw/master/sample.apk PullScrollView仿照新浪微博 Android 客户端个人中心的 ScrollView，下拉背景伸缩回弹效果。项目地址：https://github.com/MarkMjw/PullScrollView效果图： ArcLayout一个非常简单的弧布局库项目地址：https://github.com/ogaclejapan/ArcLayoutDemo 地址：https://play.google.com/store/apps/details?id=com.ogaclejapan.arclayout.demo效果图：https://raw.githubusercontent.com/ogaclejapan/ArcLayout/master/art/demo2.gif ParallaxScrollView支持视差滚动的 ScrollView ，背景图片的滚动速度小于 ScrollView 中子控件的滚动速度项目地址：https://github.com/chrisjenx/ParallaxScrollViewDemo 地址：http://cloud.github.com/downloads/chrisjenx/ParallaxScrollView/ParallaxScrollViewDemo-v1.0.5.apk AKParallax-Android支持视差滚动的 ScrollView项目地址：https://github.com/ideaismobile/AKParallax-AndroidDemo 地址：https://play.google.com/store/apps/details?id=com.appkraft.parallax_sample Android-ObservableScrollView监听滚动视图滚动事件的库，帮助与 Toolbar 的交互动效处理与 Material Design 的实现项目地址：https://github.com/ksoichiro/Android-ObservableScrollViewDemo 地址：https://play.google.com/store/apps/details?id=com.github.ksoichiro.android.observablescrollview.samples2 OverScrollView有弹性的 ScrollView，实现了当手指滑动到 ScrollView 的顶部、底部时，可以继续的向上、向下拉伸。当释放手指的时候，向上、下回弹项目地址：https://github.com/EverythingMe/OverScrollView 十、TimeView包括 TimePicker、DatePicker、CalendarView、Clock 等时间相关控件 android-times-squareAndroid 日历时间部件，支持选取单个日期，多个日期，及日期区间段和对话框形式显示项目地址：https://github.com/square/android-times-squareDemo 地址：https://github.com/Trinea/TrineaDownload/blob/master/times-square-demo.apk?raw=true android-calendar-card日历项目地址：https://github.com/kenumir/android-calendar-cardDemo 地址：https://play.google.com/store/apps/details?id=com.wt.calendarcardsample效果图： AndroidWheelAndroid Wheel 支持城市、多种日期时间、密码、图片项目地址：https://code.google.com/p/android-wheel/效果图： GoogleDateTimePickers时间选择部件项目地址：https://github.com/Mirkoddd/GoogleDateTimePickers文档介绍：https://play.google.com/store/apps/details?id=com.mirko.sample&amp;hl=it DateTimePicker日期选择部件(Google Agenda 的样式风格)项目地址：https://github.com/flavienlaurent/datetimepickerDemo 地址：https://raw.github.com/biboune/datetimepicker/master/datetimepicker-sample.apk效果图： android-betterpickers提供日期、数字、时间（数字方式和钟表方式）、重复周期（闹钟的周期重复）、HMS（时、分、秒）的选择，支持以 DialogFragment 的弹窗选择项目地址：https://github.com/derekbrameyer/android-betterpickersDemo 地址：https://play.google.com/store/apps/details?id=com.doomonafireball.betterpickers.sample效果图： Android Week View日期控件，支持周，天视图，支持自定义样式项目地址：https://github.com/alamkanak/Android-Week-View效果图： PickerView仿 iOS 的 PickerView 控件，有时间选择和选项选择并支持一二三级联动效果，TimePopupWindow 时间选择器，支持年月日时分，年月日，时分等格式；OptionsPopupWindow 选项选择器，支持一，二，三级选项选择，并且可以设置是否联动项目地址：https://github.com/saiwu-bigkoo/Android-PickerView效果图： CountdownViewAndroid 倒计时控件，使用Canvas绘制，支持多种样式项目地址：https://github.com/iwgang/CountdownView效果图： 十一、TipView包括 Toast、角标、UndoBar 等提示性控件 SVProgressHUDSVProgressHUD For Android 精仿iOS的提示库 SVProgressHUD，api也几乎一样。项目地址：https://github.com/saiwu-bigkoo/Android-SVProgressHUD效果图： Crouton丰富样式的 Toast，允许 alert、comfirm、info 样式及点击消失样式，允许设置 Toast 显示时间，允许自定义 View。 本文 32. SuperToasts 为其扩展版项目地址：https://github.com/keyboardsurfer/CroutonDemo 地址：http://play.google.com/store/apps/details?id=de.keyboardsurfer.app.demo.crouton supertooltips带动画效果的 Tips 显示项目地址：https://github.com/nhaarman/supertooltipsDemo 地址：https://play.google.com/store/apps/details?id=com.haarman.supertooltips Android ViewBadger为其他 View 添加角标（消息圆点）等项目地址：https://github.com/jgilfelt/android-viewbadgerDemo 地址：https://github.com/Trinea/TrineaDownload/blob/master/android-viewbadger.apk?raw=true效果图： SuperToasts更丰富样式的 toast，支持 Button、Progress、Horizontal Progress 样式、支持进入动画、支持撤销及其动画设置项目地址：https://github.com/JohnPersano/SuperToastsDemo 地址：https://play.google.com/store/apps/details?id=com.supertoastsdemo效果图： UndoBar屏幕底部显示取消或是确认的 PopupWindows项目地址：https://github.com/soarcn/UndoBar效果图： UndoBar屏幕底部显示取消或是确认某操作项目地址：https://github.com/jenzz/Android-UndoBar效果图： Android-ActionItemBadge可以在 ActionBar 的 MenuItem 上显示一个小角标项目地址：https://github.com/mikepenz/Android-ActionItemBadge效果图： SnackBarMaterial Design 风格的 Toast，类似 Google inbox 中的提示项目地址：https://github.com/MrEngineer13/SnackBarDemo 地址：https://play.google.com/store/apps/details?id=com.mrengineer13.snackbar.sample效果图： HeadsUp在 2.3 上使用 android 5.0 的 HeadsUp 效果项目地址：https://github.com/zzz40500/HeadsUp效果图： 十二、FlipView android-flip类似 Flipboard 翻转动画的实现项目地址：https://github.com/openaphid/android-flipDemo 地址：https://github.com/openaphid/android-flip/blob/master/FlipView/Demo/APK/Aphid-FlipView-Demo.apk?raw=trueAPP 示例：flipboard FlipImageView支持 x、y、z 及动画选择的翻转动画的实现项目地址：https://github.com/castorflex/FlipImageViewDemo 地址：https://play.google.com/store/apps/details?id=fr.castorflex.android.flipimageview FoldableLayoutFlip 翻转效果的 ListView，目前还不支持 ListView 缓存项目地址：https://github.com/alexvasilkov/FoldableLayoutDemo 地址：http://play.google.com/store/apps/details?id=com.alexvasilkov.foldablelayout.sample FlipViewPager.DracoFlip 翻转效果的 ViewPager项目地址：https://github.com/Yalantis/FlipViewPager.Draco效果： 十三、ColorPickView ColorPickerView颜色选择器，支持 PopupWindows 或新的 Activity 中打开项目地址：https://code.google.com/p/color-picker-view/效果图： HoloColorPicker颜色选择器项目地址：https://github.com/LarsWerkman/HoloColorPickerDemo 地址：https://docs.google.com/file/d/0BwclyDTlLrdXRzVnTGJvTlRfU2s/edit ColorPickerPreference颜色选择器项目地址：https://github.com/attenzione/android-ColorPickerPreference效果图： ColorPicker颜色选择器（Google Agenda 中的样式风格）项目地址：https://github.com/flavienlaurent/colorpickerDemo 地址：https://raw.github.com/biboune/colorpicker/master/colorpicker-sample.apk效果图： 十四、GraphView MPAndroidChart强大的图表绘制工具，支持折线图、面积图、散点图、时间图、柱状图、条图、饼图、气泡图、圆环图、范围（高至低）条形图、网状图等；支持图的拖拽缩放；支持 Android 2.2 以上，支持横纵轴缩放，多指缩放，展现动画、高亮、保存到 sdcard、从文件读取图表项目地址：https://github.com/PhilJay/MPAndroidChartDemo 地址：https://play.google.com/store/apps/details?id=com.xxmassdeveloper.mpchartexampleDemo 项目：https://github.com/PhilJay/MPAndroidChart/tree/master/MPChartExample效果图：https://camo.githubusercontent.com/78b4bc4e50e151970961daf56e81c4c0db72d27c/68747470733a2f2f7261772e6769746875622e636f6d2f5068696c4a61792f4d5043686172742f6d61737465722f73637265656e73686f74732f73696d706c6564657369676e5f6261726368617274332e706e67https://camo.githubusercontent.com/65f51783ec05038730b481ed614b57a94e867d86/68747470733a2f2f7261772e6769746875622e636f6d2f5068696c4a61792f4d5043686172742f6d61737465722f73637265656e73686f74732f626172636861727432642e706e67https://camo.githubusercontent.com/f66a35bf430b12480d3e2ed8e3bc8d7a17db950f/68747470733a2f2f7261772e6769746875622e636f6d2f5068696c4a61792f4d5043686172742f6d61737465722f73637265656e73686f74732f626172636861727433642e706e67https://camo.githubusercontent.com/60bd0d71462ad577df775b956944b191e939728a/68747470733a2f2f7261772e6769746875622e636f6d2f5068696c4a61792f4d50416e64726f696443686172742f6d61737465722f73637265656e73686f74732f70696563686172745f686f6c657261646975735f73706163652e706e67https://camo.githubusercontent.com/6b254aa699df7f9464967009129c3017de721b77/68747470733a2f2f7261772e6769746875622e636f6d2f5068696c4a61792f4d50416e64726f696443686172742f6d61737465722f73637265656e73686f74732f7363617474657263686172742e706e67在线演示：https://www.youtube.com/watch?v=ufaK_Hd6BpI achartengine强大的图表绘制工具，支持折线图、面积图、散点图、时间图、柱状图、条图、饼图、气泡图、圆环图、范围（高至低）条形图、拨号图/表、立方线图及各种图的结合项目地址：https://code.google.com/p/achartengine/效果图：http://www.achartengine.org/dimages/sales_line_and_area_chart.pnghttp://www.achartengine.org/dimages/temperature_range_chart.pnghttp://www.achartengine.org/dimages/combined_chart.pnghttp://www.achartengine.org/dimages/budget_chart.png官网网址：http://www.achartengine.org/APP 示例：Wordpress Android，Google Analytics GraphView绘制图表和曲线图的 View，可用于 Android 上的曲形图、柱状图、波浪图展示项目地址：https://github.com/jjoe64/GraphViewDemo 项目：https://github.com/jjoe64/GraphView-DemosAPP 示例：Wordpress Android，Google Analytics HoloGraphLibrary绘制现状图、柱状图、饼状图项目地址：https://bitbucket.org/danielnadeau/holographlibrary/src文档介绍：https://bitbucket.org/danielnadeau/holographlibrary/wiki/Home XCL-ChartsXCL-Charts 基于原生的 Canvas 来绘制各种图表,在设计时，尽量在保证开发效率的同时，给使用者提供足够多的定制化能力。因此使用简便,同时具有相当灵活的定制能力。目前支持 3D/非 3D 柱形图(Bar Chart)、3D/非 3D 饼图(Pie Chart)、堆积图(Stacked Bar Chart)、面积图(Area Chart)、 折线图(Line Chart)、曲线图(Spline Chart)、环形图(Dount Chart)、南丁格尔玫瑰图(Rose Chart)、仪表盘(Dial Chart)、刻度盘(Gauge Chart)、雷达图(Radar Chart)、圆形图(Circle Chart)等图表。其它特性还包括支持图表缩放、手势移动、动画显示效果、高密度柱形显示、图表分界定制线、多图表的混合显示及同数据源不同类型图表切换等。项目地址：https://github.com/xcltapestry/XCL-ChartsDemo 地址：https://github.com/xcltapestry/XCL-Charts/blob/master/XCL-Charts-demo/bin/XCL-Charts-demo.apk?raw=true EazeGraphAndroid 图表库，支持柱状图、分层柱状图、饼状图、线性图项目地址：https://github.com/blackfizz/EazeGraphDemo 地址：https://play.google.com/store/apps/details?id=org.eazegraph.app WilliamChart绘制图表的库，支持 LineChartView、BarChartView 和 StackBarChartView 三中图表类型，并且支持 Android 2.2 及以上的系统。项目地址：https://github.com/diogobernardino/WilliamChartDemo 地址：https://play.google.com/store/apps/details?id=com.db.williamchartdemoDemo 项目：https://github.com/diogobernardino/WilliamChart/tree/master/sample效果图： HelloCharts for Android支持折线图、柱状图、饼图、气泡图、组合图；支持预览、放大缩小，滚动，部分图表支持动画；支持 Android 2.2 以上项目地址：https://github.com/lecho/hellocharts-androidDemo 地址：https://play.google.com/store/apps/details?id=lecho.lib.hellocharts.samples在线演示：https://www.youtube.com/watch?v=xbSBjyjH2SY PieChartView比较简单直接的饼状统计报表图，使用方便，设置相应的属性参数即可项目地址：https://github.com/wuseal/PieChartViewDemo 地址：https://github.com/wuseal/PieChartView效果图： 十五、UI Style不同样式的系统 UI 风格，如 IOS、Bootstrap 风格 UITableViewios 风格控件，包括 Button、ListView、TableView项目地址：https://github.com/thiagolocatelli/android-uitableviewDemo 地址：https://github.com/Trinea/TrineaDownload/blob/master/ui-tableview-demo.apk?raw=true ATableViewios 风格控件项目地址：https://github.com/dmacosta/ATableViewDemo 地址：https://play.google.com/store/apps/details?id=com.nakardo.atableview.demo Cards-UI卡片式 View，支持单个卡片，item 为卡片的 ListView项目地址：https://github.com/afollestad/Cards-UIDemo 地址：https://github.com/Trinea/TrineaDownload/blob/master/cards-ui-demo.apk?raw=true cardslib卡片式 View，支持单个卡片，item 为卡片的 ListView 和 GridView项目地址：https://github.com/gabrielemariotti/cardslibDemo 地址：https://play.google.com/store/apps/details?id=it.gmariotti.cardslib.demo Android-BootstrapBootstrap 风格的按钮项目地址：https://github.com/Bearded-Hen/Android-Bootstrap效果图： Material Design Android LibraryAndroid L 中 Material Design 风格的组件适配到 Android 2.2+项目地址：https://github.com/navasmdc/MaterialDesignLibrary Android FlatUIAndroid 扁平化风格的组件，支持一些自定义样式项目地址：https://github.com/eluleci/FlatUI效果图： cheesesquare全新 Android 设计库演示 Demo，包括 Collapsing Toolbar、FloatingActionButton、View anchoring、NavigationView、Snackbar项目地址：https://github.com/chrisbanes/cheesesquare效果图： 十六、其他 SnappingStepper一种漂亮的UI控件，能更灵活的控制数字的增减。可用于购物车商品数量控制。项目地址：https://github.com/saiwu-bigkoo/Android-SnappingStepper效果图： SwipeBackLayout左右或向上滑动返回的 Activity项目地址：https://github.com/Issacw0ng/SwipeBackLayoutDemo 地址：https://play.google.com/store/apps/details?id=me.imid.swipebacklayout.demoAPP 示例：知乎 ParallaxBackLayout视差滑动返回的 Activity项目地址：https://github.com/anzewei/ParallaxBackLayoutDemo 地址：https://github.com/anzewei/ParallaxBackLayout/blob/master/ext/demo.apk?raw=true效果图： android-styled-dialogs可自定义样式的 dialog，默认与 Holo 主题样式一致，在 Android2.2 以上同一样式项目地址：https://github.com/inmite/android-styled-dialogsDemo 地址：https://github.com/Trinea/TrineaDownload/blob/master/styled-dialogs-demo.apk?raw=true Android Sliding Up Panel可拖动的 View，能在当前 Activity 上扶起一个可拖动的 Panel项目地址：https://github.com/umano/AndroidSlidingUpPanelDemo 地址：https://play.google.com/store/apps/details?id=com.sothree.umanoAPP 示例：Google Music 精简播放栏 TableFixHeaders第一列固定的 Table项目地址：https://github.com/InQBarna/TableFixHeadersDemo 地址：http://bit.ly/13buAIq Inscription可用于展示应用 change 和 new feature 信息项目地址：https://github.com/MartinvanZ/Inscription ActivityTransitionActivity 切换动画，包括渐变、flip、某个位置进入等等项目地址：https://github.com/ophilbert/ActivityTransition文档介绍：https://github.com/jfeinstein10/JazzyViewPager/blob/master/JazzyViewPager.apk?raw=true EasyAndroidAnimations针对 View 的各种动画项目地址：https://github.com/2359media/EasyAndroidAnimations ViewAnimation对android view 动画进行封装,实现起更简单，自带三种常见运动路径，其他的可自定义项目地址：https://github.com/guohuanwen/ViewAniamtion效果图：APP 示例：QQ名片圈圈效果 AndroidLoadingAnimation多种android加载动画项目地址：https://github.com/guohuanwen/AndroidLoadingAnimation效果图： android-lockpatternAndroid 的图案密码解锁项目地址：https://code.google.com/p/android-lockpattern/原理剖析文档：android-lockpatternDemo 地址：https://play.google.com/store/apps/details?id=group.pals.android.lib.ui.lockpattern.demo文档介绍：https://code.google.com/p/android-lockpattern/wiki/QuickUseAPP 示例：Android 开机的图案密码解锁，支付宝的密码解锁 PatternLock另一个 Android 图案解锁库项目地址：https://github.com/DreaminginCodeZH/PatternLockDemo 地址：https://github.com/DreaminginCodeZH/PatternLock/raw/master/dist/sample.apk效果图：APP 示例：Android 开机的图案密码解锁，支付宝的密码解锁 RangeBar类似于 SeekBar，不同的是可以选择一个范围内的值而不是单个值项目地址：https://github.com/edmodo/range-barDemo 地址：https://github.com/Trinea/TrineaDownload/blob/master/range-bar-demo.apk?raw=true效果图： ChromeView利用 Chromium 实现的 WebView，解决各个 Android 版本 WebView 不同的问题，同时利用最新 Chrome 代码项目地址：https://github.com/pwnall/chromeview android-phased-seek-bar支持预先定义状态的 SeekBar项目地址：https://github.com/ademar111190/android-phased-seek-bar效果图： Android Slider Preference Library可添加到设置中的基于对话框的 RankBar 小部件项目地址：https://github.com/jayschwa/AndroidSliderPreference ShowcaseView library用于高亮显示应用程序的特定部分，从而突出突出重点项目地址：https://github.com/amlcurran/ShowcaseView android-segmented-controlAndroid 上的 Segmented Controls，相当于 RadioButton 组项目地址：https://github.com/hoang8f/android-segmented-control Swipeable Cards类似 Tinder 的卡片效果，可以加载图片并动画效果展示，向左滑动表示喜欢，向右表示不喜欢项目地址：https://github.com/kikoso/Swipeable-CardsDemo 地址：https://play.google.com/store/apps/details?id=info.hoang8f.fbutton.demo EdgeEffectOverride改变 ScrollView, ListView, ExpandableListView, GridView, ViewPager 等滚动控件滚动到边缘的颜色效果项目地址：https://github.com/AndroidAlliance/EdgeEffectOverride android-pinned-header-listviews使 ExpandListView 的 Group 滑动到顶端时会固定不动直到另外一个 Group 到达顶端项目地址：https://github.com/rtyley/android-pinned-header-listviews AndroidSwipeLayout滑动 Layout，支持单个 View，ListView，GridView项目地址：https://github.com/daimajia/AndroidSwipeLayoutDemo 地址：Download Demo效果图： DynamicCardLayout在 Android 中实现的类似 Windows8 的瓷片布局项目地址：https://github.com/dodola/DynamicCardLayout效果图： Emoticons-Keyboard带表情情符号的自定义键盘项目地址：https://github.com/chiragjain/Emoticons-Keyboard效果图： Android Typeface Helper可以帮你轻松实现自定义字体的库项目地址：https://github.com/norbsoft/android-typeface-helper效果图： Android-Anim-Playground几个动画效果，其中第二个基于 android-svg 的绘制效果非常好项目地址：https://github.com/Tibolte/Android-Anim-Playground效果图： AlertView仿iOS的AlertViewController 几乎完美还原iOS 的 AlertViewController ，同时支持Alert和ActionSheet模式，每一个细节都是精雕细琢，并把api封装成懒到极致模式，一行代码就可以进行弹窗.项目地址：https://github.com/saiwu-bigkoo/Android-AlertView效果图： NiftyDialogEffects支持自定义飞入动画样式的 Dialog项目地址：https://github.com/sd6352051/NiftyDialogEffects效果图：在线演示：http://tympanus.net/Development/ModalWindowEffects/ PostOffice创建 Holo 及 Material Design 样式的 Dialog项目地址：https://github.com/r0adkll/PostOffice效果图： Swipecards类似 Tinder 的卡片效果，可以加载图片并动画效果展示，向左滑动表示喜欢，向右表示不喜欢，根据 Kikoso’s Swipeable-Cards 改造而来项目地址：https://github.com/Diolor/Swipecards SeekArc圆形的 SeekBar项目地址：https://github.com/TriggerTrap/SeekArc效果图： BlurDialogFragment显示 DialogFragment 时背景模糊效果项目地址：https://github.com/tvbarthel/BlurDialogFragmentDemo 地址：https://play.google.com/store/apps/details?id=fr.tvbarthel.lib.blurdialogfragment.sample range-seek-bar随机值选取的 SeekBar项目地址：https://github.com/yahoo/android-range-seek-bar效果图： MaterialRangeBar可以选择一个范围内的值而不是单个值的 SeekBar，RangeBar 的 Material Design 风格适配项目地址：https://github.com/oli107/material-range-bar效果图： MaterialListMaterial Design 风格的 CardView项目地址：https://github.com/dexafree/MaterialListDemo 地址：https://play.google.com/store/apps/details?id=com.dexafree.materiallistviewexample效果图： road-trip设置 path 的各种动画效果，以及如何实现复杂路径动画，类似于 ios 中的指纹注册界面的指纹动画效果项目地址：https://github.com/romainguy/road-trip效果图： dialogplus一个简单的 Android 对话框，支持不同的弹出模式项目地址：https://github.com/orhanobut/dialogplus效果图： FlowLayout一个简单的流式布局，用法类似 LinearLayout，但是能够让子元素根据宽度自动换行项目地址：FLowLayout效果图： CircleSeekbar一个环形Seekbar组件,支持叠加复合使用项目地址：CircleSeekbar效果图： FinestWebView美麗的和可定制的Android的活動，顯示在一個應用程序的網頁。项目地址: https://github.com/TheFinestArtist/FinestWebView-AndroidSample 地址: https://play.google.com/store/apps/details?id=com.thefinestartist.finestwebview.sample效果图: YouTubePlayerActivity只需通過一個URL來在新的活動播放YouTube視頻。它支持屏幕方向，媒體音量控制等。项目地址: https://github.com/TheFinestArtist/YouTubePlayerActivitySample 地址: https://play.google.com/store/apps/details?id=com.thefinestartist.ytpa.sample效果图: material-cameramaterial风格的camera。能使camera使用起来更简单的库。项目地址：https://github.com/afollestad/material-camera效果图： material-dialogs各种material风格的dialog。漂亮的的、易于使用的和可定制的Dialog API，你能够使用Material designed风格的Dialog到API 8。项目地址：https://github.com/afollestad/material-dialogsSample地址：https://github.com/afollestad/material-dialogs/blob/master/sample/sample.apk效果图： NotifyUtil最常见的通知样式库项目地址:https://github.com/wenmingvs/NotifyUtildemo地址：https://github.com/wenmingvs/NotifyUtil#notifydemo CanPhotos使用fresco选取多张图片并可预览图片项目地址：https://github.com/canyinghao/CanPhotos效果图： CanDialog仿照系统Dialog所写，继承于FrameLayout，添加一些动画，一些显示类型。项目地址：https://github.com/canyinghao/CanDialog效果图： WindRoseDiagramView一个风力玫瑰图的 View 组件，项目地址： MaterialRatingBar与 Google 系应用设计相同、支持拉伸、修正原生实现诸多问题的星级评分条。可直接替换 RatingBar。项目地址：https://github.com/DreaminginCodeZH/MaterialRatingBarDemo 地址：https://github.com/DreaminginCodeZH/MaterialRatingBar/releases/download/v1.0.2/sample-release.apk SpotlightAndroid图书馆点亮项目的教程或漫步等…項目地址：https://github.com/TakuSemba/Spotlight 效果圖: SpeedViewAndroid的动态车速表和量规。 惊人，强大，多形 :zap:項目地址: https://github.com/anastr/SpeedView效果圖: 第二部分 工具库主要包括那些不错的开发库，包括依赖注入框架、图片缓存、网络请求、数据库 ORM 建模、Android 公共库、Android 高版本向低版本兼容、多媒体相关及其他。 一、依赖注入 DI通过依赖注入减少 View、服务、资源简化初始化，事件绑定等重复繁琐工作 AndroidAnnotations(Code Diet)android 快速开发框架项目地址：https://github.com/excilys/androidannotations文档介绍：https://github.com/excilys/androidannotations/wiki官网网址：http://androidannotations.org/特点：(1) 依赖注入：包括 view，extras，系统服务，资源等等(2) 简单的线程模型，通过 annotation 表示方法运行在 ui 线程还是后台线程(3) 事件绑定：通过 annotation 表示 view 的响应事件，不用在写内部类(4) REST 客户端：定义客户端接口，自动生成 REST 请求的实现(5) 没有你想象的复杂：AndroidAnnotations 只是在在编译时生成相应子类(6) 不影响应用性能：仅 50kb，在编译时完成，不会对运行时有性能影响。其他：与 roboguice 的比较：roboguice 通过运行时读取 annotations 进行反射，所以可能影响应用性能，而 AndroidAnnotations 在编译时生成子类，所以对性能没有影响 roboguice帮你处理了很多代码异常，利用 annotation 使得更少的代码完成项目项目地址：https://github.com/roboguice/roboguice文档介绍：https://github.com/roboguice/roboguice/wiki butterknife利用 annotation 帮你快速完成 View 的初始化，减少代码项目地址：https://github.com/JakeWharton/butterknife文档介绍：http://jakewharton.github.io/butterknife/ Dagger依赖注入，适用于 Android 和 Java项目地址：https://github.com/square/dagger原理剖析文档：Dagger文档介绍：http://square.github.io/dagger/ AutoParcel注解自动生成Parcelable实现代码的库项目地址：https://github.com/frankiesardo/auto-parcel这篇文章详细介绍了它的使用方法：AutoParcel作者认为使用AutoParcel的好处是，可以简化构造函数，方便IDE代码自动完成，方便测试，前向兼容，生成不可变的对象。文档介绍：https://github.com/frankiesardo/auto-parcel 二、图片缓存 Android-Universal-Image-Loader图片缓存，目前使用最广泛的图片缓存，支持主流图片缓存的绝大多数特性。项目地址：https://github.com/nostra13/Android-Universal-Image-Loader原理剖析文档：Android-Universal-Image-LoaderDemo 地址：https://github.com/Trinea/TrineaDownload/blob/master/universal-imageloader-demo.apk?raw=true文档介绍：http://www.intexsoft.com/blog/item/74-universal-image-loader-part-3.html picassosquare 开源的图片缓存项目地址：https://github.com/square/picasso文档介绍：http://square.github.io/picasso/特点：(1)可以自动检测 adapter 的重用并取消之前的下载(2)图片变换(3)可以加载本地资源(4)可以设置占位资源(5)支持 debug 模式 Cube ImageLoader阿里巴巴一淘使用的图片加载，综合了 Android-Universal-Image-Loader 和 square 等组件优点，简单易用，良好的中文文档支持项目地址：https://github.com/etao-open-source/cube-sdkDemo 地址：https://github.com/liaohuqiu/cube-sdk/raw/master/cube-sdk-sample.apk文档介绍：http://cube-sdk.liaohuqiu.net/效果图： fresco一款强大的图片缓存工具，由 Facebook 开发项目地址：https://github.com/facebook/fresco文档介绍：http://frescolib.org/特点：(1) 两个内存缓存加上磁盘缓存构成了三级缓存(2) 支持流式，可以类似网页上模糊渐进式显示图片(3) 对多帧动画图片支持更好，如 Gif、WebP(4) 更多样的显示，如圆角、进度条、点击重试、自定义对焦点(5) 更多样的加载，如支持 EXIF、全面支持 WebP(6) 支持 Android 2.3+ GlideGlide 是一个 android 平台上的快速和高效的开源的多媒体资源管理库,提供 多媒体文件的压缩,内存和磁盘缓存, 资源池的接口。它可以最大性能地在 Android 设备上读取、解码、显示图片和视频。Glide 可以将远程的图片、视频、动画图片等缓存在设备本地便于提高用户浏览图片的流畅体验。项目地址：https://github.com/bumptech/glide特点：(1) GIF 动画的解码(2) 本地视频剧照的解码(3) 支持缩略图(4) Activity 生命周期的集成(5) 转码的支持(6) 动画的支持(7) OkHttp 和 Volley 的支持 三、网络请求 VolleyGoogle 提供的网络通信库，使得网络请求更简单、更快速项目地址：https://android.googlesource.com/platform/frameworks/volley文档介绍：http://commondatastorage.googleapis.com/io-2013/presentations/110%20-%20Volley-%20Easy,%20Fast%20Networking%20for%20Android.pdf Asynchronous Http Client for AndroidAndroid 异步 Http 请求项目地址：https://github.com/loopj/android-async-http文档介绍：http://loopj.com/android-async-http/特点：(1) 在匿名回调中处理请求结果(2) 在 UI 线程外进行 http 请求(3) 文件断点上传(4) 智能重试(5) 默认 gzip 压缩(6) 支持解析成 Json 格式(7) 可将 Cookies 持久化到 SharedPreferences android-query异步加载，更少代码完成 Android 加载项目地址：https://github.com/androidquery/androidquery 或 https://code.google.com/p/android-query/Demo 地址：https://play.google.com/store/apps/details?id=com.androidquery文档介绍：https://code.google.com/p/android-query/#Why_AQuery?特点：https://code.google.com/p/android-query/#Why_AQuery? Async Http ClientJava 异步 Http 请求项目地址：https://github.com/AsyncHttpClient/async-http-client文档介绍：http://sonatype.github.io/async-http-client/ Ion支持图片、json、http post 等异步请求项目地址：https://github.com/koush/ion文档介绍：https://github.com/koush/ion#more-examples Http Request项目地址：https://github.com/kevinsawicki/http-request文档介绍：https://github.com/kevinsawicki/http-request#examples okhttpsquare 开源的 http 工具类项目地址：https://github.com/square/okhttp文档介绍：http://square.github.io/okhttp/特点：(1) 支持 SPDY( http://zh.wikipedia.org/wiki/SPDY )协议。SPDY 协议是 Google 开发的基于传输控制协议的应用层协议，通过压缩，多路复用(一个 TCP 链接传送网页和图片等资源)和优先级来缩短加载时间。(2) 如果 SPDY 不可用，利用连接池减少请求延迟(3) Gzip 压缩(4) Response 缓存减少不必要的请求 RetrofitRESTFUL API 设计项目地址：https://github.com/square/retrofit文档介绍：http://square.github.io/retrofit/ RoboSpiceAndroid 异步网络请求工具，支持缓存、REST 等等项目地址：https://github.com/stephanenicolas/robospiceDemo 地址：https://github.com/stephanenicolas/RoboDemo/downloads TwistVolleyTwistVolley 是对 Volley 的一个封装库。提供类似 Picasso 一样的串联式 API。使得使用 Volley 更加方便。项目地址：https://github.com/TwistedEquations/TwistVolley OkHttpFinal一个对OkHttp封装的简单易用型HTTP请求和文件下载管理框架项目地址：https://github.com/pengjianbo/OkHttpFinalDemo 地址：https://github.com/pengjianbo/OkHttpFinal 四、数据库 orm 工具包orm 的 db 工具类，简化建表、查询、更新、插入、事务、索引的操作 greenDAOAndroid Sqlite orm 的 db 工具类项目地址：https://github.com/greenrobot/greenDAO文档介绍：http://greendao-orm.com/documentation/官网网址：http://greendao-orm.com/特点：(1) 性能佳(2) 简单易用的 API(3) 内存小好小(4) 库大小小 GreenDaoUpgradeHelpergreenDAO的数据库升级帮助类，只需一行代码解决数据库升级项目地址：https://github.com/yuweiguocn/GreenDaoUpgradeHelper ActiveAndroidAndroid Sqlite orm 的 db 工具类项目地址：https://github.com/pardom/ActiveAndroid文档介绍：https://github.com/pardom/ActiveAndroid/wiki/_pages SprinklesAndroid Sqlite orm 的 db 工具类，比较显著的特点就是配合 https://github.com/square/retrofit 能保存从服务器获取的数据项目地址：https://github.com/emilsjolander/sprinkles文档介绍：http://emilsjolander.github.io/blog/2013/12/18/android-with-sprinkles/ Realm移动端的数据库，适用于 Phone、Tablet、Wearable，支持 ORM，线程安全、支持连表及数据库加密，比 SQLite 性能更好项目地址：https://github.com/realm/realm-java文档介绍：http://realm.io/docs/java/0.72.0/ ormlite-android项目地址：https://github.com/j256/ormlite-android文档介绍：http://ormlite.com/sqlite_java_android_orm.shtml Schematic根据 SQLite 生成 ContentProvider项目地址：https://github.com/SimonVT/schematic DBFlowAndroid SQLite ORM 工具库。综合了 Active Android, Schematic, Ollie,Sprinkles 等库的优点；通过注解实现，性能好；能生成 ContentProvider。项目地址：https://github.com/Raizlabs/DBFlow文档介绍：https://github.com/Raizlabs/DBFlow#usage-docs SnappyDBSnappyDB是一个key-value数据库，非常流行的NoSQL数据库。项目地址：https://github.com/nhachicha/SnappyDB演示Demo：https://play.google.com/store/apps/details?id=com.snappydb.snippets.app性能对比图： 五、Android 公共库 GuavaGoogle 的基于 java1.6 的类库集合的扩展项目，包括 collections, caching, primitives support, concurrency libraries, common annotations, string processing, I/O 等等. 这些高质量的 API 可以使你的 JAVa 代码更加优雅，更加简洁项目地址：https://code.google.com/p/guava-libraries/文档介绍：https://code.google.com/p/guava-libraries/wiki/GuavaExplained AndroidCommonAndroid 公共库项目地址：https://github.com/Trinea/AndroidCommonDemo 地址：https://play.google.com/store/apps/details?id=cn.trinea.android.demo文档介绍：http://www.trinea.cn/android/android-common-lib/包括：a. ImageCache 图片缓存，包含内存和 Sdcard 缓存http://www.trinea.cn/android/android-imagecache/特点：(1)支持预取新图片，支持等待队列(2)包含二级缓存，可自定义文件名保存规则(3)可选择多种缓存算法(FIFO、LIFO、LRU、MRU、LFU、MFU 等 13 种)或自定义缓存算法(4)可方便的保存及初始化恢复数据(5)支持不同类型网络处理(6)可根据系统配置初始化缓存等 HttpCache Http 缓存文档介绍：http://www.trinea.cn/android/android-http-cache特点是：(1) 根据 cache-control、expires 缓存 http 请求(2) 支持同步、异步 Http 请求(3) 在匿名回调中处理请求结果(4) 在 UI 线程外进行 http 请求(5) 默认 gzip 压缩(2) 公共 View(下拉及底部加载更多 ListView、底部加载更多 ScrollView、滑动一页 Gallery)(3) Android 常用工具类(网络、下载、Android 资源操作、shell、文件、Json、随机数、Collection 等等) DropDownListView 下拉刷新及滑动到底部加载更多 ListView文档介绍：http://www.trinea.cn/android/dropdown-to-refresh-and-bottom-load-more-listview/ shipfaster整合了 Dagger Otto Retrofit Robolectric Picasso OkHttp，方便快速开发项目地址：https://github.com/pyricau/shipfaster CleanAndroidCode整合了 Dagger Otto AndroidAnnotations，方便快速开发项目地址：https://github.com/pyricau/CleanAndroidCode xUtils基于 Afinal，包含 DbUtils、ViewUtils、HttpUtils、BitmapUtils 四大模块，可用于快速开发项目地址：https://github.com/wyouflf/xUtils原理剖析文档：xUtils AfinalAfinal 是一个 android 的 ioc，orm 框架，内置了四大模块功能：FinalAcitivity,FinalBitmap,FinalDb,FinalHttp。通过 finalActivity，我们可以通过注解的方式进行绑定 ui 和事件。通过 finalBitmap，我们可以方便的加载 bitmap 图片，而无需考虑 oom 等问题。通过 finalDB 模块，我们一行代码就可以对 android 的 sqlite 数据库进行增删改查。通过 FinalHttp 模块，我们可以以 ajax 形式请求 http 数据项目地址：https://github.com/yangfuhai/afinal官网网址：http://www.afinal.org UltimateAndroidUltimateAndroid 是一个快速开发 Android 应用的框架，框架目前主要包含的功能有 View Injection,ORM,异步网络请求和图片加载，自动化脚本测试,磁盘 LRU 等功能.同时提供了类似于 TripleDes、Webview 快速设置、Md5 处理、String 处理,Https 处理等常用工具类，还有超过 100 多种 UI 控件效果。项目地址：https://github.com/cymcsg/UltimateAndroid官网网址：http://blog.marshalchen.com/UltimateAndroid/ SAFSAF(Simple Android Framework)是一个简单的 android 框架，它为开发 Android app 提供了基础性组件。项目地址：https://github.com/fengzhizi715/SAF官网网址：http://www.salesuite.cn/包括：(1)Event Bus(事件总线)(2) Rest Client(http 的框架)(3) Image Cache(图片缓存)(4) Dependency Injection(依赖注入)(5) Sqlite ORM(sqlite 的 orm)(6) Router(Activity、Fragment 的 Router)(7) Utils(各种常用的工具类) BarberCustom View 神器。通过简单的注解帮助你大大减少 Custom View 中的代码量。由于和 ButterKnife 一样使用了 Annotation Proccessor ，所以对程序性能没有影响。项目地址：https://github.com/hzsweers/barber device-year-classA library that analyzes an Android device’s specifications and calculates which year the device would be considered “high end”.(facebook 开发的检测手机主流配置工具)项目地址：https://github.com/facebook/device-year-class RxAndroid对RxJava在Android上的扩展，使得Android上也很容易实现reactive components，简化线程操作，从而写出很漂亮的代码。项目地址：https://github.com/ReactiveX/RxAndroid文档介绍：给Android 开发者的 RxJava 详解 MultiImageSelector一个本地图片选择器，支持图片的单选和多选，直接返回所选图片的路径。项目地址：https://github.com/lovetuzitong/MultiImageSelector.git 六、Android 高版本向低版本兼容 Nine Old Androids将 Android 3.0(Honeycomb)所有动画 API(ObjectAnimator ValueAnimator 等)兼容到 Android1.0项目地址：https://github.com/JakeWharton/NineOldAndroids原理剖析文档：Nine Old AndroidsDemo 地址：https://play.google.com/store/apps/details?id=com.jakewharton.nineoldandroids.sample文档介绍：http://nineoldandroids.com/ HoloEverywhere将 Android 3.0 的 Holo 主题兼容到 Android2.1++项目地址：https://github.com/Prototik/HoloEverywhereDemo 地址：https://raw.github.com/Prototik/HoloEverywhere/repo/org/holoeverywhere/demo/2.1.0/demo-2.1.0.apk文档介绍：http://android-developers.blogspot.com/2012/01/holo-everywhere.html SherlockNavigationDrawer将 Android NavigationDrawer 和 ActionbarSherlock 结合，解决 4.0 以下 NavigationDrawer 的适配问题项目地址：https://github.com/tobykurien/SherlockNavigationDrawer文档介绍：http://developer.android.com/training/implementing-navigation/nav-drawer.html Notifications4EveryWhere将 Android 4.1 的 Notification 兼容到 Android2.2++项目地址：https://github.com/youxiachai/Notifications4EveryWhere Android Switch Widget Backport将 Android Switch 和 SwitchPreference 的兼容到 Android2.1++项目地址：https://github.com/BoD/android-switch-backportDemo 地址：https://play.google.com/store/apps/details?id=org.jraf.android.backport.switchwidget.sample文档介绍：https://github.com/BoD/android-switch-backport#using-the-switch android-datepicker将 Android 4.0 的 datepicker 兼容到 Android2.2++项目地址：https://github.com/SimonVT/android-datepicker Transitions EverywhereAndroid 4.4 的 Transitions API 兼容到 Android 2.2 以上项目地址：https://github.com/andkulikov/transitions-everywhere KShareViewActivityManager一个兼容Android 5.0 以下Shared Element Transition （页面间共享元素位移动画）库项目地址：https://github.com/kot32go/KShareViewActivityManager效果图：http://i8.tietuku.com/aa5726b8302ae711.gif 七、多媒体相关 cocos2d-x跨平台的 2d 游戏框架，支持 Android、IOS、Linux、Windows 等众多平台项目地址：https://github.com/cocos2d/cocos2d-x文档介绍：http://www.cocos2d-x.org/wiki官网网址：http://www.cocos2d-x.org/ JustWeEngineAndroid的轻量级游戏框架，能大大缩减编写原生游戏的代码量和难度，仍在持续更新中。项目地址: https://github.com/lfkdsk/JustWeEngineDemo地址: https://github.com/lfkdsk/EngineDemo Vitamio是一款 Android 与 iOS 平台上的全能多媒体开发框架项目地址：https://github.com/yixia/VitamioBundle网站介绍：http://www.vitamio.org/docs/特点：(1) 全面支持硬件解码与 GPU 渲染(2) 能够流畅播放 720P 甚至 1080P 高清 MKV，FLV，MP4，MOV，TS，RMVB 等常见格式的视频(3) 在 Android 与 iOS 上跨平台支持 MMS, RTSP, RTMP, HLS(m3u8)等常见的多种视频流媒体协议，包括点播与直播。 VDPlayerSDK最容易集成的开源播放器组件，支持直播，支持软硬解切换，支持清晰度切换项目地址：https://github.com/SinaVDDeveloper/Demo 地址：https://github.com/SinaVDDeveloper/demo文档介绍：https://github.com/SinaVDDeveloper/sinavideo_playersdk特点：(1) 使用自定义控件方式提供播放器UI，不需要视频相关知识，能编写android应用就能使用(2) 软硬解切换、点播直播支持(3) 解码内核小于4M，更方便集成到非专业视频app中(4) 修正一些vitaimio的问题，比如m3u8可以拖动等等 VideoPlayerManager帮助实现VideoPlayer控制，使得它更容易使用ListView和recyclerview。它还可以跟踪滚动列表中可见的项。当列表中的新项可见域最大时，该库给出了接口来跟踪它。项目地址：https://github.com/danylovolokh/VideoPlayerManager文档介绍：https://medium.com/@v.danylo/implementing-video-playback-in-a-scrolled-list-listview-recyclerview-d04bc2148429#.hs5n0geqn UniversalVideoViewAndroid上定义播放器控件,支持自定义控制UI, 全屏播放, 重力感应自动切换横竖屏.项目地址：https://github.com/linsea/UniversalVideoView PhotoProcessing利用 ndk 处理图片库，支持 Instafix、Ansel、Testino、XPro、Retro、BW、Sepia、Cyano、Georgia、Sahara、HDR、Rotate(旋转)、Flip(翻转)等各种特效项目地址：https://github.com/lightbox/PhotoProcessingDemo 地址：https://github.com/Trinea/TrineaDownload/blob/master/photo-processing.apk?raw=true Android StackBlur图片模糊效果工具类项目地址：https://github.com/kikoso/android-stackblurDemo 地址：https://github.com/kikoso/android-stackblur/blob/master/StackBlurDemo/bin/StackBlurDemo.apk?raw=true文档介绍：https://github.com/kikoso/android-stackblur#usage Bitmap Smart Clipping using OpenCV图片智能裁剪保留重要部分显示项目地址：https://github.com/beartung/tclip-android利用淘宝的 http://code.taobao.org/p/tclip/ 库完成一淘玩客正在使用的图片裁剪，自动识别图片中的重要区域，并且在图片裁剪时保留重要区域特点：(1). 能进行人脸识别。图片中有人脸，将自动视为人脸区域为重要区域，将不会被裁剪掉(2).自动其它重要区域。如果图片中未识别出人脸，则会根据特征分布计算出重区域 Cropper图片局部剪切工具，可触摸控制选择区域或旋转项目地址：https://github.com/edmodo/cropper文档介绍：https://github.com/edmodo/cropper/wiki效果图： uCropYalantis 出品的强大的图片裁剪库 ，支持缩放，旋转图片，支持各种比例的裁剪框项目地址：https://github.com/Yalantis/uCrop效果图： android-crop图片裁剪 Activity项目地址：https://github.com/jdamcd/android-crop效果图： TileView可分块显示大图，支持 2D 拖动、双击、双指放大、双指捏合项目地址：https://github.com/moagrius/TileViewDemo 地址：http://moagrius.github.io/TileView/TileViewDemo.apk BlurEffectForAndroidDesign图片模糊效果项目地址：https://github.com/PomepuyN/BlurEffectForAndroidDesign android-eyePC 端网页查看同一局域网内的手机摄像头内容，可以用来监控哦项目地址：https://github.com/Teaonly/android-eyeDemo 地址：https://play.google.com/store/apps/details?id=teaonly.droideye libpng for AndroidPNG 图片的 jni 库，支持几乎 png 的所有特性项目地址：https://github.com/julienr/libpng-android文档介绍：http://www.libpng.org/pub/png/libpng.html android-gpuimage基于 GPU 的图片滤镜项目地址：https://github.com/CyberAgent/android-gpuimage AndroidFaceCropper图片脸部自动识别，将识别后的局部图片返回项目地址：https://github.com/lafosca/AndroidFaceCropper Android Video Crop利用 TextureView 播放和剪切视频，类似 ImageView.setScaleType项目地址：https://github.com/dmytrodanylyk/android-video-cropDemo 地址：https://github.com/lafosca/AndroidFaceCropper/releases/download/1.0/FaceCropper-sample-debug-unaligned.apk svg-androidAndroid Svg 矢量图形支持项目地址：https://github.com/japgolly/svg-android https://github.com/japgolly/svg-android Android Visualizer从 Android MediaPlayer 获得音频，然后像 iTunes 及 WinAmp 一样展示音轨项目地址：https://github.com/felixpalmer/android-visualizer ExoPlayer包括仪表板和 SmoothStreaming 自适应回放，缓存持久化和自定义渲染器，方便自定义和扩展，并且可以通过应用商店更新项目地址：https://github.com/google/ExoPlayer DanmakuFlameMasterandroid 上开源弹幕解析绘制引擎项目项目地址：https://github.com/ctiao/DanmakuFlameMaster OpenDanmakuandroid 上一个轻量级的更简单的开源弹幕控件项目地址：https://github.com/linsea/OpenDanmaku K-Sonic一个基于Sonic的变音Demo,可调节Speed,Pitch,Rate.项目地址：https://github.com/jcodeing/K-SonicDemo 地址：Download here KMedia一个为Android打造的应用级媒体框架, 它可以助你快速搭建媒体应用.内部重新定义Android MediaPlayer API并对其封装, 简化和扩展一些原生API不支持的功能.其中涵盖了, AB播放/循环 位置单元/间隔/循环 变速播放 媒体队列管理 媒体服务/绑定 音频后台/通知栏控制媒体按键自定义处理 音频焦点管理 媒体引擎切换/扩展… 等功能的快速实现.以及, 对视频播放实现方面的封装. 其中将视频视图主要分为: 绘制层 控制组 控制层, 三个部分.从而能够快速并灵活的实现Video相关应用的大部分功能, 包括 视频浮窗/拖动/调整位置大小 横竖屏自动切换 全屏锁定手势调整亮度/音量/进度 字幕/切换/拖动 视频段落/间隔复读 视频续集/列表/循环播放 动态切换视频控制层控制层分离… 等功能的快速实现.项目地址：https://github.com/jcodeing/KMedia →项目模块：KMedia-Core &amp; KMedia-Uie &amp; KMedia-Exo 八、事件总线(订阅者模式)通过发布/订阅事件解耦事件发送和接受，从而简化应用程序组件(Activities, Fragments 及后台线程)之间的通信 EventBusgreenrobot 的开源项目项目地址：https://github.com/greenrobot/EventBus原理剖析文档：EventBus文档介绍：https://github.com/greenrobot/EventBus#general-usage-and-api特点：(1) 支持在不同类型的线程中处理订阅，包括发布所在线程，UI 线程、单一后台线程、异步线程(2) 支持事件优先级定义，支持优先级高的订阅者取消事件继续传递，支持粘性事件，是不是跟系统的有序广播、粘性广播很像啊(3) 不是基于 annotations(4) 性能更优(5) 体积小(6) 支持单例创建或创建多个对象(7) 支持根据事件类型订阅 OttoSquare 的开源项目，基于 Guava 的 Android 优化项目地址：https://github.com/square/otto文档介绍：http://square.github.io/otto/EventBus 与 Otto 的功能及性能对比文档EventBus 与 Otto 性能对比 Demo Apk 九、传感器 Great Android Sensing ToolkitAndroid 感应器工具包，包含示例及使用过程中可能需要的算法项目地址：https://github.com/gast-lib/gast-libDemo 地址：https://play.google.com/store/apps/details?id=root.gast.playground文档介绍：https://github.com/gast-lib/gast-lib#documentation SensorManagerAndroid 传感器管理项目地址：https://github.com/nlathia/SensorManager文档介绍：https://docs.google.com/document/d/1TqThJULb-4e6TGb1gdkAaPCfyuXStjJpbnt7a0OZ9OE/edit GPSLogger记录 GPS 信息项目地址：https://github.com/mendhak/gpsloggerDemo 地址：https://play.google.com/store/apps/details?id=com.mendhak.gpslogger文档介绍：http://code.mendhak.com/gpslogger/ Pedometer计步器，使用硬件计步感应器项目地址：https://github.com/j4velin/Pedometer leapcastChromeCast 模拟器的 App项目地址：https://github.com/dz0ny/leapcast Arduino-Communicator与 Arduino 通信的 App项目地址：https://github.com/jeppsson/Arduino-Communicator android-pedometerAndroid 计步器项目地址：https://github.com/bagilevi/android-pedometerDemo 地址：http://pedometer.googlecode.com/files/Pedometer-1.4.apk OwnTracks for Android自己的轨迹记录项目地址：https://github.com/owntracks/android Shake Detector library for AndroidAndroid 手机震动摇晃检测库，提供供 UI 线程调用的回调接口项目地址：https://github.com/tbouron/ShakeDetectorDemo 地址：https://play.google.com/store/apps/details?id=com.github.tbouron.shakedetector.example Android heart rate monitorAndroid 心跳检测项目地址：https://github.com/phishman3579/android-heart-rate-monitor Bluetooth LE Library for Android蓝牙源信息，包括宝库 Mac、更新时间、RSSI、UUID、信号源距离、影响范围等信息项目地址：https://github.com/alt236/Bluetooth-LE-Library---AndroidDemo 地址：https://play.google.com/store/apps/details?id=uk.co.alt236.btlescan farebot通过 NFC 从公交卡中读取数据的一个应用项目地址：https://github.com/codebutler/farebot 十、安全 SQLCipherSqlite 加密工具项目地址：https://github.com/sqlcipher/sqlcipher文档介绍：http://sqlcipher.net/sqlcipher-for-android/ Conceal快速高效的进行文件加密解密项目地址：https://github.com/facebook/conceal文档介绍：https://github.com/facebook/conceal#usage Android-PasscodeLock应用锁，每次启动或从任何 Activity 启动应用都需要输入四位数字的密码方可进入项目地址：https://github.com/wordpress-mobile/Android-PasscodeLockDemo 地址：https://play.google.com/store/apps/details?id=org.wordpress.androidAPP 示例：Wordpress Android，支付宝，挖财 GlowPadBackport将 Android4.2 的锁屏界面解锁扩展到 Android1.6 及 1.6+项目地址：https://github.com/rock3r/GlowPadBackportDemo 地址：https://play.google.com/store/apps/details?id=net.sebastianopoggi.samples.ui.GlowPadSample效果图： GlowPadViewAndroid 4 锁屏界面解锁项目地址：https://github.com/nadavfima/GlowPadView效果图： Android-InsecureBank关于 Android 不安全性的示例项目地址：https://github.com/dineshshetty/Android-InsecureBankv2 十一、插件化更多见：Android 插件化作用、概念以及不错的资料(包括开源项目)和解决方案 dynamic-load-apkAndroid 动态加载 Apk，热部署，利用 ClassLoader 以及 Activity 代理的方式解决项目地址：https://github.com/singwhatiwanna/dynamic-load-apk原理剖析文档：dynamic-load-apk文档介绍：http://blog.csdn.net/singwhatiwanna/article/details/22597587 Android Dynamic Loader点评的实现方式，和上面不同的是：他不是用代理 Activity 的方式实现而是用 Fragment 以及 Schema 的方式实现项目地址：https://github.com/mmin18/AndroidDynamicLoaderDemo 地址：https://github.com/mmin18/AndroidDynamicLoader/raw/master/host.apk xCombineAndroid App 插件式插件开发，插件必须先安装，更推荐看上面两个开源项目项目地址：https://github.com/wyouflf/xCombine文档介绍：http://my.oschina.net/u/1171837/blog/155377 Android Plugin FrameworkAndroid 插件式开发，开放的源码目前不完整项目地址：https://github.com/umeng/apf Android OpenAtlasAndroid插件框架，基于OSGI，非代理方式，组件需要在宿主中声明项目地址：https://github.com/bunnyblue/OpenAtlasDemo 地址：https://github.com/bunnyblue/OpenAtlasExtension/blob/master/Dist/OpenAtlasLauncher.apk multidex安装多 dex 的 classloader项目地址：https://github.com/casidiablo/multidex ANR-WatchDogAndroid ANR 监听，通过监听自己的 UI Thread 是否被执行确定是否发生了 ANR，并可以设置相关事件项目地址：https://github.com/SalomonBrys/ANR-WatchDog 十二、文件对不同文档类型的处理，包括 PDF、Word、EPub、Html、Zip 等 purePDF允许从任何运行的 SWF 文件读取和创建 PDF 文档项目地址：https://github.com/sephiroth74/purePDF android-pdfview快速解析 pdf 的 view，默认支持手势缩放和相关动画项目地址：https://github.com/JoanZapata/android-pdfview Office 365 SDK for Android Preview可支持 Microsoft SharePoint Lists, Microsoft SharePoint Files, Microsoft Exchange Calendar, Microsoft Exchange Contacts, Microsoft Exchange Mail项目地址：https://github.com/OfficeDev/Office-365-SDK-for-Android OpenSpritz-AndroidEPub 阅读器项目地址：https://github.com/OnlyInAmerica/OpenSpritz-Android jsoup一个解析 html 的 java 库，可方便的提取和操作数据项目地址：https://github.com/jhy/jsoup官网网址：http://jsoup.org/作用：(1) 从一个 url、文件或 string 获得 html 并解析(2) 利用 dom 遍历或 css 选择器查找、提取数据(3) 操作 html 元素(4) 根据白名单去除用于提交的非法数据防止 xss 攻击(5) 输出整齐的 html ZIPjava 压缩和解压库项目地址：https://github.com/zeroturnaround/zt-zip文档介绍：https://github.com/zeroturnaround/zt-zip#examples作用：(1) 解压和压缩，并支持文件夹内递归操作(2) 支持包含和排除某些元素(3) 支持重命名元素(4) 支持遍历 zip 包内容(5) 比较两个 zip 包等功能 Image File Selector轻量级的图片文件选择器，用系统api选取，压缩和裁切图片，可以方便的得要指定尺寸的图片项目地址：https://github.com/sw926/ImageFileSelector 十三、其他 FragmentStack一个封装了启动模式的Fragment便捷使用库,方便构建单Activity+多Fragment轻量级框架项目地址：https://github.com/Mr-wangyong/FragmentStack效果图：https://github.com/Mr-wangyong/FragmentStack/blob/master/play.gifApp示例：南瓜电影 CustomTabsHelper快速集成 CustomTabs 的工具类项目地址：https://github.com/DreaminginCodeZH/CustomTabsHelper EffortlessPermissions基于 Google EasyPermissions 进行扩展的动态权限库项目地址：https://github.com/DreaminginCodeZH/EffortlessPermissions Salvage view带 View 缓存的 Viewpager PagerAdapter，很方便使用项目地址：https://github.com/JakeWharton/salvage Android Priority Job QueueAndroid 后台任务队列项目地址：https://github.com/path/android-priority-jobqueue文档介绍：https://github.com/path/android-priority-jobqueue#getting-started Cobub Razor开源的 mobile 行为分析系统，包括 web 端、android 端，支持 ios 和 window phone项目地址：https://github.com/cobub/razorDemo 地址：http://demo.cobub.com/razor官网网址：http://dev.cobub.com/ CountlyAndroid 移动端数据采集分析系统项目地址：https://github.com/Countly/countly-sdk-android官网网址：https://count.ly/ aFileChooser文件选择器，可内嵌到程序中，而无需使用系统或三方文件选择器。项目地址：https://github.com/iPaulPro/aFileChooser androidpn基于 xmpp 协议的消息推送解决方案，包括服务器端和 android 端。项目地址：https://github.com/dannytiehui/androidpn BoltsAndroid 的异步编程模式项目地址：https://github.com/BoltsFramework/Bolts-Android/与 AsyncTask 比较：(1) 使用的是无大小限制的线程池(2) 任务可组合可级联，防止了代码耦合 CastCompanionLibrary-android使 Android 程序中更快的接入 Google Cast项目地址：https://github.com/googlecast/CastCompanionLibrary-android文档介绍：https://developers.google.com/cast/ CastVideos-android从 Android 设备分享 Video 通过 Google Cast项目地址：https://github.com/googlecast/CastVideos-android文档介绍：https://developers.google.com/cast/ Uninstall_StaticsAndroid 应用自身被卸载监听及打开浏览器等反馈功能实现项目地址：https://github.com/sevenler/Uninstall_Statics文档介绍：http://www.cnblogs.com/zealotrouge/p/3157126.html http://www.cnblogs.com/zealotrouge/p/3159772.html Memento保证在系统配置改变时，Activity 中的某些数据可以简单安全的保持不变项目地址：https://github.com/mttkay/memento文档介绍：https://github.com/mttkay/memento#usage FreeFlow布局引擎，更简单的创建自定义布局，并且当数据和布局改变时更美观的过渡动画项目地址：https://github.com/Comcast/FreeFlowDemo 地址：https://github.com/Comcast/FreeFlow/releases Android Gesture Detectors FrameworkAndroid 手势框架，支持双指旋转、移动、平移、缩放等项目地址：https://github.com/Almeros/android-gesture-detectors Mapbox Android SDKAndroid Map 的替代版项目地址：https://github.com/mapbox/mapbox-android-sdk Activity animationActivity 跳转动画，支持各个方向波浪的效果项目地址：https://github.com/flavienlaurent/activityanimation在线演示：https://www.youtube.com/watch?v=-E0sc6w_Jck KryoNet通过 NIO 提供客户端和服务器端 TCP/UDP 网络传输的 Java 库项目地址：https://github.com/EsotericSoftware/kryonet Rebound一个模仿弹簧反弹的 Java 库，可用于创建动画项目地址：https://github.com/facebook/rebound Android Social Networks社交网络接入统一管理器，可方便的从 Twitter, LinkedIn, Facebook, Google Plus 登陆、获得个人信息、发送消息、发送专篇、添加或删除好友项目地址：https://github.com/antonkrasov/AndroidSocialNetworksDemo 地址：https://play.google.com/store/apps/details?id=com.github.androidsocialnetworks.apidemos SmartAppUpdatesAndroid App 增量升级，包含前后端方案、Demo、以及 so 库，可用于商店或大体积 App 差分升级项目地址：https://github.com/cundong/SmartAppUpdates Magnet创建类似 Facebook 聊天桌面悬浮窗的效果项目地址：https://github.com/premnirmal/Magnet AcDisplay将 Android 的通知都集中到锁屏显示项目地址：https://github.com/AChep/AcDisplayDemo 地址：https://play.google.com/store/apps/details?id=com.achep.acdisplay QrCodeScanZXing 和 ZBar 结合的二维码扫描项目，提高了扫描效率项目地址：https://github.com/SkillCollege/QrCodeScan效果图： Android-ScreenShot实现 android 系统截屏功能项目地址：https://github.com/Android-ScreenShot/AndroidScreenShotService文档介绍：http://blog.csdn.net/buptgshengod/article/details/39155979 card.io SDK for Android信用卡扫描 Android SDK项目地址：https://github.com/card-io/card.io-Android-SDKDemo 项目：https://github.com/card-io/card.io-Android-SDK/tree/master/SampleApp ASNETwitter, Facebook, Google Plus, LinkedIn, Instagram, Vkontakte, Odnoklassniki 的集成库，包括他们的大多数功能项目地址：https://github.com/gorbin/ASNEDemo 地址：https://play.google.com/store/apps/details?id=com.gorbin.androidsocialnetworksextended.asne Android Signature PadAndroid 自定义的签名 View，可自定义笔颜色和大小项目地址：https://github.com/gcacace/android-signaturepadDemo 项目：https://github.com/gcacace/android-signaturepad/tree/master/SignaturePad-Example TeleportAndroid Wear 数据同步和消息传送库项目地址：https://github.com/Mariuxtheone/Teleport DebugLog可以帮你创建更简单和更容易理解的调试日志，能够友好的显示调试信息所在类和函数。项目地址：https://github.com/MustafaFerhan/DebugLog效果图： Logger简单、美观而且十分强大的 Android 日志工具项目地址：https://github.com/orhanobut/loggerDemo 地址：https://github.com/orhanobut/logger/tree/master/app效果图： jlog可以灵活配置的日志工具，支持JSON打印，日志保存到指定文件，日志显示调用位置（混淆模式下依然有效）项目地址：https://github.com/JiongBull/jlogDemo 地址：apk地址效果图： Phrasesquare 组开源大牛写的字符串替换类项目地址：https://github.com/square/phrase ColorPhrase模仿 phrase 写的对字符串个别字符颜色改变的类，高效强大！项目地址：https://github.com/THEONE10211024/ColorPhrase效果图： PinyinSearch一个为 T9 搜索和 Qwerty 搜索,提供数据解析与匹配等方法的拼音搜索 java 库。项目地址： https://github.com/handsomezhou/PinyinSearchLibraryDemo 地址： ContactsSearch AppSearch效果图：APP 示例： 通讯录应用，微信电话本 PrainViewPaintView 是一个画图工具:可直接使用设定按钮来实现已拥有的方法，且拓展性强基础功能：更换颜色、更换橡皮、以及更换橡皮和笔的粗细、清屏、倒入图片特殊功能：保存画笔轨迹帧动画、帧动画导入导出、ReDo和UnDo项目地址：Paintview效果图： ![p2](https://github.com/lfkdsk/JustWeTools/blob/master/picture/io.gif) demo地址：apk地址原理解析：PaintView 绘图控件解析 CodeViewCodeView代码查看／修改工具: 基于WebView制作的代码编辑器,实现代码高亮，暗色主题项目地址：CodeView效果图： ![p4](https://github.com/lfkdsk/JustWeTools/blob/master/picture/edit.png) demo地址：apk地址 ExplorerView文件浏览器：继承自ListView，可拓展性强，可进行文件类型分析项目地址：CodeView效果图：demo地址：apk地址 ReadView小说阅读器，支持文字字体、颜色、背景、进度等多种调整，支持一键设置。项目地址：ReadView效果图：demo地址：apk地址 MarkDownView支持MarkDown语法的渲染器,基于WebView的MarkDown渲染器,支持标准化的MarkDown语法,调用接口和CodeView保持一致使用简便项目地址：ReadView效果图：demo地址：apk地址 VerTextView竖行排版的TextView:支持竖行排版，添加了下划线功能，开启简便，下划线粗细、颜色、间距均可自定义，接口调用方式与TextView相似，使用简便。项目地址：ReadView效果图：demo地址：apk地址 GHDownload下载框架支持单线程和多线程断点下载，简单易用。项目地址：GHDownload 第三部分 优秀项目主要介绍那些 Android 还不错的完整项目，目前包含的项目主要依据是项目有意思或项目分层规范比较好。 一、系统及平台 Linux项目地址：https://github.com/torvalds/linux Android项目地址：https://android.googlesource.com/ 二、项目 ZXing二维码扫描工具项目地址：https://github.com/zxing/zxing 或 https://code.google.com/p/zxing/APK 地址：https://play.google.com/store/apps/details?id=com.google.zxing.client.android其他：现在市面上很多应用的二维码扫描功能都是从这个修改而来 photup编辑机批量上传照片到 facebook 上项目地址：https://github.com/chrisbanes/photupAPK 地址：https://play.google.com/store/apps/details?id=uk.co.senab.photup其他：代码分包合理，很棒。不过这个项目依赖的开源项目比较多，比较难编译 github-androidGithub 的 Android 客户端项目项目地址：https://github.com/github/androidAPK 地址：https://play.google.com/store/apps/details?id=com.github.mobile NotesMIUI 便签项目地址：https://github.com/MiCode/NotesAPK 地址：https://github.com/Trinea/TrineaDownload/blob/master/miui-note-demo.apk?raw=true其他：项目分包比较合理，相比较 miui 的文件管理器 https://github.com/MiCode/FileExplorer 代码规范较好得多 weicuiyuan四次元-新浪微博客户端项目地址：https://github.com/qii/weiciyuanAPK 地址：https://play.google.com/store/apps/details?id=org.qii.weiciyuan Douya豆芽——Material Design 的豆瓣客户端项目地址：https://github.com/DreaminginCodeZH/Douya效果图： gnucash-android一个记账理财软件项目地址：https://github.com/codinguser/gnucash-androidAPK 地址：http://play.google.com/store/apps/details?id=org.gnucash.android AntennaPod支持 rss 订阅、音乐订阅项目地址：https://github.com/danieloeh/AntennaPodAPK 地址：https://play.google.com/store/apps/details?id=de.danoeh.antennapod ChaseWhisplyProject打鬼游戏项目地址：https://github.com/tvbarthel/ChaseWhisplyProjectAPK 地址：https://play.google.com/store/apps/details?id=fr.tvbarthel.games.chasewhisply Tweet Lanes功能完整的 Twitter 客户端项目地址：https://github.com/chrislacy/TweetLanesAPK 地址：https://play.google.com/store/apps/details?id=com.tweetlanes.android Financius简单易用的记账程序项目地址：https://github.com/mvarnagiris/FinanciusAPK 地址：https://play.google.com/store/apps/details?id=com.code44.finance todo.txt-androidtodo.txt 的官方 Android 应用项目地址：https://github.com/ginatrapani/todo.txt-androidAPK 地址：https://play.google.com/store/apps/details?id=com.todotxt.todotxttouch simpletask基于 todo.txt 官方应用的另一个客户端项目地址：https://github.com/mpcjanssen/simpletask-androidAPK 地址：https://play.google.com/store/apps/details?id=nl.mpcjanssen.todotxtholo Muzei Live Wallpaper定时更换桌面精美壁纸项目地址：https://github.com/romannurik/muzeiAPK 地址：https://play.google.com/store/apps/details?id=net.nurik.roman.muzei Scanbook扫描搜索查询图书信息项目地址：https://github.com/JayFang1993/ScanBookAPK 地址：http://www.wandoujia.com/apps/com.scanbook ioschedThe Google I/O 2014 Android App项目地址：https://github.com/google/ioschedAPK 地址：https://play.google.com/store/apps/details?id=com.google.samples.apps.iosched CoolClockAn Android clock项目地址：https://github.com/socoolby/CoolClockAPK 地址：https://github.com/socoolby/CoolClock/blob/master/CoolClock.apk效果图： 第四部分 开发工具及测试工具主要介绍和 Android 开发工具和测试工具相关的开源项目。 一、开发效率工具 Parceler通过注解及工具类自动完成实体类 Parcelable 及值传递项目地址：https://github.com/johncarl81/parceler Json2Java根据 JSon 数据自动生成对应的 Java 实体类，还支持 Parcel、Gson Annotations 对应代码自动生成。期待后续的提取父类以及多 url 构建整个工程的功能项目地址：https://github.com/jonfhancock/JsonToJava在线演示：http://jsontojava.appspot.com/ IntelliJ Plugin for Android Parcelable boilerplate code generationAndroid studio 插件，生成 Parcelable 代码项目地址：https://github.com/mcharmas/android-parcelable-intellij-plugin效果图： Android Holo Colors IntelliJ PluginAndroid studio 插件，生成 holo 样式 9 patch 图片项目地址：https://github.com/jeromevdl/android-holo-colors-idea-plugin效果图： Android Drawable Factory用于生成各个分辨率的图片项目地址：https://github.com/tizionario/AndroidDrawableFactory效果图： SelectorChapek for AndroidAndroid Studio 插件，可根据固定文件名格式资源自动生成 drawable selectors xml 文件。项目地址：https://github.com/inmite/android-selector-chapek Android Action Bar Style GeneratorAndroid ActionBar 样式生成器，可在线选择 ActionBar 样式自动生成所需要的图片资源及 xml 文件项目地址：https://github.com/jgilfelt/android-actionbarstylegenerator在线演示：http://jgilfelt.github.io/android-actionbarstylegenerator/ ButterKnifeZelezny用于快速生成ButterKnifeView 注入代码的 Android Studio/IDEA 插件项目地址：https://github.com/inmite/android-butterknife-zelezny RoboCoP利用 Gradle task 根据固定格式的 json 文件生成 ContentProvider项目地址：https://github.com/mediarain/RoboCoP appiconsizes用于生成各个分辨率的图片项目地址：http://www.appiconsizes.com/ AndroidUtiles集合了所有常用的安卓工具类项目地址：https://github.com/l123456789jy/Lazy Gradle Retrolambda PluginRetrolambda是将 Java8 的 Lambdas 应用于 Java7 的工具，本项目是 Gradle 插件，通过 Retrolambda 从而使 Java 或 Android 项目用 Java8 的 Lambdas 编写，将编译后的字节码转换为 Java6 和 7 的字节码从而正常运行项目地址：https://github.com/evant/gradle-retrolambda Dagger IntelliJ Plugindagger 的 intellij 插件项目地址：https://github.com/square/dagger-intellij-plugin Android Gen Drawable Maven plugin在编译时根据 SVG 描述文件生成不同分辨率的 jpg、png 或点 9 图片项目地址：https://github.com/avianey/androidgendrawable-maven-plugin Android Asset Studio各种 Android 资源自动生成器，包括启动图标、ActionBar 图标、通知栏图标、点 9 等项目地址：https://github.com/romannurik/AndroidAssetStudio在线演示：http://romannurik.github.io/AndroidAssetStudio/ jsonschema2pojo根据 Json 内容生成 java 对象，支持 jackjson 和 gson项目地址：https://github.com/joelittlejohn/jsonschema2pojo在线演示：http://www.jsonschema2pojo.org/ GsonFormat根据 JSONObject 格式的字符串,自动生成实体类参数的 Android Studio/IntelliJ IDEA 插件项目地址：https://github.com/zzz40500/GsonFormat效果图： Json2Class根据Json生成Java文件的Android Studio/IntelliJ IDEA 插件，并且可以选择Parcelable或者Serializable项目地址：https://github.com/anzewei/Json2Class效果图： 9-Patch-Resizer自动生成 png 及点 9 图片的不同分辨率版本项目地址：https://github.com/redwarp/9-Patch-Resizer AndroidLocalizationer可用于将项目中的 string 资源自动翻译为其他语言的 Android Studio/IntelliJ IDEA 插件项目地址：https://github.com/westlinkin/AndroidLocalizationer Material Palette一个将现有的色彩方案组合成材料设计的调色板方案，提供下载。选取两个主要色彩后便可以提供下载，提供下载的格式可以是 android 的资源 xml 文件，以色彩的方式提供，也可以是 CSS、SVG、PNG 等常见格式文件。项目地址：http://www.materialpalette.com/ 二、开发自测相关 Quality Tools for AndroidAndroid 测试及自测工具集合和示例项目地址：https://github.com/stephanenicolas/Quality-Tools-for-Android android-test-kitGoogle 的 Android 测试工具包括 GoogleInstrumentationTestRunner(增强版的 InstrumentationTestRunner)和 Espresso(用于快速写出可靠测试用例的 API)项目地址：https://code.google.com/p/android-test-kit/文档介绍：https://code.google.com/p/android-test-kit/w/list robolectric测试用例编写框架项目地址：https://github.com/robolectric/robolectricDemo 地址：https://github.com/robolectric/robolectricsample文档介绍：http://robolectric.org/特点：(1). 不需要模拟器在一般 JVM 就可以运行测试用例(2). 能完成在真机上的大部分测试包括感应器其他的测试用例及相关模块 Mock 可见：android-mock, mockito, easy-mock Android FEST提供一些列方便的断言，可用于提高编写 Android 自测代码效率项目地址：https://github.com/square/fest-android BoundBox可用于测试类各种访问权限的属性、方法。实际是通过 BoundBox 这个 annotation 生成一个属性和方法都是 public 权限的中间类并对此类进行测试完成的项目地址：https://github.com/stephanenicolas/boundbox Hugo用于打印函数信息及执行时间的工具，仅在 debug 模式生效项目地址：https://github.com/JakeWharton/hugo scalpel在应用下面添加一层用于界面调试项目地址：https://github.com/JakeWharton/scalpel Android Screenshot libraryAndroid 截图工具类，用于在持续集成时截图项目地址：https://github.com/rtyley/android-screenshot-lib sonar-android-lint-plugin将 android lint 的错误在 sonar 中展现项目地址：https://github.com/SonarCommunity/sonar-android 三、测试工具 Spoon可用于 android 不同机型设备自动化测试，能将应用 apk 和测试 apk 运行在不同机器上并生成相应测试报告。项目地址：https://github.com/square/spoon Tencent APTAPT 是腾讯开源的一个 Android 平台高效性能测试组件，提供丰富实用的功能，适用于开发自测、定位性能瓶颈；测试人员完成性能基准测试、竞品对比测试项目地址：https://github.com/stormzhang/APT Emmagee网易开源的性能测试工具，包括 CPU、内存、网络流量、启动时间、电池状态等项目地址：https://github.com/NetEase/Emmagee Android py-uiautomatorpy-uiautomator 是一个对 Android uiautomator 用 python 进行封装的测试框架.项目地址：https://github.com/xiaocong/uiautomator Augmented Traffic Control模拟网络状况，包括带宽、时延抖动、丢包率、错包率、包重排率项目地址：https://github.com/facebook/augmented-traffic-control stetho强大的 Android Debug 工具。支持网络请求监控以及数据库查看，可以和 Chrome DevTools 结合或者命令行模式。项目地址：https://github.com/facebook/stetho 四、开发及编译环境 Buckfacebook 开源的 Android 编译工具，效率是 ant 的两倍。主要优点在于：(1) 加快编译速度，通过并行利用多核 cpu 和跟踪不变资源减少增量编译时间实现(2) 可以在编译系统中生成编译规则而无须另外的系统生成编译规则文件(3) 编译同时可生成单元测试结果(4) 既可用于 IDE 编译也可用于持续集成编译(5) facebook 持续优化中项目地址：https://github.com/facebook/buck Android Maven PluginAndroid Maven 插件，可用于对 android 三方依赖进行管理。在 J2EE 开发中，maven 是非常成熟的依赖库管理工具，可统一管理依赖库。项目地址：https://github.com/jayway/maven-android-plugin umeng-muti-channel-build-tool渠道打包工具项目地址：https://github.com/umeng/umeng-muti-channel-build-tool另可参见 Google 的构建系统 Gradle：http://tools.android.com/tech-docs/new-build-system/user-guide Genymotion目前最好用最快的 android 模拟器项目地址：http://www.genymotion.com/Android studio 集成控件： http://plugins.jetbrains.com/plugin/7269?pr=ideaCyril Mottier 推荐：http://cyrilmottier.com/2013/06/27/a-productive-android-development-environment/ gradle-mvn-push方便的将 Gradle 的 Artifacts 上传到 Maven 仓库项目地址：https://github.com/chrisbanes/gradle-mvn-push文档介绍：https://github.com/chrisbanes/gradle-mvn-push#usage Android Emulator Plugin for JenkinsAndroid 模拟器 jenkins 插件，用于 Jenkins 做持续集成时跑模拟器测试项目地址：https://github.com/jenkinsci/android-emulator-plugin Android Maven Plugin管理应用所需要的依赖库。包括的构建工具有 Maven、Gradle、ant、sbt项目地址：https://github.com/mosabua/maven-android-sdk-deployer SDK Manager Plugin下载和管理 Android SDK 的 Gradle 插件项目地址：https://github.com/JakeWharton/sdk-manager-plugin Gradle Protobuf Plugin将.proto 文件转换成 Java 文件的 gradle 插件项目地址：https://github.com/andrewkroh/gradle-protobuf-plugin ChromeADBChrome 的 Adb 插件，当登录后，能看到所有连接的设备并操作，可以看应用、进程、内存及磁盘使用情况等项目地址：https://github.com/importre/chromeadb 五、其他 GTAPP的随身调试平台，它是直接运行在手机上的“集成调试环境”(IDTE, Integrated Debug Environment)。项目地址：https://github.com/TencentOpen/GT文档介绍：http://gt.qq.com/docs.html ViewServer允许 app 运行在任何手机上都可以用 HierarchyViewer 查看项目地址：https://github.com/romainguy/ViewServer GridWichterle for Android在整个系统上显示一个 grid，用来帮助查看应用布局及使得布局更美观，可设置 grid 网格大小和颜色，android 推荐 48dp 和 8dp，可见 Android Design Guidelines – Metrics and Grids，比起 hierarchyviewer 相差甚远，不过偶尔可用来作为布局查看工具。项目地址：https://github.com/inmite/android-grid-wichterleDemo 地址：https://play.google.com/store/apps/details?id=eu.inmite.android.gridwichterle Catlog手机端 log 查看工具，支持不同颜色显示、关键字过滤、级别过滤、进程 id 过滤、录制功能等项目地址：https://github.com/nolanlawson/Catlog在线演示：https://play.google.com/store/apps/details?id=com.nolanlawson.logcat PID Cat根据 package 查看 logcat 日志项目地址：https://github.com/JakeWharton/pidcat ACRA应用崩溃信息日志上报到 GoogleDoc 工具，网页版展现结果三方开源地址 https://github.com/BenoitDuffez/crashreportsviewer项目地址：https://github.com/ACRA/acra文档介绍：https://github.com/ACRA/acra/wiki/BasicSetup Crashlytics提供丰富的应用崩溃信息日志收集轻量级，丰富，可自定义应用崩溃信息收集器，附有邮件通知项目地址：http://www.crashlytics.com/集成插件：Android Studio, Eclipse and IntelliJ Android Resource Navigatorchrome 插件，可以方便的查看 github 上 android 源码工程的 styles.xml 和 themes.xml。主要功能：(1) 快速打开 android styles.xml themes.xml(2) 方便在资源间跳转。styles.xml themes.xml 文件中资源链接跳转，可以方便跳转到某个资源(3) 方便查找某个 style 和 theme。chrome 地址栏输入 arn+tab+搜索内容回车即可(4) 自动下载不同分辨率下的 drawable(5) 通过映射查找那些不是按照固定命名规则命名的 style 和 theme项目地址：https://github.com/jgilfelt/android-resource-navigator在线演示：https://chrome.google.com/webstore/detail/android-resource-navigato/agoomkionjjbejegcejiefodgbckeebo?hl=en&amp;gl=GB android-resource-remover根据 lint 的提示删除项目中无用的资源，减少包的大小项目地址：https://github.com/KeepSafe/android-resource-remover Telescope通过手势截图以特定主题发送到特定邮箱地址报告 Bug项目地址：https://github.com/mattprecious/telescope Complete Android Fragment &amp; Activity Lifecycle完整的 Android Fragment/Activity 生命周期图项目地址：https://github.com/xxv/android-lifecycle Bugsnag Notifier for Android通过Thread.UncaughtExceptionHandler捕获应用未处理的异常崩溃 Bug 并用 Notification 展示同时上传到后台服务器项目地址：https://github.com/bugsnag/bugsnag-android文档介绍：https://github.com/bugsnag/bugsnag-android#installation--setup Material Design IconsGoogle Material Design 规范中的 Icon项目地址：https://github.com/google/material-design-icons scrollscreenshotAndroid 滚动屏幕自动截图 jar 包，支持纵向、横向滚动截屏拼接项目地址：https://github.com/PGSSoft/scrollscreenshot效果图： droidicon1600+的海量 Icon，包括 750+的 Material Design icons项目地址：https://github.com/theDazzler/droidicon leakcanaryAndroid 内存泄露检测工具，集成方便，出现泄露后报告直观项目地址：https://github.com/square/leakcanary效果图： CacheUtilsLibrary将任何Java Object类型的数据序列化后写入缓存文件，将来使用时读取缓存文件并反序列化成对应Java Object的库项目地址：https://github.com/westlinkin/CacheUtilsLibrary BlockCanaryBlockCanary是一个Android平台的一个非侵入式的性能监控组件，应用只需要实现一个抽象类，提供一些该组件需要的上下文环境，就可以在平时使用应用的时候检测主线程上的各种卡慢问题，并通过组件提供的各种信息分析出原因并进行修复。项目地址: https://github.com/moduth/blockcanary 第五部分主要介绍那些乐于分享并且有一些很不错的开源项目的个人和组织。Follow 大神，深挖大神的项目和 following，你会发现很多。 一、个人 JakeWharton现就职于 Google，（曾就职于 Square），绝对牛逼的大神，项目主要集中在 Android 版本兼容，ViewPager 及开发工具上Github 地址：https://github.com/JakeWharton代表作：ActionBarSherlock，Android-ViewPagerIndicator，Nine Old Androids，SwipeToDismissNOA，hugo，butterknife，Android-DirectionalViewPager, scalpelpidcat 另外对 square 及其他开源项目有很多贡献主页：http://jakewharton.com/ Chris BanesGithub 地址：https://github.com/chrisbanes代表作：ActionBar-PullToRefresh，PhotoView，Android-BitmapCache，Android-PullToRefresh主页：http://chris.banes.me/ Koushik Dutta就职于 ClockworkModGithub 地址：https://github.com/koush代表作：Superuser，AndroidAsync，UrlImageViewHelper，ion, 另外对 https://github.com/CyanogenMod 的开源项目有很多贡献主页：http://koush.com/ Simon VigGithub 地址：https://github.com/SimonVT代表作：android-menudrawer，MessageBar主页：http://simonvt.net/ Manuel PeinadoGithub 地址：https://github.com/ManuelPeinado代表作：FadingActionBar，GlassActionBar，RefreshActionItem，QuickReturnHeader Emil Sj?landerGithub 地址：https://github.com/emilsjolander代表作：StickyListHeaders，sprinkles，android-FlipView主页：http://emilsjolander.se/ greenrobotGithub 地址：https://github.com/greenrobot代表作：greenDAO，EventBus主页：http://greenrobot.de/ Jeff GilfeltGithub 地址：https://github.com/jgilfelt代表作：android-mapviewballoons，android-viewbadger，android-actionbarstylegenerator，android-sqlite-asset-helper主页：http://jeffgilfelt.com Romain GuyAndroid team 成员(2013.10 已离开 Android team，仍在 Google)Github 地址：https://github.com/romainguy代表作：ViewServer主页：http://www.curious-creature.org/category/android/個人攝影作品：http://www.flickr.com/photos/romainguy sephiroth74就职于 Aviary.comGithub 地址：https://github.com/sephiroth74代表作：ImageViewZoom，HorizontalVariableListView，AndroidWheel，purePDF主页：http://www.sephiroth.it/ Cyril MottierGoogle 开发者专家认证，发布一些 Android 技巧及文章Github 地址：https://github.com/cyrilmottier代表作：GreenDroid，Polaris主页：http://cyrilmottier.com/ 二、组织 Square有态度有良心的企业，很多不错的分享Github 地址：https://github.com/square代表作：okhttp、fest-android，android-times-square、picasso、dagger、spoon 等等主页：http://square.github.io/ Inmite s.r.o.Github 地址：https://github.com/inmite代表作：android-styled-dialogs，android-grid-wichterle，android-selector-chapek主页：http://www.inmite.eu/ 三、博客部分国外著名 Android 开发者信息 LicenseCopyright 2014 [trinea.cn](http://www.trinea.cn/) Licensed under the Apache License, Version 2.0 (the &quot;License&quot;); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.","categories":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"},{"name":"java","slug":"java","permalink":"https://gowa2017.github.io/tags/java/"}],"keywords":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}]},{"title":"svn命令行的使用","slug":"svn命令行的使用","date":"2018-03-23T07:42:10.000Z","updated":"2018-03-23T07:42:10.000Z","comments":true,"path":"Android/svn命令行的使用.html","link":"","permalink":"https://gowa2017.github.io/Android/svn命令行的使用.html","excerpt":"虽然我不喜欢这个工具，但是公司用的这是这个，只能去熟悉它了。所以这是很蛋疼的事情，熟悉了 git，一点都不太喜欢这种方式的样子。","text":"虽然我不喜欢这个工具，但是公司用的这是这个，只能去熟悉它了。所以这是很蛋疼的事情，熟悉了 git，一点都不太喜欢这种方式的样子。 获取代码 checkout一般使用 svn co url 输入账号就行了。 查看状态这个很重要，你要自己你哪些文件是改了，哪些文件是过期了的（比服务器旧），然后才决定下一步的工作。 svn st 我们执行这个命令，会看到有很多输出，其第一列有 ?/M/A 这样的字符，其实这个就是代表了文件的状态。 我们可以更详细的看一下这个状态的说明。 svn help st 命令格式： svn status [option] [PATH ...] 可以加上选项进行执行。 如果我们不带任何参数执行 svn st，那么默认打印当前目录下修改的文件（不访问网络）。 -q， 只打印本地修改过项目的总结信息。 -u，添加工作修改信息和服务器过期信息。 -v，打印每个文件的完整修改信息。 输出的前七列都是一个字符： 第一列：表示项目是被新增的，删除，或改变的。 ‘ ‘ no modifications ‘A’ Added ‘C’ Conflicted ‘D’ Deleted ‘I’ Ignored ‘M’ Modified ‘R’ Replaced ‘X’ an unversioned directory created by an externals definition ‘?’ item is not under version control ‘!’ item is missing (removed by non-svn command) or incomplete ‘~’ versioned item obstructed by some item of a different kind 第二列： 对文件或目录属性的修改。 ‘ ‘ no modifications ‘C’ Conflicted ‘M’ Modified 第三列: 工作副本是否被其他Subversion客户端锁定修改。 ‘ ‘ not locked for writing ‘L’ locked for writing 第四列： 调度 commit 将会产生一个副本（加上历史） ‘ ‘ no history scheduled with commit (item was newly added) ‘+’ history scheduled with commit (item was copied) 第五列：此项目一切换或一个外部文件。 ‘ ‘ normal ‘S’ the item has a Switched URL relative to the parent ‘X’ a versioned file created by an eXternals definition 第六列：项目是否在资源中已被锁定以便独占提交。 (without -u) ‘ ‘ not locked by this working copy ‘K’ locked by this working copy, but lock might be stolen or broken (with -u) ‘ ‘ not locked in repository, not locked by this working copy ‘K’ locked in repository, lock owned by this working copy ‘O’ locked in repository, lock owned by another working copy ‘T’ locked in repository, lock owned by this working copy was stolen ‘B’ not locked in repository, lock owned by this working copy is broken 第7列 ：文件项是否是树冲突的牺牲品。 ‘ ‘ normal ‘C’ tree-Conflicted 如果文件是 tree冲突的牺牲品，会打印额外的一行来解释冲突。 过期信息在第九列出现（加上 -u）选项： ‘*’ a newer revision exists on the server ‘ ‘ the working copy is up to date 剩下的字段是变长的，且以空白分隔： 工作修订（-u, -v） 上一次提交及上一次提交者（-v） 工作路径是最后一个字段，可以包含空格。 在一个修改，上一次提交，或者在上一个提交者需要出现的地方出现的是 问号，说明信息未知。 所以一般我们的工作流程，应该是： 先看一下有哪些文件已经更新。 把服务器上的文件拖到本地来。 提交我们自己修改的文件。 propset与忽略文件使用格式： svn propset PROPNAME PROPVAL PATH...svn propset PROPNAME --revprop -r REV PROPVAL [TARGET]// propset 可以简写为 pset or ps 作用： 在工作副本内改变一个已加入版本控制的文件或目录的属性。 在一个资源版本内改变未加入版本控制的属性。 TARGET只是决定访问哪个资源。 value 可能是用 —file 选项提供，而不是 PROPVAL 以svn:开头的名字是保留的。Subversion 会识别一个文件上的以下几个属性： svn:keywords - keywords 可能是以下的几个： URL, HeadURL - 文件头部版本的 URL Author, LastChangeBy - 改变这个文件的最后一个人 Date, LastChangeDate - 上一次修改的时间 Rev, Revision, LastChangedRevision 文件改变的上一个版本 Id - 对上面四个选项的压缩概括 Header - 与Id类似，但是包括了完整的URL 自定义的keywords可以在 keyword=string 这样一个格式化的字符串来定义。有效的格式化替换字符如下： %a - 版本 %r 的作者 %b - 文件的 URL 的basename %d - %r 给定版本的 短格式日期 %D - %r 给定版本的 长格式日期 %P - 文件路径，与资源根路径相对 %r - 上一次修改这个文件的版本号 %R - 资源跟路径的 URL %u - 文件的 URL %_ - 一个空格（关键词定义不能包含一个字面的空格） %% - 一个 % %H - Equivalent to %P%_%r%_%d%_%a. %I - Equivalent to %b%_%r%_%d%_%a. 举个例子 MyKeyword=%r%_%a%_%P。一旦为一个文件自定义了关键词，就可以如同其他关键词一样使用了 ：%MyKeyword% svn:executable如果指定，让文件可执行。使用 svn propdel svn:executable PATH...来清除 svn:eol-stylenative, LF, CR, CRLF中的一个 svn:mime-type文件的mimetype。用来决定是否要合并这个文件，和在Apache上怎么样提供服务。text/开始的被当作 文本 对待。其他的就会被当作二进制文件。 svn:needs-lock如果指定，表示这个文件在修改前应该被锁定。当没有锁定的时候让工作副本文件只读。用svn propdel svn:needs-lock PATH...清除 Subversion在目录上也识别下面几个特殊的属性： svn:ignore忽略匹配正则表示式的列表，一个表达式一行。 svn:global-ignores和上面个类似，但是是可继承的 svn:auto-props当文件被添加或导入的时候，自动设置属性。包含了 键-值 对，一对一行，如下格式： PATTERN = PROPNAME=VALUE[;PROPNAME=VALUE …] propedit其实我们可以更多的以文本行的方式来修改我们要设置的属性。比如忽略文件： svn propedit svn:ignore . 文件回滚当我们错误修改了文件，我们需要把文件进行修复的时候，就需要文件回滚操作。但这分两种情况。一种是只是修改了，但是还没有 commit 到版本库，这个时候我们用： svn revert filename 就可以了。而对于已经提交到了版本库的时候，就比较麻烦了。 以我们要变更的文件为例 rc/main/resources/properties/jeeplus.properties。 查看文件的变更历史 svn log src/main/resources/properties/jeeplus.properties 找到想要回滚的版本号（我这里是4334） 执行回滚： svn merge -r 4335:4334 src/main/resources/properties/jeeplus.properties 这样文件就恢复了。这个时候，再使用 svn ci -m src/main/resources/properties/jeeplus.properties 就可以把内容恢复提交到版本库了。 文件变更列表svn diff -r 4334:4434 --summarize","categories":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"},{"name":"svn","slug":"svn","permalink":"https://gowa2017.github.io/tags/svn/"}],"keywords":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}]},{"title":"Java-基本表达式(Primary_Expressions)","slug":"Java-基本表达式(Primary_Expressions)","date":"2018-03-22T01:49:25.000Z","updated":"2018-03-22T01:49:25.000Z","comments":true,"path":"Java/Java-基本表达式(Primary_Expressions).html","link":"","permalink":"https://gowa2017.github.io/Java/Java-基本表达式(Primary_Expressions).html","excerpt":"基本表达式包含了最简单的类型的表达式，其他类似的表达式都由他们来构建：字面表达式，class字面表达式，字段访问，方法调用，数组访问。一个括号表达式语法上也被看成是一个基本表达式。","text":"基本表达式包含了最简单的类型的表达式，其他类似的表达式都由他们来构建：字面表达式，class字面表达式，字段访问，方法调用，数组访问。一个括号表达式语法上也被看成是一个基本表达式。网页内容地址 15.8. Primary Expressions Primary: PrimaryNoNewArray ArrayCreationExpressionPrimaryNoNewArray: Literal Type . class void . class this ClassName . this ( Expression ) ClassInstanceCreationExpression FieldAccess MethodInvocation ArrayAccess 类字面量一个类字面量表达式由 类，接口，数组的名字，或基本类型，伪类型 void，后跟上 .class 组成。 ClassLiteral:TypeName &#123;[ ]&#125; . class NumericType &#123;[ ]&#125; . class boolean &#123;[ ]&#125; . class void . class C.class，C是一个类，接口，数组的名字，其类型是 Class &lt;C&gt;。 p.class，p 是基本类型， 的类型是 Class &lt;B&gt;，其中 B 是 p 在经常了黑盒转换后类型的表达式。 void.class，类型是 Class &lt;void&gt;。 所以呢，如果我们在需要 Class &lt;C&gt; 的地方，我们就可以用 C.class 来指代。 那么 Class &lt;C&gt; 又是什么意思呢。 ClassClass与class并不一致，前者是 java.lang中的一个类，后者是关键词。我们常会看到 Class &lt;T&gt; cls 这样的声明。 其中，T 是被 Class 对象所模仿的 类 的类型。如，String.class 的类型是 Class &lt;String&gt;。当需要模仿的类是未知的时候，使用 Class &lt;?&gt;。 其类声明： public final class Class&lt;T&gt;extends Objectimplements Serializable, GenericDeclaration, Type, AnnotatedElement Class类的实例代表了一个Java应用中的 类 和 接口。枚举是一种类，注释是一种接口。每个数组都属于一个类，这个类是被 Class 对象反射的，所有的数组共享这个 Class 对象反射的类，因此所有数组具有相同的元素类型。基本的Java类型 (boolean, byte, char, short, long, int, fload, double）以及 void 都代表一个 Class 对象。 Class没有公开的构造器。Class对象会被 Java 虚拟机以类的形式自动构建，这种类在类加载器中加载且会调用 defineClass 方法。 下面的例子使用，Class 对象来打印一个对象的类名： void printClassName(Object obj) &#123; System.out.println(\"The class of \" + obj + \" is \" + obj.getClass().getName());&#125; 泛型类我们经常会看见类似的类声明： 在开源项目 BaseRecyclerViewAdapterHelper中就有： public abstract class BaseQuickAdapter&lt;T, K extends BaseViewHolder&gt; extends RecyclerView.Adapter&lt;K&gt; &#123;&#125; 这表示，我们在这个类中使用的关于 T ，K 类型可以是任意我们传入的。 当然，仔细理解了才会明白这是什么意思。","categories":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/tags/Java/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}]},{"title":"android_studio用户指南-配置构建概览","slug":"android_studio用户指南-配置构建概览","date":"2018-03-21T02:51:08.000Z","updated":"2018-03-21T02:51:08.000Z","comments":true,"path":"Android/android_studio用户指南-配置构建概览.html","link":"","permalink":"https://gowa2017.github.io/Android/android_studio用户指南-配置构建概览.html","excerpt":"Android 构建系统编译应用资源和源代码，然后将它们打包成可供您测试、部署、签署和分发的 APK。Android Studio 使用 Gradle 这一高级构建工具包来自动化执行和管理构建流程，同时也允许您定义灵活的自定义构建配置。每个构建配置均可自行定义一组代码和资源，同时对所有应用版本共有的部分加以重复利用。Android Plugin for Gradle 与这个构建工具包协作，共同提供专用于构建和测试 Android 应用的流程和可配置设置。","text":"Android 构建系统编译应用资源和源代码，然后将它们打包成可供您测试、部署、签署和分发的 APK。Android Studio 使用 Gradle 这一高级构建工具包来自动化执行和管理构建流程，同时也允许您定义灵活的自定义构建配置。每个构建配置均可自行定义一组代码和资源，同时对所有应用版本共有的部分加以重复利用。Android Plugin for Gradle 与这个构建工具包协作，共同提供专用于构建和测试 Android 应用的流程和可配置设置。 Gradle 和 Android 插件独立于 Android Studio 运行。这意味着，您可以在 Android Studio 内、使用计算机上的命令行工具或在未安装 Android Studio 的计算机（例如持续性集成服务器）上构建 Android 应用。如果您不使用 Android Studio，可以学习如何从命令行构建和运行您的应用。无论您是从命令行、在远程计算机上还是使用 Android Studio 构建项目，构建的输出都相同。 注：由于 Gradle 和 Android 插件独立于 Android Studio 运行，您需要单独更新构建工具。请阅读版本说明，了解如何更新 Gradle 和 Android 插件。 Android 构建系统非常灵活，让您能够在不修改应用核心源文件的情况下执行自定义构建配置。本章帮助您了解 Android 构建系统的工作原理，以及它如何帮助您对多个构建配置进行自定义和自动化处理。如果您只想了解有关部署应用的更多信息，请参阅在 Android Studio 中构建和运行项目。要立即开始使用 Android Studio 创建自定义构建配置，请参阅配置构建变体。 构建流程构建流程涉及许多将您的项目转换成 Android 应用软件包 (APK) 的工具和流程。构建流程非常灵活，因此了解它的一些底层工作原理会很有帮助。 如图 1 所示，典型 Android 应用模块的构建流程通常依循下列步骤： 编译器将您的源代码转换成 DEX（Dalvik Executable) 文件（其中包括运行在 Android 设备上的字节码），将所有其他内容转换成已编译资源。 APK 打包器将 DEX 文件和已编译资源合并成单个 APK。不过，必须先签署 APK，才能将应用安装并部署到 Android 设备上。 APK 打包器使用调试或发布密钥库签署您的 APK：a. 如果您构建的是调试版本的应用（即专用于测试和分析的应用），打包器会使用调试密钥库签署您的应用。Android Studio 自动使用调试密钥库配置新项目。b. 如果您构建的是打算向外发布的发布版本应用，打包器会使用发布密钥库签署您的应用。要创建发布密钥库，请阅读在 Android Studio 中签署您的应用。 在生成最终 APK 之前，打包器会使用 zipalign 工具对应用进行优化，减少其在设备上运行时的内存占用。 构建流程结束时，您将获得可用来进行部署、测试的调试 APK，或者可用来发布给外部用户的发布 APK。 自定义构建配置Gradle 和 Android 插件可帮助您完成以下方面的构建配置： 构建类型构建类型定义 Gradle 在构建和打包您的应用时使用的某些属性，通常针对开发生命周期的不同阶段进行配置。例如，调试构建类型支持调试选项，使用调试密钥签署 APK；而发布构建类型则可压缩、混淆 APK 以及使用发布密钥签署 APK 进行分发。您必须至少定义一个构建类型才能构建应用 - Android Studio 默认情况下会创建调试和发布构建类型。要开始为应用自定义打包设置，请学习如何配置构建类型。 产品风味产品风味代表您可以发布给用户的不同应用版本，例如免费和付费的应用版本。您可以将产品风味自定义为使用不同的代码和资源，同时对所有应用版本共有的部分加以共享和重复利用。产品风味是可选项，并且您必须手动创建。要开始创建不同的应用版本，请学习如何配置产品风味。 构建变体构建变体是构建类型与产品风味的交叉产物，是 Gradle 在构建应用时使用的配置。您可以利用构建变体在开发时构建产品风味的调试版本，或者构建已签署的产品风味发布版本进行分发。您并不直接配置构建变体，而是配置组成变体的构建类型和产品风味。创建附加构建类型或产品风味也会创建附加构建变体。要了解如何创建和管理构建变体，请阅读配置构建变体概览。 清单条目您可以为构建变体配置中清单文件的一些属性指定值。这些构建值会替换清单文件中的现有值。如果您想为模块生成多个 APK，让每一个 APK 文件都具有不同的应用名称、最低 SDK 版本或目标 SDK 版本，便可运用这一技巧。存在多个清单时，Gradle 会合并清单设置。 依赖项构建系统管理来自您的本地文件系统以及来自远程存储区的项目依赖项。这样一来，您就不必手动搜索、下载依赖项的二进制文件包以及将它们复制到项目目录内。要了解更多信息，请学习如何声明依赖项。 签署构建系统让您能够在构建配置中指定签署设置，并可在构建过程中自动签署您的 APK。构建系统通过使用已知凭据的默认密钥和证书签署调试版本，以避免在构建时提示密码。除非您为此构建显式定义签署配置，否则，构建系统不会签署发布版本。如果您没有发布密钥，可以按签署您的应用中所述生成一个。 ProGuard构建系统让您能够为每个构建变体指定不同的 ProGuard 规则文件。构建系统可在构建过程中运行 ProGuard 对类进行压缩和混淆处理。 APK拆分构建系统让您能够自动构建不同的 APK，并且每个 APK 只包含特定屏幕密度或应用二进制界面 (ABI) 所需的代码和资源。如需了解详细信息，请参阅配置 APK 拆分。 构建配置文件创建自定义构建配置需要您对一个或多个构建配置文件（或 build.gradle 文件）进行更改。这些纯文本文件使用域特定语言 (DSL) 以 Groovy 语言描述和操作构建逻辑，后者是一种适用于 Java 虚拟机 (JVM) 的动态语言。您无需了解 Groovy 便可开始配置构建，因为 Android Plugin for Gradle 引入了您需要的大多数 DSL 元素。如需了解有关 Android 插件 DSL 的更多信息，请阅读 DSL 参考文档。 开始新项目时，Android Studio 会自动为您创建其中的部分文件（如图 2 所示），并为它们填充合理的默认值。 有几个 Gradle 构建配置文件是 Android 应用标准项目结构的组成部分。您必须了解其中每一个文件的范围和用途及其应定义的基本 DSL 元素，才能着手配置构建。 Gradle 设置文件settings.gradle 文件位于项目根目录，用于指示 Gradle 在构建应用时应将哪些模块包括在内。对大多数项目而言，该文件很简单，只包括以下内容： include ‘:app’ 不过，多模块项目需要指定应包括在最终构建之中的每个模块。 顶级构建文件顶级 build.gradle 文件位于项目根目录，用于定义适用于项目中所有模块的构建配置。默认情况下，这个顶级构建文件使用 buildscript {} 代码块来定义项目中所有模块共用的 Gradle 存储区和依赖项。以下代码示例描述的默认设置和 DSL 元素可在新建项目后的顶级 build.gradle 文件中找到。 /** * buildscript &#123;&#125; 块用来为Gradle自身配置资源和依赖 ———— 这意味着，不应该在这里包含 * 模块的依赖。例如，这里把 Android for Gradle 插件作为依赖，因为这个插件提供了Gradle * 构建 Android app 模块需要的附加指令。 */buildscript &#123; /** * repositories &#123;&#125; 块配置了 Gradle 用来搜索和下载依赖的源。Gradle预配置了支持远程源， * 比如 JCenter, Maven Central, Ivy。可以使用自己的本地源或者定义自己的远程源。下面的 * 代码定义了 JCenter 作为 Gradle 寻找依赖的源。 */ repositories &#123; jcenter() &#125; /** * dependencies &#123;&#125; 块设置 Gradle 构建项目需要的依赖。下面的行添加了 Android for * Gradle插件的 3.0.1 版本作为一个 classpath 依赖。 */ dependencies &#123; classpath 'com.android.tools.build:gradle:3.0.1' &#125;&#125;/** * allprojects &#123;&#125; 块是用来设置项目中所有模块使用的源和依赖的地方，比如第三方的插件或库。 * 不是被所有模块都需要的依赖应该在模块级别的 build.gradle 文件内配置。对于新项目，Android * Studio 设置 JCenter 作为默认源，但是并配置任何依赖。 */ allprojects &#123; repositories &#123; jcenter() &#125;&#125; 模块级构建文件模块级 build.gradle 文件位于每个 &lt;project&gt;/&lt;module&gt;/ 目录，用于配置适用于其所在模块的构建设置。您可以通过配置这些构建设置来提供自定义打包选项（例如附加构建类型和产品风味），以及替换 main/ 应用清单或顶级 build.gradle 文件中的设置。 以下这个示例 Android 应用模块 build.gradle 文件概述了您应该了解的部分基本 DSL 元素和设置。 /** * 配置文件中的第一行对此构建使用 为Gradle 写的安卓 插件，且使 android &#123;&#125; 块 * 可用来指定安卓相关的构建选项。 */apply plugin: 'com.android.application'/** * android &#123;&#125; 配置所有 Android-specific 构建选项。 */android &#123; /** * compileSdkVersion 指定 Gradle 应该使用来编译 app 的 Android API level 。 * 这就是说，你的APP可以使用这个级别的API特性及更低级别的特性。 * * buildToolsVersion 指定 SDK build tools 版本, command-line * utilities, and compiler that Gradle should use to build your app. You need to * download the build tools using the SDK Manager. */ compileSdkVersion 26 buildToolsVersion \"27.0.3\" /** * The defaultConfig &#123;&#125; block encapsulates default settings and entries for all * build variants, and can override some attributes in main/AndroidManifest.xml * dynamically from the build system. You can configure product flavors to override * these values for different versions of your app. */ defaultConfig &#123; /** * applicationId uniquely identifies the package for publishing. * However, your source code should still reference the package name * defined by the package attribute in the main/AndroidManifest.xml file. */ applicationId 'com.example.myapp' // Defines the minimum API level required to run the app. minSdkVersion 15 // Specifies the API level used to test the app. targetSdkVersion 26 // Defines the version number of your app. versionCode 1 // Defines a user-friendly version name for your app. versionName \"1.0\" &#125; /** * The buildTypes &#123;&#125; block is where you can configure multiple build types. * By default, the build system defines two build types: debug and release. The * debug build type is not explicitly shown in the default build configuration, * but it includes debugging tools and is signed with the debug key. The release * build type applies Proguard settings and is not signed by default. */ buildTypes &#123; /** * By default, Android Studio configures the release build type to enable code * shrinking, using minifyEnabled, and specifies the Proguard settings file. */ release &#123; minifyEnabled true // Enables code shrinking for the release build type. proguardFiles getDefaultProguardFile('proguard-android.txt'), 'proguard-rules.pro' &#125; &#125; /** * The productFlavors &#123;&#125; block is where you can configure multiple product * flavors. This allows you to create different versions of your app that can * override defaultConfig &#123;&#125; with their own settings. Product flavors are * optional, and the build system does not create them by default. This example * creates a free and paid product flavor. Each product flavor then specifies * its own application ID, so that they can exist on the Google Play Store, or * an Android device, simultaneously. */ productFlavors &#123; free &#123; applicationId 'com.example.myapp.free' &#125; paid &#123; applicationId 'com.example.myapp.paid' &#125; &#125; /** * The splits &#123;&#125; block is where you can configure different APK builds that * each contain only code and resources for a supported screen density or * ABI. You'll also need to configure your build so that each APK has a * different versionCode. */ splits &#123; // Screen density split settings density &#123; // Enable or disable the density split mechanism enable false // Exclude these densities from splits exclude \"ldpi\", \"tvdpi\", \"xxxhdpi\", \"400dpi\", \"560dpi\" &#125; &#125;&#125;/** * The dependencies &#123;&#125; block in the module-level build configuration file * only specifies dependencies required to build the module itself. */dependencies &#123; compile project(\":lib\") compile 'com.android.support:appcompat-v7:27.1.0' compile fileTree(dir: 'libs', include: ['*.jar'])&#125; Gradle 属性文件Gradle 还包括两个属性文件，位于项目根目录，可用于指定适用于 Gradle 构建工具包本身的设置： gradle.properties您可以在其中配置项目范围 Gradle 设置，例如 Gradle 后台进程的最大堆大小。如需了解详细信息，请参阅构建环境。 local.properties为构建系统配置本地环境属性，例如 SDK 安装路径。由于该文件的内容由 Android Studio 自动生成并且专用于本地开发者环境，因此您不应手动修改该文件，或将其纳入您的版本控制系统。 将项目与 Gradle 文件同步当您在项目中对构建配置文件进行更改时，Android Studio 会要求您同步项目文件，以便其导入您的构建配置更改并执行一些检查来确保您的配置不会造成构建错误。 要同步项目文件，您可以点击做出更改后出现的通知栏中的 Sync Now（如图 3 所示），或者点击菜单栏中的 Sync Project 。如果 Android Studio 通知配置出现错误，例如：您的源代码使用了只有在 compileSdkVersion 以上的 API 级别中才会提供的 API 功能，会显示 Messages 窗口，具体描述该问题。 源集Android Studio 按逻辑关系将每个模块的源代码和资源分组为源集。模块的 main/ 源集包括其所有构建变体共用的代码和资源。其他源集目录为可选项，在您配置新的构建变体时，Android Studio 不会自动为您创建这些目录。不过，创建类似于 main/ 的源集有助于让 Gradle 只应在构建特定应用版本时使用的文件和资源井然有序： src/main/此源集包括所有构建变体共用的代码和资源。 src/\\/创建此源集可加入特定构建类型专用的代码和资源。 src/\\/创建此源集可加入特定产品风味专用的代码和资源。 src/\\/创建此源集可加入特定构建变体专用的代码和资源。例如，要生成应用的“完整调试”版本，构建系统需要合并来自以下源集的代码、设置和资源： src/fullDebug/（构建变体源集）src/debug/（构建类型源集）src/full/（产品风味源集）src/main/（主源集） 注：当您在 Android Studio 中使用 File &gt; New 菜单选项新建文件或目录时，可以针对特定源集进行创建。可供您选择的源集取决于您的构建配置，如果所需目录尚不存在，Android Studio 会自动创建。 如果不同源集包含同一文件的不同版本，Gradle 将按以下优先顺序决定使用哪一个文件（左侧源集替换右侧源集的文件和设置）： 构建变体 &gt; 构建类型 &gt; 产品风味 &gt; 主源集 &gt; 库依赖项 这样一来，Gradle 便可使用专用于您试图构建的构建变体的文件，同时对与其他应用版本共用的 Activity、应用逻辑和资源加以重复利用。在合并多个清单时，Gradle 使用同一优先顺序，这样每个构建变体都能在最终清单中定义不同的组件或权限。如需了解有关创建自定义源集的更多信息，请转至创建用于构建变体的源集。","categories":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"}],"keywords":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}]},{"title":"android_studio_3.0.1中sdk管理","slug":"android_studio_3.0.1中sdk管理","date":"2018-03-20T15:13:42.000Z","updated":"2018-03-20T15:13:42.000Z","comments":true,"path":"Android/android_studio_3.0.1中sdk管理.html","link":"","permalink":"https://gowa2017.github.io/Android/android_studio_3.0.1中sdk管理.html","excerpt":"","text":"升级到3.0.1后，居然无法在sdkmanager中下载东西了。后面仔细看了一下用户指南才发现，其实是需要通过命令行工具来进行管理的。这个用得也非常不错，我最喜欢命令行了。 位置命令行工具一般都位于自己所设置的sdk工具目录下，比如我的就位于目录~/Library/Android/sdk/ 目录下。 工具就位于上面这个目录中的 tools/bin/ 下面。 sdkmanager列出所有可用包sdkmanager --list 安装 包sdkmanager packages [options] packages 是一个SDK风格的路径，和 --list 选项显示出来的一样，然后用“来包围（比如 “build-tools;27.0.3”或platforms;android-26。可以传递多个包，中间用空格进行分隔，但是必须单独引用起来。 比如： sdkmanager &quot;platform-tools&quot; &quot;platforms;android-26&quot; 或者可以直接指定一个包含了所有包名的文件： sdkmanage --package-file=filename [options] filename每行就是一个SDK风格的路径。 卸载包sdkmanager --uninstall packages [options] sdkmanager --uninstall --package-files=filename [options] 更新包sdkmanager --update [options] 选项 —sdk_root=path 使用指定sdk路径而不是包含此工具的路径 —channel=channel_id 可用的channel_id是：0 (Stable), 1 (Beta), 2 (Dev), and 3 (Canary). —include_obsolete 包含过时的包。 —no_https 不使用 https —verbose 输出详细信息 —proxy={http | 代理类型socks} —proxy_host={ip_address | DNS_dress } —proxy_port=port_number avdmanager用来管理 android virtual device的命令行工具。 avdmanager list [ avd | target | device] avdmanager { create | move | delete } avd list 命令会显示出已建立的虚拟设备，还有可用的已定义设备类型。 已建立设备类似（avd）： Name: Nexus_5X_API_23Device: Nexus 5X (Google) Path: /Users/wodediannao/.android/avd/Nexus_5X_API_23.avdTarget: Based on: Android 6.0 (Marshmallow) Tag/ABI: default/x86_64 Skin: nexus_5xSdcard: 100M 可用类型类似（target）： Available devices definitions: id: 0 or &quot;tv_1080p&quot; Name: Android TV (1080p) OEM : Google Tag : android-tv avd建立我们需要指定建立的AVD要使用的一些设置和参数： avdmanager create avd -n name -k &quot;sdk_id&quot; [-c {path | size}] [-f] [-p path] -n name 指定avd命令 -k 镜像包路径 -c 指定sd卡路径或大小 -f 强制使用当前名字建立，重写已存在同名avd -p path 指定建立avd文件存放路径。 -d 指定target id，或者 描述。id: 0 or &quot;tv_1080p&quot; 例子: avdmanager create avd -n test -k &quot;system-images;android-25;google_apis;x86&quot; -d &quot;tv_1080p&quot;","categories":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/tags/Android/"},{"name":"java","slug":"java","permalink":"https://gowa2017.github.io/tags/java/"},{"name":"android studio","slug":"android-studio","permalink":"https://gowa2017.github.io/tags/android-studio/"}],"keywords":[{"name":"Android","slug":"Android","permalink":"https://gowa2017.github.io/categories/Android/"}]},{"title":"YouCompleteMe-readme_zh","slug":"YouCompleteMe-readme_zh","date":"2018-03-14T14:23:27.000Z","updated":"2018-03-14T14:23:27.000Z","comments":true,"path":"Vim/YouCompleteMe-readme_zh.html","link":"","permalink":"https://gowa2017.github.io/Vim/YouCompleteMe-readme_zh.html","excerpt":"正在寻找帮助，建议或者支持？YCM工作起来不正常或者不工作？ 首先认真的阅读对应系统的安装说明 ，不过我们建议你使用install.py. 接着，检查 User Guide 一节中 你所使用的语法补全器。 对于 C/C++/Objective C, 你 must必须 阅读这一节. 最好，检查 FAQ. 如果在阅读完安装说明和用户指南，并检查了FAQ，还是有问题，查看contacts 一节来联系我们。 Please do NOT go to #vim on freenode for support. Please contact theYouCompleteMe maintainers directly using the contact details below.","text":"正在寻找帮助，建议或者支持？YCM工作起来不正常或者不工作？ 首先认真的阅读对应系统的安装说明 ，不过我们建议你使用install.py. 接着，检查 User Guide 一节中 你所使用的语法补全器。 对于 C/C++/Objective C, 你 must必须 阅读这一节. 最好，检查 FAQ. 如果在阅读完安装说明和用户指南，并检查了FAQ，还是有问题，查看contacts 一节来联系我们。 Please do NOT go to #vim on freenode for support. Please contact theYouCompleteMe maintainers directly using the contact details below. Contents Intro Installation Mac OS X Ubuntu Linux x64 Fedora Linux x64 Windows FreeBSD/OpenBSD Full Installation Guide Quick Feature Summary User Guide General Usage Client-Server Architecture Completion String Ranking General Semantic Completion C-family Semantic Completion JavaScript Semantic Completion Rust Semantic Completion Python Semantic Completion Java Semantic Completion Semantic Completion for Other Languages Writing New Semantic Completers Diagnostic Display Diagnostic Highlighting Groups Commands YcmCompleter subcommands GoTo Commands Semantic Information Commands Refactoring and FixIt Commands Miscellaneous Commands Functions Autocommands Options FAQ Contributor Code of Conduct Contact License IntroYouCompleteMe 是一个快速的，当你键入就进行模糊搜索的代码补全引擎。 forVim其有几个补全引擎: 一个 基于标识符 的在任何编程语言上工作的引擎。 一个 基于Clang的 引擎对 C/C++/Objective-C/Objective-C++ 提供原生语法补全 一个 基于Jedi 的引擎来补全 Python2/3（使用 JediHTTP 封装） 一个 基于OmniSharp 引擎用来补全 C# Gocode, Godef 结合起来对Go工作 基于TSServer补全引擎来，针对TypeScript 基于Tern，JavaScript 基于racer，Rust 基于jdt.ls，Java 基于 omnifunc 的补全器，使用 Vim的 omnicomplete系统来为其他语言提供语发补全（Ruby, PHP, etc)。 下面来解释一下图片中的东西。 首先明白一点，在操作中不需要按下任何键来获取补全列表。用户只是键入字符，建议的补全结果就会自动弹出来。如果用户只想继续键入或者结果没有想要的，那么继续键入就是。 当用户看到补全建议中有自己想要的字符串时，可以用 tab 键来进行选择。这将会插入补全的字符。多次按tab键会在建议的列表项目中进行循环。 如果出现的补全列表没有用，继续键入就是，键入越多，补全就会越清晰。 一个必须要注意的问题就是，补全引擎并不基于输入的字符串是不是 某一字符的前缀。我们的输入只要是某一补全项的 [顺序匹配][] 就行 。这就是说，任何输入的字符必须在补全项中以输入的顺序出现。因此abc是 xaybgc 的一个子序列。在这个过滤器后，一个复杂的排序系统会整理补全字符串，然后最相关的一项就会出现在顶部（所以大多数时候我们只需要按一次 TAB）。 所有上面的说明对任何语言都会工作，这是 基于标识符的补全引擎实现的。这个引擎会搜集当前文件和访问过的文件中（以及 tags 文件）的标识符，当我们键入字符的时候就会进行搜索（标识符会按文件类型分组）。 这个动画也显示了 语法引擎。当在冲入模式下用户键入 ., -&gt; 或 ::（C++，其他的语言触发可能不同），，语法引擎就被触发（其也可以被一个快捷键触发）。 The last thing that you can see in the demo is YCM’s diagnostic display features(the little red X that shows up in the left gutter; inspired by Syntastic)if you are editing a C-family file. As Clang compiles your file and detectswarnings or errors, they will be presented in various ways. You don’t need tosave your file or press any keyboard shortcut to trigger this, it “just happens”in the background. YCM让下面这些插件过时，因为他们的功能YCM全部都有而且还有提高。In essence, YCM obsoletes the following Vim plugins because it has all of theirfeatures plus extra: clang_complete AutoComplPop Supertab neocomplcache 但这并不是全部And that’s not all… YCM也为多种语言提供 semantic IDE-like features包括： 查找标识符的定义，声明，使用等等。 显示类，变量，函数的类型信息。 在预览窗口中显示方法，成员等的文档。 纠正普通的编码错误，比如缺少分号。 变量在文件间的重命名（JavaScript) 特性会根据文件类型而变，所以先看一下 file type featuresummary 和full list of completer subcommands 来看一下你使用的语言拥有的特性。 你也会发现YCM有文件路径的补全和一个集成了 UltiSnips的补全。 InstallationMac OS XThese instructions (using install.py) are the quickest way to installYouCompleteMe, however they may not work for everyone. If the followinginstructions don’t work for you, check out the full installationguide. Install the latest version of MacVim. Yes, MacVim. And yes, the latest. If you don’t use the MacVim GUI, it is recommended to use the Vim binary that isinside the MacVim.app package (MacVim.app/Contents/MacOS/Vim). To ensure itworks correctly copy the mvim script from the MacVim download to yourlocal binary folder (for example /usr/local/bin/mvim) and then symlink it: ln -s /usr/local/bin/mvim vim Install YouCompleteMe with Vundle. Remember: YCM is a plugin with a compiled component. If you update YCMusing Vundle and the ycm_core library APIs have changed (happensrarely), YCM will notify you to recompile it. You should then rerun the installprocess. NOTE: If you want C-family completion, you MUST have the latest Xcodeinstalled along with the latest Command Line Tools (they are installedautomatically when you run clang for the first time, or manually by runningxcode-select --install) Install CMake. Preferably with Homebrew, but here’s the stand-aloneCMake installer. If you have installed a Homebrew Python and/or Homebrew MacVim, see the FAQfor details. Compiling YCM with semantic support for C-family languages: cd ~/.vim/bundle/YouCompleteMe ./install.py --clang-completer Compiling YCM without semantic support for C-family languages: cd ~/.vim/bundle/YouCompleteMe ./install.py The following additional language support options are available: C# support: install Mono with Homebrew or by downloading the Mono Macpackage and add --cs-completer when calling./install.py. Go support: install Go and add --go-completer when calling./install.py. TypeScript support: install Node.js and npm then install theTypeScript SDK with npm install -g typescript. JavaScript support: install Node.js and npm and add--js-completer when calling ./install.py. Rust support: install Rust and add--rust-completer when calling ./install.py. Java support: install JDK8 (version 8 required) and add--java-completer when calling ./install.py. To simply compile with everything enabled, there’s a --all flag. So, toinstall with all language features, ensure xbuild, go, tsserver, node,npm, rustc, and cargo tools are installed and in your PATH, thensimply run: cd ~/.vim/bundle/YouCompleteMe ./install.py --all That’s it. You’re done. Refer to the User Guide section on how to use YCM.Don’t forget that if you want the C-family semantic completion engine to work,you will need to provide the compilation flags for your project to YCM. It’s allin the User Guide. YCM comes with sane defaults for its options, but you still may want to take alook at what’s available for configuration. There are a few interesting optionsthat are conservatively turned off by default that you may want to turn on. Ubuntu Linux x64These instructions (using install.py) are the quickest way to installYouCompleteMe, however they may not work for everyone. If the followinginstructions don’t work for you, check out the full installationguide. Make sure you have Vim 7.4.1578 with Python 2 or Python 3 support. Ubuntu 16.04and later have a Vim that’s recent enough. You can see the version of Viminstalled by running vim --version. If the version is too old, you may need tocompile Vim from source (don’t worry, it’s easy). Install YouCompleteMe with Vundle. Remember: YCM is a plugin with a compiled component. If you update YCMusing Vundle and the ycm_core library APIs have changed (happensrarely), YCM will notify you to recompile it. You should then rerun the installprocess. Install development tools and CMake: sudo apt-get install build-essential cmake Note: On older systems (e.g. Ubuntu 14.04) you may run into compilationissues with cmake. Therefore, install the following instead: sudo apt-get install build-essential cmake3 Make sure you have Python headers installed: sudo apt-get install python-dev python3-dev Compiling YCM with semantic support for C-family languages: cd ~/.vim/bundle/YouCompleteMe ./install.py --clang-completer Compiling YCM without semantic support for C-family languages: cd ~/.vim/bundle/YouCompleteMe ./install.py The following additional language support options are available: C# support: install Mono and add --cs-completerwhen calling ./install.py. Go support: install Go and add --go-completer when calling./install.py. TypeScript support: install Node.js and npm then install theTypeScript SDK with npm install -g typescript. JavaScript support: install Node.js and npm and add--js-completer when calling ./install.py. Rust support: install Rust and add --rust-completer whencalling ./install.py. Java support: install JDK8 (version 8 required) and add--java-completer when calling ./install.py. To simply compile with everything enabled, there’s a --all flag. So, toinstall with all language features, ensure xbuild, go, tsserver, node,npm, rustc, and cargo tools are installed and in your PATH, thensimply run: cd ~/.vim/bundle/YouCompleteMe ./install.py --all That’s it. You’re done. Refer to the User Guide section on how to use YCM.Don’t forget that if you want the C-family semantic completion engine to work,you will need to provide the compilation flags for your project to YCM. It’s allin the User Guide. YCM comes with sane defaults for its options, but you still may want to take alook at what’s available for configuration. There are a few interesting optionsthat are conservatively turned off by default that you may want to turn on. Fedora Linux x64These instructions (using install.py) are the quickest way to installYouCompleteMe, however they may not work for everyone. If the followinginstructions don’t work for you, check out the full installationguide. Make sure you have Vim 7.4.1578 with Python 2 or Python 3 support. Fedora 21 andlater have a Vim that’s recent enough. You can see the version of Vim installedby running vim --version. If the version is too old, you may need to compileVim from source (don’t worry, it’s easy). Install YouCompleteMe with Vundle. Remember: YCM is a plugin with a compiled component. If you update YCMusing Vundle and the ycm_core library APIs have changed (happensrarely), YCM will notify you to recompile it. You should then rerun the installprocess. Install development tools and CMake: sudo dnf install automake gcc gcc-c++ kernel-devel cmake Make sure you have Python headers installed: sudo dnf install python-devel python3-devel Compiling YCM with semantic support for C-family languages: cd ~/.vim/bundle/YouCompleteMe ./install.py --clang-completer Compiling YCM without semantic support for C-family languages: cd ~/.vim/bundle/YouCompleteMe ./install.py The following additional language support options are available: C# support: install Mono and add --cs-completerwhen calling ./install.py. Go support: install Go and add --go-completer when calling./install.py. TypeScript support: install Node.js and npm then install theTypeScript SDK with npm install -g typescript. JavaScript support: install Node.js and npm and add--js-completer when calling ./install.py. Rust support: install Rust and add --rust-completer whencalling ./install.py. Java support: install JDK8 (version 8 required) and add--java-completer when calling ./install.py. To simply compile with everything enabled, there’s a --all flag. So, toinstall with all language features, ensure xbuild, go, tsserver, node,npm, rustc, and cargo tools are installed and in your PATH, thensimply run: cd ~/.vim/bundle/YouCompleteMe ./install.py --all That’s it. You’re done. Refer to the User Guide section on how to use YCM.Don’t forget that if you want the C-family semantic completion engine to work,you will need to provide the compilation flags for your project to YCM. It’s allin the User Guide. YCM comes with sane defaults for its options, but you still may want to take alook at what’s available for configuration. There are a few interesting optionsthat are conservatively turned off by default that you may want to turn on. WindowsThese instructions (using install.py) are the quickest way to installYouCompleteMe, however they may not work for everyone. If the followinginstructions don’t work for you, check out the full installationguide. Important: we assume that you are using the cmd.exe command prompt andthat you know how to add an executable to the PATH environment variable. Make sure you have at least Vim 7.4.1578 with Python 2 or Python 3 support. Youcan check the version and which Python is supported by typing :version insideVim. Look at the features included: +python/dyn for Python 2 and+python3/dyn for Python 3. Take note of the Vim architecture, i.e. 32 or64-bit. It will be important when choosing the Python installer. We recommendusing a 64-bit client. Daily updated copies of 32-bit and 64-bit Vim withPython 2 and Python 3 support are available. Add the line: set encoding=utf-8 to your vimrc if not already present. This option is required by YCM. Notethat it does not prevent you from editing a file in another encoding than UTF-8.You can do that by specifying the ++enc argument to the :e command. Install YouCompleteMe with Vundle. Remember: YCM is a plugin with a compiled component. If you update YCMusing Vundle and the ycm_core library APIs have changed (happensrarely), YCM will notify you to recompile it. You should then rerun the installprocess. Download and install the following software: Python 2 or Python 3. Be sure to pick the versioncorresponding to your Vim architecture. It is Windows x86 for a 32-bit Vimand Windows x86-64 for a 64-bit Vim. We recommend installing Python 3.Additionally, the version of Python you install must match up exactly withthe version of Python that Vim is looking for. Type :version and look at thebottom of the page at the list of compiler flags. Look for flags that looksimilar to -DDYNAMIC_PYTHON_DLL=\\&quot;python27.dll\\&quot; and-DDYNAMIC_PYTHON3_DLL=\\&quot;python35.dll\\&quot;. The former indicates that Vim islooking for Python 2.7 and the latter indicates that Vim is looking forPython 3.5. You’ll need one or the other installed, matching the versionnumber exactly. CMake. Add CMake executable to the PATH environmentvariable. Visual Studio. Download the community edition.During setup, select Desktop development with C++ in Workloads. 7-zip 16.04 or later. Required to build YCM with semanticsupport for C-family languages. Compiling YCM with semantic support for C-family languages: cd %USERPROFILE%/vimfiles/bundle/YouCompleteMe python install.py --clang-completer Compiling YCM without semantic support for C-family languages: cd %USERPROFILE%/vimfiles/bundle/YouCompleteMe python install.py The following additional language support options are available: C# support: add --cs-completer when calling install.py.Be sure that the build utility msbuild is in your PATH. Go support: install Go and add --go-completer when callinginstall.py. TypeScript support: install Node.js and npm then install theTypeScript SDK with npm install -g typescript. JavaScript support: install Node.js and npm and add--js-completer when calling install.py. Rust support: install Rust and add --rust-completer whencalling install.py. Java support: install JDK8 (version 8 required) and add--java-completer when calling ./install.py. To simply compile with everything enabled, there’s a --all flag. So, toinstall with all language features, ensure msbuild, go, tsserver, node,npm, and cargo tools are installed and in your PATH, then simply run: cd %USERPROFILE%/vimfiles/bundle/YouCompleteMe python install.py --all You can specify the Microsoft Visual C++ (MSVC) version using the --msvcoption. YCM officially supports MSVC 12 (Visual Studio 2013), 14 (2015), and 15(2017). That’s it. You’re done. Refer to the User Guide section on how to use YCM.Don’t forget that if you want the C-family semantic completion engine to work,you will need to provide the compilation flags for your project to YCM. It’s allin the User Guide. YCM comes with sane defaults for its options, but you still may want to take alook at what’s available for configuration. There are a few interesting optionsthat are conservatively turned off by default that you may want to turn on. FreeBSD/OpenBSDThese instructions (using install.py) are the quickest way to installYouCompleteMe, however they may not work for everyone. If the followinginstructions don’t work for you, check out the full installationguide. NOTE: OpenBSD / FreeBSD are not officially supported platforms by YCM. Make sure you have Vim 7.4.1578 with Python 2 or Python 3 support. OpenBSD 5.5 and later have a Vim that’s recent enough. You can see the version ofVim installed by running vim --version. FreeBSD 10.x comes with clang compiler but not the libraries needed to install. pkg install llvm38 boost-all boost-python-libs clang38 export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/llvm38/lib/ Install YouCompleteMe with Vundle. Remember: YCM is a plugin with a compiled component. If you update YCMusing Vundle and the ycm_core library APIs have changed (happensrarely), YCM will notify you to recompile it. You should then rerun the installprocess. Install dependencies and CMake: sudo pkg_add llvm boost cmake Compiling YCM with semantic support for C-family languages: cd ~/.vim/bundle/YouCompleteMe ./install.py --clang-completer --system-libclang --system-boost Compiling YCM without semantic support for C-family languages: cd ~/.vim/bundle/YouCompleteMe ./install.py --system-boost The following additional language support options are available: C# support: install Mono and add --cs-completer when calling./install.py. Go support: install Go and add --go-completer when calling./install.py. TypeScript support: install Node.js and npm then install theTypeScript SDK with npm install -g typescript. JavaScript support: install Node.js and npm and add--js-completer when calling ./install.py. Rust support: install Rust and add --rust-completer whencalling ./install.py. Java support: install JDK8 (version 8 required) and add--java-completer when calling ./install.py. To simply compile with everything enabled, there’s a --all flag. So, toinstall with all language features, ensure xbuild, go, tsserver, node,npm, and cargo tools are installed and in your PATH, then simply run: cd ~/.vim/bundle/YouCompleteMe ./install.py --all That’s it. You’re done. Refer to the User Guide section on how to use YCM.Don’t forget that if you want the C-family semantic completion engine to work,you will need to provide the compilation flags for your project to YCM. It’s allin the User Guide. YCM comes with sane defaults for its options, but you still may want to take alook at what’s available for configuration. There are a few interesting optionsthat are conservatively turned off by default that you may want to turn on. Full Installation Guide 完整安装指南These are the steps necessary to get YCM working on a Unix OS and on Windows. Note to Windows users: we assume that you are running the cmd.exe commandprompt and that the needed executables are in the PATH environment variable. Donot just copy the shell commands. Replace ~ by %USERPROFILE% in them and usethe right Vim home directory. It should be vimfiles by default instead of.vim. See the FAQ if you have any issues. Remember: YCM is a plugin with a compiled component. If you update YCMusing Vundle and the ycm_core library APIs have changed (happensrarely), YCM will notify you to recompile it. You should then rerun the installprocess. Please follow the instructions carefully. Read EVERY WORD. Ensure that your version of Vim is at least 7.4.1578 and that it hassupport for Python 2 or Python 3 scripting. Inside Vim, type :version. Look at the first two to three lines of output;it should say Vi IMproved X.Y, where X.Y is the major version of vim. Ifyour version is greater than 7.4, then you’re all set. If your version is7.4 then look below that where it says, Included patches: 1-Z, where Zwill be some number. That number needs to be 1578 or higher. If your version of Vim is not recent enough, you may need to compile Vimfrom source (don’t worry, it’s easy). After you have made sure that you have Vim 7.4.1578+, type the following inVim: :echo has(&#39;python&#39;) || has(&#39;python3&#39;). The output should be 1. Ifit’s 0, then get a version of Vim with Python support. On Windows, check also if your Vim architecture is 32 or 64-bit. This iscritical because it must match the Python and the YCM librariesarchitectures. We recommend using a 64-bit Vim. Install YCM with Vundle (or Pathogen, but Vundle is a betteridea). With Vundle, this would mean adding a Plugin &#39;Valloric/YouCompleteMe&#39; line to your vimrc. If you don’t install YCM with Vundle, make sure you have rungit submodule update --init --recursive after checking out the YCMrepository (Vundle will do this for you) to fetch YCM’s dependencies. [Complete this step ONLY if you care about semantic completion support forC-family languages. Otherwise it’s not necessary.] Download the latest version of libclang. Clang is an open-sourcecompiler that can compile C/C++/Objective-C/Objective-C++. The libclanglibrary it provides is used to power the YCM semantic completion engine forthose languages. YCM is designed to work with libclang version 3.9 orhigher. You can use the system libclang only if you are sure it is version 3.9 orhigher, otherwise don’t. Even if it is, we recommend using the officialbinaries from llvm.org if at all possible. Make sure youdownload the correct archive file for your OS. We STRONGLY recommend AGAINST use of the system libclang instead ofthe upstream compiled binaries. Random things may break. Save yourself thehassle and use the upstream pre-built libclang. Compile the ycm_core library that YCM needs. This libraryis the C++ engine that YCM uses to get fast completions. You will need to have cmake installed in order to generate the requiredmakefiles. Linux users can install cmake with their package manager (sudo apt-get install cmake for Ubuntu) whereas other users can download andinstall cmake from its project site. Mac users can also getit through Homebrew with brew install cmake. On a Unix OS, you need to make sure you have Python headers installed. On aDebian-like Linux distro, this would be sudo apt-get install python-dev python3-dev. On Mac they should already be present. On Windows, you need to download and install Python 2 orPython 3. Pick the version corresponding to your Vimarchitecture. You will also need Microsoft Visual C++ (MSVC) to build YCM.You can obtain it by installing Visual Studio.MSVC 12 (Visual Studio 2013), 14 (2015), and 15 (2017) are officiallysupported. Here we’ll assume you installed YCM with Vundle. That means that thetop-level YCM directory is in ~/.vim/bundle/YouCompleteMe. We’ll create a new folder where build files will be placed. Run thefollowing: cd ~ mkdir ycm_build cd ycm_build Now we need to generate the makefiles. If you DON’T care about semanticsupport for C-family languages, run the following command in the ycm_builddirectory: cmake -G &quot;&lt;generator&gt;&quot; . ~/.vim/bundle/YouCompleteMe/third_party/ycmd/cpp where &lt;generator&gt; is Unix Makefiles on Unix systems and one of thefollowing Visual Studio generators on Windows: Visual Studio 12 Win64 Visual Studio 14 Win64 Visual Studio 15 Win64 Remove the Win64 part in these generators if your Vim architecture is32-bit. For those who want to use the system version of boost, you would pass-DUSE_SYSTEM_BOOST=ON to cmake. This may be necessary on some systemswhere the bundled version of boost doesn’t compile out of the box. NOTE: We STRONGLY recommend AGAINST use of the system boost insteadof the bundled version of boost. Random things may break. Save yourselfthe hassle and use the bundled version of boost. If you DO care about semantic support for C-family languages, then yourcmake call will be a bit more complicated. We’ll assume you downloaded abinary distribution of LLVM+Clang from llvm.org in step 3 and that youextracted the archive file to folder ~/ycm_temp/llvm_root_dir (with bin,lib, include etc. folders right inside that folder). On Windows, you canextract the files from the LLVM+Clang installer using 7-zip. NOTE: This only works with a downloaded LLVM binary package, not acustom-built LLVM! See docs below for EXTERNAL_LIBCLANG_PATH when using acustom LLVM build. With that in mind, run the following command in the ycm_build directory: cmake -G &quot;&lt;generator&gt;&quot; -DPATH_TO_LLVM_ROOT=~/ycm_temp/llvm_root_dir . ~/.vim/bundle/YouCompleteMe/third_party/ycmd/cpp where &lt;generator&gt; is replaced like above. Now that configuration files have been generated, compile the librariesusing this command: cmake --build . --target ycm_core --config Release The --config Release part is specific to Windows and will be ignored on aUnix OS. For those who want to use the system version of libclang, you would pass-DUSE_SYSTEM_LIBCLANG=ON to cmake instead of the-DPATH_TO_LLVM_ROOT=... flag. NOTE: We STRONGLY recommend AGAINST use of the system libclang insteadof the upstream compiled binaries. Random things may break. Save yourselfthe hassle and use the upstream pre-built libclang. You could also force the use of a custom libclang library with-DEXTERNAL_LIBCLANG_PATH=/path/to/libclang.so flag (the library would endwith .dylib on a Mac). Again, this flag would be used instead of theother flags. If you compiled LLVM from source, this is the flag you shouldbe using. Running the cmake command will also place the libclang.[so|dylib|dll] inthe YouCompleteMe/third_party/ycmd folder for you if you compiled withclang support (it needs to be there for YCM to work). Set up support for additional languages, as desired: C# support: install Mono on non-Windows platforms.Navigate to YouCompleteMe/third_party/ycmd/third_party/OmniSharpServerand run msbuild /property:Configuration=Release /property:Platform=&quot;Any CPU&quot; /property:TargetFrameworkVersion=v4.5 On Windows, be sure that the build utility msbuild is in yourPATH. Go support: install Go and add it to your path. Navigate toYouCompleteMe/third_party/ycmd/third_party/gocode and run go build. TypeScript support: as with the quick installation, simply npm install -g typescript after successfully installing Node.js and npm. JavaScript support: install Node.js and npm. Then navigateto YouCompleteMe/third_party/ycmd/third_party/tern_runtime and run npm install --production Rust support: install Rust. Navigate toYouCompleteMe/third_party/ycmd/third_party/racerd and run cargo build --release. Java support: install JDK8 (version 8 required). Download abinary release of eclipse.jdt.ls and extract it toYouCompleteMe/third_party/ycmd/third_party/eclipse.jdt.ls/target/repository.Note: this approach is not recommended for most users and is supportedonly for advanced users and developers of YCM on a best-efforts basis.Please use install.py to enable java support. That’s it. You’re done. Refer to the User Guide section on how to use YCM.Don’t forget that if you want the C-family semantic completion engine to work,you will need to provide the compilation flags for your project to YCM. It’s allin the User Guide. YCM comes with sane defaults for its options, but you still may want to take alook at what’s available for configuration. There are a few interesting optionsthat are conservatively turned off by default that you may want to turn on. Quick Feature SummaryGeneral (all languages) Super-fast identifier completer including tags files and syntax elements Intelligent suggestion ranking and filtering File and path suggestions Suggestions from Vim’s OmniFunc UltiSnips snippet suggestions C-family languages (C, C++, Objective C, Objective C++) Semantic auto-completion Real-time diagnostic display Go to include/declaration/definition (GoTo, etc.) Semantic type information for identifiers (GetType) Automatically fix certain errors (FixIt) View documentation comments for identifiers (GetDoc) C♯ Semantic auto-completion Real-time diagnostic display Go to declaration/definition (GoTo, etc.) Semantic type information for identifiers (GetType) Automatically fix certain errors (FixIt) Management of OmniSharp server instance View documentation comments for identifiers (GetDoc) Python Intelligent auto-completion Go to declaration/definition, find references (GoTo, GoToReferences) View documentation comments for identifiers (GetDoc) Restart JediHTTP server using a different Python interpreter Go Semantic auto-completion Go to definition (GoTo) Management of gocode server instance TypeScript Semantic auto-completion Real-time diagnostic display Renaming symbols (RefactorRename &lt;new name&gt;) Go to definition, find references (GoToDefinition, GoToReferences) Semantic type information for identifiers (GetType) View documentation comments for identifiers (GetDoc) JavaScript Intelligent auto-completion Renaming variables (RefactorRename &lt;new name&gt;) Go to definition, find references (GoToDefinition, GoToReferences) Type information for identifiers (GetType) View documentation comments for identifiers (GetDoc) Management of Tern server instance Rust Semantic auto-completion Go to definition (GoTo, GoToDefinition, and GoToDeclaration areidentical) Management of racer server instance View documentation comments for identifiers (GetDoc) JavaNOTE: Java support is currently experimental. Please let us know yourfeedback. Semantic auto-completion with automatic import insertion Go to definition (GoTo, GoToDefinition, and GoToDeclaration areidentical) Reference finding (GoToReferences) Real-time diagnostic display Renaming symbols (RefactorRename &lt;new name&gt;) View documentation comments for identifiers (GetDoc) Type information for identifiers (GetType) Automatically fix certain errors including code generation (FixIt) Code formatting (Format) Detection of java projects Management of jdt.ls server instance User GuideGeneral Usage If the offered completions are too broad, keep typing characters; YCM willcontinue refining the offered completions based on your input. Filtering is “smart-case” sensitive; if you are typing only lowercase letters,then it’s case-insensitive. If your input contains uppercase letters, then theuppercase letters in your query must match uppercase letters in the completionstrings (the lowercase letters still match both). So, “foo” matches “Foo” and“foo”, “Foo” matches “Foo” and “FOO” but not “foo”. Use the TAB key to accept a completion and continue pressing TAB to cyclethrough the completions. Use Shift-TAB to cycle backwards. Note that if you’reusing console Vim (that is, not Gvim or MacVim) then it’s likely that theShift-TAB binding will not work because the console will not pass it to Vim.You can remap the keys; see the Options section below. Knowing a little bit about how YCM works internally will prevent confusion. YCMhas several completion engines: an identifier-based completer that collects allof the identifiers in the current file and other files you visit (and your tagsfiles) and searches them when you type (identifiers are put into per-filetypegroups). There are also several semantic engines in YCM. There’s a libclang-basedcompleter that provides semantic completion for C-family languages. There’s aJedi-based completer for semantic completion for Python. There’s also anomnifunc-based completer that uses data from Vim’s omnicomplete system toprovide semantic completions when no native completer exists for that languagein YCM. There are also other completion engines, like the UltiSnips completer and thefilepath completer. YCM automatically detects which completion engine would be the best in anysituation. On occasion, it queries several of them at once, merges theoutputs and presents the results to you. Client-Server ArchitectureYCM has a client-server architecture; the Vim part of YCM is only a thin clientthat talks to the ycmd HTTP+JSON server that has the vast majority ofYCM logic and functionality. The server is started and stopped automatically asyou start and stop Vim. Completion String RankingThe subsequence filter removes any completions that do not match the input, butthen the sorting system kicks in. It’s actually very complicated and uses lotsof factors, but suffice it to say that “word boundary” (WB) subsequencecharacter matches are “worth” more than non-WB matches. In effect, this meansgiven an input of “gua”, the completion “getUserAccount” would be ranked higherin the list than the “Fooguxa” completion (both of which are subsequencematches). A word-boundary character are all capital characters, characterspreceded by an underscore and the first letter character in the completionstring. General Semantic Completion You can use Ctrl+Space to trigger the completion suggestions anywhere, evenwithout a string prefix. This is useful to see which top-level functions areavailable for use. C-family Semantic CompletionIn order to perform semantic analysis such as code completion, GoTo anddiagnostics, YouCompleteMe uses libclang. This is the library version of theclang compiler, sometimes also referred to as llvm. Like any compiler,libclang requires a set of compile flags in order to parse your code. Simplyput: If libclang can’t parse your code, YouCompleteMe can’t provide semanticanalysis. There are 2 methods which can be used to provide compile flags to libclang: Option 1: Use a compilation databaseThe easiest way to get YCM to compile your code is to use a compilationdatabase. A compilation database is usually generated by your build system(e.g. CMake) and contains the compiler invocation for each compilation unit inyour project. For information on how to generate a compilation database, see the clangdocumentation. In short: If using CMake, add -DCMAKE_EXPORT_COMPILE_COMMANDS=ON when configuring (oradd set( CMAKE_EXPORT_COMPILE_COMMANDS ON ) to CMakeLists.txt) and copy orsymlink the generated database to the root of your project. If using Ninja, check out the compdb tool (-t compdb) in itsdocs. If using GNU make, check out Bear. For other build systems, check out.ycm_extra_conf.py below. If no .ycm_extra_conf.py is found,and no ycm_global_ycm_extra_conf isconfigured, YouCompleteMe automatically tries to load a compilation database ifone is found. YCM looks for a file named compile_commands.json in the directory of theopened file or in any directory above it in the hierarchy (recursively); whenthe file is found, it is loaded. YouCompleteMe performs the following lookupswhen extracting flags for a particular file: If the database contains an entry for the file, the flags for that file areused. If the file is a header file and a source file with the same root exists inthe database, the flags for the source file are used. For example, if the fileis /home/Test/project/src/lib/something.h and the database contains an entryfor /home/Test/project/src/lib/something.cc, then the flags for/home/Test/project/src/lib/something.cc are used. Otherwise, if any flags have been returned from the directory containing therequested file, those flags are used. This heuristic is intended to providepotentially working flags for newly created files. Finally, YCM converts any relative paths in the extracted flags to absolutepaths. This ensures that compilation can be performed from any Vim workingdirectory. Option 2: Provide the flags manuallyIf you don’t have a compilation database, or aren’t able to generate one,you have to tell YouCompleteMe how to compile your code some other way. Every c-family project is different. It is not possible for YCM to guess whatcompiler flags to supply for your project. Fortunately, YCM provides a mechanismfor you to generate the flags for a particular file with arbitrary complexity.This is achieved by requiring you to provide a Python module which implements atrival function which, given the file name as argument, returns a list ofcompiler flags to use to compile that file. YCM looks for a .ycm_extra_conf.py file in the directory of the opened file orin any directory above it in the hierarchy (recursively); when the file isfound, it is loaded (only once!) as a Python module. YCM calls a FlagsForFilemethod in that module which should provide it with the information necessary tocompile the current file. You can also provide a path to a global.ycm_extra_conf.py file, which will be used as a fallback. To prevent theexecution of malicious code from a file you didn’t write YCM will ask you onceper .ycm_extra_conf.py if it is safe to load. This can be disabled and you canwhite-/blacklist files. See the Options section for more details. This system was designed this way so that the user can perform any arbitrarysequence of operations to produce a list of compilation flags YCM should handto Clang. NOTE: It is highly recommended to include -x &lt;language&gt; flag to libclang.This is so that the correct language is detected, particularly for header files.Common values are -x c for C, -x c++ for C++ and -x objc for Objective-C. To give you an impression, if your c++ project is trivial, and your usualcompilation command is: g++ -Wall -Wextra -Werror -o FILE.o FILE.cc, then thefollowing .ycm_extra_conf.py is enough to get semantic analysis fromYouCompleteMe: def FlagsForFile( filename, **kwargs ): return &#123; 'flags': [ '-x', 'c++', '-Wall', '-Wextra', '-Werror' ], &#125; As you can see from the trivial example, YCM calls the FlagsForFile method,passing it the file name. The **kwargs is for advanced users and can usuallybe ignored. The FlagsForFile function returns a dictionary with a singleelement &#39;flags&#39;. This element is a list of compiler flags to pass tolibclang for the file filename. That’s it! This is actually enough for mostprojects, but for complex projects it is not uncommon to integrate directly withan existing build system using the full power of the Python language. For a more elaborate example,see YCM’s own .ycm_extra_conf.py. You should be able to useit as a starting point. Don’t just copy/paste that file somewhere andexpect things to magically work; your project needs different flags. Hint:just replace the strings in the flags variable with compilation flagsnecessary for your project. That should be enough for 99% of projects. You could also consider using YCM-Generator to generate theycm_extra_conf.py file. Errors during compilationIf Clang encounters errors when compiling the header files that your fileincludes, then it’s probably going to take a long time to get completions. Whenthe completion menu finally appears, it’s going to have a large number ofunrelated completion strings (type/function names that are not actuallymembers). This is because Clang fails to build a precompiled preamble for yourfile if there are any errors in the included headers and that preamble is key togetting fast completions. Call the :YcmDiags command to see if any errors or warnings were detected inyour file. JavaScript Semantic CompletionJavaScript quick start Ensure that you have enabled the JavaScript completer. See theinstallation guide for details. Create a .tern-project file in the root directory of your JavaScriptproject, by following the instructions in the Terndocumentation. Edit a file from your project. ExplanationJavaScript completion is based on Tern. This completion engine requires afile named .tern-project to exist in the current workingdirectory or a directory which is an ancestor of the current working directorywhen the Tern server is started. YCM starts the Tern server the first time aJavaScript file is edited and uses its directory as the working directory, sothe directory of that file at that time needs to be a descendent of thedirectory containing the .tern-project file (or that directory itself). Alternatively, as described in the Tern documentation, a global.tern-config file may be used. Multiple Tern servers are not supported. To switch to a different JavaScriptproject, you need to restart the Tern server using the RestartServersubcommand while editing a file of thatproject: :YcmCompleter RestartServer Tips and tricksThis section contains some advice for configuring .tern-project and workingwith JavaScript files. The canonical reference for correctly configuring Tern isthe Tern documentation. Any issues, improvements, advice, etc.should be sought from the Tern project. For example, see the list of ternplugins for the list of pluginswhich can be enabled in the plugins section of the .tern-project file. Configuring Tern for node supportThe following simple example .tern-project file enables nodejs support: &#123; \"plugins\": &#123; \"node\": &#123;&#125; &#125;&#125; Configuring Tern for requirejs supportThe Tern requirejs plugin requires that all included “libraries” are rootedunder the same base directory. If that’s not the case for your projects, then itis possible to make it work with appropriate symbolic links. For example, createa directory ext_lib within your project and populate it with symlinks to yourlibraries. Then set up the .tern-project something like this: &#123; \"plugins\": &#123; \"requirejs\": &#123; \"baseURL\": \"./ext_lib\", &#125; &#125;&#125; Then, given the following structure: ./ext_lib/mylib (symlink)./ext_lib/anotherlib (symlink) Can be used as follows: define( [ 'mylib/file1', 'anotherlib/anotherfile' ], function( f1, f2 ) &#123; // etc.&#125; ); Rust Semantic CompletionCompletions and GoTo commands within the current crate and its dependenciesshould work out of the box with no additional configuration (provided that youbuilt YCM with the --rust-completer flag; see the Installationsection for details). For semantic analysis inclusive of thestandard library, you must have a local copy of the Rust sourcecode. If using rustup, run the following command to download thecode:rustup component add rust-src YCM will find its location automatically. Otherwise, download the archive,extract it somewhere, and set the following option so YCM can locate it:&quot; In this example, the Rust source code archive has been extracted to&quot; /usr/local/rust/rustc-1.20.0let g:ycm_rust_src_path = &apos;/usr/local/rust/rustc-1.20.0/src&apos; Python Semantic CompletionCompletion and GoTo commands work out of the box with no additionalconfiguration. Those features are provided by the jedi library whichsupports a variety of Python versions (2.6, 2.7, 3.2+) as long as itruns in the corresponding Python interpreter. By default YCM runs jedi withthe same Python interpreter used by the ycmd server, so if you would like touse a different interpreter, use the following option specifying the Pythonbinary to use. For example, to provide Python 3 completion in your project, set: let g:ycm_python_binary_path = &apos;/usr/bin/python3&apos; If the value of g:ycm_python_binary_path is an absolute path like above itwill be used as-is, but if it’s an executable name it will be searched throughthe PATH. So for example if you set: let g:ycm_python_binary_path = &apos;python&apos; YCM will use the first python executable it finds in the PATH to runjedi. This means that if you are in a virtual environment and you start vimin that directory, the first python that YCM will find will be the one in thevirtual environment, so jedi will be able to provide completions for everypackage you have in the virtual environment. Java Semantic Completion注意：Java支持当前是实验性的。请让我们知道你的反馈feedback. Java quick Start Ensure that you have enabled the Java completer. See theinstallation guide for details. Create a project file (gradle or maven) file in the root directory of yourJava project, by following the instructions below. If you previously used Eclim or Syntastic for Java, disable them for Java. Edit a Java file from your project. For the best experience, we highly recommend at least Vim 8.0.1493 when usingJava support with YouCompleteMe. Java Project FilesIn order to provide semantic analysis, the Java completion engine requiresknowledge of your project structure. In particular it needs to know the classpath to use, when compiling your code. Fortunately jdt.lssupports eclipse project files,maven projects and gradle projects. NOTE: Our recommendation is to use either maven or gradle projects. Diagnostic display - SyntasticThe native support for Java includes YCM’s native realtime diagnostics display.This can conflict with other dianostics plugins like Syntastic, so when enablingJava support, please manually disable Syntastic Java diagnostics. Add the following to your vimrc: let g:syntastic_java_checkers = [] Diagnostic display - EclimThe native support for Java includes YCM’s native realtime diagnostics display.This can conflict with other dianostics plugins like Eclim, so when enablingJava support, please manually disable Eclim Java diagnostics. Add the following to your vimrc: let g:EclimFileTypeValidate = 0 NOTE: We recommend disabling Eclim entirely when editing Java with YCM’snative Java support. This can be done temporarily with :EclimDisable. Eclipse ProjectsEclipse style projects require two files: .project and.classpath. If your project already has these files due to previously being set up withineclipse, then no setup is required. jdt.ls should load the project justfine (it’s basically eclipse after all). However, if not, it is possible (easy in fact) to craft them manually, though itis not recommended. You’re better off using gradle or maven (see below). A simple eclipse style project example can be found inthe ycmd test dir. Normally all that is required is to copy these files to theroot of your project and to edit the .classpath to add additional libraries,such as: &lt;classpathentry kind=\"lib\" path=\"/path/to/external/jar\" /&gt;&lt;classpathentry kind=\"lib\" path=\"/path/to/external/java/source\" /&gt; It may also be necessary to change the directory in which your source files arelocated (paths are relative to the .project file itself): &lt;classpathentry kind=\"src\" output=\"target/classes\" path=\"path/to/src/\" /&gt; NOTE: The eclipse project and classpath files are not a public interfaceand it is highly recommended to use Maven or Gradle project definitions if youdon’t already use eclipse to manage your projects. Maven ProjectsMaven needs a file named pom.xml in the root of the project.Once again a simple pom.xml can be found in ycmd source. The format of pom.xml files is way beyond the scope of thisdocument, but we do recommend using the various tools that can generate them foryou, if you’re not familiar with them already. Gradle ProjecsGradle projects require a build.gradle. Again, there is atrivial example in ycmd’s tests. The format of build.gradle files is way beyond the scope ofthis document, but we do recommend using the various tools that can generatethem for you, if you’re not familiar with them already. TroubleshootingIf you’re not getting completions or diagnostics, check the server health: The Java completion engine takes a while to start up and parse your project.You should be able to see its progress in the command line, and:YcmDebugInfo. Ensure that the following lines are present: -- jdt.ls Java Language Server running-- jdt.ls Java Language Server Startup Status: Ready If the above lines don’t appear after a few minutes, check the jdt.ls and ycmdlog files using :YcmToggleLogs . The jdt.lslog file is called .log (for some reason). If you get a message about “classpath is incomplete”, then make sure you havecorrectly configured the project files. If you get messages about unresolved imports, then make sure you havecorrectly configured the project files, in particularcheck that the classpath is set correctly. For anything else, contact us. Java support is experimental atpresent so we’d love to hear your feedback! Please do remember to checkCONTRIBUTING.md for the list of diagnostics we’ll need. Semantic Completion for Other LanguagesC-family, C#, Go, Java, JavaScript, Python, Rust, and TypeScript languages aresupported natively by YouCompleteMe using the Clang, OmniSharp,Gocode/Godef, jdt.ls, Tern, Jedi, racer, andTSServer engines, respectively. Check the installationsection for instructions to enable these features if desired. YCM will use your omnifunc (see :h omnifunc in Vim) as a source for semanticcompletions if it does not have a native semantic completion engine for yourfile’s filetype. Vim comes with okayish omnifuncs for various languages likeRuby, PHP, etc. It depends on the language. You can get a stellar omnifunc for Ruby with Eclim. Just make sure you havethe latest Eclim installed and configured (this means Eclim &gt;= 2.2.* andEclipse &gt;= 4.2.*). After installing Eclim remember to create a new Eclipse project within yourapplication by typing :ProjectCreate &lt;path-to-your-project&gt; -n ruby inside vimand don’t forget to have let g:EclimCompletionMethod = &#39;omnifunc&#39; in yourvimrc. This will make YCM and Eclim play nice; YCM will use Eclim’s omnifuncs asthe data source for semantic completions and provide the auto-triggering andsubsequence-based matching (and other YCM features) on top of it. Writing New Semantic CompletersYou have two options here: writing an omnifunc for Vim’s omnicomplete systemthat YCM will then use through its omni-completer, or a custom completer for YCMusing the Completer API. Here are the differences between the two approaches: You have to use VimScript to write the omnifunc, but get to use Python towrite for the Completer API; this by itself should make you want to use theAPI. The Completer API is a much more powerful way to integrate with YCM and itprovides a wider set of features. For instance, you can make your Completerquery your semantic back-end in an asynchronous fashion, thus not blockingVim’s GUI thread while your completion system is processing stuff. This isimpossible with VimScript. All of YCM’s completers use the Completer API. Performance with the Completer API is better since Python executes faster thanVimScript. If you want to use the omnifunc system, see the relevant Vim docs with :h complete-functions. For the Completer API, see the API docs. If you want to upstream your completer into YCM’s source, you should use theCompleter API. Diagnostic DisplayYCM will display diagnostic notifications for C-family and C# languages if youcompiled YCM with Clang and Omnisharp support, respectively. Diagnostics willalso be displayed for TypeScript. Since YCM continuously recompiles your file asyou type, you’ll get notified of errors and warnings in your file as fast aspossible. Here are the various pieces of the diagnostic UI: Icons show up in the Vim gutter on lines that have a diagnostic. Regions of text related to diagnostics are highlighted (by default, a redwavy underline in gvim and a red background in vim). Moving the cursor to a line with a diagnostic echoes the diagnostic text. Vim’s location list is automatically populated with diagnostic data (off bydefault, see options). The new diagnostics (if any) will be displayed the next time you press any keyon the keyboard. So if you stop typing and just wait for the new diagnostics tocome in, that will not work. You need to press some key for the GUI to update. Having to press a key to get the updates is unfortunate, but cannot be changeddue to the way Vim internals operate; there is no way that a background task canupdate Vim’s GUI after it has finished running. You have to press a key. Thiswill make YCM check for any pending diagnostics updates. You can force a full, blocking compilation cycle with the:YcmForceCompileAndDiagnostics command (you may want to map that command to akey; try putting nnoremap &lt;F5&gt; :YcmForceCompileAndDiagnostics&lt;CR&gt; in yourvimrc). Calling this command will force YCM to immediately recompile your fileand display any new diagnostics it encounters. Do note that recompilation withthis command may take a while and during this time the Vim GUI will beblocked. YCM will display a short diagnostic message when you move your cursor to theline with the error. You can get a detailed diagnostic message with the&lt;leader&gt;d key mapping (can be changed in the options) YCM provides when yourcursor is on the line with the diagnostic. You can also see the full diagnostic message for all the diagnostics in thecurrent file in Vim’s locationlist, which can be opened with the :lopen and:lclose commands (make sure you have set let g:ycm_always_populate_location_list = 1 in your vimrc). A good way to togglethe display of the locationlist with a single key mapping is provided byanother (very small) Vim plugin called ListToggle (which also makes itpossible to change the height of the locationlist window), also written byyours truly. Diagnostic Highlighting GroupsYou can change the styling for the highlighting groups YCM uses. For the signsin the Vim gutter, the relevant groups are: YcmErrorSign, which falls back to group SyntasticErrorSign and thenerror if they exist YcmWarningSign, which falls back to group SyntasticWarningSign and thentodo if they exist You can also style the line that has the warning/error with these groups: YcmErrorLine, which falls back to group SyntasticErrorLine if it exists YcmWarningLine, which falls back to group SyntasticWarningLine if itexists Note that the line highlighting groups only work when gutter signs are turnedon. The syntax groups used to highlight regions of text with errors/warnings: YcmErrorSection, which falls back to group SyntasticError if it exists andthen SpellBad YcmWarningSection, which falls back to group SyntasticWarning if it existsand then SpellCap Here’s how you’d change the style for a group: highlight YcmErrorLine guibg=#3f0000 CommandsThe :YcmRestartServer commandIf the ycmd completion server suddenly stops for some reason, you canrestart it with this command. The :YcmForceCompileAndDiagnostics commandCalling this command will force YCM to immediately recompile your fileand display any new diagnostics it encounters. Do note that recompilation withthis command may take a while and during this time the Vim GUI will beblocked. You may want to map this command to a key; try putting nnoremap &lt;F5&gt; :YcmForceCompileAndDiagnostics&lt;CR&gt; in your vimrc. The :YcmDiags commandCalling this command will fill Vim’s locationlist with errors or warnings ifany were detected in your file and then open it. If a given error or warning canbe fixed by a call to :YcmCompleter FixIt, then (FixIt available) isappended to the error or warning text. See the FixIt completer subcommand formore information. NOTE: The absense of (FixIt available) does not strictly imply a fix-itis not available as not all completers are able to provide this indication. Forexample, the c-sharp completer provides many fix-its but does not add thisadditional indication. The g:ycm_open_loclist_on_ycm_diags option can be used to prevent the locationlist from opening, but still have it filled with new diagnostic data. See theOptions section for details. The :YcmShowDetailedDiagnostic commandThis command shows the full diagnostic text when the user’s cursor is on theline with the diagnostic. The :YcmDebugInfo commandThis will print out various debug information for the current file. Useful tosee what compile commands will be used for the file if you’re using the semanticcompletion engine. The :YcmToggleLogs commandThis command presents the list of logfiles created by YCM, the ycmdserver, and the semantic engine server for the current filetype, if any.One of these logfiles can be opened in the editor (or closed if already open) byentering the corresponding number or by clicking on it with the mouse.Additionally, this command can take the logfile names as arguments. Use the&lt;TAB&gt; key (or any other key defined by the wildchar option) to complete thearguments or to cycle through them (depending on the value of the wildmodeoption). Each logfile given as an argument is directly opened (or closed ifalready open) in the editor. Only for debugging purposes. The :YcmCompleter commandThis command gives access to a number of additional IDE-likefeatures in YCM, for things like semantic GoTo, typeinformation, FixIt and refactoring. Technically the command invokes completer-specific commands. If the firstargument is of the form ft=... the completer for that file type will be used(for example ft=cpp), else the native completer of the current buffer will beused. This command also accepts a range that can either be specified through aselection in one of Vim’s visual modes (see :h visual-use) or on the commandline. For instance, :2,5YcmCompleter will apply the command from line 2 toline 5. This is useful for the Format subcommand. Call YcmCompleter without further arguments for a list of thecommands you can call for the current completer. See the file type feature summary for an overview ofthe features available for each file type. See the YcmCompleter subcommandssection for more information on the available subcommands and their usage. YcmCompleter SubcommandsNOTE: See the docs for the YcmCompleter command before tackling thissection. The invoked subcommand is automatically routed to the currently active semanticcompleter, so :YcmCompleter GoToDefinition will invoke the GoToDefinitionsubcommand on the Python semantic completer if the currently active file is aPython one and on the Clang completer if the currently active file is aC/C++/Objective-C one. You may also want to map the subcommands to something less verbose; forinstance, nnoremap &lt;leader&gt;jd :YcmCompleter GoTo&lt;CR&gt;maps the &lt;leader&gt;jd sequence to the longer subcommand invocation. GoTo CommandsThese commands are useful for jumping around and exploring code. When movingthe cursor, the subcommands add entries to Vim’s jumplist so you can useCTRL-O to jump back to where you were before invoking the command (andCTRL-I to jump forward; see :h jumplist for details). If there is morethan one destination, the quickfix list (see :h quickfix) is populated withthe available locations and opened to full width at the bottom of the screen.You can change this behavior by using the YcmQuickFixOpenedautocommand. The GoToInclude subcommandLooks up the current line for a header and jumps to it. Supported in filetypes: c, cpp, objc, objcpp The GoToDeclaration subcommandLooks up the symbol under the cursor and jumps to its declaration. Supported in filetypes: c, cpp, objc, objcpp, cs, go, python, rust, java The GoToDefinition subcommandLooks up the symbol under the cursor and jumps to its definition. NOTE: For C-family languages this only works in certain situations,namely when the definition of the symbol is in the current translation unit. Atranslation unit consists of the file you are editing and all the files you areincluding with #include directives (directly or indirectly) in that file. Supported in filetypes: c, cpp, objc, objcpp, cs, go, javascript, python, rust, typescript, java The GoTo subcommandThis command tries to perform the “most sensible” GoTo operation it can.Currently, this means that it tries to look up the symbol under the cursor andjumps to its definition if possible; if the definition is not accessible fromthe current translation unit, jumps to the symbol’s declaration. ForC/C++/Objective-C, it first tries to look up the current line for a header andjump to it. For C#, implementations are also considered and preferred. Supported in filetypes: c, cpp, objc, objcpp, cs, go, javascript, python, rust, java The GoToImprecise subcommandWARNING: This command trades correctness for speed! Same as the GoTo command except that it doesn’t recompile the file withlibclang before looking up nodes in the AST. This can be very useful when you’reediting files that take long to compile but you know that you haven’t made anychanges since the last parse that would lead to incorrect jumps. When you’rejust browsing around your codebase, this command can spare you quite a bit oflatency. Supported in filetypes: c, cpp, objc, objcpp The GoToReferences subcommandThis command attempts to find all of the references within the project to theidentifier under the cursor and populates the quickfix list with thoselocations. Supported in filetypes: javascript, python, typescript, java The GoToImplementation subcommandLooks up the symbol under the cursor and jumps to its implementation (i.e.non-interface). If there are multiple implementations, instead provides a listof implementations to choose from. Supported in filetypes: cs, java The GoToImplementationElseDeclaration subcommandLooks up the symbol under the cursor and jumps to its implementation if one,else jump to its declaration. If there are multiple implementations, insteadprovides a list of implementations to choose from. Supported in filetypes: cs Semantic Information CommandsThese commands are useful for finding static information about the code, suchas the types of variables, viewing declarations and documentation strings. The GetType subcommandEchos the type of the variable or method under the cursor, and where it differs,the derived type. For example: std::string s; Invoking this command on s returns std::string =&gt; std::basic_string&lt;char&gt; NOTE: Causes re-parsing of the current translation unit. Supported in filetypes: c, cpp, objc, objcpp, javascript, typescript, java The GetTypeImprecise subcommandWARNING: This command trades correctness for speed! Same as the GetType command except that it doesn’t recompile the file withlibclang before looking up nodes in the AST. This can be very useful when you’reediting files that take long to compile but you know that you haven’t made anychanges since the last parse that would lead to incorrect type. When you’rejust browsing around your codebase, this command can spare you quite a bit oflatency. Supported in filetypes: c, cpp, objc, objcpp The GetParent subcommandEchos the semantic parent of the point under the cursor. The semantic parent is the item that semantically contains the given position. For example: class C &#123; void f();&#125;;void C::f() &#123;&#125; In the out-of-line definition of C::f, the semantic parent is the class C,of which this function is a member. In the example above, both declarations of C::f have C as their semanticcontext, while the lexical context of the first C::f is C and the lexicalcontext of the second C::f is the translation unit. For global declarations, the semantic parent is the translation unit. NOTE: Causes re-parsing of the current translation unit. Supported in filetypes: c, cpp, objc, objcpp The GetDoc subcommandDisplays the preview window populated with quick info about the identifierunder the cursor. Depending on the file type, this includes things like: The type or declaration of identifier, Doxygen/javadoc comments, Python docstrings, etc. Supported in filetypes: c, cpp, objc, objcpp, cs, python, typescript, javascript, rust, java The GetDocImprecise subcommandWARNING: This command trades correctness for speed! Same as the GetDoc command except that it doesn’t recompile the file withlibclang before looking up nodes in the AST. This can be very useful when you’reediting files that take long to compile but you know that you haven’t made anychanges since the last parse that would lead to incorrect docs. When you’rejust browsing around your codebase, this command can spare you quite a bit oflatency. Supported in filetypes: c, cpp, objc, objcpp Refactoring CommandsThese commands make changes to your source code in order to perform refactoringor code correction. YouCompleteMe does not perform any action which cannot beundone, and never saves or writes files to the disk. The FixIt subcommandWhere available, attempts to make changes to the buffer to correct diagnosticson the current line. Where multiple suggestions are available (such as whenthere are multiple ways to resolve a given warning, or where multiplediagnostics are reported for the current line), the options are presentedand one can be selected. Completers which provide diagnostics may also provide trivial modifications tothe source in order to correct the diagnostic. Examples include syntax errorssuch as missing trailing semi-colons, spurious characters, or other errors whichthe semantic engine can deterministically suggest corrections. If no fix-it is available for the current line, or there is no diagnostic on thecurrent line, this command has no effect on the current buffer. If anymodifications are made, the number of changes made to the buffer is echo’d andthe user may use the editor’s undo command to revert. When a diagnostic is available, and g:ycm_echo_current_diagnostic is set to 1,then the text (FixIt) is appended to the echo’d diagnostic when thecompleter is able to add this indication. The text (FixIt available) isalso appended to the diagnostic text in the output of the :YcmDiags commandfor any diagnostics with available fix-its (where the completer can provide thisindication). NOTE: Causes re-parsing of the current translation unit. Supported in filetypes: c, cpp, objc, objcpp, cs, java The RefactorRename &lt;new name&gt; subcommandIn supported file types, this command attempts to perform a semantic rename ofthe identifier under the cursor. This includes renaming declarations,definitions and usages of the identifier, or any other language-appropriateaction. The specific behavior is defined by the semantic engine in use. Similar to FixIt, this command applies automatic modifications to your sourcefiles. Rename operations may involve changes to multiple files, which may or maynot be open in Vim buffers at the time. YouCompleteMe handles all of this foryou. The behavior is described in the following section. Supported in filetypes: javascript (variables only), typescript, java Multi-file RefactorWhen a Refactor or FixIt command touches multiple files, YouCompleteMe attemptsto apply those modifications to any existing open, visible buffer in the currenttab. If no such buffer can be found, YouCompleteMe opens the file in a newsmall horizontal split at the top of the current window, applies the change,and then hides the window. NOTE: The buffer remains open, and must bemanually saved. A confirmation dialog is opened prior to doing this to remindyou that this is about to happen. Once the modifications have been made, the quickfix list (see :help quickfix)is populated with the locations of all modifications. This can be used to reviewall automatic changes made by using :copen. Typically, use the `CTRL-W combination to open the selected file in a new split. It is possible to customize how the quickfix window is opened by using [theYcmQuickFixOpened`autocommand](#the-ycmquickfixopened-autocommand). The buffers are not saved automatically. That is, you must save the modifiedbuffers manually after reviewing the changes from the quickfix list. Changescan be undone using Vim’s powerful undo features (see :help undo). Notethat Vim’s undo is per-buffer, so to undo all changes, the undo commands mustbe applied in each modified buffer separately. NOTE: While applying modifications, Vim may find files which are alreadyopen and have a swap file. The command is aborted if you select Abort or Quit inany such prompts. This leaves the Refactor operation partially complete and mustbe manually corrected using Vim’s undo features. The quickfix list is notpopulated in this case. Inspect :buffers or equivalent (see :help buffers)to see the buffers that were opened by the command. The Format subcommandThis commands formats the whole buffer or some part of it according to the valueof the Vim options shiftwidth and expandtab (see :h &#39;sw&#39; and :h etrespectively). To format a specific part of your document, you can either selectit in one of Vim’s visual modes (see :h visual-use) and run the command ordirectly enter the range on the command line, e.g. :2,5YcmCompleter Format toformat it from line 2 to line 5. Supported in filetypes: java Miscellaneous CommandsThese commands are for general administration, rather than IDE-like features.They cover things like the semantic engine server instance and compilationflags. The RestartServer subcommandRestarts the semantic-engine-as-localhost-server for those semantic engines thatwork as separate servers that YCM talks to. Use this subcommand while editing a file from a JavaScript project to switch tothat project. An additional optional argument may be supplied for Python, specifying thepython binary to use to restart the Python semantic engine. :YcmCompleter RestartServer /usr/bin/python3.4 Supported in filetypes: cs, go, javascript, python, rust, typescript, java The ClearCompilationFlagCache subcommandYCM caches the flags it gets from the FlagsForFile function in yourycm_extra_conf.py file unless you return them with the do_cache parameterset to False. It also caches the flags extracted from the compilationdatabase. The cache is in memory and is never invalidated (unless you restartthe server with the :YcmRestartServer command). This command clears that cache entirely. YCM will then re-query yourFlagsForFile function or your compilation database as needed in the future. Supported in filetypes: c, cpp, objc, objcpp The ReloadSolution subcommandInstruct the Omnisharp server to clear its cache and reload all files from disk.This is useful when files are added, removed, or renamed in the solution, filesare changed outside of Vim, or whenever Omnisharp cache is out-of-sync. Supported in filetypes: cs FunctionsThe youcompleteme#GetErrorCount functionGet the number of YCM Diagnostic errors. If no errors are present, this functionreturns 0. For example:call youcompleteme#GetErrorCount() Both this function and youcompleteme#GetWarningCount can be useful whenintegrating YCM with other Vim plugins. For example, a lightline user couldadd a diagnostics section to their statusline which would display the number oferrors and warnings. The youcompleteme#GetWarningCount functionGet the number of YCM Diagnostic warnings. If no warnings are present, thisfunction returns 0. For example:call youcompleteme#GetWarningCount() AutocommandsThe YcmLocationOpened autocommandThis User autocommand is fired when YCM opens the location list window inresponse to the YcmDiags command. By default, the location list window isopened to the bottom of the current window and its height is set to fit allentries. This behavior can be overridden by using the YcmLocationOpenedautocommand which is triggered while the cursor is in the location list window.For instance:function! s:CustomizeYcmLocationWindow() &quot; Move the window to the top of the screen. wincmd K &quot; Set the window height to 5. 5wincmd _ &quot; Switch back to working window. wincmd pendfunctionautocmd User YcmLocationOpened call s:CustomizeYcmLocationWindow() The YcmQuickFixOpened autocommandThis User autocommand is fired when YCM opens the quickfix window in responseto the GoTo* and RefactorRename subcommands. By default, the quickfix windowis opened to full width at the bottom of the screen and its height is set to fitall entries. This behavior can be overridden by using the YcmQuickFixOpenedautocommand which is triggered while the cursor is in the quickfix window. Forinstance:function! s:CustomizeYcmQuickFixWindow() &quot; Move the window to the top of the screen. wincmd K &quot; Set the window height to 5. 5wincmd _endfunctionautocmd User YcmQuickFixOpened call s:CustomizeYcmQuickFixWindow() OptionsAll options have reasonable defaults so if the plug-in works after installationyou don’t need to change any options. These options can be configured in yourvimrc script by including a line like this: let g:ycm_min_num_of_chars_for_completion = 1 Note that after changing an option in your vimrc script you have torestart Vim for the changes to take effect. The g:ycm_min_num_of_chars_for_completion optionThis option controls the number of characters the user needs to type beforeidentifier-based completion suggestions are triggered. For example, if theoption is set to 2, then when the user types a second alphanumeric characterafter a whitespace character, completion suggestions will be triggered. Thisoption is NOT used for semantic completion. Setting this option to a high number like 99 effectively turns off theidentifier completion engine and just leaves the semantic engine. Default: 2 let g:ycm_min_num_of_chars_for_completion = 2 The g:ycm_min_num_identifier_candidate_chars optionThis option controls the minimum number of characters that a completioncandidate coming from the identifier completer must have to be shown in thepopup menu. A special value of 0 means there is no limit. NOTE: This option only applies to the identifier completer; it has no effecton the various semantic completers. Default: 0 let g:ycm_min_num_identifier_candidate_chars = 0 The g:ycm_max_num_candidates optionThis option controls the maximum number of semantic completion suggestions shownin the completion menu. This only applies to suggestions from semanticcompletion engines; see the g:ycm_max_identifier_candidatesoption to limit the number ofsuggestions from the identifier-based engine. A special value of 0 means there is no limit. NOTE: Setting this option to 0 or to a value greater than 100 is notrecommended as it will slow down completion when there are a very large numberof suggestions. Default: 50 let g:ycm_max_num_candidates = 50 The g:ycm_max_num_identifier_candidates optionThis option controls the maximum number of completion suggestions from theidentifier-based engine shown in the completion menu. A special value of 0 means there is no limit. NOTE: Setting this option to 0 or to a value greater than 100 is notrecommended as it will slow down completion when there are a very large numberof suggestions. Default: 10 let g:ycm_max_num_identifier_candidates = 10 The g:ycm_auto_trigger optionWhen set to 0, this option turns off YCM’s identifier completer (theas-you-type popup) and the semantic triggers (the popup you’d get after typing. or -&gt; in say C++). You can still force semantic completion with the&lt;C-Space&gt; shortcut. If you want to just turn off the identifier completer but keep the semantictriggers, you should set g:ycm_min_num_of_chars_for_completion to a highnumber like 99. Default: 1 let g:ycm_auto_trigger = 1 The g:ycm_filetype_whitelist optionThis option controls for which Vim filetypes (see :h filetype) should YCM beturned on. The option value should be a Vim dictionary with keys being filetypestrings (like python, cpp etc) and values being unimportant (the dictionaryis used like a hash set, meaning that only the keys matter). The * key is special and matches all filetypes. By default, the whitelistcontains only this * key. YCM also has a g:ycm_filetype_blacklist option that lists filetypes for whichYCM shouldn’t be turned on. YCM will work only in filetypes that both thewhitelist and the blacklist allow (the blacklist “allows” a filetype by nothaving it as a key). For example, let’s assume you want YCM to work in files with the cpp filetype.The filetype should then be present in the whitelist either directly (cpp keyin the whitelist) or indirectly through the special * key. It should not bepresent in the blacklist. Filetypes that are blocked by the either of the lists will be completely ignoredby YCM, meaning that neither the identifier-based completion engine nor thesemantic engine will operate in them. You can get the filetype of the current file in Vim with :set ft?. Default: {&#39;*&#39; : 1} let g:ycm_filetype_whitelist = &#123; &apos;*&apos;: 1 &#125; The g:ycm_filetype_blacklist optionThis option controls for which Vim filetypes (see :h filetype) should YCM beturned off. The option value should be a Vim dictionary with keys being filetypestrings (like python, cpp etc) and values being unimportant (the dictionaryis used like a hash set, meaning that only the keys matter). See the g:ycm_filetype_whitelist option for more details on how this works. Default: [see next line] let g:ycm_filetype_blacklist = &#123; \\ &apos;tagbar&apos; : 1, \\ &apos;qf&apos; : 1, \\ &apos;notes&apos; : 1, \\ &apos;markdown&apos; : 1, \\ &apos;unite&apos; : 1, \\ &apos;text&apos; : 1, \\ &apos;vimwiki&apos; : 1, \\ &apos;pandoc&apos; : 1, \\ &apos;infolog&apos; : 1, \\ &apos;mail&apos; : 1 \\&#125; The g:ycm_filetype_specific_completion_to_disable optionThis option controls for which Vim filetypes (see :h filetype) should the YCMsemantic completion engine be turned off. The option value should be a Vimdictionary with keys being filetype strings (like python, cpp etc) andvalues being unimportant (the dictionary is used like a hash set, meaning thatonly the keys matter). The listed filetypes will be ignored by the YCM semanticcompletion engine, but the identifier-based completion engine will still triggerin files of those filetypes. Note that even if semantic completion is not turned off for a specific filetype,you will not get semantic completion if the semantic engine does not supportthat filetype. You can get the filetype of the current file in Vim with :set ft?. Default: [see next line] let g:ycm_filetype_specific_completion_to_disable = &#123; \\ &apos;gitcommit&apos;: 1 \\&#125; The g:ycm_show_diagnostics_ui optionWhen set, this option turns on YCM’s diagnostic display features. See theDiagnostic display section in the User Manual for more details. Specific parts of the diagnostics UI (like the gutter signs, text highlighting,diagnostic echo and auto location list population) can be individually turned onor off. See the other options below for details. Note that YCM’s diagnostics UI is only supported for C-family languages. When set, this option also makes YCM remove all Syntastic checkers set for thec, cpp, objc and objcpp filetypes since this would conflict with YCM’sown diagnostics UI. If you’re using YCM’s identifier completer in C-family languages but cannot usethe clang-based semantic completer for those languages and want to use the GCCSyntastic checkers, unset this option. Default: 1 let g:ycm_show_diagnostics_ui = 1 The g:ycm_error_symbol optionYCM will use the value of this option as the symbol for errors in the Vimgutter. This option is part of the Syntastic compatibility layer; if the option is notset, YCM will fall back to the value of the g:syntastic_error_symbol optionbefore using this option’s default. Default: &gt;&gt; let g:ycm_error_symbol = &apos;&gt;&gt;&apos; The g:ycm_warning_symbol optionYCM will use the value of this option as the symbol for warnings in the Vimgutter. This option is part of the Syntastic compatibility layer; if the option is notset, YCM will fall back to the value of the g:syntastic_warning_symbol optionbefore using this option’s default. Default: &gt;&gt; let g:ycm_warning_symbol = &apos;&gt;&gt;&apos; The g:ycm_enable_diagnostic_signs optionWhen this option is set, YCM will put icons in Vim’s gutter on lines that have adiagnostic set. Turning this off will also turn off the YcmErrorLine andYcmWarningLine highlighting. This option is part of the Syntastic compatibility layer; if the option is notset, YCM will fall back to the value of the g:syntastic_enable_signs optionbefore using this option’s default. Default: 1 let g:ycm_enable_diagnostic_signs = 1 The g:ycm_enable_diagnostic_highlighting optionWhen this option is set, YCM will highlight regions of text that are related tothe diagnostic that is present on a line, if any. This option is part of the Syntastic compatibility layer; if the option is notset, YCM will fall back to the value of the g:syntastic_enable_highlightingoption before using this option’s default. Default: 1 let g:ycm_enable_diagnostic_highlighting = 1 The g:ycm_echo_current_diagnostic optionWhen this option is set, YCM will echo the text of the diagnostic present on thecurrent line when you move your cursor to that line. If a FixIt is availablefor the current diagnostic, then (FixIt) is appended. This option is part of the Syntastic compatibility layer; if the option is notset, YCM will fall back to the value of the g:syntastic_echo_current_erroroption before using this option’s default. Default: 1 let g:ycm_echo_current_diagnostic = 1 The g:ycm_filter_diagnostics optionThis option controls which diagnostics will be rendered by YCM. This optionholds a dictionary of key-values, where the keys are Vim’s filetype stringsdelimited by commas and values are dictionaries describing the filter. A filter is a dictionary of key-values, where the keys are the type of filter,and the value is a list of arguments to that filter. In the case of just asingle item in the list, you may omit the brackets and just provide the argumentdirectly. If any filter matches a diagnostic, it will be dropped and YCM willnot render it. The following filter types are supported: “regex”: Accepts a string regular expression. This type matcheswhen the regex (treated as case-insensitive) is found in the diagnostic text. “level”: Accepts a string level, either “warning” or “error.” This typematches when the diagnostic has the same level. NOTE: The regex syntax is NOT Vim’s, it’s Python’s. Default: {} let g:ycm_filter_diagnostics = &#123; \\ &quot;java&quot;: &#123; \\ &quot;regex&quot;: [ &quot;.*taco.*&quot;, ... ], \\ &quot;level&quot;: &quot;error&quot;, \\ ... \\ &#125; \\ &#125; The g:ycm_always_populate_location_list optionWhen this option is set, YCM will populate the location list automatically everytime it gets new diagnostic data. This option is off by default so as not tointerfere with other data you might have placed in the location list. See :help location-list in Vim to learn more about the location list. This option is part of the Syntastic compatibility layer; if the option is notset, YCM will fall back to the value of theg:syntastic_always_populate_loc_list option before using this option’sdefault. Default: 0 let g:ycm_always_populate_location_list = 0 The g:ycm_open_loclist_on_ycm_diags optionWhen this option is set, :YcmDiags will automatically open the location listafter forcing a compilation and filling the list with diagnostic data. See :help location-list in Vim to learn more about the location list. Default: 1 let g:ycm_open_loclist_on_ycm_diags = 1 The g:ycm_complete_in_comments optionWhen this option is set to 1, YCM will show the completion menu even whentyping inside comments. Default: 0 let g:ycm_complete_in_comments = 0 The g:ycm_complete_in_strings optionWhen this option is set to 1, YCM will show the completion menu even whentyping inside strings. Note that this is turned on by default so that you can use the filenamecompletion inside strings. This is very useful for instance in C-family fileswhere typing #include &quot; will trigger the start of filename completion. If youturn off this option, you will turn off filename completion in such situationsas well. Default: 1 let g:ycm_complete_in_strings = 1 The g:ycm_collect_identifiers_from_comments_and_strings optionWhen this option is set to 1, YCM’s identifier completer will also collectidentifiers from strings and comments. Otherwise, the text in comments andstrings will be ignored. Default: 0 let g:ycm_collect_identifiers_from_comments_and_strings = 0 The g:ycm_collect_identifiers_from_tags_files optionWhen this option is set to 1, YCM’s identifier completer will also collectidentifiers from tags files. The list of tags files to examine is retrieved fromthe tagfiles() Vim function which examines the tags Vim option. See :h &#39;tags&#39; for details. YCM will re-index your tags files if it detects that they have been modified. The only supported tag format is the Exuberant Ctags format. Theformat from “plain” ctags is NOT supported. Ctags needs to be called with the--fields=+l option (that’s a lowercase L, not a one) because YCM needs thelanguage:&lt;lang&gt; field in the tags output. See the FAQ for pointers if YCM does not appear to read your tag files. This option is off by default because it makes Vim slower if your tags are on anetwork directory. Default: 0 let g:ycm_collect_identifiers_from_tags_files = 0 The g:ycm_seed_identifiers_with_syntax optionWhen this option is set to 1, YCM’s identifier completer will seed itsidentifier database with the keywords of the programming language you’rewriting. Since the keywords are extracted from the Vim syntax file for the filetype, allkeywords may not be collected, depending on how the syntax file was written.Usually at least 95% of the keywords are successfully extracted. Default: 0 let g:ycm_seed_identifiers_with_syntax = 0 The g:ycm_extra_conf_vim_data optionIf you’re using semantic completion for C-family files, this option might comehandy; it’s a way of sending data from Vim to your FlagsForFile function inyour .ycm_extra_conf.py file. This option is supposed to be a list of VimScript expression strings that areevaluated for every request to the ycmd server and then passed to yourFlagsForFile function as a client_data keyword argument. For instance, if you set this option to [&#39;v:version&#39;], your FlagsForFilefunction will be called like this: # The '704' value is of course contingent on Vim 7.4; in 7.3 it would be '703'FlagsForFile(filename, client_data = &#123;'v:version': 704&#125;) So the client_data parameter is a dictionary mapping Vim expression strings totheir values at the time of the request. The correct way to define parameters for your FlagsForFile function: def FlagsForFile(filename, **kwargs): You can then get to client_data with kwargs[&#39;client_data&#39;]. Default: [] let g:ycm_extra_conf_vim_data = [] The g:ycm_server_python_interpreter optionYCM will by default search for an appropriate Python interpreter on your system.You can use this option to override that behavior and force the use of aspecific interpreter of your choosing. NOTE: This interpreter is only used for the ycmd server. The YCMclient running inside Vim always uses the Python interpreter that’s embeddedinside Vim. Default: &#39;&#39; let g:ycm_server_python_interpreter = &apos;&apos; The g:ycm_keep_logfiles optionWhen this option is set to 1, YCM and the ycmd completion server willkeep the logfiles around after shutting down (they are deleted on shutdown bydefault). To see where the logfiles are, call :YcmDebugInfo. Default: 0 let g:ycm_keep_logfiles = 0 The g:ycm_log_level optionThe logging level that YCM and the ycmd completion server use. Validvalues are the following, from most verbose to least verbose: debug info warning error critical Note that debug is very verbose. Default: info let g:ycm_log_level = &apos;info&apos; The g:ycm_auto_start_csharp_server optionWhen set to 1, the OmniSharp server will be automatically started (once perVim session) when you open a C# file. Default: 1 let g:ycm_auto_start_csharp_server = 1 The g:ycm_auto_stop_csharp_server optionWhen set to 1, the OmniSharp server will be automatically stopped uponclosing Vim. Default: 1 let g:ycm_auto_stop_csharp_server = 1 The g:ycm_csharp_server_port optionWhen g:ycm_auto_start_csharp_server is set to 1, specifies the port forthe OmniSharp server to listen on. When set to 0 uses an unused port providedby the OS. Default: 0 let g:ycm_csharp_server_port = 0 The g:ycm_csharp_insert_namespace_expr optionBy default, when YCM inserts a namespace, it will insert the using statementunder the nearest using statement. You may prefer that the using statement isinserted somewhere, for example, to preserve sorting. If so, you can set thisoption to override this behavior. When this option is set, instead of inserting the using statement itself, YCMwill set the global variable g:ycm_namespace_to_insert to the namespace toinsert, and then evaluate this option’s value as an expression. The option’sexpression is responsible for inserting the namespace - the default insertionwill not occur. Default: ‘’ let g:ycm_csharp_insert_namespace_expr = &apos;&apos; The g:ycm_add_preview_to_completeopt optionWhen this option is set to 1, YCM will add the preview string to Vim’scompleteopt option (see :h completeopt). If your completeopt optionalready has preview set, there will be no effect. You can see the currentstate of your completeopt setting with :set completeopt? (yes, the questionmark is important). When preview is present in completeopt, YCM will use the preview window atthe top of the file to store detailed information about the current completioncandidate (but only if the candidate came from the semantic engine). Forinstance, it would show the full function prototype and all the functionoverloads in the window if the current completion is a function name. Default: 0 let g:ycm_add_preview_to_completeopt = 0 The g:ycm_autoclose_preview_window_after_completion optionWhen this option is set to 1, YCM will auto-close the preview window afterthe user accepts the offered completion string. If there is no preview windowtriggered because there is no preview string in completeopt, this option isirrelevant. See the g:ycm_add_preview_to_completeopt option for more details. Default: 0 let g:ycm_autoclose_preview_window_after_completion = 0 The g:ycm_autoclose_preview_window_after_insertion optionWhen this option is set to 1, YCM will auto-close the preview window afterthe user leaves insert mode. This option is irrelevant ifg:ycm_autoclose_preview_window_after_completion is set or if no previewwindow is triggered. See the g:ycm_add_preview_to_completeopt option for moredetails. Default: 0 let g:ycm_autoclose_preview_window_after_insertion = 0 The g:ycm_max_diagnostics_to_display optionThis option controls the maximum number of diagnostics shown to the user whenerrors or warnings are detected in the file. This option is only relevant if youare using the C-family semantic completion engine. Default: 30 let g:ycm_max_diagnostics_to_display = 30 The g:ycm_key_list_select_completion optionThis option controls the key mappings used to select the first completionstring. Invoking any of them repeatedly cycles forward through the completionlist. Some users like adding &lt;Enter&gt; to this list. Default: [&#39;&lt;TAB&gt;&#39;, &#39;&lt;Down&gt;&#39;] let g:ycm_key_list_select_completion = [&apos;&lt;TAB&gt;&apos;, &apos;&lt;Down&gt;&apos;] The g:ycm_key_list_previous_completion optionThis option controls the key mappings used to select the previous completionstring. Invoking any of them repeatedly cycles backwards through the completionlist. Note that one of the defaults is &lt;S-TAB&gt; which means Shift-TAB. That mappingwill probably only work in GUI Vim (Gvim or MacVim) and not in plain console Vimbecause the terminal usually does not forward modifier key combinations to Vim. Default: [&#39;&lt;S-TAB&gt;&#39;, &#39;&lt;Up&gt;&#39;] let g:ycm_key_list_previous_completion = [&apos;&lt;S-TAB&gt;&apos;, &apos;&lt;Up&gt;&apos;] The g:ycm_key_list_stop_completion optionThis option controls the key mappings used to close the completion menu. This isuseful when the menu is blocking the view, when you need to insert the &lt;TAB&gt;character, or when you want to expand a snippet from UltiSnips and navigatethrough it. Default: [&#39;&lt;C-y&gt;&#39;] let g:ycm_key_list_stop_completion = [&apos;&lt;C-y&gt;&apos;] The g:ycm_key_invoke_completion optionThis option controls the key mapping used to invoke the completion menu forsemantic completion. By default, semantic completion is triggered automaticallyafter typing ., -&gt; and :: in insert mode (if semantic completion supporthas been compiled in). This key mapping can be used to trigger semanticcompletion anywhere. Useful for searching for top-level functions and classes. Console Vim (not Gvim or MacVim) passes &lt;Nul&gt; to Vim when the user types&lt;C-Space&gt; so YCM will make sure that &lt;Nul&gt; is used in the map command whenyou’re editing in console Vim, and &lt;C-Space&gt; in GUI Vim. This means that youcan just press &lt;C-Space&gt; in both console and GUI Vim and YCM will do the rightthing. Setting this option to an empty string will make sure no mapping is created. Default: &lt;C-Space&gt; let g:ycm_key_invoke_completion = &apos;&lt;C-Space&gt;&apos; The g:ycm_key_detailed_diagnostics optionThis option controls the key mapping used to show the full diagnostic text whenthe user’s cursor is on the line with the diagnostic. It basically calls:YcmShowDetailedDiagnostic. Setting this option to an empty string will make sure no mapping is created. Default: &lt;leader&gt;d let g:ycm_key_detailed_diagnostics = &apos;&lt;leader&gt;d&apos; The g:ycm_global_ycm_extra_conf optionNormally, YCM searches for a .ycm_extra_conf.py file for compilation flags(see the User Guide for more details on how this works). This option specifiesa fallback path to a config file which is used if no .ycm_extra_conf.py isfound. You can place such a global file anywhere in your filesystem. Default: &#39;&#39; let g:ycm_global_ycm_extra_conf = &apos;&apos; The g:ycm_confirm_extra_conf optionWhen this option is set to 1 YCM will ask once per .ycm_extra_conf.py fileif it is safe to be loaded. This is to prevent execution of malicious codefrom a .ycm_extra_conf.py file you didn’t write. To selectively get YCM to ask/not ask about loading certain .ycm_extra_conf.pyfiles, see the g:ycm_extra_conf_globlist option. Default: 1 let g:ycm_confirm_extra_conf = 1 The g:ycm_extra_conf_globlist optionThis option is a list that may contain several globbing patterns. If a patternstarts with a ! all .ycm_extra_conf.py files matching that pattern will beblacklisted, that is they won’t be loaded and no confirmation dialog will beshown. If a pattern does not start with a ! all files matching that patternwill be whitelisted. Note that this option is not used when confirmation isdisabled using g:ycm_confirm_extra_conf and that items earlier in the listwill take precedence over the later ones. Rules: * matches everything ? matches any single character [seq] matches any character in seq [!seq] matches any char not in seq Example: let g:ycm_extra_conf_globlist = [&apos;~/dev/*&apos;,&apos;!~/*&apos;] The first rule will match everything contained in the ~/dev directory so.ycm_extra_conf.py files from there will be loaded. The second rule will match everything in the home directory so a.ycm_extra_conf.py file from there won’t be loaded. As the first rule takes precedence everything in the home directory excludingthe ~/dev directory will be blacklisted. NOTE: The glob pattern is first expanded with Python’sos.path.expanduser() and then resolved with os.path.abspath() before beingmatched against the filename. Default: [] let g:ycm_extra_conf_globlist = [] The g:ycm_filepath_completion_use_working_dir optionBy default, YCM’s filepath completion will interpret relative paths like ../as being relative to the folder of the file of the currently active buffer.Setting this option will force YCM to always interpret relative paths as beingrelative to Vim’s current working directory. Default: 0 let g:ycm_filepath_completion_use_working_dir = 0 The g:ycm_semantic_triggers optionThis option controls the character-based triggers for the various semanticcompletion engines. The option holds a dictionary of key-values, where the keysare Vim’s filetype strings delimited by commas and values are lists of strings,where the strings are the triggers. Setting key-value pairs on the dictionary adds semantic triggers to theinternal default set (listed below). You cannot remove the default triggers,only add new ones. A “trigger” is a sequence of one or more characters that trigger semanticcompletion when typed. For instance, C++ (cpp filetype) has . listed as atrigger. So when the user types foo., the semantic engine will trigger andserve foo‘s list of member functions and variables. Since C++ also has -&gt;listed as a trigger, the same thing would happen when the user typed foo-&gt;. It’s also possible to use a regular expression as a trigger. You have to prefixyour trigger with re! to signify it’s a regex trigger. For instance,re!\\w+\\. would only trigger after the \\w+\\. regex matches. NOTE: The regex syntax is NOT Vim’s, it’s Python’s. Default: [see next line] let g:ycm_semantic_triggers = &#123; \\ &apos;c&apos; : [&apos;-&gt;&apos;, &apos;.&apos;], \\ &apos;objc&apos; : [&apos;-&gt;&apos;, &apos;.&apos;, &apos;re!\\[[_a-zA-Z]+\\w*\\s&apos;, &apos;re!^\\s*[^\\W\\d]\\w*\\s&apos;, \\ &apos;re!\\[.*\\]\\s&apos;], \\ &apos;ocaml&apos; : [&apos;.&apos;, &apos;#&apos;], \\ &apos;cpp,objcpp&apos; : [&apos;-&gt;&apos;, &apos;.&apos;, &apos;::&apos;], \\ &apos;perl&apos; : [&apos;-&gt;&apos;], \\ &apos;php&apos; : [&apos;-&gt;&apos;, &apos;::&apos;], \\ &apos;cs,java,javascript,typescript,d,python,perl6,scala,vb,elixir,go&apos; : [&apos;.&apos;], \\ &apos;ruby&apos; : [&apos;.&apos;, &apos;::&apos;], \\ &apos;lua&apos; : [&apos;.&apos;, &apos;:&apos;], \\ &apos;erlang&apos; : [&apos;:&apos;], \\ &#125; The g:ycm_cache_omnifunc optionSome omnicompletion engines do not work well with the YCM cache—in particular,they might not produce all possible results for a given prefix. By unsettingthis option you can ensure that the omnicompletion engine is re-queried on everykeypress. That will ensure all completions will be presented, but might causestuttering and lagginess if the omnifunc is slow. Default: 1 let g:ycm_cache_omnifunc = 1 The g:ycm_use_ultisnips_completer optionBy default, YCM will query the UltiSnips plugin for possible completions ofsnippet triggers. This option can turn that behavior off. Default: 1 let g:ycm_use_ultisnips_completer = 1 The g:ycm_goto_buffer_command optionDefines where GoTo* commands result should be opened.Can take one of the following values:[ &#39;same-buffer&#39;, &#39;horizontal-split&#39;, &#39;vertical-split&#39;, &#39;new-tab&#39;, &#39;new-or-existing-tab&#39; ]If this option is set to the &#39;same-buffer&#39; but current buffer can notbe switched (when buffer is modified and nohidden option is set),then result will be opened in horizontal split. Default: &#39;same-buffer&#39; let g:ycm_goto_buffer_command = &apos;same-buffer&apos; The g:ycm_disable_for_files_larger_than_kb optionDefines the max size (in Kb) for a file to be considered for completion. If thisoption is set to 0 then no check is made on the size of the file you’re opening. Default: 1000 let g:ycm_disable_for_files_larger_than_kb = 1000 The g:ycm_python_binary_path optionThis option specifies the Python interpreter to use to run the jedicompletion library. Specify the Python interpreter to use to get completions.By default the Python under which ycmd runs is used (ycmd runs onPython 2.7 or 3.4+). Default: &#39;&#39; let g:ycm_python_binary_path = &apos;python&apos; NOTE: the settings above will make YCM use the first python executablefound through the PATH. FAQI used to be able to import vim in .ycm_extra_conf.py, but now can’tYCM was rewritten to use a client-server architecture where most of the logic isin the ycmd server. So the magic vim module you could have previouslyimported in your .ycm_extra_conf.py files doesn’t exist anymore. To be fair, importing the magic vim module in extra conf files was neversupported in the first place; it only ever worked by accident and was never apart of the extra conf API. But fear not, you should be able to tweak your extra conf files to continueworking by using the g:ycm_extra_conf_vim_data option. See the docs on thatoption for details. I get ImportError exceptions that mention PyInit_ycm_core or initycm_coreThese errors are caused by building the YCM native libraries for Python 2 andtrying to load them into a Python 3 process (or the other way around). For instance, if building for Python 2 but loading in Python 3: ImportError: dynamic module does not define init function (PyInit_ycm_core) If building for Python 3 but loading in Python 2: ImportError: dynamic module does not define init function (initycm_core) Setting the g:ycm_server_python_interpreter option to force the use of aspecific Python interpreter for ycmd is usually the easiest way to solve theproblem. Common values for that option are /usr/bin/python and/usr/bin/python3. I get a linker warning regarding libpython on Mac when compiling YCMIf the warning is ld: warning: path &#39;/usr/lib/libpython2.7.dylib&#39; following -L not a directory, then feel free to ignore it; it’s caused by a limitation ofCMake and is not an issue. Everything should still work fine. I get a weird window at the top of my file when I use the semantic engineThis is Vim’s preview window. Vim uses it to show you extra information aboutsomething if such information is available. YCM provides Vim with such extrainformation. For instance, when you select a function in the completion list,the preview window will hold that function’s prototype and the prototypes ofany overloads of the function. It will stay there after you select thecompletion so that you can use the information about the parameters and theirtypes to write the function call. If you would like this window to auto-close after you select a completionstring, set the g:ycm_autoclose_preview_window_after_completion option to 1in your vimrc file. Similarly, the g:ycm_autoclose_preview_window_after_insertionoption can be set to close the preview window after leaving insert mode. If you don’t want this window to ever show up, add set completeopt-=preview toyour vimrc. Also make sure that the g:ycm_add_preview_to_completeopt optionis set to 0. It appears that YCM is not workingIn Vim, run :messages and carefully read the output. YCM will echo messages tothe message log if it encounters problems. It’s likely you misconfiguredsomething and YCM is complaining about it. Also, you may want to run the :YcmDebugInfo command; it will make YCM spew outvarious debugging information, including the YCM and ycmd logfile paths andthe compile flags for the current file if the file is a C-family language fileand you have compiled in Clang support. Logfiles can be opened in the editorusing the :YcmToggleLogs command. Sometimes it takes much longer to get semantic completions than normalThis means that libclang (which YCM uses for C-family semantic completion)failed to pre-compile your file’s preamble. In other words, there was an errorcompiling some of the source code you pulled in through your header files. Isuggest calling the :YcmDiags command to see what they were. Bottom line, if libclang can’t pre-compile your file’s preamble because therewere errors in it, you’re going to get slow completions because there’s no ASTcache. YCM auto-inserts completion strings I don’t want!If this happens when Vim automatically wraps text then it’s a Vim bug that hasbeen fixed in version 8.0.0127. Update your Vim to this version or later. This could also be some mappings that interfere with YCM’s internal ones. Makesure you don’t have something mapped to &lt;C-p&gt;, &lt;C-x&gt; or &lt;C-u&gt; (in insertmode). YCM never selects something for you; it just shows you a menu and the user hasto explicitly select something. If something is being selected automatically,this means there’s a bug or a misconfiguration somewhere. I get a E227: mapping already exists for &lt;blah&gt; error when I start VimThis means that YCM tried to set up a key mapping but failed because you alreadyhad something mapped to that key combination. The &lt;blah&gt; part of the messagewill tell you what was the key combination that failed. Look in the Options section and see if any of the default mappings conflictwith your own. Then change that option value to something else so that theconflict goes away. I get &#39;GLIBC_2.XX&#39; not found (required by libclang.so) when starting VimYour system is too old for the precompiled binaries from llvm.org. CompileClang on your machine and then link against the libclang.so you just produced.See the full installation guide for help. I’m trying to use a Homebrew Vim with YCM and I’m getting segfaultsSomething (I don’t know what) is wrong with the way that Homebrew configures andbuilds Vim. I recommend using MacVim. Even if you don’t like the MacVim GUI,you can use the Vim binary that is inside the MacVim.app package (it’sMacVim.app/Contents/MacOS/Vim) and get the Vim console experience. I have a Homebrew Python and/or MacVim; can’t compile/SIGABRT when startingYou should probably run brew rm python; brew install python to get the latestfixes that should make YCM work with such a configuration. Also rebuild Macvimthen. If you still get problems with this, see issue #18 forsuggestions. I get LONG_BIT definition appears wrong for platform when compilingLook at the output of your CMake call. There should be a line in it like thefollowing (with .dylib in place of .so on a Mac): -- Found PythonLibs: /usr/lib/libpython2.7.so (Required is at least version &quot;2.5&quot;) That would be the correct output. An example of incorrect output wouldbe the following: -- Found PythonLibs: /usr/lib/libpython2.7.so (found suitable version &quot;2.5.1&quot;, minimum required is &quot;2.5&quot;) Notice how there’s an extra bit of output there, the found suitable version &quot;&lt;version&gt;&quot; part, where &lt;version&gt; is not the same as the version of thedynamic library. In the example shown, the library is version 2.7 but the secondstring is version 2.5.1. This means that CMake found one version of Python headers and a differentversion for the library. This is wrong. It can happen when you have multipleversions of Python installed on your machine. You should probably add the following flags to your cmake call (again, dylibinstead of so on a Mac): -DPYTHON_INCLUDE_DIR=/usr/include/python2.7 -DPYTHON_LIBRARY=/usr/lib/libpython2.7.so This will force the paths to the Python include directory and the Python libraryto use. You may need to set these flags to something else, but you need to makesure you use the same version of Python that your Vim binary is built against,which is highly likely to be the system’s default Python. I get libpython2.7.a [...] relocation R_X86_64_32 when compilingThe error is usually encountered when compiling YCM on Centos or RHEL. The fullerror looks something like the following: /usr/bin/ld: /usr/local/lib/libpython2.7.a(abstract.o): relocation R_X86_64_32 against `a local symbol&apos; can not be used when making a shared object; recompile with -fPIC It’s possible to get a slightly different error that’s similar to the one above.Here’s the problem and how you solve it: Your libpython2.7.a was not compiled with -fPIC so it can’t be linked intoycm_core.so. Use the -DPYTHON_LIBRARY= CMake flag to point it to a .soversion of libpython on your machine (for instance,-DPYTHON_LIBRARY=/usr/lib/libpython2.7.so). Naturally, this means you’ll haveto go through the full installation guide by hand. I get Vim: Caught deadly signal SEGV on Vim startupThis can happen on some Linux distros. If you encounter this situation, run Vimunder gdb. You’ll probably see something like this in the output when Vimcrashes: undefined symbol: clang_CompileCommands_dispose This means that Vim is trying to load a libclang.so that is too old. You needat least a 3.9 libclang. Just go through the installation guide and make sureyou are using a correct libclang.so. We recommend downloading prebuiltbinaries from llvm.org. I get Fatal Python error: PyThreadState_Get: no current thread on startupThis is caused by linking a static version of libpython into ycmd’sycm_core.so. This leads to multiple copies of the python interpreter loadedwhen python loads ycmd_core.so and this messes up python’s global state.The details aren’t important. The solution is that the version of Python linked and run against must be builtwith either --enable-shared or --enable-framework (on OS X).This is achieved as follows (NOTE: for Mac, replace --enable-sharedwith --enable-framework): When building python from source: ./configure --enable-shared {options} When building python from pyenv:PYTHON_CONFIGURE_OPTS=&quot;--enable-shared&quot; pyenv install {version} install.py says python must be compiled with --enable-framework. Wat?See the previous answer for how to ensure your python is built to supportdynamic modules. YCM does not read identifiers from my tags filesFirst, put let g:ycm_collect_identifiers_from_tags_files = 1 in your vimrc. Make sure you are using Exuberant Ctags to produce your tagsfiles since the only supported tag format is the Exuberant Ctagsformat. The format from “plain” ctags is NOT supported. Theoutput of ctags --version should list “Exuberant Ctags”. Ctags needs to be called with the --fields=+l (that’s a lowercase L, not aone) option because YCM needs the language:&lt;lang&gt; field in the tags output. NOTE: Exuberant Ctags by default sets language tag for*.h files as C++. If you have C (not C++) project, consider giving parameter--langmap=c:.c.h to ctags to see tags from *.h files. NOTE: Mac OS X comes with “plain” ctags installed by default. brew install ctags will get you the Exuberant Ctags version. Also make sure that your Vim tags option is set correctly. See :h &#39;tags&#39; fordetails. If you want to see which tag files YCM will read for a given buffer,run :echo tagfiles() with the relevant buffer active. Note that that functionwill only list tag files that already exist. CTRL-U in insert mode does not work while the completion menu is visibleYCM uses completefunc completion mode to show suggestions and Vim disables&lt;C-U&gt; in that mode as a “feature.” Sadly there’s nothing I can do about this. YCM conflicts with UltiSnips TAB key usageYCM comes with support for UltiSnips (snippet suggestions in the popup menu),but you’ll have to change the UltiSnips mappings. See :h UltiSnips-triggers inVim for details. You’ll probably want to change some/all of the followingoptions: g:UltiSnipsExpandTriggerg:UltiSnipsJumpForwardTriggerg:UltiSnipsJumpBackwardTrigger Snippets added with :UltiSnipsAddFiletypes do not appear in the popup menuFor efficiency, YCM only fetches UltiSnips snippets in specific scenarios likevisiting a buffer or setting its filetype. You can force YCM to retrieve them bymanually triggering the FileType autocommand: :doautocmd FileType Why isn’t YCM just written in plain VimScript, FFS?Because of the identifier completion engine and subsequence-based filtering.Let’s say you have many dozens of files open in a single Vim instance (I oftendo); the identifier-based engine then needs to store thousands (if not tens ofthousands) of identifiers in its internal data-structures. When the user types,YCM needs to perform subsequence-based filtering on all of those identifiers(every single one!) in less than 10 milliseconds. I’m sorry, but that level of performance is just plain impossible to achievewith VimScript. I’ve tried, and the language is just too slow. No, you can’t getacceptable performance even if you limit yourself to just the identifiers in thecurrent file and simple prefix-based filtering. Why does YCM demand such a recent version of Vim?YCM needs a version of Vim with the timers feature to achieve fullasynchronicity. This feature is available since Vim 7.4.1578. Nasty bugs happen if I have the vim-autoclose plugin installedUse the delimitMate plugin instead. It does the same thing withoutconflicting with YCM. Is there some sort of YCM mailing list? I have questionsIf you have questions about the plugin or need help, please use theycm-users mailing list, don’t create issues on the tracker. The tracker isfor bug reports and feature requests. I get an internal compiler error when installingThis can be a problem on virtual servers with limited memory. A possiblesolution is to add more swap memory. A more practical solution would be to forcethe build script to run only one compile job at a time. You can do this bysetting the YCM_CORES environment variable to 1. Example: YCM_CORES=1 ./install.py --clang-completer I get weird errors when I press Ctrl-C in VimNever use Ctrl-C in Vim. Using Ctrl-C to exit insert mode in Vim is a bad idea. The main issue here isthat Ctrl-C in Vim doesn’t just leave insert mode, it leaves it withouttriggering InsertLeave autocommands (as per Vim docs). This is a bad idea andis likely to break many other things and not just YCM. Bottom line, if you use Ctrl-C to exit insert mode in Vim, you’re gonna have abad time. If pressing &lt;esc&gt; is too annoying (agreed, it is), we suggest mapping it tosomething more convenient. On a QWERTY keyboard, a good pick for the &lt;esc&gt; mapis inoremap jk &lt;Esc&gt;. This is right on the home row, it’s an incredibly raredigraph in English and if you ever need to type those two chars in sequence ininsert mode, you just type j, then wait 500ms, then type k. Why did YCM stop using Syntastic for diagnostics display?Previously, YCM would send any diagnostics it would receive from the libclangsemantic engine to Syntastic for display as signs in the gutter, red squigglesetc. Today, YCM uses its own code to do that. Using Syntastic for this was always a kludge. Syntastic assumes its “checker”plugins behave in a certain way; those assumptions have never fit YCM. Forinstance, YCM continuously recompiles your code in the background for C-familylanguages and tries to push new diagnostics to the user as fast as possible,even while the user types. Syntastic assumes that a checker only runs on file save (“active” mode) or evenless frequently, when the user explicitly invokes it (“passive” mode). Thismismatch in assumptions causes performance problems since Syntastic code isn’toptimized for this use case of constant diagnostic refreshing. Poor support for this use case also led to crash bugs in Vim caused bySyntastic-Vim interactions (issue #593) and other problems, likerandom Vim flickering. Attempts were made to resolve these issues inSyntastic, but ultimately some of them failed (for various reasons). Implementing diagnostic display code directly in YCM resolves all of theseproblems. Performance also improved substantially since the relevant code is nowwritten in Python instead of VimScript (which is very slow) and is tailored onlyfor YCM’s use-cases. We were also able to introduce new features in this areasince we’re now not limited to the Syntastic checker API. We’ve tried to implement this in the most backwards-compatible way possible; YCMoptions that control diagnostic display fall back to Syntastic options thatcontrol the same concepts if the user has those set. Still, some Syntastic-specific configuration you might have had might notbe supported by the new code. Please file issues on the tracker in suchcases; if we find the request to be reasonable, we’ll find a way to address it. Completion doesn’t work with the C++ standard library headersThis is caused by an issue with libclang that only affects some operatingsystems. Compiling with clang the binary will use the correct default headersearch paths but compiling with libclang.so (which YCM uses) does not. Mac OS X is normally affected, but there’s a workaround in YCM for that specificOS. If you’re not running that OS but still have the same problem, continuereading. The workaround is to call echo | clang -v -E -x c++ - and look at thepaths under the #include &lt;...&gt; search starts here: heading. You should takethose paths, prepend -isystem to each individual path and append them all tothe list of flags you return from your FlagsForFile function in your.ycm_extra_conf.py file. See issue #303 for details. When I open a JavaScript file, I get an annoying warning about .tern-project fileTake a look at the instructions for using the JavaScriptcompleter. If this is still really annoying, and you have a good reason not to have a.tern-project file, create an empty .tern-config file in your home directoryand YCM will stop complaining. When I start vim I get a runtime error saying R6034 An application has made an attempt to load the C runtime library incorrectly.CMake and other things seem to screw up the PATH with their own msvcrXX.dllversions. Add the following to the very top of your vimrcto remove these entries from the path. python &lt;&lt; EOFimport osimport repath = os.environ['PATH'].split(';')def contains_msvcr_lib(folder): try: for item in os.listdir(folder): if re.match(r'msvcr\\d+\\.dll', item): return True except: pass return Falsepath = [folder for folder in path if not contains_msvcr_lib(folder)]os.environ['PATH'] = ';'.join(path)EOF I hear that YCM only supports Python 2, is that true?No. Both the Vim client and the ycmd server run on Python 2 or 3. Ifyou work on a Python 3 project, you may need to set g:ycm_python_binary_pathto the Python interpreter you use for your project to get completions for thatversion of Python. On Windows I get E887: Sorry, this command is disabled, the Python&#39;s site module could not be loadedIf you are running vim on Windows with Python 2.7.11, this is likely caused by abug. Follow thisworkaround or use a different version(Python 2.7.12 does not suffer from the bug). I can’t complete python packages in a virtual environment.This means that the Python used to run JediHTTP is not the Python of thevirtual environment you’re in. To resolve this you either setg:ycm_python_binary_path to the absolute path of the Python binary in yourvirtual environment or since virtual environment will put that Pythonexecutable first in your PATH when the virtual environment is active then ifyou set g:ycm_python_binary_path to just &#39;python&#39; it will be found as thefirst Python and used to run JediHTTP. I want to defer loading of YouCompleteMe until after Vim finishes bootingIn recent versions of Vim, you can install YCM in a folder under~/.vim/pack/*/opt and then load it once the user is idle via an autocommand: augroup load_ycm autocmd! autocmd CursorHold, CursorHoldI * :packadd YouCompleteMe \\ | autocmd! load_ycmaugroup END YCM does not shut down when I quit VimYCM relies on the VimLeave event to shut down the ycmd server. Someplugins prevent this event from triggering by exiting Vim through an autocommandwithout using the nested keyword (see :h autocmd-nested). One of theseplugins is vim-nerdtree-tabs. You should identify which plugin isresponsible for the issue and report it to the plugin author. Note that whenthis happens, ycmd will automatically shut itself down after 30 minutes. Contributor Code of ConductPlease note that this project is released with a Contributor Code ofConduct. By participating in this project you agree to abide by itsterms. ContactIf you have questions about the plugin or need help, please join the Gitterroom or use the ycm-users mailing list. If you have bug reports or feature suggestions, please use the issuetracker. Before you do, please carefully readCONTRIBUTING.md as this asks for important diagnostics whichthe team will use to help get you going. The latest version of the plugin is available athttp://valloric.github.io/YouCompleteMe/. The author’s homepage is http://val.markovic.io. Please do NOT go to #vim on freenode for support. Please contact theYouCompleteMe maintainers directly using the contact details below. LicenseThis software is licensed under the GPL v3 license.© 2015-2017 YouCompleteMe contributors","categories":[{"name":"Vim","slug":"Vim","permalink":"https://gowa2017.github.io/categories/Vim/"}],"tags":[{"name":"Vim","slug":"Vim","permalink":"https://gowa2017.github.io/tags/Vim/"},{"name":"YouCompleteMe","slug":"YouCompleteMe","permalink":"https://gowa2017.github.io/tags/YouCompleteMe/"},{"name":"YCM","slug":"YCM","permalink":"https://gowa2017.github.io/tags/YCM/"}],"keywords":[{"name":"Vim","slug":"Vim","permalink":"https://gowa2017.github.io/categories/Vim/"}]},{"title":"ultisnips的readme文档中文","slug":"ultisnips的readme文档中文","date":"2018-03-14T14:19:57.000Z","updated":"2018-03-14T14:19:57.000Z","comments":true,"path":"Vim/ultisnips的readme文档中文.html","link":"","permalink":"https://gowa2017.github.io/Vim/ultisnips的readme文档中文.html","excerpt":"UltiSnips 是VIM中代码片段（snippets）的最终解决办法。它拥有很多的特性，而且非常快。","text":"UltiSnips 是VIM中代码片段（snippets）的最终解决办法。它拥有很多的特性，而且非常快。 UltiSnips展示中是在编辑一个python文件。 首先，展开了 #! 片段，然后是 class 片段。下拉菜单来自YouCompleteMe, UltiSnips 也集成了 neocomplete。我在占位符间跳转，添加文本，片段会自动更新其他地方: 当我添加 Animal作为一个基类时， __init__ 进行了更新来调用基类的构造函数。 当我为构造函数添加参数时，他们会被自动的赋给实例变量。接着，我插入了我个人自己的用来打印调试的片段 print。要注意的是，当我离开插入模式，插入了其他的片段，然后再回来为__init__添加额外参数的时候，这个类的片段依然是或者的，并且会自动增加了一个实例变量。 UltiSnips 的官方站点是 https://github.com/sirver/ultisnips. 欢迎 pull 请求和 issues。 UltiSnips was started in Jun 2009 by @SirVer. In Dec 2015, maintenance washanded over to @seletskiy. What can you do with UltiSnips? Advanced snippets: Snippets Aliases Dynamic Tabstops/Tabstop Generation Quick Start假设使用的是Vundle来管理VIM插件。 在 .vimrc中加入下面的代码： &quot; Track the engine. Plugin &#39;SirVer/ultisnips&#39; &quot; Snippets are separated from the engine. Add this if you want them: Plugin &#39;honza/vim-snippets&#39; &quot; Trigger configuration. Do not use &lt;tab&gt; if you use https://github.com/Valloric/YouCompleteMe. let g:UltiSnipsExpandTrigger=&quot;&lt;tab&gt;&quot; let g:UltiSnipsJumpForwardTrigger=&quot;&lt;c-b&gt;&quot; let g:UltiSnipsJumpBackwardTrigger=&quot;&lt;c-z&gt;&quot; &quot; If you want :UltiSnipsEdit to split your window. let g:UltiSnipsEditSplit=&quot;vertical&quot; UltiSnips有非常详细的文档documentation。这里有很多选项和特性我建议你最少看一下。 ScreencastsFrom a gentle introduction to really advanced in a few minutes: The blog postsof the screencasts contain more advanced examples of the things discussed in thevideos. Episode 1: What are snippets and do I need them? Episode 2: Creating Basic Snippets Episode 3: What’s new in version 2.0 Episode 4: Python Interpolation Also the excellent Vimcasts dedicated three episodes toUltiSnips: Meet UltiSnips Using Python interpolation in UltiSnips snippets Using selected text in UltiSnips snippets","categories":[{"name":"Vim","slug":"Vim","permalink":"https://gowa2017.github.io/categories/Vim/"}],"tags":[{"name":"Vim","slug":"Vim","permalink":"https://gowa2017.github.io/tags/Vim/"}],"keywords":[{"name":"Vim","slug":"Vim","permalink":"https://gowa2017.github.io/categories/Vim/"}]},{"title":"LVM的介绍及使用","slug":"LVM的介绍及使用","date":"2018-03-13T23:28:23.000Z","updated":"2018-03-13T23:28:23.000Z","comments":true,"path":"Linux/LVM的介绍及使用.html","link":"","permalink":"https://gowa2017.github.io/Linux/LVM的介绍及使用.html","excerpt":"","text":"LVM是Linux内核中的一个 逻辑卷组管理工具；其管理磁盘驱动器或类似的块存储设备。其利用了内核的 device-mapper 特性来给系统提供独立于底层磁盘的分区。使用LVM，抽象了你的存储然后拥有的是虚拟分区，这使 扩展/收缩 更加容易。 基本概念 物理卷（PV/Physical volume）可在其上建立卷组的分区或硬盘。每个PV都有一个特殊的头部，并且被分隔成PE。把PV想象成用来建立硬盘驱动的巨大块。 卷组（VG/Volume group）一组用来当作存储卷的PV（像一个硬盘一样提供服务）。其包含LV。可以把vg想象成硬盘驱动器。 逻辑卷（LV、Logical volume）存在于卷组内的虚拟/逻辑 分区，由PE组成。把PV想象成常规分区。 物理扩展（PE、Physical extend）PV中的最小单位，可以被分配给LV（默认是 4MB）。PE是硬盘的一部分，然后可以被分配给任何分区。 例子 Physical disks Disk1 (/dev/sda): _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ |Partition1 50 GiB (Physical volume) |Partition2 80 GiB (Physical volume) | |/dev/sda1 |/dev/sda2 | |_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ |_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ | Disk2 (/dev/sdb): _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ |Partition1 120 GiB (Physical volume) | |/dev/sdb1 | |_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _| LVM logical volumes Volume Group1 (/dev/MyStorage/ = /dev/sda1 + /dev/sda2 + /dev/sdb1): _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ |Logical volume1 15 GiB |Logical volume2 35 GiB |Logical volume3 200 GiB | |/dev/MyStorage/rootvol |/dev/MyStorage/homevol |/dev/MyStorage/mediavol | |_ _ _ _ _ _ _ _ _ _ _ _ |_ _ _ _ _ _ _ _ _ _ _ _ _ _ |_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _|``` ![nner workings of the version 1 of LVM. In this diagram, PE stands for a Physical Extent.](/res/500px-LVM1.svg.png)# LV类型除了简单的LV外，LVM支持 *snapshots（快照）、LV缓存（logical volume caching）、预分配的LV、RAID*，## Snapshots（快照）LVM允许你对系统以一个更效率的方式做快照。其利用了一种叫做 **COW（copy-on-write）**技术。初始建立的快照只是简单的包含对真实数据inodes的 **硬链接**。因此，如果数据一直没有改变，快照几乎只是包含了Inode的指针，而不是数据本身。当修改一个快照指向的文件或者目录，LVM会自动克隆被快照引用老的数据。所以，可以使用35GB来快照一个系统，当预计修改少于2GB的时候，可以只留下2G的空闲空间（在原始和快照分区上都要）。想要创建快照，必须在 VG内有未分配的空间。快照也会像其他卷一样消耗VG的空间。因此，如果想要使用快照来备份 root 分区，那么不要把VG的空间全部分配给 root LV。### 配置如此简单的就可以建立一个 快照LV：```bashlvcreate --size 100M --snapshot --name snap01 /dev/mapper/vg0-vg 上面建立这个快照，在快照卷充满以前我们只能修改100M的数据。 当 snap01 建立后就可以把 pv 这个LV恢复到之前的状态： lvconvert --merge /dev/mapper/vg0-snap01 如果原始的LV是活跃的，合并会在下一次重启时发生。 合并后 快照不会继续存在。 可以建立多个快照，然后每个都可以任意合并到原始的LV。 快照可以挂载或以 dd, tar 命令备份。以 dd 备份的文件尺寸将会是 快照卷内存在的数据尺寸。想要恢复的时候，建立一个快照，挂载，接着把备份的文件解压过去。最后，和原始的LV合并。 快照的主要用途是用来提供对文件系统的冷备份。 简单命令lvmdiskscan # list all your devices capable of being used as a physical volumepvcreate DEVICE # Create a physical volume on thempvcreate /dev/sda2 # pvdisplay # track created physical volumesvgcreate VolGroup00 /dev/sda2 # create vg on pvsvgextend VolGroup00 /dev/sdb1 # add vg /dev/sdb1 to vg VolGroup00vgdisplay # track vgvgcreate VolGroup00 /","categories":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/tags/Linux/"},{"name":"LVM","slug":"LVM","permalink":"https://gowa2017.github.io/tags/LVM/"}],"keywords":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}]},{"title":"rsync进行数据同步","slug":"rsync进行数据同步","date":"2018-03-12T01:19:02.000Z","updated":"2018-03-12T01:19:02.000Z","comments":true,"path":"Linux/rsync进行数据同步.html","link":"","permalink":"https://gowa2017.github.io/Linux/rsync进行数据同步.html","excerpt":"","text":"rsync是一个快速，灵活的可用来替代rcp的工具，但是其有更多的选项和使用 rsync 远程更新协议来提高已更新文件的传输速度。 rsync远程更新协议允许rsync只传输文件中的不同，使用一种校验和搜索算法。 特性 支持复制链接，设备，所有者，组及权限 类似GNU tar 的排除选项 类似 CVS 的排除模式 可以使用透明的远程shell，包括 ssh/rsh 不需要特权 文件传输管道最小化了开销 支持匿名或授权的rsync守护进程 一般说明Rsync从远程主机复制文件或复制文件到远程主机，或只是在本地主机上复制文件（不支持在两个远程主机间复制文件）。 有两种不同的方式来远程主机：使用远程-shell来作为传输（ssh,rsh），或者通过 TCP来联系rsync服务。当源或目标主机标识的路径包含一个 : 的时候会使用远程shell。当源或目标主机后的路径包含两个 :: 的时候就会直接与远程的rsync服务通信，或者 rsync:// 链接被指定也是一样（查看通过远程-shell连接使用 rsync-服务特性来查看例外）。 作为一个特殊情况，如果单独一个源参数，没有目标参数，那么会输出一个列表，类似ls -l 如果源或目标都没有指定一个远程主机的话，那只是在本地进行复制。 设置查看 README 了解安装指令。 安装后，你可以有rsync联系任何可以通过远程shell访问的机器（包括 rsync 服务模式协议的机器）。对于远程传输，现代的rsync使用 ssh 来进行通信，默认情况下可能已经配置成了不同的shell，如 rsh/remsh。 可以指定我们自己喜欢的远程shell，使用 -e 命令行选项， 或设置 RSYNC_RSH 环境变量。 rsync 必须在源或目标机器上都安装。 使用可以以类似 rcp 的方式使用 rsync，必须指定源和目标，其中一个可能会是远程主机。 也许最好的方式是以实际的例子进行展示： rsync -t *.c foo:src/ 这将会传输任何匹配 *.c 格式的文件到机器foo上的 src 目录内。如果foo机器上有些文件已经存在，那么rsync会使用远程更新协议来发送不同的部分。 rsync -avz foo:src/bar /data/tmp 这会递归将远程foo机器上，src/bar 目录 传输到 /data/tmp/bar。文件以archive模式传输，这能确保 符号链接，设备文件，属性，权限，所有信息都被完整传输。同时，使用压缩可以减少传输的数据量。 rsync -avz foo:src/bar/ /data/tmp 源后拖尾的 / 改变了行为，将不会在目标上建立一个目录。 使用Usage: rsync [OPTION]... SRC [SRC]... DEST or rsync [OPTION]... SRC [SRC]... [USER@]HOST:DEST or rsync [OPTION]... SRC [SRC]... [USER@]HOST::DEST or rsync [OPTION]... SRC [SRC]... rsync://[USER@]HOST[:PORT]/DEST or rsync [OPTION]... [USER@]HOST:SRC [DEST] or rsync [OPTION]... [USER@]HOST::SRC [DEST] or rsync [OPTION]... rsync://[USER@]HOST[:PORT]/SRC [DEST]The &apos;:&apos; usages connect via remote shell, while &apos;::&apos; &amp; &apos;rsync://&apos; usages connectto an rsync daemon, and require SRC or DEST to start with a module name.Options -v, --verbose increase verbosity -q, --quiet suppress non-error messages --no-motd suppress daemon-mode MOTD (see manpage caveat) -c, --checksum skip based on checksum, not mod-time &amp; size -a, --archive archive mode; same as -rlptgoD (no -H) --no-OPTION turn off an implied OPTION (e.g. --no-D) -r, --recursive recurse into directories -R, --relative use relative path names --no-implied-dirs don&apos;t send implied dirs with --relative -b, --backup make backups (see --suffix &amp; --backup-dir) --backup-dir=DIR make backups into hierarchy based in DIR --suffix=SUFFIX set backup suffix (default ~ w/o --backup-dir) -u, --update skip files that are newer on the receiver --inplace update destination files in-place (SEE MAN PAGE) --append append data onto shorter files -d, --dirs transfer directories without recursing -l, --links copy symlinks as symlinks -L, --copy-links transform symlink into referent file/dir --copy-unsafe-links only &quot;unsafe&quot; symlinks are transformed --safe-links ignore symlinks that point outside the source tree -k, --copy-dirlinks transform symlink to a dir into referent dir -K, --keep-dirlinks treat symlinked dir on receiver as dir -H, --hard-links preserve hard links -p, --perms preserve permissions --executability preserve the file&apos;s executability --chmod=CHMOD affect file and/or directory permissions -o, --owner preserve owner (super-user only) -g, --group preserve group --devices preserve device files (super-user only) --specials preserve special files -D same as --devices --specials -t, --times preserve times -O, --omit-dir-times omit directories when preserving times --super receiver attempts super-user activities -S, --sparse handle sparse files efficiently -n, --dry-run show what would have been transferred -W, --whole-file copy files whole (without rsync algorithm) -x, --one-file-system don&apos;t cross filesystem boundaries -B, --block-size=SIZE force a fixed checksum block-size -e, --rsh=COMMAND specify the remote shell to use --rsync-path=PROGRAM specify the rsync to run on the remote machine --existing skip creating new files on receiver --ignore-existing skip updating files that already exist on receiver --remove-source-files sender removes synchronized files (non-dirs) --del an alias for --delete-during --delete delete extraneous files from destination dirs --delete-before receiver deletes before transfer (default) --delete-during receiver deletes during transfer, not before --delete-after receiver deletes after transfer, not before --delete-excluded also delete excluded files from destination dirs --ignore-errors delete even if there are I/O errors --force force deletion of directories even if not empty --max-delete=NUM don&apos;t delete more than NUM files --max-size=SIZE don&apos;t transfer any file larger than SIZE --min-size=SIZE don&apos;t transfer any file smaller than SIZE --partial keep partially transferred files --partial-dir=DIR put a partially transferred file into DIR --delay-updates put all updated files into place at transfer&apos;s end -m, --prune-empty-dirs prune empty directory chains from the file-list --numeric-ids don&apos;t map uid/gid values by user/group name --timeout=TIME set I/O timeout in seconds -I, --ignore-times don&apos;t skip files that match in size and mod-time --size-only skip files that match in size --modify-window=NUM compare mod-times with reduced accuracy -T, --temp-dir=DIR create temporary files in directory DIR -y, --fuzzy find similar file for basis if no dest file --compare-dest=DIR also compare destination files relative to DIR --copy-dest=DIR ... and include copies of unchanged files --link-dest=DIR hardlink to files in DIR when unchanged -z, --compress compress file data during the transfer --compress-level=NUM explicitly set compression level -C, --cvs-exclude auto-ignore files the same way CVS does -f, --filter=RULE add a file-filtering RULE -F same as --filter=&apos;dir-merge /.rsync-filter&apos; repeated: --filter=&apos;- .rsync-filter&apos; --exclude=PATTERN exclude files matching PATTERN --exclude-from=FILE read exclude patterns from FILE --include=PATTERN don&apos;t exclude files matching PATTERN --include-from=FILE read include patterns from FILE --files-from=FILE read list of source-file names from FILE -0, --from0 all *-from/filter files are delimited by 0s --address=ADDRESS bind address for outgoing socket to daemon --port=PORT specify double-colon alternate port number --sockopts=OPTIONS specify custom TCP options --blocking-io use blocking I/O for the remote shell --stats give some file-transfer stats -8, --8-bit-output leave high-bit chars unescaped in output -h, --human-readable output numbers in a human-readable format --progress show progress during transfer -P same as --partial --progress -i, --itemize-changes output a change-summary for all updates --out-format=FORMAT output updates using the specified FORMAT --log-file=FILE log what we&apos;re doing to the specified FILE --log-file-format=FMT log updates using the specified FMT --password-file=FILE read password from FILE --list-only list the files instead of copying them --bwlimit=KBPS limit I/O bandwidth; KBytes per second --write-batch=FILE write a batched update to FILE --only-write-batch=FILE like --write-batch but w/o updating destination --read-batch=FILE read a batched update from FILE --protocol=NUM force an older protocol version to be used -E, --extended-attributes copy extended attributes --cache disable fcntl(F_NOCACHE) -4, --ipv4 prefer IPv4 -6, --ipv6 prefer IPv6 --version print version number(-h) --help show this help (-h works with no other options)","categories":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/tags/Linux/"},{"name":"rsync","slug":"rsync","permalink":"https://gowa2017.github.io/tags/rsync/"}],"keywords":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}]},{"title":"MySQL二进制日志格式","slug":"MySQL二进制日志格式","date":"2018-03-08T15:45:43.000Z","updated":"2018-03-08T15:45:43.000Z","comments":true,"path":"MySQL/MySQL二进制日志格式.html","link":"","permalink":"https://gowa2017.github.io/MySQL/MySQL二进制日志格式.html","excerpt":"","text":"我们都知道二进制日志是一个非常好的习惯和工具。其可以用来进行恢复数据到某一时间点，或重放整个数据的变更过程，但其实这里面还有不少学问。 简介二进制日志包含的是描述数据库改变（比如表建立或表数据修改）的事件。在使用 基于行 的日志格式时也会包含可能会改变数据的事件（如 DELETE语句，但并无匹配行）。二进制日志也会记录每个语句更新数据所消耗的时间。二进制日志的设计，有两个重要的目标： 复制，二进制日志记录了在主服务器上数据变更记录，用来发送给从服务器。主服务器会把二进制日志中的事件发送给从服务器，然后在从服务器上再次执行。 一些数据恢复操作需要二进制日志。在一个备份恢复后，二进制日志中在此备份后的事件可以被重新执行。这能保证让数据库从备份时恢复到最新状态。 二进制日志并不会记录类似 select, show这些不会改变数据的语句。 开启二进制日志会使服务器性能轻微下降，但开启这个日志来设置从服务器和数据恢复的好处远远大过了性能的降低。 要保护好二进制日志，因为记录的语句中可能会含有密码。 二进制日志格式二进制日志有几种格式。 基于语句的日志格式。选项 --binlog-format=STATEMENT 基于行的格式。主服务器将表示每个单独表行受影响的事件写入二进制日志。选项--binlog-format=ROW 混合格式。当设置这个选项--bilong-format=MIXED，默认会使用 基于行的格式，但在某些情况下会自动切换为基于语句的格式。 在MySQL5.5中，默认的二进制日志格式是 STATEMET。 日志格式可以被存储引擎设置或限制。这用来避免在使用不同存储引擎的主从服务器在执行特定语句时的问题。 在基于语句的复制中，在复制非确定性的语句时可能会出现问题。在确定一个语句使用基于语句的复制是否安全时，MySQL会确定能不能保证这个语句可以用基于语句的格式进行复制。如果不能保证，则会抛出警告。为了避免这个问题，可以采用基于行的复制。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://gowa2017.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://gowa2017.github.io/tags/MySQL/"}],"keywords":[{"name":"MySQL","slug":"MySQL","permalink":"https://gowa2017.github.io/categories/MySQL/"}]},{"title":"Cocos2d-X-lua中关于类的实现及使用","slug":"cocos2dx-lua中关于类的实现及使用","date":"2018-02-26T06:53:59.000Z","updated":"2018-02-26T06:53:59.000Z","comments":true,"path":"Cocos2d-X/cocos2dx-lua中关于类的实现及使用.html","link":"","permalink":"https://gowa2017.github.io/Cocos2d-X/cocos2dx-lua中关于类的实现及使用.html","excerpt":"Lua中，没有什么其他的数据对象，只有表。但是其提供的元表和元方法，让我们的程序有了更多的可能。另外，我们必须明白一点的就是，cocos2dx框架中，开启了一个Lua State，我们所有的脚本，逻辑都是在这里面执行，然后这个里面会调用一些 cocos2dx 导出给 lua 使用的接口，最终还是通过 c 代码来完成工作的。","text":"Lua中，没有什么其他的数据对象，只有表。但是其提供的元表和元方法，让我们的程序有了更多的可能。另外，我们必须明白一点的就是，cocos2dx框架中，开启了一个Lua State，我们所有的脚本，逻辑都是在这里面执行，然后这个里面会调用一些 cocos2dx 导出给 lua 使用的接口，最终还是通过 c 代码来完成工作的。 main.lua中解析在框架启动完毕后，会执行 engine-&gt;executeScriptFile(&quot;src/main.lua&quot;); lua入口文件。根据版本的不同，可能是 src/main.lua，也有可能直接是 main.lua 但这没有什么影响。 具体的代码请查看 framework/runtime-src/Classes/AppDelegate.cpp。 一开始，cocos2dx就已经把其提供的接口函数注册到了Lua State中，我们已经可以直接使用一些了，当然，我们也可以把它提供的接口，再次用Lua进行封装，Quick干的就是这样的事情。 我们关注的其实，只是main.lua中的一行： require(\"app.MyApp\").new():run() 其只是加载了 app.MyApp 文件，然后执行其中的 new() 方法后返回一个新 AppBase 对象，再执行对象中的 run() 方法。 MyApp.lua 是 AppBase.lua的一个实例，从其文件中我们可以看得出来： -- app/MyApp.lualocal AppBase = require(\"framework.AppBase\")local MyApp = class(\"MyApp\", AppBase) 其以 AppBase作为基类（父类），建立了一个对象MyApp。我们可以以如下代码来打印出 MyApp的内容及其元表的内容。 local m = require(\"app.Myapp\")for k, v in pairs(m) do print(k, v)endprint(\"-------------\")for k, v in pairs(getmetatable(m)) do print(k, v)end 输出结果是： [LUA-print] run function: 0x07c45220[LUA-print] __ctype 2[LUA-print] new function: 0x07c44360[LUA-print] __cname MyApp[LUA-print] super table: 0x07c44cf8[LUA-print] ctor function: 0x07c451e0[LUA-print] __index table: 0x07c44650[LUA-print] -------------[LUA-print] __index table: 0x07c44cf8 其中 spuer 表明其父类是一个表，__cname 表示其类名 MyApp ，__index 是一个表，这里暂时不讨论这个，放在这里，其表示它也可以作为其他类的元表（父类）而已。 最后一行是其 元表的 输出，其元表中只有一个 __index 方法，那么所有 MyApp 内不存在的方法都会从 __index 对应的表中获取。 这里，我们加载了 app.MyApp.lua 模块，返回了类 AppBase.lua 的一个子类 MyApp。 new()及 class的实现在 app.MyApp.lua中，我们发现，其实并没有定义 new, super, ctype, __index 这几个字段。其实由 class() 函数进行设置的。 在 文件 src/framework/functions.lua，定义了 class() 函数： function class(classname, super) local superType = type(super) local cls -- 父类 只能是一个函数 或者 一个表 if superType ~= \"function\" and superType ~= \"table\" then superType = nil super = nil end if superType == \"function\" or (super and super.__ctype == 1) then -- inherited from native C++ Object cls = &#123;&#125; if superType == \"table\" then -- copy fields from super for k,v in pairs(super) do cls[k] = v end cls.__create = super.__create cls.super = super else cls.__create = super cls.ctor = function() end end cls.__cname = classname cls.__ctype = 1 function cls.new(...) local instance = cls.__create(...) -- copy fields from class to native object for k,v in pairs(cls) do instance[k] = v end instance.class = cls instance:ctor(...) return instance end else -- inherited from Lua Object if super then cls = &#123;&#125; setmetatable(cls, &#123;__index = super&#125;) cls.super = super else cls = &#123;ctor = function() end&#125; end cls.__cname = classname cls.__ctype = 2 -- lua cls.__index = cls function cls.new(...) local instance = setmetatable(&#123;&#125;, cls) instance.class = cls instance:ctor(...) return instance end end return clsend 其通过一个 类名，父类 作为参数，然后返回一个新的类。 这里，我们首先假设都已经知道，对于元表中的__index，其值（元方法）可以是一个函数（当找不到对应的键值是会以 表，键 为参数进行调用后返回），或一个表（找不到对应键值时以 t[k] 进行返回）。 父类可能有两种情况，我们先来看简单的一种。 super是lua表这是比较简单的一种情况，代码体现在： -- inherited from Lua Object if super then cls = &#123;&#125; setmetatable(cls, &#123;__index = super&#125;) cls.super = super else cls = &#123;ctor = function() end&#125; end cls.__cname = classname cls.__ctype = 2 -- lua cls.__index = cls function cls.new(...) local instance = setmetatable(&#123;&#125;, cls) instance.class = cls instance:ctor(...) return instance endend 我们需要关注的是，class() 自动为每个类建立了一个 new() 方法：其会返回以接收消息类的实例，并将 对应参数传递给 ctor() 方法。 super是一个函数当 spuer 是一个函数，或者 super类型是 C 类的时候，会麻烦一些： if superType == \"function\" or (super and super.__ctype == 1) then -- inherited from native C++ Object cls = &#123;&#125; if superType == \"table\" then -- copy fields from super for k,v in pairs(super) do cls[k] = v end cls.__create = super.__create cls.super = super else cls.__create = super cls.ctor = function() end end cls.__cname = classname cls.__ctype = 1 function cls.new(...) local instance = cls.__create(...) -- copy fields from class to native object for k,v in pairs(cls) do instance[k] = v end instance.class = cls instance:ctor(...) return instance end 如果 super是一个lua 函数，其会设置类的 __create字段为 super函数，构造的 new()方法就会调用这个函数。而当 super是一个是C类时，会调用这个C类构造函数来返回实例。 lua中的C类前面提到，当一个类的父类是一个表，但表中的__ctype 是 1时，这个类是一个C类。其本质，也是Lua中的一张表。 关于在Lua进行模块的注册流程，请关注一下另外一篇文章cocos2dx-lua的启动流程.lua。 现在，我们来关注一下类的导出吧，以Scene为例： // cocos/scripting/lua-bindings/auto/lua_cocos2dx_auto.cppint lua_register_cocos2dx_Scene(lua_State* tolua_S)&#123; // 注册一个用户数据类型 cc.Scene 到State中 tolua_usertype(tolua_S,\"cc.Scene\"); // 映射C类 cc.Scene 到Lua 类 Scene ，父类为 cc.NodeSceneLuatolua_cclass(tolua_S,\"Scene\",\"cc.Scene\",\"cc.Node\",nullptr); // 注册模块 Scene tolua_beginmodule(tolua_S,\"Scene\"); // 注册模块（类）的函数 tolua_function(tolua_S,\"render\",lua_cocos2dx_Scene_render); tolua_function(tolua_S,\"createWithSize\", lua_cocos2dx_Scene_createWithSize); tolua_function(tolua_S,\"create\", lua_cocos2dx_Scene_create); tolua_endmodule(tolua_S); std::string typeName = typeid(cocos2d::Scene).name(); g_luaType[typeName] = \"cc.Scene\"; g_typeCast[\"Scene\"] = \"cc.Scene\"; return 1;&#125; 我们来简要的说一下这个过程： tolua_usertype(L, &quot;cc.Scene&quot;) 这个调用，会在Lua State的LUA_REGISTRYINDEX 索引处的注册表 registry 中建立两项： registry[\"cc.Scene\"] = &#123; \"__name\" = \"cc.Scene\"&#125;registry[\"const cc.Scene\"] = &#123; \"__name\" == \"const cc.Scene\"&#125; tolua_beginmodule(tolua_S,&quot;Scene&quot;); 注册模块 Scene 注册Scene模块的方法。 因此，调用 .new() 方法会创建一个 MyApp 类（AppBase类的子类）的实例，之后，再调用 实例 的run()方法，进入了主场景。","categories":[{"name":"Cocos2d-X","slug":"Cocos2d-X","permalink":"https://gowa2017.github.io/categories/Cocos2d-X/"}],"tags":[{"name":"Lua","slug":"Lua","permalink":"https://gowa2017.github.io/tags/Lua/"},{"name":"Cocos2d-X","slug":"Cocos2d-X","permalink":"https://gowa2017.github.io/tags/Cocos2d-X/"}],"keywords":[{"name":"Cocos2d-X","slug":"Cocos2d-X","permalink":"https://gowa2017.github.io/categories/Cocos2d-X/"}]},{"title":"Cocos2d-X-lua的启动流程.lua","slug":"cocos2dx-lua的启动流程.lua","date":"2018-02-23T12:35:48.000Z","updated":"2018-02-23T12:35:48.000Z","comments":true,"path":"Cocos2d-X/cocos2dx-lua的启动流程.lua.html","link":"","permalink":"https://gowa2017.github.io/Cocos2d-X/cocos2dx-lua的启动流程.lua.html","excerpt":"","text":"可能以前用的项目就是Lua，所以比较喜欢Lua。服务端也用skynet框架，都用Lua，能统一的话是最好的了。完全是个人爱好。但是有必要看一下，我对客户端是最不熟的了，图形这一块。 启动新建一个Lua项目后: cocos new -l lua -p com.example.me -d game 进入目录： cd game/MyLuaGame/frameworks/rutime-src/Classes AppDelegate.cpp是我们需要关注的文件。他干了一系列的事情： bool AppDelegate::applicationDidFinishLaunching()&#123; // set default FPS Director::getInstance()-&gt;setAnimationInterval(1.0 / 60.0f); // register lua module // 注册 lua 模块 auto engine = LuaEngine::getInstance(); ScriptEngineManager::getInstance()-&gt;setScriptEngine(engine); lua_State* L = engine-&gt;getLuaStack()-&gt;getLuaState(); lua_module_register(L); register_all_packages(); LuaStack* stack = engine-&gt;getLuaStack(); stack-&gt;setXXTEAKeyAndSign(\"2dxLua\", strlen(\"2dxLua\"), \"XXTEA\", strlen(\"XXTEA\")); //register custom function //LuaStack* stack = engine-&gt;getLuaStack(); //register_custom_function(stack-&gt;getLuaState()); // 添加的这两个路径，我们其实都不用手动在项目内添加了#if CC_64BITS FileUtils::getInstance()-&gt;addSearchPath(\"src/64bit\");#endif FileUtils::getInstance()-&gt;addSearchPath(\"src\"); FileUtils::getInstance()-&gt;addSearchPath(\"res\"); if (engine-&gt;executeScriptFile(\"main.lua\")) &#123; return false; &#125; return true;&#125; 这个类其实就干了两个事情： 开个Lua State 把模块都注册进去 引擎执行 main.lua 另外，其实以前那种写法: cc.FileUtils:getInstance():addSearchPath(\"src/\")cc.FileUtils:getInstance():addSearchPath(\"res/\") 这样的代码已经不需要了。程序已经自动注册了这两个路径了。程序会自动在这两个地方寻找资源。 模块及函数的注册到Statelua_module_register(L);这玩意会在我们的Lua State内注册一系列的模块。我们取个例子来看一下，比如第一个模块。 // frameworks/cocos2d-x/cocos/scripting/lua-bindings/manual/lua_module_register.cppint lua_module_register(lua_State* L)&#123; // Don't change the module register order unless you know what your are doing register_cocosdenshion_module(L); register_network_module(L); register_cocosbuilder_module(L); register_cocostudio_module(L); register_ui_module(L); register_extension_module(L); register_spine_module(L); register_cocos3d_module(L); register_audioengine_module(L);#if CC_USE_3D_PHYSICS &amp;&amp; CC_ENABLE_BULLET_INTEGRATION register_physics3d_module(L);#endif#if CC_USE_NAVMESH register_navmesh_module(L);#endif return 1;&#125; register_cocosdenshion_module这个函数干的活比较简单，就是获取一下Lua的全局环境，然后把所有的模块内容注册进去。 //scripting/lua-bindings/manual/cocosdenshion/lua_cocos2dx_cocosdenshion_manual.cppint register_cocosdenshion_module(lua_State* L)&#123; lua_getglobal(L, \"_G\"); if (lua_istable(L,-1))//stack:...,_G, &#123; register_all_cocos2dx_cocosdenshion(L); &#125; lua_pop(L, 1); return 1;&#125; 真正干活的，还是下面一个函数。 register_all_cocos2dx_cocosdenshiontolua 没有用过，但是一下他们的代码就知道了。很明显，是用了open, module, beginmodule, endmodule来干活的。TOLUA_API int register_all_cocos2dx_cocosdenshion(lua_State* tolua_S)&#123; tolua_open(tolua_S); tolua_module(tolua_S,\"cc\",0); tolua_beginmodule(tolua_S,\"cc\"); lua_register_cocos2dx_cocosdenshion_SimpleAudioEngine(tolua_S); tolua_endmodule(tolua_S); return 1;&#125; 小插曲我们先来看一下，Lua关于注册表的概念。 Lua提供了应该注册表，这个表可以被任何C代码用来存储任何的Lua值。注册表总是位于伪索引 LUA_REISTRYINDEX上（并不在Lua State的真正的栈上）。任何C库都可以使用这个表来存储数据，但必须谨慎选择键，以避免出现冲突。典型滴，用一包含你库名的字符串作为键，或者是一个light userdata（C对象的指针），或者任何被自己代码创建的Lua对象。和变量名字一样，以一个下划线后跟大写字母的字符串是保留的。 整型的键用来做索引算法（luaL_ref）和一些预定义的值。因此，整型键不应该用作其他目录。 当建一个新的Lua State时，这个注册您就有一些预定义的值。这些预定义的值以lua.h定义的常量整数作为键，下面的两个是定义好的： LUA_RIDX_MAINTHREAD 注册内保存的State的主线程（与State一起建立的那个线程）LUA_RIDX_GLOBALS 注册表内的这个索引保存了全局环境。 我们可以假设这个注册表刚开始的时候是这样的： t_reg = &#123; [LUA_RIDX_MAINTHREAD] = value, [LUA_RIDX_GLOBALS] = _G, &#125; lua_settable lua_rawsetluasettable(L, index)luarawset(L, index) 这两个函数和代码 t[k] = v是一样的，t 就是位于 index 处的值，v 是栈的顶部的值， k 是在栈顶部下的值。 这两个函数会将 键 和 值都弹出。 不同的是，luarawset 并不会触发事件 __newindex 的元方法。 lua_gettable lua_rawgetlua_gettable(L, index)lua_rawget(L, index) 把 t[k]的值压入栈，t 是 index 指定的值，k 是栈顶部的值。 这两个函数都会把键弹出，然后把结果值压入那个位置。lua_rawget不会触发 __index 事件的元方法。 返回值是是结果值的类型。 toluatolua_open首先调用的是 tolua_open 函数： // frameworks/cocos2d-x/external/lua/tolua/tolua_map.cTOLUA_API void tolua_open (lua_State* L)&#123; int top = lua_gettop(L); // 检查 tolua 是否打开。用 t[\"tolua_opened\"] = true | false 来判断 lua_pushstring(L,\"tolua_opened\"); lua_rawget(L,LUA_REGISTRYINDEX); if (!lua_isboolean(L,-1)) &#123; // 如果没打开就打开它 // t_reg[\"tolua_opened\"] = 1 lua_pushstring(L,\"tolua_opened\"); lua_pushboolean(L,1); lua_rawset(L,LUA_REGISTRYINDEX); // create value root table // 建立根表 // t_reg[\"tolua_value_root\"] = &#123;&#125; lua_pushstring(L, TOLUA_VALUE_ROOT); lua_newtable(L); lua_rawset(L, LUA_REGISTRYINDEX);#ifndef LUA_VERSION_NUM /* only prior to lua 5.1 */ /* create peer object table */ lua_pushstring(L, \"tolua_peers\"); lua_newtable(L); /* make weak key metatable for peers indexed by userdata object */ lua_newtable(L); lua_pushliteral(L, \"__mode\"); lua_pushliteral(L, \"k\"); lua_rawset(L, -3); /* stack: string peers mt */ lua_setmetatable(L, -2); /* stack: string peers */ lua_rawset(L,LUA_REGISTRYINDEX);#endif /* create object ptr -&gt; udata mapping table */ lua_pushstring(L,\"tolua_ubox\"); lua_newtable(L); /* make weak value metatable for ubox table to allow userdata to be garbage-collected */ lua_newtable(L); lua_pushliteral(L, \"__mode\"); lua_pushliteral(L, \"v\"); lua_rawset(L, -3); /* stack: string ubox mt */ lua_setmetatable(L, -2); /* stack: string ubox */ lua_rawset(L,LUA_REGISTRYINDEX);// /* create object ptr -&gt; class type mapping table */// lua_pushstring(L, \"tolua_ptr2type\");// lua_newtable(L);// lua_rawset(L, LUA_REGISTRYINDEX); lua_pushstring(L,\"tolua_super\"); lua_newtable(L); lua_rawset(L,LUA_REGISTRYINDEX); lua_pushstring(L,\"tolua_gc\"); lua_newtable(L); lua_rawset(L,LUA_REGISTRYINDEX); /* create gc_event closure */ lua_pushstring(L, \"tolua_gc_event\"); lua_pushstring(L, \"tolua_gc\"); lua_rawget(L, LUA_REGISTRYINDEX); lua_pushstring(L, \"tolua_super\"); lua_rawget(L, LUA_REGISTRYINDEX); lua_pushcclosure(L, class_gc_event, 2); lua_rawset(L, LUA_REGISTRYINDEX); tolua_newmetatable(L,\"tolua_commonclass\"); tolua_module(L,NULL,0); tolua_beginmodule(L,NULL); tolua_module(L,\"tolua\",0); tolua_beginmodule(L,\"tolua\"); tolua_function(L,\"type\",tolua_bnd_type); tolua_function(L,\"takeownership\",tolua_bnd_takeownership); tolua_function(L,\"releaseownership\",tolua_bnd_releaseownership); tolua_function(L,\"cast\",tolua_bnd_cast); tolua_function(L,\"isnull\",tolua_bnd_isnulluserdata); tolua_function(L,\"inherit\", tolua_bnd_inherit);#ifdef LUA_VERSION_NUM /* lua 5.1 */ tolua_function(L, \"setpeer\", tolua_bnd_setpeer); tolua_function(L, \"getpeer\", tolua_bnd_getpeer);#endif tolua_function(L,\"getcfunction\", tolua_bnd_getcfunction); tolua_function(L,\"iskindof\", tolua_bnd_iskindof); tolua_endmodule(L); tolua_endmodule(L); &#125; lua_settop(L,top);&#125; 这些都不用多说了，反正就是在 注册表内，添加两很多元素。 tolua_module这个函数会创建一个模块。 // frameworks/cocos2d-x/external/lua/tolua/tolua_map.cTOLUA_API void tolua_module (lua_State* L, const char* name, int hasvar)&#123; if (name) &#123; /* tolua module */ lua_pushstring(L,name); lua_rawget(L,-2); if (!lua_istable(L,-1)) /* check if module already exists */ &#123; lua_pop(L,1); lua_newtable(L); lua_pushstring(L,name); lua_pushvalue(L,-2); lua_rawset(L,-4); /* assing module into module */ &#125; &#125; else &#123; /* global table */ lua_pushvalue(L,LUA_GLOBALSINDEX); &#125; if (hasvar) &#123; if (!tolua_ismodulemetatable(L)) /* check if it already has a module metatable */ &#123; /* create metatable to get/set C/C++ variable */ lua_newtable(L); tolua_moduleevents(L); if (lua_getmetatable(L,-2)) lua_setmetatable(L,-2); /* set old metatable as metatable of metatable */ lua_setmetatable(L,-2); &#125; &#125; lua_pop(L,1); /* pop module */&#125; 这个函数么，就是在注册表内，建立一个新模块。havar 表示是不是这个模块有元表。 注册完成在执行了函数 register_all_cocos2dx_cocosdenshion后，我们的注册表可能看起来是这样的： t_reg = &#123;... -- 预定义的值[\"cc\"] = &#123; [\"getInstance\"] = lua_cocos2dx_cocosdenshion_SimpleAudioEngi, -- 这就是导出来给我们在Lua中用的 ..... &#125;&#125; main.lua的执行engine-&gt;executeScriptFile(&quot;main.lua&quot;)就开始执行 main.lua了。 之后，其实就跟普通的Lua脚本执行没有什么差别了，通过在State中调用C函数，来操作整个引擎了。 而对于，导出的函数，继续以 Lua 进行封装后以模块的方式调用，其实也没有什么特别的。 这就是 C -&gt; Lua State -&gt; lua script -&gt; Cfunction -&gt; Cobj 流程类似了。 不信你看一下，项目中 src 目录下的 cocos中。全是这样干的。 在我们所有的项目中，都有： require \"config\"require \"cocos.init\" 其实就是加载我们的配置文件，然后再加载 cocos Lua封装的初始化文件。打开 cocos/init.lua 就可以看到，其一一个个个 require 语句，用来加载封装成Lua的各个模块。 我们关注有一句： -- src/cocos/init.luaif CC_USE_FRAMEWORK then require \"cocos.framework.init\"end 其实这一段，是用了更高层的封装，更加方便使用，其实应该就是 Quick 干的事情。 如果我们在我们的 config.lua 中定义了这个变量，那么，就可以使用那些封装了。","categories":[{"name":"Cocos2d-X","slug":"Cocos2d-X","permalink":"https://gowa2017.github.io/categories/Cocos2d-X/"}],"tags":[{"name":"Cocos2d-X","slug":"Cocos2d-X","permalink":"https://gowa2017.github.io/tags/Cocos2d-X/"}],"keywords":[{"name":"Cocos2d-X","slug":"Cocos2d-X","permalink":"https://gowa2017.github.io/categories/Cocos2d-X/"}]},{"title":"PIL.16Lua的编译、执行","slug":"PIL.16Lua的编译、执行和错误","date":"2018-02-21T15:18:33.000Z","updated":"2018-02-21T15:18:33.000Z","comments":true,"path":"Lua/PIL.16Lua的编译、执行和错误.html","link":"","permalink":"https://gowa2017.github.io/Lua/PIL.16Lua的编译、执行和错误.html","excerpt":"尽管我们说Lua是一个解释型的语言，但Lua总是在运行代码前会编译成一种中间格式。（这并不重要，很多解释型也会这样做）编译阶段的存在对于解释型语言听起来有点不太对。然而，解释型语言的重要特性不是说他们不会被编译，而是说其轻易执行在空中生成的代码。我们可以说，一个dofile这样的函数存在给为了我们把Lua称为解释型语言的资格。","text":"尽管我们说Lua是一个解释型的语言，但Lua总是在运行代码前会编译成一种中间格式。（这并不重要，很多解释型也会这样做）编译阶段的存在对于解释型语言听起来有点不太对。然而，解释型语言的重要特性不是说他们不会被编译，而是说其轻易执行在空中生成的代码。我们可以说，一个dofile这样的函数存在给为了我们把Lua称为解释型语言的资格。我们会讨论Lua执行代码chunks的过程，编译意味着什么（做了什么），Lua怎么样运行编译了的代码，在这过程中怎么控制错误。 编译前面，我们把 dofile 介绍为一种Lua中执行代码的基本方式，但是 dofile 其实是一个辅助函数：loadfile 才做了真正的工作。 类似 dofile ， loadfile 从一个文件加载 Lua chunk，但是不会运行这个 chunk。他只会编译这个 chunk，然后把编译后的 chunk 以一个函数返回。而且，loadfile 不会和 dofile 一样返回错误，其只会返回错误代码。我们可以如下定义 dofile： function dofile (filename) local f = assert(loadfile(filename)) return f()end 当 loadfile 失败时用 assert 来抛出错误。 对于简单的任务， dofile 是很方便的，因为其在一个调用中就完成了工作。 然而， loadfile 更灵活。如果出错， loadfile 返回 nil 加上错误消息，这就允许我们以自定义的方式处理错误。 然后，如果我们需要多次运行一个文件，我们可以调用 loadfile一次，然后调用其结果多次。这个方式比多次调用 dofile 更廉价，因为只编译文件一次。（在语言中，编译对比其他操作始终是比较昂贵的） load函数和 loadfile 类似，不同的是其从一个字符串或一个函数读取 chunk，而不是从一个文件。考虑下面的代码： f = load(\"i = i + 1\") 在这个代码后，f 将会是一个函数，在调用的时候会执行 i = i + 1： i = 0f(); print(i) -- 1f(); print(i) -- 2 load 是非常强大的；但我们要小心使用。但它也是昂贵的函数（和其他操作对比而言）而且有可能得到费解的代码。在用它之前，确定实在没有更简单的办法来解决问题。 如果我们想要做一个 快速但脏 的 dostring（加载并运行一个chunk），我们可以load的结果： load(s)() 然而，如果这里有语法错误，load 将会返回 nil 和最后的错误消息（类似 attempt to call a nil value）这样。对于更清楚的错误消息，最好使用： assert(load(s))() 通常，在一个字符串上使用 load 并没有什么意义。 f = load(\"i = i + 1\")f = function () i = i + 1 end 这两种方式是相等的，但是后面这种方式会更快，因为Lua这把函数及其包围的chunk一起编译。第一种方式中，load 会导致一次单独的编译。 load并不以词法范围来编译，前面例子中的两行并不真正的相等。为了看到不同，我们稍微改变一下例子： i = 32local i = 0f = load(\"i = i + 1; print(i) \")g = function () i = i + 1; print(i) endf() -- 33g() -- 1 函数 g 操纵的是局部变量 i，正是我们想要的，但是 f 操纵的是 全局 的 i，因为load总是在全局环境中编译其 chunk。 load最典型的用法是用来运行外部的代码（程序外的）或者动态生成的代码。比如我们可能想要策划一个被用户定义的函数；用户进入这个函数代码，然后我们使用 load 来执行它。注意，load 期望一个chunk，也就是语句。如果我们要执行一个计算一个表达式，我们可以用 return 放在表达式前： print \"enter your expression:\"local line = io.read()local func = assert(load(\"return \" .. line))print(\"the value of your expression is \" .. func()) 因为load返回的是一个普通函数，我们可以多次调用它： print \"enter function to be plotted (with variable 'x'):\"local line = io.read()local f = assert(load(\"return \" .. line))for i = 1, 20 do x = i -- global 'x' (to be visible from the chunk) print(string.rep(\"*\", f()))end 我们可以以一个 阅读器函数 来作为 load 的第一个参数。一个阅读器函数可以按部分返回chunk；load会成功调用阅读器直到其返回 nil，这个nil 代表着chunk的结束。下面的代码，和loadfile 相等： f = load(io.lines(filename, \"*L\")) 每次调用中，io.lines(filename, &quot;*L&quot;)会从给定的文件返回一个新行。所以，load会从文件逐行读取chunk。下面的版本是类似的，但是更高效： f = load(io.lines(filename, 1024)) 这里，被 io.lines返回的迭代器从 1024 字节的快读取文件。 Lua把每个独立的chunk当做匿名可变函数的主体对待。load(&quot;a = 1&quot;)返回和下面相等的表达式： function (...) a = 1 end 和其他函数一样，chunks 可以声明局部变量： f = load(\"local a = 10; print(a + 20)\")f() -- 30 使用这些特性，我们可以重写我们的策划例子来避免使用全局变量 x： print \"enter function to be plotted (with variable 'x'):\"local line = io.read()local f = assert(load(\"local x = ...; return \" .. line))for i = 1, 20 do print(string.rep(\"*\", f(i)))end load, loadfile 不会抛出错误。如果有，他们会返回 nil 和错误消息： print(load(\"i i\"))-- &gt; nil [strng \"i i\"]:1: '=' expected near 'i' 重要的是，这些函数从不会有什么副作用，这就说，他们不会改变或者创建变量，不写出文件等等。他们只是把chunk编译为一个内部格式然后以一个匿名函数运行编译结果。一个常常错误的假设就是 加载一个chunk定义了函数。在Lua中，函数定义其实是赋值；这是在运行时发生的，而不是编译时。现在我们有 foo.lua文件： -- file foo.luafunction foo (x) print(x)end 当执行命令： f = loadfile(\"foo.lua\") 这个命令编译了 foo，但是并没有定义它。为了定义它，我们必须运行下面的chunk： f = loadfile(\"foo.lua\")print(foo) -- nilf() -- run the chunkfoo(\"ok\") ok 这个行为听起来有点奇怪，但如果我们重写一下我们的文件就明白了： -- file 'foo.lua'foo = function (x) print(x)end 在一个生产力程序中，如果需要运行外部代码，我们必须处理任何加载chunk产生的错误。而且，我们可能想要在保护环境下运行新的chunk，来避免不友好的副作用。 预编译代码Lua会在运行前预编译代码，也允许我们以预编译的格式发布代码 最简单的方式来产生预编译文件————术语叫 二进制chunk————是使用luac程序。下面的调用会建立一个新文件prog.lc，其中存有 文件 prog.lua的预编译版本： $luac -o prog.lc prog.lua Lua解释器可以像其他Lua文件一样执行这个新文件： $lua prog.lc Lua在接受源代码的地方就能接受预编译代码。实际上，loadfile, load都接受预编译代码。 我们可以在Lua中写一个最小的 luac: p = loadfile(arg[1])f = io.open(arg[2], \"wb\")f:write(string.dump(p))f:close() 关键的函数是 string.dump：其接受一个Lua函数，然后返回其预编译的代码为一个字符（已合适的格式化，能被Lua载入回去） luac提供了一切有趣的选项。实际上，-l 选项列出了编译器为一个给定chunk产生的操作码。下面这行： a = x + y - z 用 luac -l 产生的输出如下： main &lt;stdin:0,0&gt; (7 instructions, 28 bytes at 0x988cb30) 0+ params, 2 slots, 0 upvalues, 0 locals, 4 constants, 0 functions 1 [1] GETGLOBAL 0 -2 ; x 2 [1] GETGLOBAL 1 -3 ; y 3 [1] ADD 0 0 1 4 [1] GETGLOBAL 1 -4 ; z 5 [1] SUB 0 0 1“Lua.The luac program offers some other interesting options. In particular, option -l lists the opcodes that the compiler generates for a given chunk. As an example, Figure 16.1, “Example of output from luac -l” shows the output of luac with option -l on the following one-line file: a = x + y - zFigure 16.1. Example of output from luac -l main &lt;stdin:0,0&gt; (7 instructions, 28 bytes at 0x988cb30) 0+ params, 2 slots, 0 upvalues, 0 locals, 4 constants, 0 functions 1 [1] GETGLOBAL 0 -2 ; x 2 [1] GETGLOBAL 1 -3 ; y 3 [1] ADD 0 0 1 4 [1] GETGLOBAL 1 -4 ; z 5 [1] SUB 0 0 1 6 [1] SETGLOBAL 0 -1 ; a 7 [1] RETURN 0 1” 预编译格式的代码并不总是比源代码小，但是加载更快。另外一个好处是其对意外的修改源文件做了一个保护。和源代码不同，恶意的崩溃二进制代码会让Lua解释器崩溃设置用户提供的机器代码。当运行普通代码时，没有什么好担心的。然而，请不要以预编译格式运行不可信的代码。load 有一个选项可以来干这个工作。 load有四个参数，后面三个是可选的。第二个是chunk的名字，只会在错误消息中使用。第四个参数是一个环境。我们感兴趣的是第三个；其控制了什么类型的chunk可以被加载。如果存在第三个参数，其必须是一个字符串：t 只允许文本（正常）chunk；b 只允许二进制（预编译）chunk；bt，默认值，允许两种格式。","categories":[{"name":"Lua","slug":"Lua","permalink":"https://gowa2017.github.io/categories/Lua/"}],"tags":[{"name":"Lua","slug":"Lua","permalink":"https://gowa2017.github.io/tags/Lua/"}],"keywords":[{"name":"Lua","slug":"Lua","permalink":"https://gowa2017.github.io/categories/Lua/"}]},{"title":"PIL.17Lua中的模块与包","slug":"PIL.17Lua中的模块与包","date":"2018-02-21T12:18:38.000Z","updated":"2018-02-21T12:18:38.000Z","comments":true,"path":"Lua/PIL.17Lua中的模块与包.html","link":"","permalink":"https://gowa2017.github.io/Lua/PIL.17Lua中的模块与包.html","excerpt":"通常，Lua并不设置什么规则，而是提供足够的方法给开发者来实现最适合他们自己的规则。然而，这些方法对于模块来说工作得并不好。模块系统的一个重要目的就是允许不同的团队共享代码。通用规则的缺乏阻碍了这个共享的实现。","text":"通常，Lua并不设置什么规则，而是提供足够的方法给开发者来实现最适合他们自己的规则。然而，这些方法对于模块来说工作得并不好。模块系统的一个重要目的就是允许不同的团队共享代码。通用规则的缺乏阻碍了这个共享的实现。 从 5.1 开始，Lua就定义了一系列关于模块和包的规则（一个包就是很多模块的集合）。这些规则并不需要从语言获得额外的设置；程序员可以用我们已经见到的东西来实现它。程序员可以自由使用不同的规则。当然，有些实现可能会使程序无法使用外部的模块，或者外部的程序不能使用它。 从用户的角度看，模块就是 能通过 require加载，然后创建并返回一个表 的代码（用C或者Lua写的）。模块导出的所有东西，比如函数和常量，都定义在表内，这个表工作类似一个命名空间。 来看个例子，所有的标准库都是模块。我们可以像下面这样使用数学库： local m = require \"math\"print(m.sin(3.14)) -- 0.0015926529164868 然而，发行版内的解释器预加载了所有的标准库，代码与下相等： math = require \"math\"string = require \"string\" 这个预加载允许我们写一些常用的函数而不用自己去加载 那些库。 用表来实现模块的一个非常明显的好处就是，我们可以向操纵其他表一样操作模块，并能利用Lua全部的能力来建立额外的特性。在大部分语言中，模块并不是第一类的值（这就是说，他们不能存储在变量中，或者作为参数传递给函数 等等）；要为模块提供一些额外的特性时，这样的语言需要一些特别的方法。在LUa我们可以自由活动额外的特性。 具体点说，用户有好几种方法可以从一个模块调用函数。常用的方法是： local mod = require \"mod\"mod.foo() 我们也可以为模块设置一个局部的名字： local m = require \"mod\"m.foo() 同时，还可以为单独的函数提供名字： local m = require \"mod\"local f = m.foof() 还可以只导入一个特定的函数： local f = require \"mod\".foo -- (require(\"mod\")).foof() 这些使用方法是Lua已经提供的，不需要什么额外的工作来支持。 require 函数抛开require函数在整个模块实现中的重要角色不提，它其实只是一个普通的函数，没有什么特权。要加载一个模块，我们简单的以一个参数调用它，也就是模块的名字。记住，当给函数的参数是一个 字符串，括号是可选的，通常我们会省略它。下面的用法是正确的： local m = require ('math')local modname = 'math'local m = require(modname) 函数require试图对一个模块是什么做最小的假设。对它来说，一个模块只是一些定义了几个值（函数或包含函数的表）的代码。典型的，这些代码会返回一个由模块函数组成的表。然而，因为这个动作是由模块代码完成的，而不是通过 require，某些模块可能会选择返回其他值或者，设置会有一些副作用（如建立了全局变量）。 require的第一步是检查表 package.loaded，确定这个模块是否已经加载。如果加载，就返回对应的值。因此，一旦一个模块加载后，其他调用加载这个模块只会简单的返回同样的值，而不会再次运行模块代码。 如果模块没有加载，require会以模块名字搜索一个文件。（这个搜索被变量package.path来引导，我们在后面会讨论）如果找到这样一个文件，就会使用 loadfile来加载。结果就是我们叫做 loader 的函数。（loader在调用的时候会加载模块） 如果require不能找到对应的Lua文件，就会以那个名字搜索一个C库（这时，搜索通过变量package.cpath来引导）。如果找到一个C库，则会以底层函数 package.loadlib来加载，寻找一个叫做 luaopen_模块名 的函数。在这样的情况下，loader是 loadlib的结果。luaopen_模块名是个C函数，但表现得就像一个Lua函数。 不要关心这个模块是Lua文件还是C库，require现在有了一个加载器。为了最终加载这个模块，require以两个参数调用加载器(loader）：模块名，找到的加载器名字。（多数模块会忽略这些参数）。如果加载器返回了什么值，require返回这些值并把他们保存在 package.loaded表中，将来再加载这个模块的时候会返回这个值。如果加载器没有返回任何值，表项package.loaded[@rep{modname}]仍然是空的，require表现得就像这个模块返回了 true 。没有这个修正的话，接下来调用 require 加载这个模块会再次执行这个模块。 为了让 require 强制性的重复加载同样的模块，我们可以在 package.loaded中擦除对应的项： package.loaded.模块名 = nil 这样下次的话 require 就会再次加载了。 一个经常遇到的抱怨就是，require 不能在模块在加载的时候传递参数。具体说，数据库模块可能会有一个选项来在 弧度 和角度间选择： -- bad codelocal math = require(\"math\", \"degree\") 这里的问题是，require 的一个主要目的就是避免多次加载同一模块。一旦加载一个模块，程序的任何部分都可以重复使用这个模块。当以不同的参数加载同一模块时可能和出现冲突。如果你想要你的模块有参数，较好的方式就是建立一个显式的函数来设置他们，这样： local mod = require \"mod\"mod.init(0, 0) 如果初始化函数返回模块本身，我们可以这样写： local mod = require \"mod\".init(0, 0) 无论何时要记住，模块本身只会被加载一次。 重命名一个模块通常，我们以模块的原始名字来使用它，但某些时候我们要重命名来避免名字冲突。一个典型的情况就是当我们要加载同一模块的不同版本来测试时。Lua模块在内部不会保持名字固定，所以一般重命名 .lua文件就够了。然而，我们不能编辑C库的 对象代码来改变 luaopen_*函数的名字。为了支持类似的重命名，require使用了个小把戏：如果模块名包含一个连字符 -，require会在建立 luaopen_*函数的时候去掉这个连字符后的内容。比如，如果一个模块叫 mod-v3.4，require 会期望它的打开函数是 luaopen_mod，而不是luaopen_mod-v3.4（即使是一个合法的C名字）。因此，我们要使用两个模块（或同一模块的不同版本），我们可以把其中一个命名为 mod-v1。当我们调用 m1 = require &quot;mod-v1时，require会找到命名过的 文件，但在文件中，其打开函数依然是 luaopen_mod。 路径搜索当搜索一个Lua文件时，引导 require 的路径和典型的路径有点不同。一个典型的路径就是一个目录列表，在里面搜索给定的文件。然而，ISO C并没有目录的概念。因此，require 使用的路径是一个 模板 列表，每个模板指定了一个可选的方式来 转换一个模块名（ require 的参数）到一个文件名。更特别地，路径中的每个模块都是一个包含可选 ? 的名字。 对于每个模板，require以模块名替换对应的?，然后检查是否存在这么样一个文件；如果没有，就继续下一个妙手空空。路径中的模板以 ;分隔。： “?;?.lua;c:\\windows\\?;/usr/local/lua/?/?.lua” 当我们调用 require &quot;sql&quot;时，将会尝试下面的文件： sqlsql.luac:\\windows\\sql/usr/local/lua/sql/sql.lua require用来搜索Lua文件的路径总是 变量package.path的当前值。当模块 package在初始化时，其会设置这个变量值为环境变量LUA_PATH_5_3；如果环境变量没有定义，则会尝试环境变量LUA_PATH。如果两者都没有定义的话，Lua使用一个编译器定义的默认路径。比如，当我们设置 LUA_PATH_5_3为mydir/?.lua时，最终的路径将会是 mydir/?.lua加上默认的路径。 用来搜索C库的路径工作起来相似，其值从 package.cpath取得。一个POSIX中典型的路径值会是：./?.so;/usr/local/lib/lua/5.2/?.so 注意这里面定义了后缀名，因此在windows中应该是这样的： .\\?.dll;c:\\Program Files\\Lua502\\dll\\?.dll 函数 package.searchpath对搜索库的这些规则进行了编码。其接受一个模块名和一个路径，然后根据这些规则来寻找一个文件。其返回第一个找到 文件名或者 nil 加上描述所有文件打开都失败的错误消息，例如：&gt; path = &quot;.\\\\?.dll;C:\\\\Program Files\\\\Lua502\\\\dll\\\\?.dll&quot;&gt; print(package.searchpath(&quot;X&quot;, path)) nil no file &apos;.\\X.dll&apos; no file &apos;C:\\Program Files\\Lua502\\dll\\X.dll&apos;” 搜索器实际上，require比我们已经描述的更复杂些。搜索Lua文件和搜索C库是 searchers（搜索器）的两个不同实例。一个搜索器只是一个函数，其会根据模块名来返回这个模块的加载器，或者在其找不到时返回nil。 数组package.searchers列出了require使用的搜索器。当找寻一个模块时，require会把参数逐个传递给表中的搜索器，直到有返回这个模块加载器的出现。如果并没有，那require会给出一个错误。 使用一个列表来驱动对模块的搜索允许require变得非常灵活。如果我们想把模块放在压缩的 zip 文件中，我们只需要提供一个何时的搜索器函数，然后把他放在这个列表中。默认设置下，Lua文件和C库的搜索器分别是第二第三个元素。在他们之前，是预加载的搜索器。 预加载(preload)的搜索器允许一个专门的函数来加载模块。其使用一个表，package.preload，来映射模块名与加载器函数。当搜索一个模块名时，这个搜索器简单的在表中寻找给定名字。如果找到就把对应函数返回为加载器，否则返回nil。这个加载器提供了一个操控某些不符合习惯的情况的一般性方法。比如，静态链接至Lua的C库可以把其 luaopen_*函数注册到 preload表中，这样其只会在用户需要那个模块时被调用。这样的方式，程序将不会因为要打开不使用的模块而浪费资源。 package.searchers的默认内容包含第四个函数，这和子模块相关。我们后面讨论。 编写模块的基本方式最简单的建立一个模块就是：建立一个表，把所有希望导出的函数放在里面，然后返回这个表。 local M = &#123;&#125;local function new(r, i) return &#123;r = r, i = i&#125;endM.new = newM.i = new(0, 1)function M.add (c1, c2) return new(c1.r + c2.r, c1.i + c2.i)endfunction M.sub (c1, c2) return new(c1.r - c2.r, c1.i - c2.i)end function M.mul (c1, c2) return new(c1.r*c2.r - c1.i*c2.i, c1.r*c2.i + c1.i*c2.r)end local function inv (c) local n = c.r^2 + c.i^2 return new(c.r/n, -c.i/n)end function M.div (c1, c2) return M.mul(c1, inv(c2))end function M.tostring (c) return string.format(\"(%g,%g)\", c.r, c.i)endreturn M 注意：只是通过在其前面加上 local 就把函数 new, inv定义成为了私有的 某些人可能不喜欢最后的返回语句。一个避免的方式是直接把模块表赋值给 package.loaded： local M = &#123;&#125;package.loaded[...] = M 需要注意的是 require 在调用加载器的时候会传递模块名作为第一个参数。因此，... 就代表了那个名字。在这个赋值后，我们就不需要在模块的最后返回 M：如果一个模块不返回一个值，require 将会返回package.loaded[modname]的当前值（如果不是nil）。不管怎么样，我发现在最后写上return会非常的清晰。如果我们忘记了这点，任何与这个模块相关的测试都会检查到错误。 另外一个方式就是把所有的函数定义为局部的，然后在最后构造要返回的表： local function new (r, i) return &#123;r=r, i=i&#125; end -- defines constant 'i'local i = complex.new(0, 1) other functions follow the same patternreturn &#123; new = new, i = i, add = add, sub = sub, mul = mul, div = div, tostring = tostring, &#125; 这种方式的好处是什么？我们不需要在每个名字前加上前缀 M 或者其他类似的前缀；这里有一个显式的导出列表；我们同样的方式定义和使用导出的/内部的 函数。不好的地方是什么？导出列表到了模块的后面而不是开始，在进行快速文档的时候会更实用；导出列表有点多余，因为我们必须写两次名字。（最后一个坏处有可能是一个好处，因为其允许在模块内外拥有不同的名字，但我想程序员很少做这个事情） 不管我们如何定义一个模块，用户都可以以标准的方式进行使用： local cpx = require \"complex\"print(cpx.tostring(cpx.add(cpx.new(3,4), cpx.i)))-- (3, 5) 后面我们会看到怎样使用某些Lua的进阶特性，比如元表和环境，来写模块。然而，多数时候我都只使用这些基本的方式。 子模块和包Lua允许模块名字是层级的，使用一个.来分别名字等级。一个mod.sub 的模块是 mod 的子模块。一个 包是模块的完整树；其是Lua中发行版的单元。 当我们需要一个mod.sub模块时，函数 require 将会首先查询 package.loaded表，然后package.preload表，使用的是mod.sub作为键。这里，.就是一个普通的字符，和其他字符一样。 然而，当搜索定义了那个子模块的文件时，require把 . 翻译为另外一个字符，通常是系统的目录分隔符（/或 windows中的\\）。","categories":[{"name":"Lua","slug":"Lua","permalink":"https://gowa2017.github.io/categories/Lua/"}],"tags":[{"name":"Lua","slug":"Lua","permalink":"https://gowa2017.github.io/tags/Lua/"}],"keywords":[{"name":"Lua","slug":"Lua","permalink":"https://gowa2017.github.io/categories/Lua/"}]},{"title":"PIL.22-Lua中的环境","slug":"PIL.22-Lua中的环境","date":"2018-02-21T02:20:30.000Z","updated":"2018-02-21T02:20:30.000Z","comments":true,"path":"Lua/PIL.22-Lua中的环境.html","link":"","permalink":"https://gowa2017.github.io/Lua/PIL.22-Lua中的环境.html","excerpt":"在大多数编程语言中，全局变量是非常讨厌的。一方面，使用全局变量会导致复杂的代码，让程序中不相关的不相关的部分看起来纠缠在了一起。另一方面，谨慎的使用全局变量可以很好的表达一个程序中的全局部分；但是，全局常量是没有大的问题的，但是像Lua一样的动态语言没有办法来分别一个变量是不是常量。","text":"在大多数编程语言中，全局变量是非常讨厌的。一方面，使用全局变量会导致复杂的代码，让程序中不相关的不相关的部分看起来纠缠在了一起。另一方面，谨慎的使用全局变量可以很好的表达一个程序中的全局部分；但是，全局常量是没有大的问题的，但是像Lua一样的动态语言没有办法来分别一个变量是不是常量。Lua这样的嵌入式语言增加了另外一个混合的集成部分：全局变量在程序内均可见，但是Lua对于一个程序是什么没有清晰的概念，而以被塑主程序调用的一串代码来表示（chunks）。 Lua通过不使用全局变量，而是不遗余力的进行了模拟。在第一个近似方法中，我们可以认为LUa把所有的全局变量放在一个常规的表中，叫做 全局环境。在后面我们可以看到，Lua可以把它的“全局”变量保存在几个环境中。当现在，我们只关注第一个情况。 使用表来保存全局变量简化了Lua的内部实现，因为不需要单独为全局变量设计一个不同的数据结构。另外一个好处是我们可以像操纵其他表一样操纵这个全局环境。为了帮助这些操纵，Lua将全局环境本身存储在全局变量_G中。（结果就是，_G._G等于 _G）。具体而言，下面的代码打印出全局环境中所有变量的名字： for n in pairs(_G) do print(n) end 环境对于每个Lua State，其在建立的时候，就有一个全局环境，这个环境通过 _G变量来引用，这是Lua内部保留的。 而对于每个执行的代码片段， chunk，都会在编译的时候，被Lua设置一个 自己的环境。这个环境就是它的第一个上值 _ENV，通常，会让 _ENV与 _G相等。我们可以通过代码来验证这一点： print(_G, _ENV) 输出结果： table: 0x7fea4ad002e0 table: 0x7fea4ad002e0 说明两者引用的对象相同。我们说道，一个没有加 local 的变量是全局的，很明显，在这个时候，我们定义一个全局变量的话，也会影响 _G。 所以可以通过一个把 _ENV 变量变化一下来让他不要影响 _G： _ENV = &#123;_G = _G&#125;g = \"global var\"_G.print(_ENV.g, _G.g) 可以看到，全局环境 _G不再受到影响。而局部变量，并不会进入 _ENV中。 动态名字的全局变量通常，访问并设置全局变量通过赋值就够了。然而，某些时候我们需要一些类似 元-编程的形式，例如当我们需要操作一个名字存储在其他变量中或是在运行时计算的全局变量。为了获得这样一个变量的值，某些程序员会写如下代码： value = load(\"return\" .. varname)() 如果 varname 是 x，字符串连接后的返回值是 return x，这将会得到我们期待的结果。然而，这样的代码会创建并编译一个新的 chunk，代价是昂贵的。我们可以通过下面的代码来达成同样的目的，这个的效率会提高一个量级： value = _G[varname] 因为环境是一个普通表，我们可以简单的用我们期待的键来索引它就好了（变量名字）。 类似地，我们可以为一个名字动态计算的全局变量赋值，通过 _G[varname] = value。要注意：有些程序员因为这个特性而有点兴奋，写出了类似 _G[&quot;a&quot;] = _G[&quot;b&quot;]这样的代码，但这仅仅只是一个 a = b的复杂方式。 前面那个问题的一般化就是在动态名字内运行字段，比如io.read 或者 a.b.c.d。如果我们写出 _G[&quot;io.read&quot;]，很明显，我们不会从 表 io 内获得字段 read。但是我们可以编写函数getfield，然后 getfield(&quot;io.read&quot;)就可以获得期望的结果。这个函数的主体是一个循环，从 _G开始，然后逐个字段进化。 function getfield (f) local v = _G -- start with the table of globals for w in string.gmatch(f, \"[%a_][%w_]*\") do v = v[w] end return vend 我们依赖 gmatch 来遍历所有 f 中的标识符。 对应来设置字段的函数有点复杂。类似 a.b.c.d = v 这样的赋值类似： local temp = a.b.ctemp.d = v 这就是说，我们必须获取直到最后一个名字，然后单独的操作最后这个名字。 setfield 做了这个工作，还会在值不存在时建立临时表。 function setfield (f, v) local t = _G -- start with the table of globals for w, d in string.gmatch(f, \"([%a_][%w_]*)(%.?)\") do if d == \".\" then -- not last name? t[w] = t[w] or &#123;&#125; -- create table if absent t = t[w] -- get the table else t[w] = v end endend 下面的代码会建立一个全局表 t ， 另外一个表 t.x，然后把 10 赋给 t.x.y ： setfield(\"t.x.y\", 10)print(t.x.y) -- 10print(getfield(\"t.x.y\")) -- 10 全局变量声明Lua中的全局变量不需要声明。尽管在小程序中这个行为非常的方便，但在大程序中一个简单的排印错误就可能产生难以找到的Bug。然而，我们也可以改变这个行为。因为Lua在普通表内保存全局变量，我们可以使用元表来检查是否Lua在访问一个不存在的变量。 第一个方式简单检查任何对全局表中不存在键的访问： setmetable(_G, &#123; __newindex = function (_, n) error(\"attempt to write to undeclared variable \".. n, 2) end, __index = function (_, n) error(\"attempt to read undeclared variable \".. n, 2) end, &#125;) 在这个代码后，所有试图访问一个不存在的全局变量都会触发一个错误： &gt;print(a)stdin:1: attempt to read undeclared variable a 但是我们怎么样来声明新变量呢？一个选择是使用 rawset，这通过下面的元方法： function declare (name, initval) rawset(_G, name, initval or false)end （ or, false 保证新全局变量总是与值 nil 不同） 另外一个更简单的选择只在函数内限制对新的全局变量赋值，在一个chunk的外部等级上运行自由赋值。 为了检查一个赋值是不是在 main chunk中，我们必须使用 debug 库。 调用 debug.getinfo(2, &quot;S&quot;)会返回一个表：表中的字段 what 表明 调用元方法的 函数是一个 main chunk，还是一个普通的Lua函数，或是一个C函数。使用这个函数，我们可以重写我们的 __newindex 元方法： __newindex = function (t, n, v) local w = debug.getinfo(2, \"S\").what if w ~= \"main\" and w ~= \"C\" then error(\"attempt to write to undeclared variable \" .. n, 2) end rawset(t, n, v)end 新版本的函数也会接受从C代码的赋值，就跟这个类型的代码通常会知道他们在做什么。 如果我们需要测试一个变量是否存在，我们不能简单的把它和 nil 比较，因为如果其是 nil 的话，就会产生一个错误。我们应该使用 rawget，这将会避免触发元方法： if rawget(_G, var) == nil then -- 'var' is undeclared ...end 我们的设计不允许全局变量的值是 nil，因为这样会被自动的认为是未声明的。但纠正这个问题并不难。我们所需要的只是一个辅助的表，用这个表来保存所有声明过的变量名字。无论合适调用一个元方法，就会在这个表内检查这个变量是不是没有声明。代码可能如下： local declaredNames = &#123;&#125;setmetatable(_G, &#123; __newindex = function (t, n, v) if not declaredNames[n] then local w = debug.getinfo(2, \"S\").what if w ~= \"main\" and w ~= \"C\" then error(\"attempt to write to undeclared variable \" .. n, 2) end declaredNames[n] = true end rawset(t, n, v) end, __index = function (_, n) if not declaredNames[n] then error(\"attempt to read undeclared variable\" .. n, 2) else return nil end end,&#125;) 现在，即使是类似 x = nil 这样的赋值也可以用来声明一个全局变量。 两种解决方式的开销都是微不足道的。第一种方式，在正常操作间元方法永不会被调用。第二种中，他们可能会被调用，但只是在程序访问一个值为 nil 的变量时。 Lua的发行版中有一个模块 strict.lua，使用上面的代码来实现全局变量的检查。在开发Lua代码的时候使用它是一个好习惯。 非全局环境Lua中，全局变量不需要真正的是全局的。就跟我们已经提到的一样，Lua并不真正的有全局变量。 这听起来会有点奇怪，因为我们这些文章中都使用了全局变量了。其实是Lua是不遗余力的给程序员一个模拟的全局变量。现在我们就来看一下Lua是怎么样来做的。 首先，我们先忘记关于全局变量的一切。我们会先从 自由名字 的概念开始。 一个 自由名字 是一个没有显式声明限制的名字，这就是说，其不会出现在一个对应局部变量的范围内。具体而说，在下面的chunk中， x, y 是自由名字，而 z 不是： local z = 10x = y + z 现在到重要的部分了：Lua的编译器会被所有的自由名字如 x ，翻译为 _ENV.x。因此，前面的chunk 和下面完全相等： local z = 10_ENV.x = _ENV.y + z 但是，新的变量 _ENV又是什么？ _ENV_ENV不能是一个全局变量；我刚才说了Lua没有全局变量。再次，编译器耍了个小把戏。我已经提到过，Lua把任何 chunk都当做一个 匿名函数 。实际上，Lua会把我们的原始chunk编译成下面这样： local _ENV = some valuereturn function (...) local z = 10 _ENV.x = _ENV.y + zend 这就是说，Lua在一个预定义的上值（一个外部的局部变量）_ENV存在的情况下编译chunk。因此，所有的变量要么是一个局部的（如果绑定到一个名字），或者是 _ENV的一个字段。这里_ENV是一个局部变量（一个上值）。 _ENV的初始值可以是任何表。（实际上，其也不需要一定是一个表；后面会提到）这样的表被叫做环境。 为了保存全局变量的模拟，Lua内部保留了应一个用做 全局环境 的表。通常，在我们加载一个 chunk，函数 load 会以这个 全局环境来初始化预定义的上值。所以，我们原始的chunk 会变得和下面的相等： local _ENV = the global environmentreturn function (...) local z = 10 _ENV.x = _ENV.y + zend 这个代码的结果就是，全局环境的 x 字段获得值为 y 字段的值加上10。 第一种见解认为，这看起来是一个非常复杂的方式来操作全局变量。我不会辩解这是最简单的方式，但是其提供的灵活性，以其他简单实现很难达到。 在我们继续以前，我们来总结一下Lua操纵全局变量的过程： 编译器在其编译的chunk外建立一个局部变量 _ENV。 把所有的自由名字 var 翻译为 _ENV.var 函数 load, loadfile以全局环境（Lua内部保留的一个普通表）初始化chunk的第一个上值。 除此之外，其他的并不那么复杂。 某些用户可能会变得很混淆，因为他们试图在这些规则上弄些魔法出来。没有什么额外的魔法。实际上，前面的两条是完全被编译器完成的。除了被编译器预定义的，_ENV是一个简单的变量。在编译器外，_ENV并没有什么特别的意义。类似的，从 x 到 _ENV.x 的翻译也是一个简单的语发上的变化，并没有隐藏的意思。实际上，在翻译后，_ENV将会指向的任何_ENV变量在代码中可见的地方，遵循标准的可见性规则。 使用 _ENV在本节中，我们会看到一些_ENV带来的灵活性。 要记住，我们必须在本节中以 一个 chunk来运行例子程序。我们如果在交互模式下一行行的输入，每行都会成为一个不同的chunk，因此也具有不同的_ENV变量。因此，我们使用 do ... end 来包围代码块。 因为_ENV是一个普通变量，我们可以像其他变量一样赋值或者访问。_ENV = nil 将会时任何接下来在chunk对全局变量的访问无效。 这个用来控制我们代码使用的变量是非常有效的： local print, sin = print, math.sin_ENV = nilprint(13) -- 13print(sin(13)) -- 0.42016703682664print(math.cos(13)) -- error! 所有对自由名字的赋值都会产生一个类似的错误。 我们可以显示的写出 _ENV 来绕过一个局部声明： a = 13 -- globallocal a = 12print(a) -- 12 (local)print(_ENV.a) -- 13 (global) 可以用_G来完成同样的事： a = 13 -- globallocal a = 12 print(a) -- 12 (local)print(_G.a) -- 13 (global) 通常，_G 和 _ENV 引用同样的表，但是，不管这个事实，他们是不同的实体。 _ENV 是一个局部变量，所有访问 全局变量 的操作都是访问它。_G是一个全局变量，没有什么特殊的状态。从定义上讲，_ENV 总是向当前环境； _G通常引用全局环境，没有人会改变它的值。 _ENV 主要的用途就是来改变代码的环境。一旦我们改变环境，所有全局访问 都会使用这个新表。 -- change current environment to a new empty table_ENV = &#123;&#125;a = 1print(a) -- stdin:4: attempt t ocall global 'print' (a nil value) 如果新环境是空的，我们就丢失了所有的全局变量，包括 print。所以，我们应该首先以一些常用的变量来保存，具体点说，就是用全局环境。 a = 15 -- create a global variable_ENV = &#123;g = _G&#125; -- change current environmenta = 1 -- create a field in _ENVg.print(_ENV.a, g.a) -- 1 15 现在，当我们访问全局的 g 时（存在于 _ENV 中，不在全局环境中）我们获得了全局环境，Lua会在这里面找到函数 print。 我们可以使用 _G 名字来重写先前的例子： a = 15_ENV = &#123;_G = _G&#125;a = 1_G.print(_ENV.a, _G.a) 统一特殊的地方就是，当Lua建立初始化的全局表时，让 _G 字段指向 全局环境 _G本身。Lua不关心这个变量的当前值。 另外一个保存我们新环境的方式是通过继承： a = 1local newgt = &#123;&#125;setmetatable(newgt, &#123;__index = _G&#125;)_ENV = newgtprint(a) 在代码中，新环境从全局环境继承了 print, a。然而，所有的赋值都是到新表中。错误的在全局环境中改变一个变量是没有危险的，尽管我们还能通过 _G 改变他们： -- 从前面的代码继续a = 10 -- 这个值将会在_ENV.a/newgt.a 中print(a, _G.a) -- 10 1_G.a = 20print(_G.a) -- 20 因为是一个普通的变量，_ENV遵循常规的范围规则。实际上，在一个chunk内定义的函数 访问 _ENV 就和他们访问其他的外部变量一样: _ENV = &#123;_G = _G&#125;local function foo () _G.print(a) -- 编译为 _ENV._G.print(_ENV.a)enda = 10foo() -- 10_ENV = &#123;_G = _G, a = 20&#125;foo() -- 20 如果我们定义了一个新的局部变量 _ENV，对自由名字的访问将会绑定到这个新变量： a = 2do local _ENV = &#123;print = print, a = 14&#125; print(a)endprint(a) 因此，定义一个有一个私有环境的函数并不难： function factory (_ENV) return function () return a endendf1 = factory &#123;a = 6&#125;f2 = factory &#123;a = 7&#125;print(f1())print(f2()) 环境与模块在编写模块中，有一个害处就是会很容易的污染全局环境，比如忘记了给一个私有声明忘记了 local 。环境提高了一个有趣的技术来解决这个问题。一旦模块的 main chunk有一个独占的环境，模块内的所有函数共享这个表，所有的全局变量也会在这个表内。我们可以声明所有公共函数为全局变量，他们就会自动的进入一个单独的表。模块只需要把这个表 赋值给 _ENV 就可以了。在这后，当我声明一个函数 add，就将会变为 M.add： local M = &#123;&#125;_ENV = mfunction add (c1, c2) return new(c1.r + c2.r, c1.i + c2.i)end 更多的是，我们可以不用加前缀就能调用其他函数 。在前面的例子中，add 从其环境中获得 new，也就是说，其调用的是 M.new。 这个方法提供了对模块的很好的支持，而程序员只需要做很少的事情。这将完全不需要前缀了。在调用 导出函数 和私有汗衫没也不再有区别。 如果程序员忘记了 local，其也不会污染全局的命名空间；而一个私有函数 简单的变成公有的。 尽管这样，但我还是宁愿使用原始的基本变成方法。他会需要更多的工作，但是得出的代码会非常去清晰。为了避免错误的建立一个全局，我使用 _ENV = nil。在这之后，所有对全局变量的赋值都会出错。 为了访问其他模块，我们可以使用前面提到的方式之一。具体点，我们可以声明一个局部变量来保存全局环境。 local M = &#123;&#125;local _G = _G_ENV = nil 接下来我们就可以用_G访问全局名字，用M 来访问模块。 一个更守规矩的方式是只把我们需要的函数，最多是模块需要的函数声明为局部的。 -- module setuplocal M = &#123;&#125;-- IMport section:-- declare everythin this module needs from outsidelocal sqrt = math.sqrtlocal io = io-- no more external access after this point_ENV = nil 这个技术会做更多的活，但是更好的指出了模块的依赖。 _ENV 和 load先前提到，load 在加载一个chunk的时候通常时用全局环境来初始化 _ENV上值。 然而，load 有一个可选的第四参数来允许我们给 _ENV一个不同的值。 （函数 loadfile有一个类似的参数） 作为一个初始化的例子，考虑我们有一个典型的配置文件，定义了几个常量和函数，接下来我们会使用它们；看起来会是这样的： -- file 'config.lua'width = 200height = 200... 我们可以用下面的代码来加载： env = &#123;&#125;loadfile(\"config.lua\", \"t\", env)() 配置文件内的所有代码会在空环境 env 下运行，就跟沙盒一样。实际上，所有的定义都会进入这个函数。配置文件没有办法来影响其他什么东西，及时是犯错。即使是恶意的代码也不会造成伤害。 某些时候，我们需要执行一个chunk多次，每次有不同的环境表。在这样的情况下，load 额外的参数是不实用的。我们有其他两个选择。 第一个选择是使用函数 debugsetupvalue。就跟名字一样，setupvalue运行我们改变一个给定函数任何上值。下面的片段演示了其用法： f = load(\"b = 10; return a\")env = &#123;a = 20&#125;debug.setupvalue(f, 1, env) -- 第一个上值是 _ENVprint(f()) -- 20print(env.b) -- 10 给setupvalue的第一个参数是函数，第二个是上值索引， 接着是上值的新值。在这种用法中，第二个参数总是1：当一个函数代表一个chunk，Lua假设其只有一个上值 _ENV。 一个不好的地方就是这种方式依赖debug库。这个库打破了程序的某些通常假设。比如，debug.setupvalue打破了Lua的可见性规则：我们在词法范围外不能访问一个局部变量。 另外以不同环境运行一个chunk的选择是在加载它是进行设置。想象我们在chunk前添加了下面的行： _ENV = ...; 要记住，Lua把任何的chunk编译成一个变参的函数。所以，_ENV会获得传给函数的第一个参数，相当是把这个参数设置为了环境。下面的代码片段展示了这点： prefix = \"_ENV = ...;\"f = loadwithprefix(prefix, io.lines(filename, \"*L\"))...env1 = &#123;&#125;f(env1)env2 = &#123;&#125;f(env2)","categories":[{"name":"Lua","slug":"Lua","permalink":"https://gowa2017.github.io/categories/Lua/"}],"tags":[{"name":"Lua","slug":"Lua","permalink":"https://gowa2017.github.io/tags/Lua/"},{"name":"PIL","slug":"PIL","permalink":"https://gowa2017.github.io/tags/PIL/"}],"keywords":[{"name":"Lua","slug":"Lua","permalink":"https://gowa2017.github.io/categories/Lua/"}]},{"title":"skynet中sproto使用示例","slug":"skynet中sproto使用示例","date":"2018-02-15T17:09:23.000Z","updated":"2018-02-15T17:09:23.000Z","comments":true,"path":"Lua/skynet中sproto使用示例.html","link":"","permalink":"https://gowa2017.github.io/Lua/skynet中sproto使用示例.html","excerpt":"Sproto是一个用C编写的高效序列化库，主要是想用来做Lua绑定。类似Google的 protocol buffers，但是速度更快。其设计得非常简单。只支持Lua支持的几种数据类型，其可以很容易的绑定到其他动态语言，或者直接在C中使用。","text":"Sproto是一个用C编写的高效序列化库，主要是想用来做Lua绑定。类似Google的 protocol buffers，但是速度更快。其设计得非常简单。只支持Lua支持的几种数据类型，其可以很容易的绑定到其他动态语言，或者直接在C中使用。 简介其项目开源到 github.com/cloudwu/sproto 其主要包含一些提供给 Lua 使用的 API，一个语法解析模块(parser) sprotoparser，还有一个RPC API，加上 C库。 解析器local parser = require \"sprotoparser\" parser.parse 把一个sproto 协议框架解析为一个二进制字符串 在解析的时候需要用到这个。可以用它来产生二进制字符串。框架文本和解析器在程序运行的时候并不需要 Lua API我们先看看看它提供给 Lua 使用的API。 local sproto = require \"sproto\"local sprotocore = require \"sproto.core\" -- optional sproto.parse(schema) 通过一个 文本字符串 的框架生成一个 sproto 对象。 sproto.new(spbin) 通过一个 二进制的字符串（parser生成） 生成一个 sproto 对象。 sprotocore.newproto(spbin) 通过一个 二进制的字符串（parser生成） 生成一个 C sproto 对象。 sproto.sharenew(spbin) 从一个 sproto C 对象（sprotocore.newproto()生成）共享一个 sproto 对象。 sproto:exist_type(typename) 检查sproto对象中是否存在此类型。 sproto:encode(typename, luatable) 把一个Lua表以 typename 编码到二进制字符串内。 sproto:decode(typename, blob [,sz]) 以typename来解码一个 sproto:encode()产生的二进制字符串。如果 blob 是一个 lightuserdata (C 指针），sz 是必须的。 sproto:pencode(typename, luatable) 类似sproto:encode，但是会压缩结果。 sproto:pdecode(typename, blob [,sz]) 类似 sproto.decode，但是会先解压缩对象。 sproto:default(typename, type) 以类型名的默认值来建立一个表。类型可以是 nil, REQUEST, RESPONSE。 RPC API这些API是对 core API的封装。 sproto:host([packagename]) 以 packagename 建立一个宿主对象 host 来传输RPC消息。 host:dispatch(blob [,sz]) 以 host 对象内的（packagename）来解压并解码（sproto:pdecode）二进制字符串。 如果 .type 存在，这是一个 有.type REQUEST 消息，返回REQUEST, protoname, message, responser, .ud。responser是一个用来编码 响应消息的函数。 当.session不存在时，responser将会是 nil。 如果 .type 不存在，这是一个给 .session 的 RESPONSE消息。返回 REPONSE, .session, message, .ud。 host:attach(sprotoobj) 建立一个以 sprotoobj 来压缩和编码请求消息的函数 function(protoname, message, session, ud)。 如果不想使用主机对象，可以用下面的API来编码和解码RPC消息。 sproto:request_encode(protoname, tbl) 以protoname 来编码一个请求消息。 sproto:response_encode(protoname, tbl) 以protoname 来编码一个响应消息。 sproto:request_decode(protoname, blob [,sz]) 解码一个请求消息。 sproto:response_decode(protoname, blob [,sz] 解码一个响应消息 数据类型 string : string binary : binary string (字符串的子类型) integer : 整型，最大整型是有符号64位的。 可以是一个不动点的特定精度的数字。 boolean : true or false 在类型前面添加一个 * 来表示一个数组。 可以指定一个主索引，数组将会被编码成一个无序的 map。 用户定义的类型可以是任何非保留的名字，也支持嵌套类型。 没有双精度或者实数类型。作者认为，这些类型非常少使用。如果果真需要的话，可以用字符串来序列化双精度数。如果需要十进制数，可以指定固定的精度。 枚举类型并不十分实用。我们在Lua定义一个 enum 表来实现。 协议定义sproto是一个协议封装库。所以我们要定义我们自己的协议格式(schema)。 sproto消息是强类型的，而且不是自描述的。所以必须用一个特殊的语言来定义我们自己的消息结构。 然后调用 sprotoparser 来把 协议格式 解析为二进制字符串，这样 sproto 库就可以使用它。 可以离线解析，然后保存这些字符串，或者可以在程序运行的时候解析。 一个协议框架可能会像这样： # 注释.Person &#123; # . 表示一个用户定义数据类型 name 0 : string # 内建数据类型 string id 1 : integer email 2 : string .PhoneNumber &#123; # 可以嵌套用户自定义数据类型 number 0 : string type 1 : integer &#125; phone 3 : *PhoneNumber # *PhoneNumber 表示数组 height 4 : integer(2) # (2) means a 1/100 精度的数 data 5 : binary # 二进制数据&#125;.AddressBook &#123; person 0 : *Person(id) # (id) 可选， Person.id 是一个主索引&#125;foobar 1 &#123; # 定义一个新协议 (for RPC used) tag 1 request Person # 把数据类型 Person与 foobar.request 相关联 response &#123; # 定义 foobar.response 的数据类型 ok 0 : boolean &#125;&#125; 一个框架可以是 被 sproto 框架语言自描述的： .type &#123; .field &#123; name 0 : string buildin 1 : integer type 2 : integer # type is fixed-point number precision when buildin is SPROTO_TINTEGER; When buildin is SPROTO_TSTRING, it means binary string when type is 1. tag 3 : integer array 4 : boolean key 5 : integer # If key exists, array must be true, and it&apos;s a map. &#125; name 0 : string fields 1 : *field&#125;.protocol &#123; name 0 : string tag 1 : integer request 2 : integer # index response 3 : integer # index confirm 4 : boolean # response nil where confirm == true&#125;.group &#123; type 0 : *type protocol 1 : *protocol&#125; Wire protocol每个整数以小端（little endian）格式序列化。 sproto消息必须是一个用户定义类型结构，每个结构编码成三个部分。header, field, data（头部，字段，数据）。标签（tag）和 小的整数 或 布尔值 会被编码到 field 部分，其他的都在 data 部分。 所有的字段必须以升序编码（通过 标签 tag，从0开始）。当有字段是 nil的时候（lua中的默认值），不要在消息中进行编码。 字段的标签因此可能是不连续的。 头部（header）是一个16bit整数。就是字段数两。 字段部分的所有字段都是一个 16bit 整数(n)。如果 n 为0，表示这个字段的数据编码在数据部分； 如果 n 是不为0的偶数，字段的值是 n/2-1，tag（标签）会增加1；如果 n 是奇数，表示标签是不连续的，我们应该把当前标签 增加 (n+1)/2。 数组总是被编码到数据部分，4 bytes来表示大小，接下来的字节就是内容。（len-value)二元组。查看 例子2 来了解 结构数组； 例子 3/4 展示整数数组； 例子5 是布尔数组。 对于一个整型数组，一个额外的字节(4 or 8)来表示这个值是 32bit还是 64bit。 查看下面的例子。 注意：如果 标签没有在 框架内声明，解码器为了协议版本的兼容，会忽略那些字段。 .Person &#123; name 0 : string age 1 : integer marital 2 : boolean children 3 : *Person&#125;.Data &#123; numbers 0 : *integer bools 1 : *boolean number 2 : integer bignumber 3 : integer&#125; 例子1person &#123; name = &quot;Alice&quot; , age = 13, marital = false &#125; 03 00 (fn = 3)00 00 (id = 0, value in data part)1C 00 (id = 1, value = 13)02 00 (id = 2, value = false)05 00 00 00 (sizeof &quot;Alice&quot;)41 6C 69 63 65 （“Alice) 例子2person &#123; name = &quot;Bob&quot;, age = 40, children = &#123; &#123; name = &quot;Alice&quot; , age = 13 &#125;, &#123; name = &quot;Carol&quot; , age = 5 &#125;, &#125;&#125;04 00 (fn = 4)00 00 (id = 0, value in data part)52 00 (id = 1, value = 40)01 00 (skip id = 2)00 00 (id = 3, value in data part)03 00 00 00 (sizeof &quot;Bob&quot;)42 6F 62 (&quot;Bob&quot;)26 00 00 00 (sizeof children)0F 00 00 00 (sizeof child 1)02 00 (fn = 2)00 00 (id = 0, value in data part)1C 00 (id = 1, value = 13)05 00 00 00 (sizeof &quot;Alice&quot;)41 6C 69 63 65 (&quot;Alice&quot;)0F 00 00 00 (sizeof child 2)02 00 (fn = 2)00 00 (id = 0, value in data part)0C 00 (id = 1, value = 5)05 00 00 00 (sizeof &quot;Carol&quot;)43 61 72 6F 6C (&quot;Carol&quot;) 例子3data &#123; numbers = &#123; 1,2,3,4,5 &#125;&#125;01 00 (fn = 1)00 00 (id = 0, value in data part)15 00 00 00 (sizeof numbers)04 ( sizeof int32 )01 00 00 00 (1)02 00 00 00 (2)03 00 00 00 (3)04 00 00 00 (4)05 00 00 00 (5) 例子4data &#123; numbers = &#123; (1&lt;&lt;32)+1, (1&lt;&lt;32)+2, (1&lt;&lt;32)+3, &#125;&#125;01 00 (fn = 1)00 00 (id = 0, value in data part)19 00 00 00 (sizeof numbers)08 ( sizeof int64 )01 00 00 00 01 00 00 00 ( (1&lt;32) + 1)02 00 00 00 01 00 00 00 ( (1&lt;32) + 2)03 00 00 00 01 00 00 00 ( (1&lt;32) + 3) 例子 5:data &#123; bools = &#123; false, true, false &#125;&#125;02 00 (fn = 2)01 00 (skip id = 0)00 00 (id = 1, value in data part)03 00 00 00 (sizeof bools)00 (false)01 (true)00 (false) 例子 6:data &#123; number = 100000, bignumber = -10000000000,&#125;03 00 (fn = 3)03 00 (skip id = 1)00 00 (id = 2, value in data part)00 00 (id = 3, value in data part)04 00 00 00 (sizeof number, data part)A0 86 01 00 (100000, 32bit integer)08 00 00 00 (sizeof bignumber, data part)00 1C F4 AB FD FF FF FF (-10000000000, 64bit integer) 0 Packing算法类似 Cap’n proto,但是不特别对待 0x00。 在打包的格式中，消息会被填充到8。每个标签背后的都是8字节的倍数。 标签字节的位对应了未打包字的字节数，最不重要的位对应第一个字节。 每个为0的位表示对应的字节是0。而非0的字节被打包到 标签后面。 比如： unpacked (hex): 08 00 00 00 03 00 02 00 19 00 00 00 aa 01 00 00packed (hex): 51 08 03 02 31 19 aa 01 0xff 标签会被特别对待。一个数字 N 会跟在 0xff 标签后面，表示 (N+1)\\8* 字节应该被直接复制。 字节可能包含也可能不包含0值。因为这个规则，最行的空间浪费就是每2 KB输入只打包了 2字节数据。 例如： unpacked (hex): 8a (x 30 bytes)packed (hex): ff 03 8a (x 30 bytes) 00 00 C APIstruct sproto * sproto_create(const void * proto, size_t sz); 以一个被 sprotoparser 编码的 框架字符串来建立一个 sproto 对象。 void sproto_release(struct sproto *); 释放sproto object: int sproto_prototag(struct sproto *, const char * name);const char * sproto_protoname(struct sproto *, int proto);// SPROTO_REQUEST(0) : request, SPROTO_RESPONSE(1): responsestruct sproto_type * sproto_protoquery(struct sproto *, int proto, int what); 在一个协议的 标签和名字间转换，并查询对象的类型。 struct sproto_type * sproto_type(struct sproto *, const char * typename); 从一个sproto对象查询类型对象。 struct sproto_arg &#123; void *ud; const char *tagname; int tagid; int type; struct sproto_type *subtype; void *value; int length; int index; // array base 1 int mainindex; // for map int extra; // SPROTO_TINTEGER: fixed-point presision ; SPROTO_TSTRING 0:utf8 string 1:binary&#125;;typedef int (*sproto_callback)(const struct sproto_arg *args);int sproto_decode(struct sproto_type *, const void * data, int size, sproto_callback cb, void *ud);int sproto_encode(struct sproto_type *, void * buffer, int size, sproto_callback cb, void *ud); 以一个用户定义的回调函数编码和解码 sproto 消息。查看 lsproto.c的实现来看更多的信息。 int sproto_pack(const void * src, int srcsz, void * buffer, int bufsz);int sproto_unpack(const void * src, int srcsz, void * buffer, int bufsz); 以 0 packing 算法来打包和解包消息。 总结在TCP连接上，我们发送和读取的的数据，都是连续的字节流。我们无法知道我应该读取的内容到底是什么，内容到底是什么，是由我们自己定义的协议所确定的。 而在基本的套接字编程示例中，我们都是调用系统的 read(int fd, void * buffer, ssize_t sz) 来将从文件描述符上将内存缓冲区的数据，读到我们自己的缓冲区内。 对此，在skynet的使用示例中，其把每个消息的前两个字节定义为 消息的长度，后面跟上真正的消息内容。 然后在我们以我们指定的协议进行解码。协议内容总是会包含一个协议头部： .package &#123; type 0 : integer--消息类型 session 1 : integer--回应消息对应的关系&#125; 跟上真正的协议内容，然后以 0-packing方式打包。 ?type 的值，表明了我们定义的协议中类型的标签值？ 消息类型与请求类型在云风的博客上提到： 对于 request/response 的 RPC 方案，除了消息本身打包外，还有两个重要的信息需要传输。它们分别是请求的类型以及请求的 session 。不要把请求的类型和消息的类型混为一谈。因为不同的请求可以用相同的消息类型，所以在 sproto 中，需要对 rpc 请求额外编码。你也不一定为每个请求额外设计一个消息类型，可以直接在定义 rpc 协议时内联写上请求（以及回应）的消息结构。 通常，我们用数字作为消息类型的标识，当然你也可以使用字符串。在用类 json 的无 schema 的协议中使用字符串多一些，但在 sproto 这种带 schema 的协议中，使用数字会更高效。同样，session 作为一条消息的唯一标识，你也可以用数字或字符串。而生成唯一数字 session 更容易，编码也更高效。 所以，每当我们发送一次远程请求，需要传输的数据就有三项：请求的类型、一个请求方自己保证唯一的 session id 以及请求的数据内容。 服务方收到请求后，应根据请求的类型对请求的数据内容解码，并根据类型分发给相应的处理器。同时应该把 session id 记录下来。等处理器处理完毕后，根据类型去打包回应的消息，并附加上 session id ，发送回客户端。 注意：回应是不需要传输消息类型的。这是因为 session id 就唯一标识了这是对哪一条请求的回应。而 session id 是客户端保证唯一的，它在产生 session id 时，就保存了这个 session 对应的请求的类型，所以也就有能力对回应消息解码。 btw ，如果只是单向推送消息（也就是 publish/subscribe 模式），直接省略 session 就可以了，也不需要回应。 在上面一节中，我们说道 .package 就是一个我们定义的消息类型，而其中的 type 字段，定义了我们的请求类型。 对于每个包，都以这个 package 开头，后面接上 (padding）消息体。最后连在一起，用 sproto 自带的 0-pack 方式压缩。 我们可以这样理解： 消息类型 .package 定义了我们消息包含的内容。 而 .type 定义了我们消息内容是怎么表示的。 client.lua 使用示例我们先来看一下一般性的代码： -- 加载 socket, proto, sproto 库local socket = require \"client.socket\"-- proto是我们自己定义的协议库（模块）local proto = require \"proto\"local sproto = require \"sproto\"local host = sproto.new(proto.s2c):host \"package\"local request = host:attach(sproto.new(proto.c2s))local fd = assert(socket.connect(\"127.0.0.1\", 8888)) 首先，我们先要定义我们的协议，然后通过 parser来解析成为一个二进制字符串，最后，调用 sproto.new来建立一个 sproto 对象。 协议定义这是通过 parser.parse来解析一个我们用 schema 语言定义的框架，然后生成的字符串保存在 表中进行了返回。 其中对于 c2s 的协议，我们定义了一个 消息类型 .package，四个请求（协议）类型。 而对于 s2c的协议，我们只定义了一个请求（协议）类型。 proto.c2s = sprotoparser.parse [[.package &#123; type 0 : integer -- 消息类型 session 1 : integer -- 会话ID&#125;handshake 1 &#123; response &#123; msg 0 : string &#125;&#125;get 2 &#123; request &#123; what 0 : string &#125; response &#123; result 0 : string &#125;&#125;set 3 &#123; request &#123; what 0 : string value 1 : string &#125;&#125;quit 4 &#123;&#125;]]proto.s2c = sprotoparser.parse [[.package &#123; type 0 : integer session 1 : integer&#125;heartbeat 1 &#123;&#125;]] 对象建立我们先来看看第一个调用： local host = sproto.new(proto.s2c):host \"package\" 这个调用实际上就是： local sobj = sproto.new(proto.s2c)local host = sobj:host \"package\" 我们先看看第一步 sproto.new的定义： local weak_mt = &#123; __mode = \"kv\" &#125;local sproto_mt = &#123; __index = sproto &#125;local sproto_nogc = &#123; __index = sproto &#125;local host_mt = &#123; __index = host &#125;function sproto.new(bin) local cobj = assert(core.newproto(bin)) local self = &#123; __cobj = cobj, __tcache = setmetatable( &#123;&#125; , weak_mt ), __pcache = setmetatable( &#123;&#125; , weak_mt ), &#125; return setmetatable(self, sproto_mt)end 其实是调用 注册出的的 core.newproto API，来建立了一个 sproto 对象。返回值就是 一个表 ，此表中的 __cobj 引用了 这个建立的 对象。这个表的元表已经被设置为 sproto_mt sobj = &#123; __cobj = cobj, __tcache = setmetatable( &#123;&#125; , weak_mt ), __pcache = setmetatable( &#123;&#125; , weak_mt ), &#125;``` 接下来我们调用的`sobj:host`，在 sobj 表内并不存在方法 `host`，所以其转而去寻找去 `__index`事件的元方法，这是一个表，就是 *sproto*，其实其调用的就是下面的这个方法。```luafunction sproto:host( packagename ) packagename = packagename or \"package\" local obj = &#123; __proto = self, __package = assert(core.querytype(self.__cobj, packagename), \"type package not found\"), __session = &#123;&#125;, &#125; return setmetatable(obj, host_mt)end 会根据我们给定的 packagename 消息类型来建立一个表对象 obj，这个表内的 __proto 事件就指向了我们的 sproto表，然后__package事件引用了 packagename 在 建立的 sproto对象中的位置。host对象的元表被设置成了 host_mt，其中具有 dispatch, attach两个方法。所以当 host，不存在对应方法时会调用元表中的方法。 最终我们可以得到一个表，也可以说是一个对象。host， host = &#123; __proto = sobj, __package = assert(core.querytype(self.__cobj, packagename), \"type package not found\"), __session = &#123;&#125;, &#125; 消息分发器实际上，我们对一个 sproto 对象调用 :host方法，就是为它绑定一个有两个方法 dispatch, attach 的元表。这样当访问这两个方法的时候就会直接访问我们绑定的方法。 host:attach我们来看一下 attach 方法： function host:attach(sp) return function(name, args, session, ud) // 在 sproto 对象内查找 name 协议 local proto = queryproto(sp, name) // 消息头部 &#123; type, session, ud&#125; header_tmp.type = proto.tag header_tmp.session = session header_tmp.ud = ud // 头部进行 0 packing local header = core.encode(self.__package, header_tmp) if session then self.__session[session] = proto.response or true end // 封装请求内容 if proto.request then local content = core.encode(proto.request, args) return core.pack(header .. content) else return core.pack(header) end endend 这个函数会返回一个函数： function (name, args, session, ud) ... end 其会根据 name（协议类型/请求类型）来把 代表内容的 args, session 打包。 host:dispatch我们先来看一下 dispatch方法： function host:dispatch(...) local bin = core.unpack(...) header_tmp.type = nil header_tmp.session = nil header_tmp.ud = nil local header, size = core.decode(self.__package, bin, header_tmp) local content = bin:sub(size + 1) if header.type then -- request local proto = queryproto(self.__proto, header.type) local result if proto.request then result = core.decode(proto.request, content) end if header_tmp.session then return \"REQUEST\", proto.name, result, gen_response(self, proto.response, header_tmp.session), header.ud else return \"REQUEST\", proto.name, result, nil, header.ud end else -- response local session = assert(header_tmp.session, \"session not found\") local response = assert(self.__session[session], \"Unknown session\") self.__session[session] = nil if response == true then return \"RESPONSE\", session, nil, header.ud else local result = core.decode(response, content) return \"RESPONSE\", session, result, header.ud end endend 消息发送在调用 local request = host:attach(sproto.new(proto.c2s))后，建立了一个消息封装函数request。 函数 ： local function send_request(name, args) session = session + 1 local str = request(name, args, session) send_package(fd, str) print(\"Request:\", session)end 会将 会话ID，协议名，参数传递给 消息封装函数。之后，函数： local function send_package(fd, pack) local package = string.pack(\"&gt;s2\", pack) socket.send(fd, package)end 会将打包好的消息，进行大端封装后发送到套接字去。 消息接收服务端使用了 snax.gateserver 的实例 gate来实现连接管理，当收到一个消息时，如果有agent，就会将消息转发到agent去： -- services/gate.luafunction handler.message(fd, msg, sz) -- recv a package, forward it local c = connection[fd] local agent = c.agent if agent then skynet.redirect(agent, c.client, \"client\", 1, msg, sz) else skynet.send(watchdog, \"lua\", \"socket\", \"data\", fd, netpack.tostring(msg, sz)) endend 我们的 agent 服务在启动时即注册了 client 类型的消息： -- examples/agent.luaskynet.register_protocol &#123; name = \"client\", id = skynet.PTYPE_CLIENT, unpack = function (msg, sz) return host:dispatch(msg, sz) end, dispatch = function (_, _, type, ...) if type == \"REQUEST\" then local ok, result = pcall(request, ...) if ok then if result then send_package(result) end else skynet.error(result) end else assert(type == \"RESPONSE\") error \"This example doesn't support request client\" end end&#125; 其会使用 host:dispatch来解压消息，然后注册了自己的消息回调函数。 我们注意到，在服务端中，建立消息消息分发器的方式同客户端似乎都不一样： -- examples/agent.luafunction CMD.start(conf) local fd = conf.client local gate = conf.gate WATCHDOG = conf.watchdog -- slot 1,2 set at main.lua host = sprotoloader.load(1):host \"package\" send_request = host:attach(sprotoloader.load(2)) skynet.fork(function() while true do send_package(send_request \"heartbeat\") skynet.sleep(500) end end) client_fd = fd skynet.call(gate, \"lua\", \"forward\", fd)end 其是通过 sprotoloader.load(1):host &quot;package&quot;来建立的。我们有理由去猜测，这个其实应该等价与： sproto.new(proto.c2s):host \"package\" 因为其处理的，是从客户端到服务端的消息。 sprotoloader如果想要在程序中，各个服务中共享同样的消息类型和协议类型，为每个服务都单独的保存这些协议信息似乎是非常浪费的。所以就有了把共享的协议由一个服务来提供的想法。 其先启动了一个全局唯一的协议加载服务： skynet.uniqueservice(\"protoloader\") skynet.start(function() sprotoloader.save(proto.c2s, 1) sprotoloader.save(proto.s2c, 2) -- don't call skynet.exit() , because sproto.core may unload and the global slot become invalidend) 把 客户端到服务端的消息类型保存为索引 1。 这样当我们通过 sprotoloader.load(1)，就得出了这个索引对应的对象指针，在通过 sproto.sharenew()来把这个对象给返回给调用者。 -- lualib/sprotoloader.luafunction loader.load(index) local sp = core.loadproto(index) -- no __gc in metatable return sproto.sharenew(sp)endreturn loader -- lualib/sproto.luafunction sproto.sharenew(cobj) local self = &#123; __cobj = cobj, __tcache = setmetatable( &#123;&#125; , weak_mt ), __pcache = setmetatable( &#123;&#125; , weak_mt ), &#125; return setmetatable(self, sproto_nogc)end 这个函数其实是 sproto.new返回的值一样，不过其是直接传过去的对象，而不是二进制的字符串。 如此，我们的消息处理流程就完美了。","categories":[{"name":"Lua","slug":"Lua","permalink":"https://gowa2017.github.io/categories/Lua/"}],"tags":[{"name":"Lua","slug":"Lua","permalink":"https://gowa2017.github.io/tags/Lua/"},{"name":"skynet","slug":"skynet","permalink":"https://gowa2017.github.io/tags/skynet/"},{"name":"sproto","slug":"sproto","permalink":"https://gowa2017.github.io/tags/sproto/"}],"keywords":[{"name":"Lua","slug":"Lua","permalink":"https://gowa2017.github.io/categories/Lua/"}]},{"title":"IO的阻塞与多路复用","slug":"IO的阻塞与多路复用","date":"2018-02-15T07:25:20.000Z","updated":"2018-02-15T07:25:20.000Z","comments":true,"path":"Linux/IO的阻塞与多路复用.html","link":"","permalink":"https://gowa2017.github.io/Linux/IO的阻塞与多路复用.html","excerpt":"对于大多数的编程场景来多，很多时候的任务都是在处理I/O，因为读写设备的不同，所以需要花很多的心思来整。从POSIX的标准来看，其提供了 select, poll来实现多个描述符的监控读写。而Linux自身还实现了一个更高效的 epoll。","text":"对于大多数的编程场景来多，很多时候的任务都是在处理I/O，因为读写设备的不同，所以需要花很多的心思来整。从POSIX的标准来看，其提供了 select, poll来实现多个描述符的监控读写。而Linux自身还实现了一个更高效的 epoll。 POSIX中的I/O在类Unix中，我们运用 open, read, write, lseek, close就能实现对文件的读写，而其哲学就是，所有的设备对象都是文件。所以实现了统一的读写处理。在多数的系统实现中，在设备-内核-应用之间都会有缓存。当我们对一个由open返回的文件描述符 fd 调用 read(fd, buffer, len)是，内核会从 fd 读取对应的数据，放到内核缓冲区，然后再返回到 应用程序的缓冲区 buffer。而在如果无法及时获得请求数据的时候，就会出现阻塞状态，整个程序流程将无法执行其他任务工作。调用 write时候一样。 对于这种问题的解决方法，就出现了两种不同的思路。一个是随着多线程支持而来的并发读写，已经内核实现的一种多描述符的检查机制。 selectselect在大多数系统上都有了实现。其基本原理就是把想要监控的描述符放到一个描述符集合中，然后内核会对特定的事件进行监控，一旦对应描述集上有事件发生，则返回。接下来我们就必须通过轮询描述符集来检查，是哪个描述符发生了事件。 #include &lt;sys/select.h&gt;// 操作描述符集的宏 #include &lt;sys/select.h&gt; void FD_CLR(fd, fd_set *fdset); void FD_COPY(fd_set *fdset_orig, fd_set *fdset_copy); int FD_ISSET(fd, fd_set *fdset); void FD_SET(fd, fd_set *fdset); void FD_ZERO(fd_set *fdset);// 参数：描述符数量，读，写，错误，超时 int select(int nfds, fd_set *restrict readfds, fd_set *restrict writefds, fd_set *restrict errorfds, struct timeval *restrict timeout);// 参数：描述符数量，读，写，意外，等待时间，信号屏蔽字 int pselect(int, fd_set * __restrict, fd_set * __restrict, fd_set * __restrict, const struct timespec * __restrict, const sigset_t * __restrict) 唯一需要注意的是，描述符数量 nfds 会是最大描述符 + 1，因为描述符是从0开始的。 我们可以让程序 阻塞在 select上，而一旦有描述符准备好读写，则会开始继续运行。 在返回的时候，select会修改描述符集，其中有事件产生的被置位，其返回值是发生了准备好事件的描述符数量，而如果一个描述符在读写都进行了测试的话，如果即可读也可写就会计算为两次。 这其中就会产生一个很头疼的问题，如果我们要监控1000个描述符，而其中只有一个描述符 999 准备好了的话，我们将不得不逐个的测试返回描述符集的结果才能知道是谁准备好了读写。这是一个巨大的浪费。因此我们有了另外一个方法。 poll#include &lt;poll.h&gt; struct pollfd &#123; int fd; /* file descriptor */ short events; /* events to look for */ short revents; /* events returned */ &#125;; int poll(struct pollfd fds[], nfds_t nfds, int timeout); poll中，我们只需要把我们关心的描述符和事件放到一个结构中，然后把这些结构组成一个数组传递给 poll，在返回的时候，我们就不用去测试那些没有发生事件的描述了。但我们却也不得不检查每个传递过去的结构是不是发生了对应的事件。 还有没有更好的办法呢？如果我们能在返回的时候知道，其返回的描述符确实发生了特定的事件而直接进行操作的话，那不是就完美了么。 epollepoll所做的工作和 poll类似，但其可以进行水平触发或者边缘触发，主要是利用三个函数来进行的。 其工作方式是利用一个 epoll 描述符来管理其他的 文件描述符，并让文件描述符与对应的事件相关联。一旦所管理的描述符有事件发生，那么就会把发生了事件的描述符和事件一起进行返回。这样我们进行遍历返回的结构，就知道所有的描述符都是发生了事件的，不会出现浪费CPU时间的情况。 epoll_create(2) 创建一个引用 epoll 实例的 文件描述符。新的函数 epoll_create1(2)已经扩展了这个函数的功能和特性。 epoll_ctl(2) 注册我们要监控的描述符，这些描述符的集合有时候被称做 epoll集 epoll_wait(2) 等待事件，如果当前线程并无什么事件发生的话则会阻塞这个线程。 水平触发（LT）与边缘触发（ET）这两者有如下不同。我们考虑一下这样种情况： 将一个管道的读端描述符 rfd 注册到 epoll 实例中 管道的写端写了 2KB 的数据 调用 epoll_wait(2)，将会返回 rfd 已就绪可读 从读端读取 1KB 数据 再次调用 epoll_wait(2) 如果在添加 rfd 的时候，设置了 EPOLLET 标志的话，那么我们在第五步中，第二次调用 epoll_wait时就可能挂起，尽管，管道还有数据可读；同时，写端可能会根据其发出的数据而期望一个回应。这是因为 ET 设置只会在被监控的描述符上有事件发生时进行通知。因此，在步骤五中的调用，结果就是一直在等待已经在了管道中的数据。在上面的例子中，步骤二中 rfd 会产生一个事件，然后在步骤三中被消费。 但是在步骤四中并没有读取完所有的数据，而且接着也没有事件发生，那么步骤五的epoll_wait调用将会永远阻塞。 在使用EPOLLET标志的时候，必须使用非阻塞描述符来避免读写多个描述符程序的饿死。建议使用 ET 设置的方式如下： 使用非阻塞描述符。并且 只有在 read/write 返回 EAGAIN 后才进行事件的等待 对比来说，当使用 水平触发 LT 的时候，epoll就是一个更快的 poll而已（默认情况）。所有使用 poll的地方这时候都能使用 epoll，因为使用相似的语法。 在使用 ET 触发的时候，在接收到大块的数据时可能会产生多个事件，有一个选项可以让我们来设置在 epoll 在接收到一个事件后忽略其他事件。EPOLLONESHOT设置后，要想再继续接收其他事件的话，必须用 epoll_ctl的EPOLL_CTL_MOD来重设文件描述符。 建立的使用方式水平触发没有什么好说的，和 poll的用法差不多，而ET 触发就需要多说一些了。例子中，listener 是一个非阻塞的套接字。函数do_use_fd()使用就绪的描述符，直到 read/write 返回一个 EAGAIN 错误。在接收到 EAGAIN后，一个事件驱动的状态机程序应该记录其当前的状态，以便下次调用 do_use_fd()时能从其停止的地方继续。 #define MAX_EVENTS 10int listen_sock, conn_sock, nfds, epollfd;/* Code to set up listening socket, 'listen_sock', (socket(), bind(), listen()) omitted */ epollfd = epoll_create1(0);if (epollfd == -1) &#123; perror(\"epoll_create1\"); exit(EXIT_FAILTURE);&#125;ev.events = EPOLLIN;ev.data.fd = listen_sock;if (epoll_ctl(epollfd, EPOLL_CTL_ADD, listen_sock, &amp;ev) == -1) &#123; perror(\"epoll_ctl: listen_sock\"): exit(EXIT_FAILURE);&#125;for ( ;; ) &#123; nfds = epoll_wait(epollfd, events, MAX_EVENTS, -1); if (nfds == -1) &#123; perror(\"epoll_wait\"); exit(EXIT_FAILURE); &#125; for (n = 0; n &lt; nfds; n++) &#123; if (events[n].data.fd == listen_sock) &#123; conn_sock = accept(listen_sock, (struct sockaddr *) &amp;addr, &amp;addrlen); if (conn_sock == -1) &#123; perror(\"accept\"); exit(EXIT_FAILURE); &#125; setnonblocking(conn_sock); ev.events = EPOLLIN | EPOLLET; ev.data.fd = conn_sock; if (epoll_ctl(epollfd, EPOLL_CTL_ADD, conn_sock, &amp;ev) == -1) &#123; perror(\"epoll_ctl: conn_sock\"); exit(EXIT_FAILURE); &#125; else &#123; do_use_fd(events[n].data.fd); &#125; &#125;&#125; 当配置 ET时，为了性能上的考虑，可以在 调用 epoll_ctl进行增加时（EPOLL_CTL_ADD）同时指定EPOLLIN | EPOLLOUT。这样就可以避免需要不停的调用 epoll_ctl的 EPOLL_CTL_MOD来不同的在两个标志间切换。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}],"tags":[{"name":"编程","slug":"编程","permalink":"https://gowa2017.github.io/tags/编程/"},{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/tags/Linux/"},{"name":"epoll","slug":"epoll","permalink":"https://gowa2017.github.io/tags/epoll/"},{"name":"select","slug":"select","permalink":"https://gowa2017.github.io/tags/select/"},{"name":"poll","slug":"poll","permalink":"https://gowa2017.github.io/tags/poll/"}],"keywords":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}]},{"title":"skynet中的网络服务与消息处理","slug":"skynet中的网络服务与消息处理","date":"2018-02-13T10:07:32.000Z","updated":"2018-02-13T10:07:32.000Z","comments":true,"path":"Lua/skynet中的网络服务与消息处理.html","link":"","permalink":"https://gowa2017.github.io/Lua/skynet中的网络服务与消息处理.html","excerpt":"网络信息与普通消息的封装似乎有所不同，所以关注一下这个过程是非常的有必要的。我们先从网络服务的注册开始说起。skynet封装了一个socket库作为Lua模块来给我们使用。我们可以看一下对于一个socket的注册是怎么样的。","text":"网络信息与普通消息的封装似乎有所不同，所以关注一下这个过程是非常的有必要的。我们先从网络服务的注册开始说起。skynet封装了一个socket库作为Lua模块来给我们使用。我们可以看一下对于一个socket的注册是怎么样的。 服务注册流程 注册网络服务时调用 socketdriver:listen(address, port); 调用C库函数 llisten，获取 每个 Lua State中保存的 服务结构 ctx，其是通过存储为上值实现的。然后调用skynet_socket_listen(ctx, host, port, backlog); skynet_socket_listen(ctx, host, port, backlog)中，根据 ctx 获得服务的 handle，然后调用socket_server_listen(SOCKET_SERVER, handle, host, port, backlog) socket_server_listen 会获取一个handle，全局未使用的代表网络服务结构的id，及监听套接字 fd，构造一个请求发送给 SOCKET_SERVER。send_request(ss, &amp;request, &#39;L&#39;, sizeof(request.u.listen)); 并返回网络服务id; 第四步的操作，其实就把请求发送到了 SOCKET_SERVER监听的管道中。 消息处理流程 thread_socket工作线程会监听所有的套接字接控制管理消息。具体是在skynet_socket_poll工作； skynet_socket_poll会调用 socket_server_poll获得取到的消息类型及消息体，然后根据返回的消息类型，转发消息forward_message。 skynet_socket_poll是一个非常重要的函数。其做了两个工作： 如果有控制命令，就是在管道中有消息。则会调用 ctrl_cmd进行对应的操作。比如开启、监听、绑定、关闭、打开一个套接字。 或者根据 epoll_wait 返回的事件，来进行操作。如果是读事件，获取事件的 socket结构，调用forward_message_tcp(ss, s, &amp;l, result);进行转发tcp消息。同样会返回一个消息体。 forward_message根据消息体中的 handle，把消息push到对应的 ctx 中的消息队列中。 工作线程会轮流取消息后，调用服务注册的对应回调函数进行处理。 gateserver在 lualib/snax/gateserver.lua中有绑定套接字的代码存在: -- lualib/snax/gateserver.lualocal socketdriver = require \"skynet.socketdriver\"function gateserver.start(handler) assert(handler.message) assert(handler.connect) function CMD.open( source, conf ) assert(not socket) local address = conf.address or \"0.0.0.0\" local port = assert(conf.port) maxclient = conf.maxclient or 1024 nodelay = conf.nodelay skynet.error(string.format(\"Listen on %s:%d\", address, port)) socket = socketdriver.listen(address, port) socketdriver.start(socket) if handler.open then return handler.open(source, conf) end end ... 这是一个作为C库加载的： // lualib-src/lua-socket.cLUAMOD_API intluaopen_skynet_socketdriver(lua_State *L) &#123; luaL_checkversion(L); luaL_Reg l[] = &#123; &#123; \"buffer\", lnewbuffer &#125;, &#123; \"push\", lpushbuffer &#125;, &#123; \"pop\", lpopbuffer &#125;, &#123; \"drop\", ldrop &#125;, &#123; \"readall\", lreadall &#125;, &#123; \"clear\", lclearbuffer &#125;, &#123; \"readline\", lreadline &#125;, &#123; \"str2p\", lstr2p &#125;, &#123; \"header\", lheader &#125;, &#123; \"unpack\", lunpack &#125;, &#123; NULL, NULL &#125;, &#125;; luaL_newlib(L,l); luaL_Reg l2[] = &#123; &#123; \"connect\", lconnect &#125;, &#123; \"close\", lclose &#125;, &#123; \"shutdown\", lshutdown &#125;, &#123; \"listen\", llisten &#125;, &#123; \"send\", lsend &#125;, &#123; \"lsend\", lsendlow &#125;, &#123; \"bind\", lbind &#125;, &#123; \"start\", lstart &#125;, &#123; \"nodelay\", lnodelay &#125;, &#123; \"udp\", ludp &#125;, &#123; \"udp_connect\", ludp_connect &#125;, &#123; \"udp_send\", ludp_send &#125;, &#123; \"udp_address\", ludp_address &#125;, &#123; NULL, NULL &#125;, &#125;; lua_getfield(L, LUA_REGISTRYINDEX, \"skynet_context\"); struct skynet_context *ctx = lua_touserdata(L,-1); if (ctx == NULL) &#123; return luaL_error(L, \"Init skynet context first\"); &#125; luaL_setfuncs(L,l2,1); return 1;&#125; socketdriver.listensocketdriver.listen其实加载的是库中的C函数llisten： // lualib/lua-socket.c// 通过把 host,port 压入Lua，然后进行处理 // 返回的是一个代表 一个skynet socket结构的idstatic intllisten(lua_State *L) &#123; const char * host = luaL_checkstring(L,1); int port = luaL_checkinteger(L,2); int backlog = luaL_optinteger(L,3,BACKLOG); struct skynet_context * ctx = lua_touserdata(L, lua_upvalueindex(1)); int id = skynet_socket_listen(ctx, host,port,backlog); if (id &lt; 0) &#123; return luaL_error(L, \"Listen error\"); &#125; lua_pushinteger(L,id); return 1;&#125;static intlstart(lua_State *L) &#123; struct skynet_context * ctx = lua_touserdata(L, lua_upvalueindex(1)); int id = luaL_checkinteger(L, 1); skynet_socket_start(ctx,id); return 0;&#125; skynet_socket_listen通过Lua中的上值来确定 ctx 结构，然后调用skynet_socket_listen： // skynet-src/skynet_socket.cskynet_socket_listen(struct skynet_context *ctx, const char *host, int port, int backlog) &#123; uint32_t source = skynet_context_handle(ctx); return socket_server_listen(SOCKET_SERVER, source, host, port, backlog);&#125; 首先会获取 ctx 结构的 handle，然后传递给 socket_server_listen。 socket_server_listen// skynet-src/socket_server.cintsocket_server_listen(struct socket_server *ss, uintptr_t opaque, const char * addr, int port, int backlog) &#123; int fd = do_listen(addr, port, backlog); if (fd &lt; 0) &#123; return -1; &#125; struct request_package request; int id = reserve_id(ss); if (id &lt; 0) &#123; close(fd); return id; &#125; request.u.listen.opaque = opaque; request.u.listen.id = id; request.u.listen.fd = fd; send_request(ss, &amp;request, 'L', sizeof(request.u.listen)); return id;&#125;static intreserve_id(struct socket_server *ss) &#123; int i; for (i=0;i&lt;MAX_SOCKET;i++) &#123; int id = ATOM_INC(&amp;(ss-&gt;alloc_id)); if (id &lt; 0) &#123; id = ATOM_AND(&amp;(ss-&gt;alloc_id), 0x7fffffff); &#125; struct socket *s = &amp;ss-&gt;slot[HASH_ID(id)]; if (s-&gt;type == SOCKET_TYPE_INVALID) &#123; if (ATOM_CAS(&amp;s-&gt;type, SOCKET_TYPE_INVALID, SOCKET_TYPE_RESERVE)) &#123; s-&gt;id = id; s-&gt;protocol = PROTOCOL_UNKNOWN; // socket_server_udp_connect may inc s-&gt;udpconncting directly (from other thread, before new_fd), // so reset it to 0 here rather than in new_fd. s-&gt;udpconnecting = 0; s-&gt;fd = -1; return id; &#125; else &#123; // retry --i; &#125; &#125; &#125; return -1;&#125; 其首先通过 do_listen获得socket套接字的 文件描述符，然后再通过 reserve_id获得一个代表全局 网络服务的id，把这两者写到一个请求包内，发送到 SOCKET_SERVER去。 send_request信息的发送是通过send_request(ss, &amp;request, &#39;L&#39;, sizeof(request.u.listen));发送一个L类型的请求消息到 SOCKET_SERVER。 // skynet-src/socket_server.cstruct request_package &#123; uint8_t header[8]; // 6 bytes dummy union &#123; char buffer[256]; struct request_open open; struct request_send send; struct request_send_udp send_udp; struct request_close close; struct request_listen listen; struct request_bind bind; struct request_start start; struct request_setopt setopt; struct request_udp udp; struct request_setudp set_udp; &#125; u; uint8_t dummy[256];&#125;;static voidsend_request(struct socket_server *ss, struct request_package *request, char type, int len) &#123; // 这两个header字段存储了 请求的类型 和 消息的长度 request-&gt;header[6] = (uint8_t)type; request-&gt;header[7] = (uint8_t)len; for (;;) &#123; ssize_t n = write(ss-&gt;sendctrl_fd, &amp;request-&gt;header[6], len+2); if (n&lt;0) &#123; if (errno != EINTR) &#123; fprintf(stderr, \"socket-server : send ctrl command error %s.\\n\", strerror(errno)); &#125; continue; &#125; assert(n == len+2); return; &#125;&#125; 实际上，是把相应的数据写到 全局服务器 SOCKET_SERVER中建立的管道的写端。skynet 的socket线程会每次监听对应的事件，优先读取管道中的数据。 request_package是一个联合，用了封装了所有类型的请求消息。 thread_socket 线程这个线程会读取所有的网络消息，并转交到对应的消息队列中去。 // skynet-src/skyent_start.cstatic void *thread_socket(void *p) &#123; struct monitor * m = p; skynet_initthread(THREAD_SOCKET); for (;;) &#123; int r = skynet_socket_poll(); if (r==0) break; if (r&lt;0) &#123; CHECK_ABORT continue; &#125; wakeup(m,0); &#125; return NULL;&#125; skynet_socket_poll此函数会根据得到的消息类型，然后进行转发： // skynet-src/skynet_start.cintskynet_socket_poll() &#123; struct socket_server *ss = SOCKET_SERVER; assert(ss); struct socket_message result; int more = 1; int type = socket_server_poll(ss, &amp;result, &amp;more); switch (type) &#123; case SOCKET_EXIT: return 0; case SOCKET_DATA: forward_message(SKYNET_SOCKET_TYPE_DATA, false, &amp;result); break; case SOCKET_CLOSE: forward_message(SKYNET_SOCKET_TYPE_CLOSE, false, &amp;result); break; case SOCKET_OPEN: forward_message(SKYNET_SOCKET_TYPE_CONNECT, true, &amp;result); break; case SOCKET_ERR: forward_message(SKYNET_SOCKET_TYPE_ERROR, true, &amp;result); break; case SOCKET_ACCEPT: forward_message(SKYNET_SOCKET_TYPE_ACCEPT, true, &amp;result); break; case SOCKET_UDP: forward_message(SKYNET_SOCKET_TYPE_UDP, false, &amp;result); break; case SOCKET_WARNING: forward_message(SKYNET_SOCKET_TYPE_WARNING, false, &amp;result); break; default: skynet_error(NULL, \"Unknown socket message type %d.\",type); return -1; &#125; if (more) &#123; return -1; &#125; return 1;&#125; socket_server_poll// skynet-src/sokcet_server.cintsocket_server_poll(struct socket_server *ss, struct socket_message * result, int * more) &#123; for (;;) &#123; // 是否检查控制命令，也就是说对应的管道有无套接字服务的请求 if (ss-&gt;checkctrl) &#123; // 管道内有无请求？ if (has_cmd(ss)) &#123; // 获取请求类型和结果 int type = ctrl_cmd(ss, result); if (type != -1) &#123; clear_closed_event(ss, result, type); return type; &#125; else continue; &#125; else &#123; ss-&gt;checkctrl = 0; &#125; &#125; if (ss-&gt;event_index == ss-&gt;event_n) &#123; ss-&gt;event_n = sp_wait(ss-&gt;event_fd, ss-&gt;ev, MAX_EVENT); ss-&gt;checkctrl = 1; if (more) &#123; *more = 0; &#125; ss-&gt;event_index = 0; if (ss-&gt;event_n &lt;= 0) &#123; ss-&gt;event_n = 0; if (errno == EINTR) &#123; continue; &#125; return -1; &#125; &#125; struct event *e = &amp;ss-&gt;ev[ss-&gt;event_index++]; struct socket *s = e-&gt;s; if (s == NULL) &#123; // dispatch pipe message at beginning continue; &#125; struct socket_lock l; socket_lock_init(s, &amp;l); switch (s-&gt;type) &#123; case SOCKET_TYPE_CONNECTING: return report_connect(ss, s, &amp;l, result); case SOCKET_TYPE_LISTEN: &#123; int ok = report_accept(ss, s, result); if (ok &gt; 0) &#123; return SOCKET_ACCEPT; &#125; if (ok &lt; 0 ) &#123; return SOCKET_ERR; &#125; // when ok == 0, retry break; &#125; case SOCKET_TYPE_INVALID: fprintf(stderr, \"socket-server: invalid socket\\n\"); break; default: if (e-&gt;read) &#123; int type; if (s-&gt;protocol == PROTOCOL_TCP) &#123; type = forward_message_tcp(ss, s, &amp;l, result); &#125; else &#123; type = forward_message_udp(ss, s, &amp;l, result); if (type == SOCKET_UDP) &#123; // try read again --ss-&gt;event_index; return SOCKET_UDP; &#125; &#125; if (e-&gt;write &amp;&amp; type != SOCKET_CLOSE &amp;&amp; type != SOCKET_ERR) &#123; // Try to dispatch write message next step if write flag set. e-&gt;read = false; --ss-&gt;event_index; &#125; if (type == -1) break; return type; &#125; if (e-&gt;write) &#123; int type = send_buffer(ss, s, &amp;l, result); if (type == -1) break; return type; &#125; if (e-&gt;error) &#123; // close when error int error; socklen_t len = sizeof(error); int code = getsockopt(s-&gt;fd, SOL_SOCKET, SO_ERROR, &amp;error, &amp;len); const char * err = NULL; if (code &lt; 0) &#123; err = strerror(errno); &#125; else if (error != 0) &#123; err = strerror(error); &#125; else &#123; err = \"Unknown error\"; &#125; force_close(ss, s, &amp;l, result); result-&gt;data = (char *)err; return SOCKET_ERR; &#125; break; &#125; &#125;&#125;``` ## ctrl_cmd(ss, result);```c// skynet-src/socket_server.c// return typestatic intctrl_cmd(struct socket_server *ss, struct socket_message *result) &#123; // 控制管道读端 int fd = ss-&gt;recvctrl_fd; // the length of message is one byte, so 256+8 buffer size is enough. uint8_t buffer[256]; uint8_t header[2]; // 读请求的前两字节 （type, len) block_readpipe(fd, header, sizeof(header)); int type = header[0]; int len = header[1]; // 读请求内容 block_readpipe(fd, buffer, len); // ctrl command only exist in local fd, so don't worry about endian. switch (type) &#123; case 'S': return start_socket(ss,(struct request_start *)buffer, result); case 'B': return bind_socket(ss,(struct request_bind *)buffer, result); case 'L': return listen_socket(ss,(struct request_listen *)buffer, result); case 'K': return close_socket(ss,(struct request_close *)buffer, result); case 'O': return open_socket(ss, (struct request_open *)buffer, result); case 'X': result-&gt;opaque = 0; result-&gt;id = 0; result-&gt;ud = 0; result-&gt;data = NULL; return SOCKET_EXIT; case 'D': case 'P': &#123; int priority = (type == 'D') ? PRIORITY_HIGH : PRIORITY_LOW; struct request_send * request = (struct request_send *) buffer; int ret = send_socket(ss, request, result, priority, NULL); dec_sending_ref(ss, request-&gt;id); return ret; &#125; case 'A': &#123; struct request_send_udp * rsu = (struct request_send_udp *)buffer; return send_socket(ss, &amp;rsu-&gt;send, result, PRIORITY_HIGH, rsu-&gt;address); &#125; case 'C': return set_udp_address(ss, (struct request_setudp *)buffer, result); case 'T': setopt_socket(ss, (struct request_setopt *)buffer); return -1; case 'U': add_udp_socket(ss, (struct request_udp *)buffer); return -1; default: fprintf(stderr, \"socket-server: Unknown ctrl %c.\\n\",type); return -1; &#125;; return -1;&#125;``` 我们在 `send_request`中发送的是 `L`类型的消息，所以返回的是`listen_socket(ss,(struct request_listen *)buffer, result);`## listen_socket```c// skynet-src/socket_server.cstatic intlisten_socket(struct socket_server *ss, struct request_listen * request, struct socket_message *result) &#123; int id = request-&gt;id; int listen_fd = request-&gt;fd; // 获取一个 socket结构，此结构会放在全局服务 SOCKET_SERVER中 struct socket *s = new_fd(ss, id, listen_fd, PROTOCOL_TCP, request-&gt;opaque, false); if (s == NULL) &#123; goto _failed; &#125; s-&gt;type = SOCKET_TYPE_PLISTEN; return -1;_failed: close(listen_fd); result-&gt;opaque = request-&gt;opaque; result-&gt;id = id; result-&gt;ud = 0; result-&gt;data = \"reach skynet socket number limit\"; ss-&gt;slot[HASH_ID(id)].type = SOCKET_TYPE_INVALID; return SOCKET_ERR;&#125;// 最后一个参数，代表是否要把这个套接字放到 epoll 的监听中去，现在listen阶段不需要加入，在start阶段才会加入static struct socket *new_fd(struct socket_server *ss, int id, int fd, int protocol, uintptr_t opaque, bool add) &#123; struct socket * s = &amp;ss-&gt;slot[HASH_ID(id)]; assert(s-&gt;type == SOCKET_TYPE_RESERVE); if (add) &#123; if (sp_add(ss-&gt;event_fd, fd, s)) &#123; s-&gt;type = SOCKET_TYPE_INVALID; return NULL; &#125; &#125; s-&gt;id = id; s-&gt;fd = fd; s-&gt;sending = ID_TAG16(id) &lt;&lt; 16 | 0; s-&gt;protocol = protocol; s-&gt;p.size = MIN_READ_BUFFER; s-&gt;opaque = opaque; s-&gt;wb_size = 0; s-&gt;warn_size = 0; check_wb_list(&amp;s-&gt;high); check_wb_list(&amp;s-&gt;low); spinlock_init(&amp;s-&gt;dw_lock); s-&gt;dw_buffer = NULL; s-&gt;dw_size = 0; return s;&#125; start_socket调用start_socket(ss,(struct request_start *)buffer, result); static intstart_socket(struct socket_server *ss, struct request_start *request, struct socket_message *result) &#123; int id = request-&gt;id; result-&gt;id = id; result-&gt;opaque = request-&gt;opaque; result-&gt;ud = 0; result-&gt;data = NULL; struct socket *s = &amp;ss-&gt;slot[HASH_ID(id)]; if (s-&gt;type == SOCKET_TYPE_INVALID || s-&gt;id !=id) &#123; result-&gt;data = \"invalid socket\"; return SOCKET_ERR; &#125; struct socket_lock l; socket_lock_init(s, &amp;l); if (s-&gt;type == SOCKET_TYPE_PACCEPT || s-&gt;type == SOCKET_TYPE_PLISTEN) &#123; if (sp_add(ss-&gt;event_fd, s-&gt;fd, s)) &#123; force_close(ss, s, &amp;l, result); result-&gt;data = strerror(errno); return SOCKET_ERR; &#125; s-&gt;type = (s-&gt;type == SOCKET_TYPE_PACCEPT) ? SOCKET_TYPE_CONNECTED : SOCKET_TYPE_LISTEN; s-&gt;opaque = request-&gt;opaque; result-&gt;data = \"start\"; return SOCKET_OPEN; &#125; else if (s-&gt;type == SOCKET_TYPE_CONNECTED) &#123; // todo: maybe we should send a message SOCKET_TRANSFER to s-&gt;opaque s-&gt;opaque = request-&gt;opaque; result-&gt;data = \"transfer\"; return SOCKET_OPEN; &#125; // if s-&gt;type == SOCKET_TYPE_HALFCLOSE , SOCKET_CLOSE message will send later return -1;&#125; socket中的普通事件多数时候我们更关注的时从外部来的网络数据。 其基本流程就是，通过 epoll全局服务中的套接字，对应的事件触发操作。然后获取一个 socket结构，根据返回结构的事件来转发消息。 // skynet-src/socket_server.cintsocket_server_poll(struct socket_server *ss, struct socket_message * result, int * more) &#123; for (;;) &#123; // 是否检查控制命令，也就是说对应的管道有无套接字服务的请求 if (ss-&gt;checkctrl) &#123; // 管道内有无请求？ if (has_cmd(ss)) &#123; // 获取请求类型和结果 int type = ctrl_cmd(ss, result); if (type != -1) &#123; clear_closed_event(ss, result, type); return type; &#125; else continue; &#125; else &#123; ss-&gt;checkctrl = 0; &#125; &#125; if (ss-&gt;event_index == ss-&gt;event_n) &#123; ss-&gt;event_n = sp_wait(ss-&gt;event_fd, ss-&gt;ev, MAX_EVENT); ss-&gt;checkctrl = 1; if (more) &#123; *more = 0; &#125; ss-&gt;event_index = 0; if (ss-&gt;event_n &lt;= 0) &#123; ss-&gt;event_n = 0; if (errno == EINTR) &#123; continue; &#125; return -1; &#125; &#125; struct event *e = &amp;ss-&gt;ev[ss-&gt;event_index++]; struct socket *s = e-&gt;s; if (s == NULL) &#123; // dispatch pipe message at beginning continue; &#125; struct socket_lock l; socket_lock_init(s, &amp;l); switch (s-&gt;type) &#123; case SOCKET_TYPE_CONNECTING: return report_connect(ss, s, &amp;l, result); case SOCKET_TYPE_LISTEN: &#123; int ok = report_accept(ss, s, result); if (ok &gt; 0) &#123; return SOCKET_ACCEPT; &#125; if (ok &lt; 0 ) &#123; return SOCKET_ERR; &#125; // when ok == 0, retry break; &#125; case SOCKET_TYPE_INVALID: fprintf(stderr, \"socket-server: invalid socket\\n\"); break; // 绝大部分流程都会走到这。 default: if (e-&gt;read) &#123; int type; if (s-&gt;protocol == PROTOCOL_TCP) &#123; type = forward_message_tcp(ss, s, &amp;l, result); &#125; else &#123; type = forward_message_udp(ss, s, &amp;l, result); if (type == SOCKET_UDP) &#123; // try read again --ss-&gt;event_index; return SOCKET_UDP; &#125; &#125; if (e-&gt;write &amp;&amp; type != SOCKET_CLOSE &amp;&amp; type != SOCKET_ERR) &#123; // Try to dispatch write message next step if write flag set. e-&gt;read = false; --ss-&gt;event_index; &#125; if (type == -1) break; return type; &#125; if (e-&gt;write) &#123; int type = send_buffer(ss, s, &amp;l, result); if (type == -1) break; return type; &#125; if (e-&gt;error) &#123; // close when error int error; socklen_t len = sizeof(error); int code = getsockopt(s-&gt;fd, SOL_SOCKET, SO_ERROR, &amp;error, &amp;len); const char * err = NULL; if (code &lt; 0) &#123; err = strerror(errno); &#125; else if (error != 0) &#123; err = strerror(error); &#125; else &#123; err = \"Unknown error\"; &#125; force_close(ss, s, &amp;l, result); result-&gt;data = (char *)err; return SOCKET_ERR; &#125; break; &#125; &#125;&#125; 对于 tcp 套接字的内容，其会进行如下的转发： forward_message_tcp根据对应的套接字结构，获得套接字，然后把消息读到缓存中去。 // skynet-src/socket_server.cstatic intforward_message_tcp(struct socket_server *ss, struct socket *s, struct socket_lock *l, struct socket_message * result) &#123; int sz = s-&gt;p.size; char * buffer = MALLOC(sz); int n = (int)read(s-&gt;fd, buffer, sz); if (n&lt;0) &#123; FREE(buffer); switch(errno) &#123; case EINTR: break; case AGAIN_WOULDBLOCK: fprintf(stderr, \"socket-server: EAGAIN capture.\\n\"); break; default: // close when error force_close(ss, s, l, result); result-&gt;data = strerror(errno); return SOCKET_ERR; &#125; return -1; &#125; if (n==0) &#123; FREE(buffer); force_close(ss, s, l, result); return SOCKET_CLOSE; &#125; if (s-&gt;type == SOCKET_TYPE_HALFCLOSE) &#123; // discard recv data FREE(buffer); return -1; &#125; if (n == sz) &#123; s-&gt;p.size *= 2; &#125; else if (sz &gt; MIN_READ_BUFFER &amp;&amp; n*2 &lt; sz) &#123; s-&gt;p.size /= 2; s-&gt;p.size /= 2; &#125; result-&gt;opaque = s-&gt;opaque; result-&gt;id = s-&gt;id; result-&gt;ud = n; result-&gt;data = buffer; return SOCKET_DATA;&#125; 最终，事件 SOCKET_DATA和 消息 result返回到了主线程中。主线程会将消息进行转发。 forward_message// skynet-src/skynet_socket.c// mainloop threadstatic voidforward_message(int type, bool padding, struct socket_message * result) &#123; struct skynet_socket_message *sm; size_t sz = sizeof(*sm); if (padding) &#123; if (result-&gt;data) &#123; size_t msg_sz = strlen(result-&gt;data); if (msg_sz &gt; 128) &#123; msg_sz = 128; &#125; sz += msg_sz; &#125; else &#123; result-&gt;data = \"\"; &#125; &#125; sm = (struct skynet_socket_message *)skynet_malloc(sz); sm-&gt;type = type; sm-&gt;id = result-&gt;id; sm-&gt;ud = result-&gt;ud; if (padding) &#123; sm-&gt;buffer = NULL; memcpy(sm+1, result-&gt;data, sz - sizeof(*sm)); &#125; else &#123; sm-&gt;buffer = result-&gt;data; &#125; struct skynet_message message; message.source = 0; message.session = 0; message.data = sm; message.sz = sz | ((size_t)PTYPE_SOCKET &lt;&lt; MESSAGE_TYPE_SHIFT); if (skynet_context_push((uint32_t)result-&gt;opaque, &amp;message)) &#123; // todo: report somewhere to close socket // don't call skynet_socket_close here (It will block mainloop) skynet_free(sm-&gt;buffer); skynet_free(sm-&gt;buffer); skynet_free(sm); &#125;&#125; 其最终是构造了一个消息发送到对应服务消息队列中去。 而对应服务就会根据注册的消息回调函数进行处理了。","categories":[{"name":"Lua","slug":"Lua","permalink":"https://gowa2017.github.io/categories/Lua/"}],"tags":[{"name":"Lua","slug":"Lua","permalink":"https://gowa2017.github.io/tags/Lua/"},{"name":"skynet","slug":"skynet","permalink":"https://gowa2017.github.io/tags/skynet/"}],"keywords":[{"name":"Lua","slug":"Lua","permalink":"https://gowa2017.github.io/categories/Lua/"}]},{"title":"skynet中服务分析(wathchdog,gate,snxa.gateserver)","slug":"skynet中服务分析(wathchdog,gate,snxa.gateserver)","date":"2018-02-13T08:29:56.000Z","updated":"2018-02-13T08:29:56.000Z","comments":true,"path":"Lua/skynet中服务分析(wathchdog,gate,snxa.gateserver).html","link":"","permalink":"https://gowa2017.github.io/Lua/skynet中服务分析(wathchdog,gate,snxa.gateserver).html","excerpt":"其实对于服务还是有些迷惑。比如在skynet.wiki中说到，gate服务，是snax.gateserver的一个实现，然后watchdog又是gate的一个使用。看了一下代码确实有点头疼，现在来从头分析一下。","text":"其实对于服务还是有些迷惑。比如在skynet.wiki中说到，gate服务，是snax.gateserver的一个实现，然后watchdog又是gate的一个使用。看了一下代码确实有点头疼，现在来从头分析一下。 启动 watchdogmain.lua中： -- examples/main.lua local watchdog = skynet.newservice(\"watchdog\") skynet.call(watchdog, \"lua\", \"start\", &#123; port = 8888, maxclient = max_client, nodelay = true, &#125;) 就是注册，并启动了服务watchdog。首先加载脚本 wathchdog.lua，然后执行其中的启动函数： -- examples/wathchdog.luaskynet.start(function() skynet.dispatch(\"lua\", function(session, source, cmd, subcmd, ...) if cmd == \"socket\" then local f = SOCKET[subcmd] f(...) -- socket api don't need return else local f = assert(CMD[cmd]) skynet.ret(skynet.pack(f(subcmd, ...))) end end) gate = skynet.newservice(\"gate\")end) 我们看到，watchdog.lua的启动函数只是注册了 lua类型消息的处理函数，其中还对 socket操作的消息类型定义了操作。 最后，启动了服务 gate。在gate.lua中，定义了很多多的操作 CMD{}，和handler{}，然后启动了 gateserver。 启动gate-- service/gate.lualocal gateserver = require \"snax.gateserver\"gateserver.start(handler) 其本质，是把 snax.gateserver.lua加载到了 gate服务的虚拟机内，然后执行。 那么，背后的意义就是，wathchdog服务启动了一个gate服务，而且两者之间建立了联系。 启动网络服务之后我们调用 skynet.call(watchdog, \"lua\", \"start\", &#123; port = 8888, maxclient = max_client, nodelay = true,&#125;) 其实这个消息是转发给了 gate： skynet.call(gate, \"lua\", \"open\", conf) 这样，消息在 snax.gateserver.lua代码中的 open处执行，开始监听端口。 在这里，snax.gateserver.lua中的代码已经加载到了 gate服务中，由其进行执行对应的代码。 gate服务启动后主要做了两件事情： -- lualib/snax/gateserver.lua skynet.register_protocol &#123; name = \"socket\", id = skynet.PTYPE_SOCKET, -- PTYPE_SOCKET = 6 unpack = function ( msg, sz ) return netpack.filter( queue, msg, sz) end, dispatch = function (_, _, q, type, ...) queue = q if type then MSG[type](...) end end &#125; skynet.start(function() skynet.dispatch(\"lua\", function (_, address, cmd, ...) local f = CMD[cmd] if f then skynet.ret(skynet.pack(f(address, ...))) else skynet.ret(skynet.pack(handler.command(cmd, address, ...))) end end) end) 注册了 socket类型的消息。 注册了消息处理函数。 对于 lua 类别的消息，会调用 匿名函数 进行处理。 而对于 socket 类别的消息，则会调用 dispatch = function (_, _, q, type, ...) queue = q if type then MSG[type](...) endend 进行处理。 其就是根据消息类型，来进行对应的操作。 在gate.lua中，定义了几个操作： local handler = &#123;&#125;function handler.open(source, conf) watchdog = conf.watchdog or sourceendfunction handler.message(fd, msg, sz) -- recv a package, forward it local c = connection[fd] local agent = c.agent if agent then skynet.redirect(agent, c.client, \"client\", 1, msg, sz) else skynet.send(watchdog, \"lua\", \"socket\", \"data\", fd, netpack.tostring(msg, sz)) endend 其在连接打开的时候，会把 watchdog设置为消息来源，或者指定的服务。 这也就是，当我们的watchdog启动了gate服务后，以后 gate收到常规的消息，都会转发到 watchdog服务去。如果是用单独的agent进行消息处理的话，就转发到对应的 agent。 事实上我还有一个疑问的就是，对于网络信息，框架底层到底是怎么处理的？ 请查看 skynet中的网络服务与消息处理一节 消息处理流程我们把gate 服务注册到了 skynet 中去后，在收到了对应的套接字消息后就会调用对应的回调函数进行处理。 一个典型服务器端流程是： bind() -&gt; listen() -&gt; accept() -&gt; read() -&gt; response -&gt; write() -&gt; close() 客户端： connect -&gt; read()/write() -&gt; close() 当我们注册了服务后，其实 gate 服务应该是处于 accept()状态，但这个工作由skynet完成。 gate 服务注册了两种消息类型的处理机制： skynet.register_protocol &#123; name = \"socket\", id = skynet.PTYPE_SOCKET, -- PTYPE_SOCKET = 6 unpack = function ( msg, sz ) return netpack.filter( queue, msg, sz) end, dispatch = function (_, _, q, type, ...) queue = q if type then MSG[type](...) end end&#125;skynet.start(function() skynet.dispatch(\"lua\", function (_, address, cmd, ...) local f = CMD[cmd] if f then skynet.ret(skynet.pack(f(address, ...))) else skynet.ret(skynet.pack(handler.command(cmd, address, ...))) end end)end) 对于网络消息，定义在 MSG{}内，用来处理数据；而对于 lua 类型的消息，则定义在 CMD{}内，主要用来控制服务的启停。 处理方法下面是MSG的定义： local MSG = &#123; open, -- new connect close, -- client close error, -- error warning, more = dispatch_queue(), data = dispatch_msg(fd, msg, sz), -- message &#125; 我们在一个监听套接字上可能出现的事件有：连接建立，数据到达，出错，关闭，甚至还有shutdown半开状态。 其实对应的事件中都是调用我们自己定义的函数来处理的： local handler = &#123; open, -- serivce start message, -- data connect, -- new connect disconnect, -- client close error, -- 错误 warning, command, -- 自定义命令&#125; 完全不用关注 gateserver.lua中定义的那些函数，我们只关注一下我们自己定义的。 local handler = &#123;&#125;function handler.open(source, conf) watchdog = conf.watchdog or sourceendfunction handler.connect(fd, addr) local c = &#123; fd = fd, ip = addr, &#125; connection[fd] = c skynet.send(watchdog, \"lua\", \"socket\", \"open\", fd, addr)endfunction handler.message(fd, msg, sz) -- recv a package, forward it local c = connection[fd] local agent = c.agent if agent then skynet.redirect(agent, c.client, \"client\", 1, msg, sz) else skynet.send(watchdog, \"lua\", \"socket\", \"data\", fd, netpack.tostring(msg, sz)) endendfunction handler.disconnect(fd) close_fd(fd) skynet.send(watchdog, \"lua\", \"socket\", \"close\", fd)endfunction handler.error(fd, msg) close_fd(fd) skynet.send(watchdog, \"lua\", \"socket\", \"error\", fd, msg)endfunction handler.warning(fd, size) skynet.send(watchdog, \"lua\", \"socket\", \"warning\", fd, size)end 看来这个wathchdog只是一个接收各种事件的服务而已，并没有干什么卵事。 其还有一个重要的功能，就是每当一个新连接到来时开启一个agent服务。之后的消息 gate 就会全部都丢给 agent处理了。 function SOCKET.open(fd, addr) skynet.error(\"New client from : \" .. addr) agent[fd] = skynet.newservice(\"agent\") skynet.call(agent[fd], \"lua\", \"start\", &#123; gate = gate, client = fd, watchdog = skynet.self() &#125;)end 整个服务流程就是如下： client connect() -&gt; gate.connect() -&gt; watchdog.open() -&gt; new agent。 client data -&gt; gate.data -&gt; agent.dispatch()","categories":[{"name":"Lua","slug":"Lua","permalink":"https://gowa2017.github.io/categories/Lua/"}],"tags":[{"name":"Lua","slug":"Lua","permalink":"https://gowa2017.github.io/tags/Lua/"},{"name":"skynet","slug":"skynet","permalink":"https://gowa2017.github.io/tags/skynet/"}],"keywords":[{"name":"Lua","slug":"Lua","permalink":"https://gowa2017.github.io/categories/Lua/"}]},{"title":"PIL.9Lua中的闭包","slug":"PIL.9Lua中的闭包","date":"2018-02-12T01:14:15.000Z","updated":"2018-02-12T01:14:15.000Z","comments":true,"path":"Lua/PIL.9Lua中的闭包.html","link":"","permalink":"https://gowa2017.github.io/Lua/PIL.9Lua中的闭包.html","excerpt":"Lua中的函数是 第一类的值加上合适的词法域。那么，函数是第一类值意味着什么呢？这是说，在Lua中，一个函数，就是一个和 数字或字符串一样具有某些权限的值。一个程序可以把函数存储在变量中（全局或者局部都可以）和表中，把函数作为参数传递给其他函数，或者以函数作为值返回。","text":"Lua中的函数是 第一类的值加上合适的词法域。那么，函数是第一类值意味着什么呢？这是说，在Lua中，一个函数，就是一个和 数字或字符串一样具有某些权限的值。一个程序可以把函数存储在变量中（全局或者局部都可以）和表中，把函数作为参数传递给其他函数，或者以函数作为值返回。 函数具有词法域又是什么意思呢？就是说函数可以访问他们包裹函数的变量。 这两个特性给了Lua巨大的弹性；具体点说，一个程序在运行一段不受信任的代码时（比如从网络上收到的代码）可以重新定义一个函数来增加功能或者擦除一个函数来创建一个安全的环境。更重要的是，这些特性运行我们从函数语言的世界应用很多强大的编程技术到Lua。即使你对函数式编程没有什么兴趣，但是看一下这些技术是非常有价值的，这会让你的程序更小更简单。 函数作为第一类值下面的例子说明了函数作为第一类值的情况： a = &#123;p = print&#125; -- 'a.p' refers to the 'print' functiona.p(\"hello world\") -- hello worldprint = math.sin -- 'print' now refers to the sine functiona.p(print(1)) -- 0.8414709848079math.sin = a.p -- 'sin' no refers to the print functionmath.sin(10, 20) -- 20 如果函数是值，这些表达式会创建函数么？当然。实际上，在Lua经常编写函数的方式： function foo (x) return 2*x end 其实只是一个被我们称作 语法糖的东西；其只是下面代码的一个比较漂亮的方式： foo = function (x) return 2*x end 在表达式右边的赋值部分function (x) return 2*x end是一个函数构造器，同样的方式{ }是一个表构造器。这就是说，一个函数定义，实际上就是一个建立一个类型为function的值并把它赋给一个变量的声明。 注意，在Lua中，所有的函数都是匿名的。和其他值一样，他们没有名字。当我们在谈论一个函数名字的时候，比如print，其实我们是在谈论存储函数的变量。尽管我们经常把函数赋值给全局变量，似乎给了他们一个名字，仍然有几种情况函数会保持匿名。我们来看看例子。 基本库中，表这个库提供了一个函数table.sort，其会接受一个表，然后排序表的元素。这样的函数必须能接受不受限制的排序方式：升序或降序，数字的或字母的，以键排序表等等。没有尝试提供所有的选项类型，sort提供了一个单一定选项order function（排序函数）：一个获取两个元素，然后返回第一个是否要在排序好的表中比第二个元素先出现。看看下面的例子： network = &#123; &#123;name = \"grauna\", IP = \"210.26.30.34\"&#125;, &#123;name = \"arraial\", IP = \"210.26.30.23\"&#125;,” &#123;name = \"lua\", IP = \"210.26.23.12\"&#125;, &#123;name = \"derain\", IP = \"210.26.23.20\"&#125;, &#125; 如果我们想以 字段name来排序表，以字母逆序排列，我们只需要这样写： table.sort(network, function (a,b) return (a.name &gt; b.name) end) 这个声明内可以匿名函数是非常方便的。 一个函数以其他函数作为参数，如sort，我们称它为 高层函数。高层函数是一个强大的编程方法，而以匿名函数来建立他们的函数参数又非常具有弹性。但要记住，高层函数没有特殊的权限；Lua会把所有函数当作第一类值。 为了更多的展示一下高层函数，我们来写一个常用的高层函数，导数函数。在一个正式的定义中，函数 f 的导数是当 d 变得无穷小时的函数 f’(x) = (f(x + d) - f(x)) / d。根据这个定义，我们可以如下计算出一个近似导数： function derivative (f, delta) delta = deleta or 1e-4 return function (x) return (f(x + deleta) - f(x))/deleta endend 给出一个函数 f，调用 derivative(f)返回（近似）导数，也就是另外一个函数： c = derivative(math.sin)print(math.cos(5.2), c(5.2))-- 0.46851667130038 0.46856084325086print(math.cos(10), c(10))-- -0.83907152907645 -0.83904432662041 非全局函数一个很明显的结论就是，我们不但可以把函数存储在全局变量，而且也可以存在在表字段或者局部变量内。 我们已经看到了很多个把函数放在表字段内的例子：大多数Lua库使用这种方法（如 io.read, math.sin）。为了建立这样的函数： Lib = &#123;&#125;Lib.foo = function (x,y) return x + y endLib.goo = function (x,y) return x - y endprint(Lib.foo(2,3), Lib.goo(2, 3))-- 5 -1 当然，我们也可以使用 表构造器： Lib = &#123; foo = function (x,y) return x + y end, goo = function (x,y) return x - y end &#125; Lua，也提供了特别的方式来定义这样的函数： Lib = &#123;&#125; function Lib.foo (x,y) return x + y end function Lib.goo (x,y) return x - y end 在lua中的面向对象一节中，我们可以看到，把函数放在表字段中是实现面向对象的重要部分。 当我们把函数存储在一个局部变量中时，我们获得了一个 局部函数 就是说这个函数被限制在给定的范围内。这样的定义对于 包 来说是非常有用的：因为Lua把每个 chunk 当作函数处理，一个 chunk可以定义 局部函数，其只在当前的 chunk内可见。词法域 保证了这个 chunk内的其他函数可以访问这个 局部函数。 Lua这样以一个语法糖的方式使用局部函数： local function f (params) bodyend 这样在进行递归定义函数的时候会出现一个微妙的错误，因为这种方式不会工作。看一下下面的定义： local fact = function (n) if n == 0 then return 1 else return n*fact(n-1) -- buggy end end Lua编译函数体中调用fact(n - 1)时，局部的fact并没有定义完成。因此，这个表示式会尝试调用一个全局的 fact，而不是本地的这个。我们可以通过先定义变量，然后再定义函数体来避免这个错误： local factfact = function (n) if n == 0 then return 1 else return n*fact(n-1) end end 现在 函数内的fact就引用本地的变量。在定义函数的时候其值不重要，在函数执行时，fact会有正确的值。 当Lua展开其对局部函数的语法糖时，其不使用这种写法。这样的定义 : local function foo (params) body end 会展开成： local foo; foo = function (params) body end 因此，我们可以这样来使用递归函数而不用有其他担心。 当然，这在我们使用非直接的递归函数时不会起作用。这样的情况下，我们必须使用一种显式的声明： local f -- \"forward\" declarationlocal function g () some code f() some codeendfunction f () some code g () some codeend 注意，在最后一个第一中不要写 local。否则，Lua会创建一个新的 本地变量 f ，并使 原来 的 f 变成未定义的。 词法域在我们写一个被其他函数包围的函数时，其可以完全的访问包围函数的变量；我们把这个特性叫做 词法定界。 这个可见性规则听起来可能很明显，但不是的。词法定界加上嵌套的第一类函数，给了Lua很大的力量，但很多语言并不支持这样的结合。 我们以一个简单的例子开始。我们有一个学习名字的表，已经一张名字和学位等级映射的表；我们想通过学生的学位来排序学生名字那张表，高学位的在前。我们可以向下面这样做： names = &#123;\"Peter\", \"Paul\", \"Mary\"&#125;grades = &#123;Mary = 10, Paul = 7, Peter = 8&#125; table.sort(names, function (n1, n2) return grades[n1] &gt; grades[n2] end ) 现在，假如我们想建立一个函数来做这个任务： function sortbygrade (names, grades) table.sort(names, function (n1, n2) return grades[n1] &gt; grades[n2] end)end 后面这个例子有趣的一点就是，sort中的匿名函数访问了 grades ，而这是 包围函数 sortbygrade 的参数。 在匿名函数中， grades 不是一个全局变量，也不是一个局部变量，我们把它叫做 非局部变量。（因为历史原因，非局部变量，也被叫做 上值(upvalues)） 我们这点会非常有趣？因为函数，是第一类值，可以 逃脱 其变量的原始范围。看一下下面的代码： function newCounter () local count = 0 return function () count = count + 1 return count endendc1 = newCounter()print(c1()) -- 1print(c1()) -- 2 在这些代码中，匿名函数引用了一个非局部变量count ，来保持其计数器。然而，在我们调用这个匿名函数的时候，变量 count 看起来已经在其范围之外了， 因为建立这个变量的函数 newCounter 已经返回了。然而，Lua会正确的处理这样的情况，使用了closure(闭包)的概念。 简单地说， 闭包 就是一个函数 加上其需要访问的所有 非局部变量。 如果我们再次调用 newCounter，其会建立一个新的局部变量 count 并加上一个新的闭包，不在新的变量上作用： c2 = newCounter()print(c2()) -- 1print(c1()) -- 3print(c2()) -- 2 因此， c1, c2是不同的闭包。他们都是一同一个函数来建立，但是每个在不同的 局部变量 count 上动作。 技术上讲，Lua中的值是闭包，而不是这个函数。函数只是闭包的一种原型。但是呢，在不混淆的情况下， 我们会继续使用 函数 来引用一个闭包。 闭包在很多上下文中非常有价值。如我们所见，其作为高层函数的参数非常有用，比如sort。 闭包对于建立其他函数的函数也非常有价值，如 newCounter或 导数例子；这和方法允许Lua程序把高端编程技术和函数世界相结合。闭包对 回调(callback)函数也很有用。一个典型的例子就是在我们在GUI工具中建立一个按钮的时候。每个按钮都在用户按这个按钮时调用一个 回调函数 ；但我们需要每个按钮干不同的事情。 具体来说，一个数字计算器需要10个类似的按钮，每个数字一个。我们可以通过一个函数来创建他们： function diginButton (digit) return Button &#123; lable = tostring(digit), action = function () add_to_display(digit) end &#125;end 在这个例子中，我们假装 Button是一个创建新按钮的工具函数；label 是按钮的标签； action 是按下按钮时的回调函数。 回调函数可能会在 digitButton完成任务后很久才会被调用，但其仍然可以访问 digit 变量。 闭包在不同的上下文中也很有价值。因为函数存储于普通的变量中，我们可以在Lua重新定义函数，即使是预定义的函数。这也是为什么Lua如此扩展性好的原因之一。假如我们想要重新定义 sin来操作角度而不是弧度。这个新函数把其参数进行转换然后调用原来的 sin函数来做真正的工作。代码类似下面： local oldSin = math.sinmath.sin = function (x) return oldSin(x * (math.pi / 180)) end 一个更清楚的方式是像下面一定义： do local oldSin = math.sin local k = math.pi / 180 math.sin = function (x) return oldSin(x * k) endend 代码使用 do .. end来限制本地变量 oldSin 的词法范围；其只在当前 chunk内可见。其只能通过 新函数来访问。 可以用同样的方法来建立安全的环境，也叫做沙盒。安全环境在运行不受信任的歹时非常重要，这样的代码通过服务从网络获得。具体来说，为了限制一个程序可以访问的文件，我们可以用闭包来重新定义 io.open函数： do local oldOpen = io.open local access_OK = function (filename, mode) check_access end io.open = function (filename, mode) if access_OK(filename, mode) return oldOpen（filename, mode) else return nil, \"access dinied\" end endend 我们让这个例子变得很好的地方是在这重新定义后，没有其他方式来调用不受限制的 io.open函数版本，其只能通过新函数来访问。其将不受限制的版本在闭包中以一个变量保存，外部将不能访问。通过这样的技术，我们可以在Lua自身建立沙盒，有常用的好处：简单 和弹性。Lua提供了 meta-mechanism，而不是 one-size-fits-all的方式，我们可以根据我们的需求来定义我们的环境。 函数编程的好处为了给予更多函数编程的例子，我们来开发一个几合形状的简单系统。目的是开发一个表示几何形状的系统，一个形状是一系列点的集合。我们需要能表示所有类型的形状，并以几种方式来结合和修改形状。 为了实现这个系统，我们要寻找好的数据结构来表达形状；我们可以尝试面向对象的方式并定义一些形状的层级。或者我们可以在更高的抽象层面工作，并通过形状的特点函数来表示我们的设置。 每个几何区域都是一系列点的集合，我们可以通过特征函数来代表一个区域；这就是说，我们可以通过一个函数来代表一个区域，这个函数得到一个点后，会返回这个点是否属于区域内。 下面的函数代表了一个圆，中心(1.0, 3.0)，半径 4.5: function disk1 (x,y) return (x - 1.0)^2 + (y - 3.0)^2 &lt;= 4.5^2end 集合高层函数和词法定界，很容易定义滚个 圆盘工厂，其以给定的半径和中心来建立圆盘： function disk (cx, cy, r) return function (x, y) return (x - cx)^2 + (y - cy)^2 &lt;= r^2 endend 调用 disk(1.0, 3.0, 4.5)和 disk1一样。","categories":[{"name":"Lua","slug":"Lua","permalink":"https://gowa2017.github.io/categories/Lua/"}],"tags":[{"name":"Lua","slug":"Lua","permalink":"https://gowa2017.github.io/tags/Lua/"},{"name":"Closure","slug":"Closure","permalink":"https://gowa2017.github.io/tags/Closure/"}],"keywords":[{"name":"Lua","slug":"Lua","permalink":"https://gowa2017.github.io/categories/Lua/"}]},{"title":"Cocos2d-X-基本概念","slug":"cocos2dx-基本概念","date":"2018-02-11T06:23:18.000Z","updated":"2018-02-11T06:23:18.000Z","comments":true,"path":"Cocos2d-X/cocos2dx-基本概念.html","link":"","permalink":"https://gowa2017.github.io/Cocos2d-X/cocos2dx-基本概念.html","excerpt":"游戏其实是对画面、文字、动作、剧情的展示。无论是MMORPG还是小小的游戏，都需要有这样的表达方式。而cocos2d就是通过你来给砖头，他来建房子的这样一个东西。当然，其实我喜欢Lua但是其对Lua的文档实在是太少，只能自己摸索了。","text":"游戏其实是对画面、文字、动作、剧情的展示。无论是MMORPG还是小小的游戏，都需要有这样的表达方式。而cocos2d就是通过你来给砖头，他来建房子的这样一个东西。当然，其实我喜欢Lua但是其对Lua的文档实在是太少，只能自己摸索了。 本文来自于官方的新手指导cocos2d-x基本概念，版权归其所有。 组件精通cocos2d-x很难，但是上手很容易。 下面是一个简单的游戏画面： 然后把他进行分解： 能看到一个菜单(Menu)，几个精灵(Sprite)，和几个标签(Label)，观察一下喜欢的游戏，会发现这些组件以某种形式存在其中。 导演(Director)其实就是你切换每个场景的逻辑而已。比如，传送新地图等等，但是更文字化的描述还要看官方的。 Cocos2d-x 使用导演的概念，这个导演和电影制作过程中的导演一样！导演控制电影制作流程，指导团队完成各项任务。在使用 Cocos2d-x 开发游戏的过程中，你可以认为自己是执行制片人，告诉 导演(Director) 该怎么办！一个常见的 Director 任务是控制场景替换和转换。 Director是一个共享的单例对象，可以在代码中的任何地方调用。 这是一个典型的游戏流程实例。当您的游戏设计好时，Director 就负责场景的转换： 你是你的游戏的导演。你决定着发生什么，何时发生，如何发发生。 场景(Scene)看看刚才那个图片： 这是一个主菜单场景，这个场景是由很多小的对象拼接而成，所有的对象组合在一起，形成了最终的结果。场景是被 渲染器(renderer) 画出来的。渲染器负责渲染精灵和其它的对象进入屏幕。为了更好的理解这个过程，我们需要讨论一下 场景图。 场景图(Scene Graph)场景图(Scene Graph)是一种安排场景内对象的数据结构，它把场景内所有的 节点(Node) 都包含在一个 树(tree) 上。(场景图虽然叫做”图”，但实际使用一个树结构来表示)。而节点（Node）则是场景图的基本元素。所有场景图内的元素必须是 节点 或者 其衍生类。最常见的Node类是：Scene, Layer, Sprite, Menu, Label。 听起来这好像很复杂，可能你会问，我为什么要关注这个技术细节，Cocos2d-x 值得我研究的这么深入吗？值得！这个对你真正了解渲染器是如何绘制场景的非常重要。 当你开发游戏的时候，你会添加一些节点，精灵和动画到一个场景中，你期望的是每一个添加的对象都能被正确的展示，可是如果有个对象没有被展示呢？可能你错误的把这个对象隐藏到背景中了。怎么办？别着急，这是个小问题，停下来，拿出一张纸，把场景图画出来，你肯定能很容易的发现错误。 既然场景图是一个树结构，你就能遍历它，Cocos2d-x 使用 中序遍历，先遍历左子树，然后根节点，最后是右子树。中序遍历下图的节点，能得到 A, B, C, D, E, F, G, H, I 这样的序列。 初步了解了场景图，让我们看一下这个游戏场景。 分解这个场景，看一下它有哪些元素，这些最终会被渲染为一个树。 另一点要考虑的是，z-order 为负的元素，z-order 为负的节点会被放置在左子树，非负的节点会被放在右子树。实际开发的过程中，你可以按照任意顺序添加对象，他们会按照你指定的 z-order 自动排序。 如上图，左侧的场景是由很多节点对象组成的，他们根据被指定的 z-order 相互叠加。在 Cocos2d-x 中，通过 Scene 的 addChild() 方法构建场景图。 self:addChild(title_node, -2)self:addChild(label_node)self:addChild(sprite_node, 1) 渲染时 z-order 值大的节点对象会后绘制，值小的节点对象先绘制。如果两个节点对象的绘制范围有重叠，z-order 值大的可能会覆盖 z-order 值小的。 精灵(Sprite)不知你是否意识到，所有的游戏都有 精灵(Sprite) 对象，精灵是您在屏幕上移动的对象，它能被控制。你喜欢玩的游戏中主角可能就是一个精灵，我知道你在想是不是每个图形对象都是一个精灵，不是的，为什么? 如果你能控制它，它才是一个精灵，如果无法控制，那就只是一个节点(Node)。 看下面的图片，我们来指出一下，哪个是精灵(Sprite)，哪个是节点(Node)。 精灵在所有游戏中都很重要，每个游戏都有这样的情景：一个舞台，上面站着一个某种形式的主角，那主角就是精灵。Sprite 很容易被创建，它有一些可以被配置的属性，比如：位置，旋转角度，缩放比例，透明度，颜色 等等。 local mySprite = display.newSprite(\"mysprite.png\") :setPosition(500, 0) :setRotation(40) :setScale(2.0) :setAnchorPoint(0,0) 让我们举例说明每个属性的含义，思考下面不同截图中精灵的区别： 设置位置：:setPosition(500, 0): 现在这个精灵的位置就变成了，我们设置的新地方。 设置旋转角度setRotation(40)： 设置缩放比例setScale(2.0)： 看到了精灵的大小，由于我们设置缩放而变化了。 我们再来说一下 锚点(anchor point) ，所有的节点(Node)对象都有锚点值，Sprite 是 Node 的子类，自然也具有锚点。锚点是节点对象在计算坐标位置时的一个基准点。 以我们刚才的展示的精灵为例，设置锚点(0,0)： setAnchorPoint(0, 0) 精灵的左下角就变为了 setPosition() 调用，计算坐标的基础。再看看其它的锚点效果： 注意每张图片中的红点，红点表示锚点的位置。 正如你所看到的那样，锚点对于确定节点对象的位置是非常有用的，你可以在你的游戏中动态的调整锚点值以实现你想要的效果。 现在我们可以静态调整精灵的各个方面，但是你要想这些属性按照时间自动变化该如何做呢? 继续阅读，很快你就会有答案。 动作创建一个场景，在场景里面增加精灵只是完成一个游戏的第一步，接下来我们要解决的问题就是，怎么让精灵动起来。动作(Action) 就是用来解决这个问题的，它可以让精灵在场景中移动，如从一个点移动到另外一个点。你还可以创建一个动作 序列(Sequence) ，让精灵按照这个序列做连续的动作，在动作过程中你可以改变精灵的位置，旋转角度，缩放比例等等。 有示例是这样的： 5s 后，精灵移动到了一个新的位置： Action对象的创建： local mySprite = display.newSprite(\"mysprite.png\")local moveBy = cc.MoveBy:create(2, cc.p(50, 10))mySprite:runAction(moveBy);local moveTo = cc.MoveTo:create(2, cc.p(50, 10))mySprite:runAction(moveTo); 序列(Sequence)能在屏幕上移动精灵，是制作一个游戏所需的一切，是吗？不是的，至少要考虑一下如何执行多个 Action。Cocos2d-x 通过 序列(Sequence) 来支持这种需求。 顾名思义，序列就是多个动作按照特定顺序的一个排列，当然反向执行这个序列也是可以的，Cocos2d-x 能很方便的完成这项工作。 让我们来看一个通过序列控制精灵移动的例子： 创建 Sequence ： local mySprite = cc.Node:create() -- display.newNode()local moveTo1 = cc.MoveTo:create(2, cc.p(50,10))local moveBy1 = cc.MoveBy:create(2, cc.p(100,100))local moveTo2 = cc.MoveTo:create(2, cc.p(150,10))local delay = cc.DelayTime:create(1)mySprite:runAction(cc.Sequence:create(moveTo1, delay, moveBy1, delay:clone(), moveTo2, NULL)) 这个例子执行了一个动作的 Sequence 序列，那要是想让所有的特定动作同时执行呢？Cocos2d-x 也支持！通过引擎中的 Spawn 对象，你能让多个动作同时被解析执行。可能不同动作的执行时间不一致，在这种情况下，他们不会同时结束。 local node = cc.Node:create()local moveTo1 = cc.MoveTo:create(2, cc.p(50,10))local moveBy1 = cc.MoveBy:create(2, cc.p(100,100))local moveTo2 = cc.MoveTo:create(2, cc.p(150,10))node:runAction(cc.Spawn:create(moveTo1,moveBy1, moveTo2, NULL)) 节点关系Cocos2d-x 的 节点关系，是被附属和附属的关系，就像数据结构中的父子关系，如果两个节点被添加到一个父子关系中，那么父节点的属性变化会被自动应用到子节点中。想一下处于父子关系中的精灵有什么特性。 这三个精灵被添加到了一个父子关系中，当父精灵(被其它精灵附属的精灵)设置了旋转角度之后，子精灵也会自动做同样的改变： local myNode = cc.Node:create():setRotation(50):setScale(2.0) 需要注意的是，不是所有的父节点属性都会被自动应用到子节点，如改变父节点的锚点只会影响转换效果(比例缩放，位置变化，角度旋转，变形等)，不会影响子节点锚点，子节点的锚点总会是左下角 (0,0)。","categories":[{"name":"Cocos2d-X","slug":"Cocos2d-X","permalink":"https://gowa2017.github.io/categories/Cocos2d-X/"}],"tags":[{"name":"Lua","slug":"Lua","permalink":"https://gowa2017.github.io/tags/Lua/"},{"name":"Cocos2d-X","slug":"Cocos2d-X","permalink":"https://gowa2017.github.io/tags/Cocos2d-X/"}],"keywords":[{"name":"Cocos2d-X","slug":"Cocos2d-X","permalink":"https://gowa2017.github.io/categories/Cocos2d-X/"}]},{"title":"利用协程实现多线程","slug":"利用协程实现多线程","date":"2018-02-10T14:07:02.000Z","updated":"2018-02-10T14:07:02.000Z","comments":true,"path":"Lua/利用协程实现多线程.html","link":"","permalink":"https://gowa2017.github.io/Lua/利用协程实现多线程.html","excerpt":"Lua并没有真正的多线程，其是通过协程来实现的。这章我们就来看看通过协程来实现一个多线程系统。协程允许一种协作式的多线程。每个协程就等于一个线程。一对 yield-resume调用，会把控制从一个线程转交到另外一个。但是和常规的多线程不同，协程是非抢占式的。","text":"Lua并没有真正的多线程，其是通过协程来实现的。这章我们就来看看通过协程来实现一个多线程系统。协程允许一种协作式的多线程。每个协程就等于一个线程。一对 yield-resume调用，会把控制从一个线程转交到另外一个。但是和常规的多线程不同，协程是非抢占式的。 当一个协程运行时，我们不能从外部停止它。其只能显式的在其需要的时候通过yield来让出时间片。对于只有少数几个流程的应用来说可，这不是什么问题，非常的简单。 抢占式的编程可能会更简单些。我们不用为同步产生的Bug而头疼，因为所有线程间的同步在程序内是非常明显的。我们只需要保证一个协程是在非临界区域时让出时间片就可以了。 然而，对于非抢占式的多线程，当一个线程调用阻塞式操作时，整个程序都会等待直到这个操作完成。对于很多应用，这个行为是不可接受的，所以很多程序员不认为协程是一个真正合适的多线程方式。但我们会看到，这个问题有一个非常有趣的（也非常明显，事后也显得非常聪明）解决办法。 我们来假设一个非常典型的多线程场景：我们想通过 HTTP来下载几个远程文件。 为了下载多个远程文件首先我们要知道如何下载一个远程文件。 在这个例子中，我们使用了LuaSocket库。为了下载一个文件我们必须先打开一个到远程地址的连接，然后发送请求，接着接收文件（阻塞式），接收完毕就关闭连接。在Lua中，我们可以如下完成这个任务。首先，我们导入 LuaSocket 库： local socket = require \"socket\" 然后，我们定义主机及需要下载的文件。在这个例子中，我们会从 Lua 网站上下载 Lua 5.3的参考手册： host = \"www.lua.org\"file = \"/manual/5.3/manual.html\" 接着，打开一个 TCP:80 的连接： c = assert(socket.connect(host, 80)) 这将会返回一个连接对象，我们会用它来发送请求： local request = string.format(\"GET %s HTTP/1.0\\r\\nhost:%s\\r\\n\\r\\n\", file, host)c:send(request) 下面我们就会以 1KB 一块的来读取文件，把每个读取到的块写到标准输出： repeat local s, status, partial = c:receive(2^10) io.write(s or partial)until status == \"closed\" 方法receive会返回其读取到的字符或在发生错误时的 nil；在后面一种情况，其会返回一个错误代码（status），以及部分阅读到的内容（partial)。当主机关闭这个连接时，我们打印出剩余的输出，接着跳出了接收循环。 在下载完这个文件后，我们关闭连接： c:close() 现在我们知道了怎么下载一个文件，现在我们回到下载多个文件的问题上。比较低效的方式就是每次下载一个。然而，这种串行化的方式，我们只能在完成前一个下载后才可以阅读下一个文件，非常的慢。当阅读一个远程文件时，程序大多数时间都花在了等待数据到达上。更特别地，其多数时间都花在了receive上。所以，并发的进行下载会更加的快速。 而当一个连接没有数据到达的时候，程序可以从另外一个连接进行读取。很明白地，协程提供了一个非常方便的方式来组织安全这种同时的下载情况。我们为每个任务建立一个线程。当一个线程没有数据到达时，就让出时间片给另外一个分发器，其会调用 另外一个线程。 我们来用协程重写程序，我们把先前的下载代码写成一个函数。 function download (host, file) local c = assert(socket.connect(host, 80)) local count = 0 local request = string.format(\"GET %s HTTP/1.0\\r\\nhost:%s\\r\\n\\r\\n\", file, host) c:send(request) while true do local s, status = receive(c) count = count + #s if status == \"closed\" then break end end c:close() print(file, count)end 我们对远程文件的内容不关心，所以这个函数只是计算并打印出文件的大小，而不是写到标准输出。 在新的代码中，我们使用了一个辅助函数receive来从连接接收数据。在串行化的方式中，代码可能会是这样的： function receive (connection) local s, status, partial = connection:receive(2^10) return s or partial, statusend 对于并发的实现，函数必须不阻塞的接收数据。如果没有足够的数据可用，就会让出时间片。新代码类似这样： function receive (connection) connection:settimeout(0) -- do not block local s, status, partial = connection:receive(2^10) if status == \"timeout\" then coroutine.yield(connection) end return s or partial, statusend 调用 settimeout(0)会让对对连接上的所有操作都是非阻塞的。如果返回的状态是timeout，那就说明操作没有完成就返回了。 在这样的情况下，线程会让出时间片。 传递到 yield的非假参数告诉 分发处理器 线程还在进行它的任务。注意到这点，及时一超时， 这个连接也会返回其阅读到的内容，也就是说在 partial中保留的不完整的数据。 tasks = &#123;&#125; -- list of all live tasksfunction get (host, file)-- create coroutine for a tasklocal co = coroutine.wrap(function () download(host, file) end)-- insert it in the list-- co is not start, nowtable.insert(tasks, co)endfunction dispatch () local i = 1 while true do if tasks[i] == nil then -- no other tasks? if tasks[1] == nil then -- list is empty? break end i = 1 -- else restart the loop end local res = tasks[i]() -- run a task if not res then -- task finished? table.remove(tasks, i) else i = i + 1 end endend 表tasks保存了给予分发器活跃任务的列表。get保证了每个下载任务在独立的线程内运行。 分发器 就是一个遍历所有任务的循环，一个一个的恢复他们。其必须从列表我移除已经完成的任务。如果没有任务的时候，就要跳出循环。 最后，主程序创建任务，然后调用分发器。为了从Lua上下载一些发行版，主程序如下类似： get(\"www.lua.org\", \"/ftp/lua“5.3.2.tar.gz\") get(\"www.lua.org\", \"/ftp/lua-5.3.1.tar.gz\") get(\"www.lua.org\", \"/ftp/lua-5.3.0.tar.gz\") get(\"www.lua.org\", \"/ftp/lua-5.2.4.tar.gz\") get(\"www.lua.org\", \"/ftp/lua-5.2.3.tar.gz\")”dispatch() -- main loop 在我的机器上，串行化的实现花了15秒来下载这些文件。以协程来实现的速度快了三倍有余。 不要看到速度有了提成，最后的实现依然不是最优的。在最少有应该线程有数据需要读时这工作得良好。然而，当所有线程都没有数据需要读的时候，分发器 就处于 忙-等状态，不停的检查是否存在有数据需要读任务。 为了避免这样的行为，我们可以使用 LuaSocket 中的 select函数：其允许程序在等待一组套接字状态变更时进行等待。在我们实现中的变化是非常小的：我们只需要改变分发器： function dispatch () local i = 1 local timedout = &#123;&#125; while true do if tasks[i] == nil then -- no other tasks? if tasks[1] == nil then -- list is empty? break end i = 1 -- else restart the loop timedout = &#123;&#125; end local res = tasks[i]() -- run a task if not res then -- task finished? table.remove(tasks, i) else i = i + 1 timedout[#timedout + 1] = res if #timedout == #tasks then -- all tasks blocked? socket.select(timedout) -- wait end end endend 在循环内，新的分发器搜集所有超时连接的到表timedout中。（记住，receive把这些连接传递给 yield，这样 resume也会返回他们）。如果所有的连接都是超市的，分发器调用select来等待所有这些连接改变状态。这个实现和先前用协程的实现一样快。更好的时，其不会处于忙等状态，其和串行化使用的CPU一样多。","categories":[{"name":"Lua","slug":"Lua","permalink":"https://gowa2017.github.io/categories/Lua/"}],"tags":[{"name":"Lua","slug":"Lua","permalink":"https://gowa2017.github.io/tags/Lua/"}],"keywords":[{"name":"Lua","slug":"Lua","permalink":"https://gowa2017.github.io/categories/Lua/"}]},{"title":"关于Cocos2d-X在xcode9之中无法使用system系统调用的问题","slug":"关于cocos2dx在xcode9之中无法使用system系统调用的问题","date":"2018-02-09T01:53:19.000Z","updated":"2018-02-09T01:53:19.000Z","comments":true,"path":"Cocos2d-X/关于cocos2dx在xcode9之中无法使用system系统调用的问题.html","link":"","permalink":"https://gowa2017.github.io/Cocos2d-X/关于cocos2dx在xcode9之中无法使用system系统调用的问题.html","excerpt":"这个问题还是在更新成了xcode9.2后出现的，以前没有出现，搜索了一下确实是还有。在github上的 cocos2d-x的开源项目上已经有了解决方案的。止不过一直没有遇到罢了。","text":"这个问题还是在更新成了xcode9.2后出现的，以前没有出现，搜索了一下确实是还有。在github上的 cocos2d-x的开源项目上已经有了解决方案的。止不过一直没有遇到罢了。 详细参考issue #17921","categories":[{"name":"Cocos2d-X","slug":"Cocos2d-X","permalink":"https://gowa2017.github.io/categories/Cocos2d-X/"}],"tags":[{"name":"Cocos2d-X","slug":"Cocos2d-X","permalink":"https://gowa2017.github.io/tags/Cocos2d-X/"}],"keywords":[{"name":"Cocos2d-X","slug":"Cocos2d-X","permalink":"https://gowa2017.github.io/categories/Cocos2d-X/"}]},{"title":"PIL.33Lua的线程和状态机","slug":"PIL.33Lua的线程与状态机","date":"2018-02-06T06:52:32.000Z","updated":"2018-02-06T06:52:32.000Z","comments":true,"path":"Lua/PIL.33Lua的线程与状态机.html","link":"","permalink":"https://gowa2017.github.io/Lua/PIL.33Lua的线程与状态机.html","excerpt":"Lua并不支持真正的多线程，也就是说，抢先的线程间共享内存。缺乏这个支持有两个原因。一是ISO C不提供，所以没有可移植的方式来实现。第二个原因就是我们不认为多线程对Lua是一件好事。","text":"Lua并不支持真正的多线程，也就是说，抢先的线程间共享内存。缺乏这个支持有两个原因。一是ISO C不提供，所以没有可移植的方式来实现。第二个原因就是我们不认为多线程对Lua是一件好事。 简介多线程被开发来针对底层的编程。像信号量和监视器这样的同步算法在操作系统的上下文中被提出。找出并修正与多线程相关的bug是非常困难的，某几个这样的bug还会导致安全问题。而且，在某些非常挑剔的情况下同步会导致巨大的性能下降，如内存分配。 多线程的问题是由于对内存的抢占使用而生，所以我们可以使用非抢占式的线程或者不共享内存来避免这些问题。Lua两者都支持。Lua线程（经常被叫做协程）是合作性的，因此会避免未知的线程切换所带来的问题。Lua状态机不共享内存，所以在Lua为并行提供了一个好的基础。接下来我们就会介绍 多线程Lua中，线程的本制就是一个协程， coroutine。我们可以把一个协程看做一个线程，加上一个好的接口；或者我们可以把线程就作一个底层的API。 从C API的观点来看，你会发觉把线程看成一个 栈 会非常有用————从实现的观点来看，Lua线程就是一个栈。每个 栈 保留了一个线程所有挂起的调用，已经每个调用 的参数和本地变量。换句话说，一个栈拥有一个函数继续运行的所有信息。所以，多线程就意味着多个不同的栈。 绝大多数 Lua的C API在一个 特定的 栈上操作。Lua怎么知道用哪一个栈呢？当我们调用 lua_pushnumber的时候，我们怎么告诉它把数字压到哪里呢？秘密就是 类型 lua_State，这些函数的第一个参数，不仅代表了一个 Lua状态机，而且包括里面的一个线程。（很多人认为这个类型应该叫lua_thread。可能他们是正确的） 每当我们建立一个Lua State时，Lua会自动的在state内建立一个主线程，并返回一个 lua_State值来代表这个线程。 这个主线程绝不会被回收。它只会在我们调用lua_close时和state一起释放。程序一点都不用担心主线程里运行的东西。 可以在一个state内调用 lua_newthread来建立一个新线程： lua_State *lua_newthread(lua_State *L); 这个函数会被线程压入到栈上，值类型是thread，被返回一个lua_State来代表这个新线程。更具体点，看下面： L1 = lua_newthread(L); 在运行了这段代码后，我们有了两个线程，L1, L，两个都内部地指向同一个Lua State。每个线程有它自己的栈。线程L1以一个空栈开始；老的线程L在其栈顶对 新线程有一个引用： printf(\"%d\\n\", lua_gettop(L1)); --&gt; 0printf(\"%s\\n\", luaL_typename(L, -1)); --&gt; thread 除了主线程外，所有的线程都遵从垃圾回收，就跟其他的Lua对象一样。每当我们建立一个新线程，压入到栈的值保证这个线程不会被回收。我们绝不能使用一个没有在State内正确锁定的线程。（主线程会被Lua内部锚定，所以不用担心这个问题）。任何对Lua API的调用都可能会回收一个未锚定的线程，及时调用一个使用这个线程的函数。具体点说，看看下面的代码片段： lua_State *L1 = lua_newthread(L);lua_pop(L, 1); /* L1 now is garbage for lua */lua_pushstring(L1, \"hello\") 调用lua_pushstring将会触发垃圾回收器，并回收L1，使这个程序崩溃，尽管 L1是在被使用。为了避免这样，总是保持一个对你使用的线程的引用，具体点，要么是在一个锚定线程的栈上，或者注册表，或者Lua变量中。 一旦有了一个新线程，我们就跟使用主线程一样使用它。我们可以向它的栈上压入或者弹出元素，用它来调用函数等等。下面的代码在新线程内调用f(5)，然后把结构移动到老线程内： lua_getglobal(L1, \"f\"); /* assume a global function 'f' */lua_pushinteger(L1, 5);lua_call(L1, 1, 1);lua_xmove(L1, L, 1); lua_xmove会在同一State的两个栈间移动值。一个类似lua_xmove(F, T, n)的调用会从 栈F上弹出 n个元素，然后把n个元素压入到T。 在这样的情况时，我们并不真的需要一个新的线程；我们可以仅仅使用主线程。使用多线程的主要目标是为了实现协程，这样我们就可以挂起执行，后面又可以恢复。这时，我们就需要 lua_resume函数了： int lua_resume(lua_State *L, lua_State *from, int narg); 为了运行一个协程，我们像使用lua_pcall一样使用lua_resume：压入 待执行函数（协程主体），压入参数，以nargs为参数个数调用lua_resume。（from参数一进行此调用的线程或者NULL）。这个的行为有点类似lua_pcall，但有三点不同。 lua_resume没有返回的结果个数；其总将函数的所有值返回。 没有消息处理器；一个错误不会解开栈，因此我们可以在错误发生后在检查栈。 如果运行的函数让出了时间片，lua_resume会返回LUA_YIELD，但线程在此State保留，且能进行恢复。 当lua_resume返回LUA_YIELD时，线程的栈只有传递给yield函数的值可见。调用lua_gettop会返回 让出时间片时传递的值。可以用lua_xmove来把这些值转移到其他线程。 为了恢复一个挂起的线程，我们可以继续使用lua_resume。在这个调用时，Lua假设所有栈上的值都会被yield返回。 更具体点，如果在一个lua_resume和下一个恢复间不访问线程的栈，yield函数会返回其让出时间片时确切的值。 典型情况，我们会以一个函数体作为协程的开始。这个Lua函数可以调用其他函数，其他任何函数也可能会发生让出时间片，因此会中断 lua_resume的调用。看看下面代码： function foo (x) coroutine.yield(10, x) endfunction foo1 (x) foo(x + 1); return 3 end 现在我们来运行下面的C代码： lua_State *L1 = lua_newthread(L);lua_getglobal(L1, \"foo1\");lua_pushinteger(L1, 20);lua_resume(L1, L, 1); 调用lua_resume将会返回LUA_YIELD，以此来表明线程让出了时间片。在这个时候，L1拥有传递给yield的值： printf(\"%d\\n\", lua_gettop(L1)); ---&gt;2printf(\"%lld\\n\", lua_tointeger(L1, 1)); ---&gt;10printf(\"%lld\\n\", lua_tointeger(L1, 2)); ---&gt;21 当我们继续恢复这个线程，它将会从其停止的地方继续运行（调用yield的位置）。在这里，foo函数，返回到了foo1，然后就按序返回到了 lua_resume： lua_resume(L1, L, 0);printf(\"%d\\n\", lua_gettop(L1)); ---&gt; 1printf(\"lld\\n\", lua_tointeger(L1, 1)); ---&gt; 3 第二次调用lua_resume会返回LUA_OK，表示一个正常的返回。 一个协程也可以调用C函数，这个C函数又能调用其他Lua函数。我们已经讨论了如何使用接续函数来运行这样Lua函数的让出时间片。一个C函数也可以让出时间片。在这样的情况下，其必须提供一个接续函数来在线程恢复的时候调用。为了让出时间片，一个C函数必须调用下面的函数： int lua_yieldk (lua_State *L, int nresults, int ctx, lua_CFuntion k); 我们在一个返回声明中应该总是使用这个函数： static int myCfunction (lua_State *L) &#123; ... return lua_yieldK(L, nresults, ctx, k):&#125; 这个调用会立即挂起运行的协程。nresults是将用从栈上返回到lua_resume的值个数；ctx 是要传递给接续函数的上下文； k就是接续函数。当协程恢复，控制直接转到k。在让出时间片后，myCfunction什么都不能做；它只能把他应该做的工作全部交给接续函数k。 我们来看一个典型的例子。假如我们想写一个读一些数据的函数，在数据不可用时就让出时间片。 int readK (lua_State *L, int status, lua_KContext ctx) &#123; (void) status; (void) ctx; /* unused parameters */ if (something_to_read()) &#123; lua_pushstring(L, read_some_data()); return 1; &#125; else return lua_yieldk(L, 0, 0, &amp;readK); &#125; int prim_read (lua_State *L) &#123; return readK(L, 0, 0); &#125; 例子中，prim_read不需要任何初始化，所以其会直接调用 接续函数readK。如果有数据需要读，readK读取并返回这些数据。否则的话，让出时间片。当线程恢复，继续调用接续函数，这将继续尝试读取一些数据。 如果一个C函数在让出时间片后没什么需要做的，可以不传递接续函数参数给lua_yieldk或者调用lua_yield宏： return lua_yield(L, nres); 在这个调用后，线程恢复时，控制转到调用myCfunction的函数。 Lua States调用lua_newstate, luaL_newstate都会建立一个新的Lua State。每个Lua State都是相互独立的，不会共享任何数据。这就是说无论一个Lua State内发生了什么都不会影响其他的State；这也意味着不同的Lua State间不能直接通信；我们必须使用一些中间的C 代码。 比如，有两个State L1, L2，下面的命令会把L1栈顶的字符压入到L2去： lua_pushstring(L2, lua_tostring(L1, -1)); 因为数据必须通过C传递，Lua States就只能交换C能描述的数据，如 字符串和数字。其他类型，比如表，必须序列化来传输。 在支持多线程的系统中，一个有趣的设计就是为每个系统线程建立一个独立的Lua State。这样设计的结果就是得到了类似 POSIX进程的线程，我们不需要共享内存而获得并发。在这节中，我们会通过这种方式来开发一个类似实现的原型。我打算使用 POSIX 线程（pthread）来实现。想把代码移植到其他多线程系统并不困难，只是使用了一些基础的特性而已。 我们要开发的系统很简单。主要目的是展示在多线程的上下文中使用多个Lua States。在我们跑起来后，我们可以在其上添加一些高级特性。把我们的库叫做：lproc，只是包含了四个函数： lproc.start(chunk) 启动一个新过程来运行给定的chunk（一个字符串）。库通过一个C 线程加上关联的Lua State来实现 Lua 进程。 lproc.send(channel, var1, var2, ...) 把所有给定的值（字符串）发送到被其名字所标记的通道，这也是一个字符串标记。（练习会要求你支持其他类型） lproc.receive(channle) 接收发送到给定通道的值。 lproc.exit() 结束一个进程。只有主进程需要这个函数。如果进程不以调用lpro.exit而结束，整个程序都会终止，而不等待其他进程的结束。 库通过字符串来标记通道，并用他们来匹配发出者和接收者。一个发送操作可以发送任何数量的自负串值，然后会被对应的接收操作所返回。所有的通信都是同步的：一个发送消息的进程会屏蔽，直到有一个进程从此通道接收（就跟 管道一样），反之一样。 和接口一样，lproc的实现也很简单。使用了两个双向链表，一个给等待发送消息的进程用，一个给等待接受消息的进程用。使用了一个互斥量来控制对链表的访问。每个进程都有一个相关的 条件变量。 当一个进程想要发送一个消息到通道，其会遍历接收链表来找到一个等待对应通道消息的进程。如果找到，就会从这个接收链表内移除对应的进程，把消息的值从其自身移动到找到的进程，并信号通知其他进程。如果找不到等待的进程，就会把自己放到发送链表内，等待条件变量的唤醒。如果想要接收消息的，也会做这样一个对称类似的操作。 在这个实现内的一个主要元素就是代表一个进程的结构： #include &lt;pthread.h&gt;#include \"lua.h\"#include \"lauxlib.h\"typedef struct Proc &#123; lua_State *L; pthread_t thread; pthread_cond_t cond; const char *channel; strunct Proc *previous, *next;&#125; Proc; 开头的两个字段分别代表了 这个进程使用的Lua State和 在系统级别上跑这个进程的 C 线程。第三个字段，是用来等待线程唤醒一个 发送/接收操作的条件变量。第四个字段指的是当前进程等待的通道。接下来的代码声明了两个等待链表和关联的互斥量： static Proc *waitsend = NULLstatic Proc *waitreceive = NULL:static pthread_mutex_t kernel_access = PTHREAD_MUTEX_INITIALIZER; 每个进程都需要一个Proc结构，当其需要send/receive时也需要访问这个结构。所有这些函数需要的参数只有进程的Lua State；因此，每个进程需要将它自己的Proc结构保存在Lua State内。在我们的实现中，每个State在 注册表内 保存其对应的Proc结构为完全用户数据，以键_SELF进行关联。 辅助函数 getself会获得与一个指定 State 关联的 Proc结构： static Proc *getself (lua_State *L) &#123; Proc *p; lua_getfield(L, LUA_REGISTRYINDEX, \"_SELF\"); p = (Proc *)lua_touserdate(L, -1); lua_pop(L, 1); return p;&#125; 下一个函数，movevalues，会从一个发送进程移动数据到接收进程： static void movevalues (lua_State *send, lua_State *rec) &#123; int n = lua_gettop(send); int i; luaL_checkstack(rec, n, \"too many results\"); for (i = 2; i &lt;= n; i ++) lua_pushstring(rec, lua_tostring(send, i);&#125; 此函数会将发送者栈内除第一个元素外的所有值移动到接收者，第一个元素代表的是通道。注意，因为我们要压入任意数量的元素，所以必须检查栈的空间。 接下来的函数会遍历链表来找到一个匹配的，等待对应通道的进程。 static Proc *searchmatch (const char *channel, Proc **List) &#123; Proc *node; for (node = *List; node != NULL: node = node-&gt;next) &#123; if (strcmp(channel, node-&gt;channel) == 0) &#123; if (*list == node) *list = (node-&gt;next == node) ? NULL : node-&gt;next; node-&gt;previous-&gt;next = node-&gt;next; node-&gt;next-&gt;previous = node-&gt;previous; return node; &#125; return NULL; &#125; 找到一个的话就把对应的结构从链表中移除并返回，如果找不到就返回NULL。 下面的函数是找不到对应的进程时，把自己添加到链表中： static void waitonlist (lua_State *L, const char*channel, Proc **list) &#123; Proc *p = getself(L); if (*list == NULL) &#123; *list = p; p-&gt;previous = p-&gt;next = p; &#125; else &#123; p-&gt;previous = (*list)-&gt;previous; p-&gt;next = *list; p-&gt;previous-&gt;next = p-&gt;next-&gt;previous = p &#125; p-&gt;channel = channel; do &#123; pthread_cond_wait(&amp;p-&gt;cond, &amp;kernel_access); &#125; while (p-&gt;channel); &#125;``` 在这样的情况下，进程会把其自身放在等待链表的尾部，并等待条件变量的唤醒。当一个进程唤醒其他进程时，会被其唤醒进程的字段*channel*设置为NULL。所以，如果`p-&gt;channel`不是NULL，说明没有唤醒过，会一直保持等待。接下来我们编写的是发送和接收函数：```cstatic int ll_send (lua_State *L) &#123; Proc *p; const char *channel = luaL_checkstring(L, 1); pthread_mutex_lock(&amp;kernel_access); p = searchmatch(channel, &amp;waitreceive); if (p) &#123; movevalues(L, p-&gt;L); p-&gt;channel = NULL; pthread_cond_signal(&amp;p-cond); &#125; else &#123; waitonlist(L, channel, &amp;waisend): pthread_mutex_unlock(&amp;kernel_access); return 0;&#125;static int ll_receive (lua_State *L) &#123; Proc *p; const char *channel = luaL_checkstring(L, 1); lua_settop(L, 1); pthread_mutex_lock(&amp;kernel_access); p = searchmath(channel, &amp;waisend); if (p) &#123; movevalues(p-&gt;L, L); p-&gt;channel = NULL; pthread_cond_signal(&amp;p-&gt;cond): &#125; else &#123; waitonlist(L, channel, &amp;waitreceive); pthread_mutex_unlock(&amp;kernel_access); return lua_gettop(L) - 1;&#125;``` 接下来我们看看如何建立一个新进程呢。一个新进程需要一个新的POSIX线程，并且需要一个线程运行入口（函数）。下面是一个原型： static void *ll_thread (void *arg); 为了建立后运行一个进程，系统必须建立一个新的Lua State，开始一个新线程，编译给定的chunk，调用chunk，然后释放资源。原始的线程做了开始的三个任务，新线程做剩下的。（为了简化错误处理，系统只是在成功编译给定的chunk后启动一个新的线程）。```c// 建立一个新进程static int ll_start (lua_State *L) &#123; pthread_t thread; const char *chunk = luaL_checkstring(L, 1); lua_State *L1 = luaL_newstate(); if (L1 == NULL) luaL_error(L, &quot;unable to create new thread&quot;); if (luaL_loadstring(L1, chunk) != 0) luaL_error(L, &quot;error in thread body:%s&quot;, lua_tostring(L1, -1)); if (pthread_create(&amp;thread, NULL, ll_thread, L1) !== 0) luaL_error(L, &quot;unable to create new thread&quot;) pthread_detach(thread); return 0;&#125; 这个函数先建立新的Lua State L1，然后在其内编译给定的chunk。出错的话，就会在原来的 state L内进行处理。接着，建立一个新线程，执行ll_thread，并以新的State L1 作为参数。pthread_detach告诉系统此进程不需要任何结束恢复。 每个线程的主体在函数 ll_thread中。 int luaopen_lproc(lua_State *L);static void *ll_thread (void *arg) &#123; lua_State *L = (lua_State) *arg; Proc *self; openlibs(L); luaL_requiref(L, \"lproc\", luaopen_lproc, 1); lua_pop(L, 1); self = (Proc *)lua_newuserdata(L, sizeof(Proc)); lua_setfield(L, LUA_REGISTRYINDEX, \"_SELF\"); self-&gt;L = L; self-&gt;thread = pthread_self(); self-&gt;channel = NULL; pthread_cond_init(&amp;self-&gt;cond, NULL); if (lua_pcall(L, 0, 0, 0) != 0) fprintf(stderr, \"thread error: %s\", lua_tostring(L, -1)); pthread_cond_destory(&amp;getself(L)-&gt;cond); lua_close(L): return NULL;&#125; 首先，打开标准Lua库和lproc库。 然后，建立和初始化其自身的控制块。接着，调用主要的chunk。最后，销毁条件变量和Lua State。 注意这里使用luaL_requiref来打开lproc库。这函数和 require类似，不过其使用给定的函数（luaopen_lproc，我们例子中）来打开库，而不是寻找一个加载器。在调用这个函数后，luaL_requiref会将结果注册到pacage.loaded表中，后面调用这个库函数就不用再次加载了。如果函数的最后一个参数是 true，其也会在对应的全局变量内注册这个库。 下面是最后几个函数： static int ll_exit (lua_State *L) &#123; pthread_exit(NULL): return 0;&#125;static const struct luaL_reg ll_funcs[] = &#123; &#123;\"start\", ll_start&#125;, &#123;\"send\", ll_send&#125;, &#123;\"receive\", ll_receive&#125;, &#123;\"exit\", ll_exit&#125;, &#123;NULL, NULL&#125; &#125;; int luaopen_lproc (lua_State *L) &#123; luaL_newlib(L, ll_func); return 1;&#125; 都很简单。 ll_exit应该只能被主进程结束时调用，以避免程序的立刻结束。luaopen_lproc是打开这个库的标准函数。 和早先说的一样，在Lua内进程的实现是很简单的。我们可以无止境的进行提升。这里就简单的说一下。 一个很明显的提高就是改变对于匹配通道 线性搜索。更好的办法是使用hash表，并对每个通道使用独立的等待链表。 另外一个关于效率的就在进程的创建。建立Lua State是很轻量的，但是，打开标准库就不那么轻量了，而且很多State并不一定需要全部的标准库。我们可以通过使用 预注册的库来避免这个开销。就和我们在require 函数一节说的一样。通过这种方式，不再需要为每个标准库调用luaL_requiref函数，我们只是将库打开函数放在 package.preload表中。如果进程调用 require &quot;lib&quot;，然后（也只有 require会）调用这个关联的函数来打开这个库。下面来看看： static void registerlib (lua_State *L, const char *name, lua_CFunction f) &#123; lua_getglobal(L, \"package\"); lua_getfield(L, -1, \"preload\"); pua_pushcfunction(L, f); lua_setfield(L, -2, name); lua_pop(L, 2);&#125;static void openlibs (lua_State *L) &#123; luaL_requiref(L, \"_G\", luaopen_base, 1); luaL_requiref(L, \"package\", luaoepn_package, 1); lua_pop(L, 2); /* remove results from previous calls */ registerlib(L, \"coroutine\", luaopen_coroutine); registerlib(L, \"table\", luaopen_table); registerlib(L, \"io\", luaopen_io); registerlib(L, \"os\", luaopen_os); registerlib(L, \"string\", luaopen_string); registerlib(L, \"math\", luaopen_math); registerlib(L, \"utf8\", luaopen_utf8); registerlib(L, \"debug\", luaopen_debug);”&#125; 打开基本库总是没有错的。我们也会需要 包 这个库；否则，我们就没有require函数来打开其他库。其他库都是可选的。我们可以调用我们自己的openlibs，而不用调用luaL_openlibs。当一个进程需要其中一个库时，就可以显示指定库名，require会调用对应的luaopen_*函数。","categories":[{"name":"Lua","slug":"Lua","permalink":"https://gowa2017.github.io/categories/Lua/"}],"tags":[{"name":"Lua","slug":"Lua","permalink":"https://gowa2017.github.io/tags/Lua/"}],"keywords":[{"name":"Lua","slug":"Lua","permalink":"https://gowa2017.github.io/categories/Lua/"}]},{"title":"Program-Library-HOWTO","slug":"Program-Library-HOWTO","date":"2018-02-05T08:57:32.000Z","updated":"2018-02-05T08:57:32.000Z","comments":true,"path":"Linux/Program-Library-HOWTO.html","link":"","permalink":"https://gowa2017.github.io/Linux/Program-Library-HOWTO.html","excerpt":"这个文档讨论了怎么样在Linux上建立和使用程序库。包括了静态库，共享库，动态载入库。 介绍这个 HOWTO讨论的是使用GNU的工具集来建立和使用程序库。一个 程序库 就是一个简单的包含了编译代码（和数据）的文件，在后面将会用来和一个程序共同工作；程序库允许程序更加模块化，重新编译更快，更容易更新。程序库可以被分为三类：静态库， 共享库， 动态载入库（DL）。","text":"这个文档讨论了怎么样在Linux上建立和使用程序库。包括了静态库，共享库，动态载入库。 介绍这个 HOWTO讨论的是使用GNU的工具集来建立和使用程序库。一个 程序库 就是一个简单的包含了编译代码（和数据）的文件，在后面将会用来和一个程序共同工作；程序库允许程序更加模块化，重新编译更快，更容易更新。程序库可以被分为三类：静态库， 共享库， 动态载入库（DL）。 首先讨论静态库，它会在一个程序运行前安装到一个可执行文件中。然后再讨论共享库，它会在程序启动时载入，然后在程序间共享。最好，讨论动态载入库，这可以在程序运行的任何时间载入。DL库并不真正是一个不同的库模式（静态和共享库都可以用作DL库）；只是因为其被程序员使用的方式不同而已。 大多数开发库的程序员都应该建立共享库，因为这允许用户单独的更新库而不影响应用程序。DL库是实用的，但是这需要更多的工作，很多程序并不需要这个特性。 相对的，静态库让升级库变得非常麻烦，所以一般不建议使用它。但是，每个库都有他们的优点，接下来我们会讨论到。使用 C++和DL库的开发者应该看一下C++ dlopen mini-HOWTO。 值得注意时，有些人使用术语动态链接库（DLLs）来指代共享库，某些使用 DLL来表示所有用做DL的库，某些使用DLL来表示所有这些意思。不管你用什么术语，这个HOWTO都覆盖了Linux的DLLs。 这个文档，只讨论 可执行和链接格式（ELF）的可执行文件和库，基本上所有的Linux发行版都使用这个格式。GNU 的 gcc工具集可以处理不是ELF格式的库；实际上，很多Linux发行板还在使用废弃的 a.out格式。然后，我们文档不讨论这个格式。 如果你要构建一个想要在很多系统上使用的应用，你应该考虑一下使用 GNU libtool来构建和安装库，而不是使用 直接使用Linux的工具。 GNU libtool是一个常规的库支持脚本，隐藏了使用共享库的复杂性（比如，建立和安装）。在Linux上，GNU libtools在这些工具之上构建，在本文档也有描述。为动态载入库提供一个可移植的接口，可以使用很多可移植的封装方法。GNU libtools包含了一个这样的封装器，叫做libltdl。可选地，你也可以使用 glib 库（不要和glibc混淆）对 模块动态载入的支持。可以在这里了解更多 glib的知识glib。 静态库静态库只是普通对象文件的简单集合；一般来说，静态库以.a结尾，使用ar(archiver)程序来建立。静态库并不经常使用，因为共享库的比它更有优势。但是呢，某些时候还是需要使用，首先是因为历史因素，再者，解释起来简单。 静态库允许用户不需要重新编译代码就能链接到程序中，这样就减少了重新编译的时间。不过在今天编译器已经非常快速的情况下，其实编译时间并不重要，所以这个原因并不像以前那么有用。静态库对于开发者只允许程序员链接至他们的库，但并不想提供源代码的时候非常有用。理论上，静态 ELF 库链接至可执行文件后，运行速度会比共享库或动态载入库轻微加快（1-5%），但实际上这并不是使用它的原因。 为了建立一个静态库，或者把当前目标文件加入到已有的静态库，使用下面的命令： ar rcs my_library.a file1.o file2.o 建立了库后可能就想使用它。在建立可执行文件时，可以把它编译或链接过程的一部分。如果是使用gcc来产生可执行文件，可以使用-l选项来指定这个库。 要小心使用gcc时的参数顺序；-l是一个链接器选项，因此需要放在被编译文件的后面。这和通常的选项语法有所不同。如果你把-l选项放在被编译文件的前面，这会失败，并发生错误。 也可以使用链接器ld，加上-l, -L选项；然而，多数时候使用gcc会更好，因为ld的接口可能会改变。 共享库共享库是在程序在启动时加载的库。一个共享库正确的安装好，后续启动的程序都可使用这个库。但实际上比描述的更加复杂和灵活，因为Linux使用的方式允许我们： 更新库，并允许程序员使用老版本的库，不用保持库的后向兼容。 重写指定库或库中指定函数。 在程序运行时就跟所有这些事情。 约定为了让共享库支持所有希望的属性，很多约定和指导必须遵守。必须要明白库 名字间的不同，实际上就是soname和real name（已经他们怎么交互）。也要明白他们放在文件系统中的位置。 共享库名字每个共享库有一个特殊的soname。soname有前缀lib，后跟.so，后跟一个 .和一个版本号（在接口改变的时候，版本号会增加）（一个特殊的例外，最底层的C库并不以 lib 开头）。一个完全引用的 soname包括了其所在的目录；在一个正常工作的系统中，一个全引用的 soname只是简单的对 库real name的符号链接。 每个共享库有一个real name，就是包含库代码的文件名字。真实名字在 soname后加上.，次版本号，另外一个.，发布号。后面的.和发布号是可选的。 一个次版本号和发布号通过让你知道你安装库的确切版本来支持配置控制。要注意，这些数字可能和库文档中所有的不一致，尽管这会让事情变得更简单。 另外，这里还有一个编译器在需要一个库时使用的名字，我们把它叫做链接名(linker name)，这个名字就是soname 去掉版本号。 管理共享库的关键就是分开它们的名字。程序员，当列出他们需要的库时，应该只是列出他们需要的soname。相反，当你建立一个共享库时，你只需要以一个特别的名字建立这个库（和更多详细的版本信息）。当安装一个库的新版本时，把它放在几个特殊的目录内，然后执行程序 ldconfig(8)。ldconfig会测试已存文件，然后建立 soname符号链接至真实名字，同时设置缓存文件/etc/ld.so.cache。 ldconfig不会设置linker name；典型的是在库安装时进行设置，linker name只是简单的连接至最新版本的soname或者real name。建议把linker name链接至soname，因为大多数情况下在更新库的时候，我们都想要在链接时自动使用它。我询问过 H. J. Lu为什么 ldconfig 不会自动设置 linker name。他的解释基于用户可能希望用最新版本的库来运行代码，但可能需要 开发时链接至一个老的不兼容库。因此，ldconfig不会对 程序员怎么链接做任何建设，所以安装者必须手动的来指定链接至哪一个版本的库。 文件系统位置共享库必须放在文件系统的某些地方。多数开源软件遵守GNU标准。GNU标准建议将所有的库默认安装在/usr/local/lib中（所有的命令建议放在/usr/local/bin中）。他们也定义了覆盖这些默认设置的约定和安装的过程。 文件分层标准（FHS）在一个发行中应该放在哪里。根据FHS，大多数库应该安装在/usr/lib，但是如果是启动系统所需要的应该安装在/lib，不是系统部分的库应该在/usr/local/lib。 在这两个文档中并没有真正的冲突：GNU标准建议的是源代码的开发者默认设置，FHS建议的是发行者的默认设置（会选择性的覆盖源代码默认设置，通常是通过系统的包管理系统）。实践中工作得很好：最新版本的代码会自动安装在/usr/local，一旦代码成熟了，包管理器就可以修改默认设置把它安装到发行版的标准位置去。 注意，如果你的库调用了只能被库调用的程序，你应该把这些程序放在/usr/local/libexec（某些发行版中是/usr/libexec）。某个Red Hat系统在默认的库搜索路径中不包含/usr/local/lib；看一下下面的 /etc/ld.so.conf的讨论。其他标准的库位置为X-windows包含/usr/X11R6/lib。还要注意/lib/security是 PAM模块使用的，但这些库经常是作为 DL库使用。 怎么样使用共享库在以 GNU glibc为基础的系统上，包括所有的Linux系统，启动一个ELF的二进制可执行文件会让程序的加载器自动运行。在Linux系统上，这个加载器叫做 /lib/ld-linux.so.X（X是一个版本号）。这个加载器会按序加载所有其他被程序使用的共享库。 会被搜索的目录写在/etc/ld.so.conf中。很多 Red Hat为基础的发行版在这个文件中不包含/usr/local/lib。我觉得这是一个Bug，所以把/usr/local/lib添加到文件/etc/ld.so.conf文件中是在很多这样的系统上运行很多程序的一个Bug修复。 如果只是想重写某个库中的几个函数，可以在/etc/ld.so.preload文件中写入想要重写的库名（.o文件）；这些preloading的库会在标准设置前生效。这些预加载的文件典型的是用来紧急修复；一个发布版本通常是不包含一个这样的文件的。 在程序启动的时候搜索所有的这些目录是非常低效的，所以，使用了一个缓存安排。ldconfig(8)程序默认读取/etc/ld.so.conf文件，在动态链接目录内设置合适的符号链接（所以这会遵从标准的约定），然后写入缓存文件/etc/ld.so.cache，之后就可以被其他程序使用。这大大提高了访问库的速度。限制就是在一个DLL被增加，移除或DLL目录改变的时候就要运行ldconfig；运行ldconfig经常是包管理器安装一个库后的必要步骤。然后，在启动时，动态加载器就会使用/etc/ld.so.cache来载入其需要的库。 FreeBSD使用一个稍微不同的缓存文件名。在FreeBSD中，ELF的缓存是在/var/run/ld-elf.so.hints，a.out的缓存是在/var/run/ld.so.hints。这些文件也会被ldconfig更新，所以这不是很重要。 环境变量很多环境变量可以控制这个过程，也有很多环境变量允许你重写这些过程。 LD_LIBRARY_PATH可以为当前实际的执行临时替换一个不同的库。在Linux中，环境变量LD_LIBRARY_PATH是一个:分隔的目录集合，会首先在这些目录中搜索库，然后再搜索标准位置；这在调试一个新库或者使用一个特定目标使用非标准库时非常有用。环境变量LD_PRELOAD列出来重写标准设置的函数的共享库，就和/etc/ld.so.preload做的一样。这被加载器/lib/ld-linux.so所实现。要注意到，LD_LIBRARY_PATH在多数Unix-like的系统上运行，但是并不是所有；比如，在HP-UX上这个以环境变量SHLIB_PATH运行，在AIX上，以环境变量LIBPATH运行。（语法相同，冒号分隔的目录列表） LD_LIBRARY_PATH对于开发和测试是非常方便的，但不应该被普通用户一般性的使用时被安装过程所修改；查看Why LD_LIBRARY_PATH is Bad。但是这对开发和调试是非常有用的。如果不想设置 这个环境变量，在Linux上可以直接向加载器传递一个参数。比如，接下来的代码使用给定的PATH而不是环境变量的内容，然后运行给定的可执行文件。 /lib/ld-linux.so.2 --library-path PATH EXECUTABLE 不带参数运行ld-linux.so会给我们很多使用它的信息，但是不要在常规时这样使用——只是为了调试而使用。 LD_DEBUGGNU C载入器中另外一个使用的环境变量是LD_DEBUG。这将触发dl*函数族给出更多详细信息来表明他们在干什么。比如： export LD_DEBUG=filescommand_to_run 将会显示在处理过程中的文件和库，告诉你检测到的依赖关系和什么顺序载入了多个so。把LD_DEBUG设置为bindings显示富号绑定的信息，设置为libs显示库搜索路径，设置为versions显示版本依赖关系。 设置LD_DEBUG为help，然后运行一个程序的话会列出可能的选项。再次重复，LD_DEBUG不是为了常规使用，只是为了调试或者测试。 其他环境变量还有很多其他控制加载过程的环境变量；他们的名字以LD或者RTLD开头。大多数其他变量是为了加载过程的底层调试或实现特殊的能力。大多变量都没有很好的文档；如果想要知道他们，最好的方法就是阅读 加载器的源码。（gcc的一部分） 允许用户控制动态链接库，对于采取了特殊方法的 setuid/setgid程序来说是灾难性的。因此，在GNU加载器中，如果程序是setuid/setgid的，这些变量会被忽略或不严重的限制了功能。加载器通过检查程序的身份信息来确定其是不是 setuid/setgid程序；如果 uid和 euid不同，或 gid与egid不同，加载器就认为这个程序是 setuid/setgid的，因此就会强烈的限制控制链接的能力。如果你阅读 GNU glibc 库的源码，你会看到这些；首先看一下 elf/rtld.c, sysdeps/generic/dl-sysdep.c。这就意味着，如果你让 uid/gid 与 euid/egid 相等，然后调用一个程序，这些变量就有完整的影响。其他 Unix-like的系统处理这样的情况有所不同，但是因为同样的原因：一个 setuid/setgid 程序不应该被环境变量过度影响。 建立一个共享库建立共享库很简单。首先，使用 gcc -fPIC 或 gcc -fpic来建立将要在库内使用目标文件。-fPIC, -fpic选项启动了位置无关代码的产生，共享库需要这样做。通过 -Wl gcc 选项来传递 soname。 gcc -shared -Wl, -soname, you_soname \\ -o library_name file_list library_list -Wl 选项传递属于 链接器的选项（这个情况下是 -soname 链接器选项），在-wl后的冒号不是一个错误。 下面是一个例子，建立两个目标文件a.o, h.o，然后建立一个包含这两个文件的共享库。注意这个编译包含了调试信息-g，还会产生警告信息-Wall，对于共享库来说不是必须的，但是建议这样做。编译通过 -c来产生目标文件，同时包含需要的-fPIC选项： gcc -fPIC -g -c -Wall a.cgcc -fPIC -g -c -Wall b.cgcc -shared -Wl,-soname,libmystuff.so.1 \\ -o libmystuff.so.1.0.1 a.o b.o -lc 有几点值得注意的地方： 不要strip得到的库，不是必要的话，不要加上编译选项-fomit-frame-pointer。生成的库会工作，但是这些动作会让调试者很难使用。 使用-fPIC, -fpic来产生代码。是否使用这两个标志根据目标来定。-fPIC总是会工作，但是会比-fpic产生更多的代码（-fPIC是大写的，就会产生更多的代码，这样来记忆）。-fpic会产生更少更快的代码，但是会产生平台相关的限制，比如全局可见符号数或代码的大小。链接器会在你建立一个共享库的时候告诉你是否合适。如果有疑问，使用-fPIC，总是没有错的。 某些情况下，调用 gcc来产生目标文件也需要包含选项-Wl, -export-dynamic。通常情况下， 动态符号表只包含被动态目标使用的符号。这个选项（在建立一个ELF文件时）把所有的符号都添加到动态符号表中（查看 ld(1)获取更多信息）。当有反向依赖的时候需要使用这个选项，比如，某程序要调用含有未解析的符号的DL库，而这些符号又必须在程序内定义时。为了让反向依赖工作，程序必须让它的符号动态可见。如果只是在Linux系统工作，可以用-rdynamic来替代-Wl, -export-dynamic，但是在ELF文档中说明，-rdynamic标志在非Linux系统上的gcc中并不总是能工作。 在开发着，修改一个被其他程序使用的库有潜在的问题————而且你也不需要其他程序使用开发版的库，只有特定的程序你想要进行测试。一个可能会用的链接选项就是 ld 的rpath，这选项指定了特定程序编译时的运行时库搜索路径。在GCC中，可以用下面的形式指定 rpath选项： -wl,-rpath,$&#123;DEFAULT_LIB_INSTALL_PATH&#125; 如果在构建库客户程序时使用这个选项，就不用因为要保证与LD_LIBRARY_PATH不相冲突而烦恼，或者需要用一些其他技术来隐藏这个库。 安装和使用共享库在建立了一个库后，你可能会想要安装它。简单的方式就是复制到一个 标准的目录内然后运行 ldconfig(8)。 首先，需要建立这个共享库。 然后，设置一下必要的符号链接，实际上就是一个从 soname 到 real name的链接。最简单的方式就是： ldconfig -n directory_with_shared_libraries 最后，在编译程序的时候，需要告诉编译器要使用的静态或者共享库。使用-l, -L选项。 如果不能或者不想把库安装在标准位置，就需要改变方式了。把库放在某个地方，然后告诉程序足够的信息让它能够找到这个库，有好几种方式可以做到这个。较简单的情况下可以使用gcc的-L标志。如果只有特定程序使用这个库的话，可以使用莱〔rpath方式。也可以使用环境变量来控制。实际上，可以设置LD_LIBRARY_PATH。如果使用bash，可以这样： LD_LIBRARY_PATH=.:$LD_LIBRARY_PATH my_program 如果只是为了重写几个函数，可以通过建立一些重写目标文件然后设置LD_RELOAD。 实际操作使用的环境是CentOS 7，根据上文描述，查看了一下 /etc/ld.so.conf文件，确实没有包含/usr/local/lib目录，我们来加上它，后面我们自己的库就放在这个地方了。 echo &apos;/usr/local/lib&apos; &gt;&gt; /etc/ld.so.conf 代码我们有两个源文件 a.c, b.c分别只是实现了简单的两个函数： // a.c#include &lt;stdio.h&gt;inta() &#123; printf(\"hello, i'm in function a\"); return 0;&#125; // b.c#include &lt;stdio.h&gt;intb() &#123; printf(\"hello, i'm in function b\"); return 0;&#125; 共享库生成gcc -g -Wall -fPIC -c a.cgcc -g -Wall -fPIC -c b.cgcc -g -shared -Wl,-soname,libgowa.so.1 -o libgowa.so.1.0.1 a.o b.o 三个名字的链接接下来我们把生成的库libgowa.so.1.0.1复制到 /usr/local/lib下。 cp libgowa.so.1.0.1 /usr/local/lib 建立 soname到 real name的符号链接： ln -s libgowa.so.1.0.1 libgowa.so.1 建立 linker name到 soname的 链接 ln -s libgowa.so.1 libgowa.so 运行 ldconfig: ldconfig -v 看一下我们当前/usr/local/lib目录的样子： ll /usr/local/liblrwxrwxrwx 1 root root 12 2月 5 21:33 libgowa.so -&gt; libgowa.so.1lrwxrwxrwx 1 root root 16 2月 5 21:24 libgowa.so.1 -&gt; libgowa.so.1.0.1-rwxr-xr-x 1 root root 9360 2月 5 21:53 libgowa.so.1.0.1 使用我们的库编写如下代码： // c.c#include &lt;stdio.h&gt;intmain() &#123; a(); b(); printf(\"hello, i'm in function main\"); return 0;&#125; 编译： gcc -g -Wall c.c -lgowa 接下来我们执行编译出的文件a.out: $ ./a.outhello, i&apos;m in function ahello, i&apos;m in function bhello, i&apos;m in function main 看起来所有的输出都到了一行上，我觉得我们需要修改一下这个库函数才行。 修改库只是简单的在库函数的输出后面加上换行符。 // a.c#include &lt;stdio.h&gt;inta() &#123; printf(\"hello, i'm in function a\\n\"); return 0;&#125; // b.c#include &lt;stdio.h&gt;intb() &#123; printf(\"hello, i'm in function b\\n\"); return 0;&#125; 我们来生成我们的第二个版本的库： gcc -g -Wall -fPIC -c a.cgcc -g -Wall -fPIC -c b.cgcc -g -shared -Wl,-soname,libgowa.so.1 -o libgowa.so.1.0.2 a.o b.o 然后把这个新版本的库放到/usr/local/lib中，就一下我们当前的目录是什么样： cp libgowa.so.1.0.2 /usr/local/libll /usr/local/liblrwxrwxrwx 1 root root 12 2月 5 21:33 libgowa.so -&gt; libgowa.so.1lrwxrwxrwx 1 root root 16 2月 5 21:24 libgowa.so.1 -&gt; libgowa.so.1.0.1-rwxr-xr-x 1 root root 9360 2月 5 21:53 libgowa.so.1.0.1-rwxr-xr-x 1 root root 9360 2月 5 21:57 libgowa.so.1.0.2 接下来我们执行一下ldconfig: ./ldconfig -v 看一下/usr/local/lib目录变成什么样了： ll /usr/local/liblrwxrwxrwx 1 root root 12 2月 5 21:33 libgowa.so -&gt; libgowa.so.1lrwxrwxrwx 1 root root 16 2月 5 21:59 libgowa.so.1 -&gt; libgowa.so.1.0.2-rwxr-xr-x 1 root root 9360 2月 5 21:53 libgowa.so.1.0.1-rwxr-xr-x 1 root root 9360 2月 5 21:57 libgowa.so.1.0.2 ldconfig 自动的把我们的 soname libgowa.so.1 链接到了新的版本 libgowa.so.1.0.2 然后执行一下我们先前的程序 a.out ./a.outhello, i&apos;m in function ahello, i&apos;m in function bhello, i&apos;m in function main 输出果然发生了变化。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/tags/Linux/"},{"name":"动态库","slug":"动态库","permalink":"https://gowa2017.github.io/tags/动态库/"}],"keywords":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}]},{"title":"PIL.29Lua中调用C函数","slug":"PIL.29Lua中调用C函数","date":"2018-02-04T08:53:03.000Z","updated":"2018-02-04T08:53:03.000Z","comments":true,"path":"Lua/PIL.29Lua中调用C函数.html","link":"","permalink":"https://gowa2017.github.io/Lua/PIL.29Lua中调用C函数.html","excerpt":"我们在说Lua调用C函数的时候，不是说Lua可以调用所有的C函数，我们必须在传递参数和获得结果之间遵从一些协议。同时，必须要注册C函数，也就是说，要以合适的方式给Lua这个函数的地址。","text":"我们在说Lua调用C函数的时候，不是说Lua可以调用所有的C函数，我们必须在传递参数和获得结果之间遵从一些协议。同时，必须要注册C函数，也就是说，要以合适的方式给Lua这个函数的地址。 C 函数我们先来看一个简单的函数： static int l_sin(lua_State *L) &#123; double d = lua_tonumber(L, 1); lua_pushnumber(L, sin(d)); return 1;&#125; 从C的位置来看，这个函数从Lua state获取一个参数，然后把结果压入Lua state。因此，函数在压入结果前不需要清理栈。在函数返回后，Lua会自动的保存结果然后清理C函数的栈。 在我们可以在Lua中用这个函数前，我们必须先注册。我们使用lua_pushcfunction来实现：获取这个C函数的地址，在Lua中建立一个function的值来保存这个地址。一旦注册后，C函数就跟其他Lua内的函数一样了。 一个快速但是很不简洁的方法是在官方的lua解释器代码lua.c中放入 l_sin的代码，然后在调用了luaL_openlibs函数后加入下面的两行： lua_pushcfunction(L, l_sin); lua_setglobal(L, \"mysin\"); 第一行压入一个函数类型的值；第二行把这个值赋给全局变量mysin。在这些修改后，我们就可以在Lua脚本中使用mysin这个函数了，我们在后面再讨论一些链接C函数到Lua的比较好的方式。我们这里先看一下怎么写C函数。 对一个更专业sin函数，必须检查参数的类型，lua辅助库可以帮我们完全这个工作。luaL_checknumber检查是不是给了一个数值参数：一旦出错，就会给出一个错误提示信息；不然就返回这个数值。修改后代码应该如下： static int l_sin (lua_State *L) &#123; double d = luaL_checknumber(L, 1); lua_pushnumber(L, sin(d)); return 1; /* number of results */ &#125; 在上面的定义后，我们如果调用mysin(&#39;a&#39;)，就会得到如下的错误： bad argument #1 to &#39;mysin&#39; (number expected, got string) 作为一个更复杂的例子，我们来写一个返回指定目录内容的函数。Lua内在标准库内没有提供这个函数，ISO C不提供这样的操作。我们假设我们的系统兼容 POSIX。我们的函数————我们会在Lua把它叫做dir，在C中叫l_dir————获取一个字符串的路径参数，然后返回所有的目录项。具体来说，dir(&quot;/home/lua&quot;)会返回一个表{&quot;.&quot;, &quot;..&quot;, &quot;src&quot;, &quot;bin&quot;, &quot;lib&quot;}。代码如下： #include &lt;dirent.h&gt; #include &lt;errno.h&gt; #include &lt;string.h&gt; #include \"lua.h\" #include \"lauxlib.h\" static int l_dir (lua_State *L) &#123; DIR *dir; struct dirent *entry; int i; const char *path = luaL_checkstring(L, 1); /* open directory */ dir = opendir(path); if (dir == NULL) &#123; /* error opening the directory? */ lua_pushnil(L); /* return nil... */ lua_pushstring(L, strerror(errno)); /* and error message */ return 2; /* number of results */ &#125; /* create result table */ lua_newtable(L); i = 1; while ((entry = readdir(dir)) != NULL) &#123; /* for each entry */ lua_pushinteger(L, i++); /* push key */ lua_pushstring(L, entry-&gt;d_name); /* push value */ lua_settable(L, -3); /* table[i] = entry name */ &#125; closedir(dir); return 1; /* table is already on top */ &#125; 此函数通过 luaL_checkstring来检查参数是否为一个字符串。然后通过系统调用opendir来打开目录。如果无法打开目录，就会返回一个nil与错误信息。在打开目录后，会创建一个表，然后把目录项都放在里面。最后，关闭目录，返回值1，这在Lua中表示到达了栈的顶部。（lua_settable会从栈中弹出 键和值。因此，在循环后，在栈顶的元素就是返回的表） 接续函数通过lua_pcall, lua_call，一个在Lua调用的C函数，依然可以调用Lua。某些标准库函数就会这样做：table.sort可以调用一个排序函数；string.gsub可以调用一个替换函数；pcall, xpcall可以在保护模式下调用函数。如果我们记住，Lua的 main函数代码也是从C（宿主程序）调用的，我们的调用流程就跟这样的：C（宿主）调用Lua（脚本），Lua（脚本）调用C（库函数），Lua库函数调用Lua（回调）。 通常，Lua这样做是没有什么问题的；与C的集合还是Lua语言的一个特色。然后，也有某些情况下这样的交互会导致一些困难：比如协程。 Lua中的每个协程都有自己的栈，其中保留了这个协程所有挂起的调用信息。特别地，栈内保存了返回地址，参数，以及每个调用的本地变量。对于调用Lua函数，解释器只需要这个栈，我们叫做soft stack。然而，对于调用C函数，解释器必须使用C栈。毕竟，C函数中的返回地址和本地变量是存在与C栈中的。 让解释器拥有多个soft stack是非常容易的，但是ISO C运行时只有一个内部的栈。因此，Lua协程不能挂起一个C函数的执行：如果一个C函数想要在协程内恢复到其让出时间片的地方，Lua不能C函数的状态来让其恢复。试着看一下下面的代码：Lua 5.1 co = coroutine.wrap(function() print(pcall(coroutine.yield)) end)co --&gt; false atttemp to yield across metamethod/C-call boundary pcall是一个C函数；所以Lua 5.1不能挂起它，因为ISO C没有一个可以挂起C函数然后恢复运行的方式。 Lua 5.2和后续的版本通过continuations来减轻这样的困难。Lua通过 long jumps 来实现 yields（让出时间片），这和实现错误是一样的。一个 long jump只是简单的丢C栈中的C函数信息，所以这是不可能恢复运行这个函数的。然而，一个C函数foo可以指定一个连续函数foo_k，这个函数用来在恢复foo的时候进行执行。这就是说，如果解释器检查到要恢复执行foo，但是一个long jump已经丢弃了其在栈中的信息，它就会去调用foo_k。 为了让事情变得更具体一点，我们看一下pcall的实现例子。在Lua 5.1中，其代码如下： static int luaB_pcall (luaState *L) &#123; int status; luaL_checkany(L, 1); /* at least one parameter */ status = lua_pcall(L, lua_gettop(L) - 1, LUA_MULTRET, 0); lua_pushboolean(L, (status == LUA_OK)); /* status */ lua_insert(L, 1); /* status is first result */ return lua_gettop(L); /* return status + all results */ 如果通过lua_pcall调用的函数让出时间片，想要恢复luaB_pcall是不可能的。因此，无论合适，只要在一个受保护的调用中让出时间片，解释器会抛出一个错误。Lua 5.3实现pcall框架上和下面相似： static int finishpcall (lua_State *L, int status, intptr_t ctx) &#123; (void)ctx; /* unused parameter */ status = (status != LUA_OK &amp;&amp; status != LUA_YIELD); lua_pushboolean(L, (status == 0)); /* status */ lua_insert(L, 1); /* status is first result */ return lua_gettop(L); /* return status + all results */ &#125; static int luaB_pcall (lua_State *L) &#123; int status; luaL_checkany(L, 1); status = lua_pcallk(L, lua_gettop(L) - 1, LUA_MULTRET, 0, 0, finishpcall); return finishpcall(L, status, 0); &#125; 这和Lua 5.1有三个重要的不同： 用lua_pcallk替换了lua_pcall。 将所有在调用后要做的事情放在一个复制函数finishcall中。 lua_callk返回的状态可能是：LUA_YIELD, LUA_OK，或者一个错误。 如果在调用中没有让出时间片的情况，lua_pcallk与lua_pcall工作起来是一样的。然后，在有让出时间片的情况时，情况就变得非常不同。如果被lua_pcall调用的函数试出让出时间片，Lua会抛出一个错误。但是当lua_pcallk调用的函数要这样做时，这将没有错误：Lua进行一个long jump，然后丢弃所有C栈中luaB_pcall的信息，但是在协程soft stack中保留了一个到continuation function（接续函数）的引用（我们的例子中是finishpcall）。后续在解释器检查到要继续执行luaB_pcall的时候，就会去调用这个接续函数。 在发生错误的时候也可以调用finishpcall。和原始的luaB_pcall不一样，finishpcall不能获得lua_pcallk返回的值。所以，其通过一个额外的参数来获得这个值，status。当没有错误时，status是LUA_YIELD而不是LUA_OK，这样接续函数就知道它是被怎么样调用的。如果出现了错误，status就是原始的错误代码。 和调用返回的状态一起，接续函数也接收一个context，上下文.lua_pcallk的第五个参数是一个专门的整数，将会被传递为接续函数的最后一个参数。（参数的类型，intptr_t，允许指针传递）这个值允许原始的函数传输一些专门的信息到接续函数。（我们的例子没有用这个特性） Lua 5.3的接续系统是一个非常机灵的做法，但这不是万能的。某些C函数需要传递很多的上下文给他们的接续函数。比如table.sort，使用C栈来进行递归；string.gsub，必须保持一个快照和缓存来给部分结果使用。尽管可以写一个yieldable的函数来替换，但这似乎并不值得增加复杂性和性能的降低。 模块一个Lua模块就是一个定义了一些Lua函数并且存储到一个合适地方的chunk（大块代码），典型例子是表的条目。Lua的C模块模拟了这种行为。在C函数的定义中，也不许定义一个在Lua库中扮演 main chunk的函数。这个函数应该注册模块中的所有C函数和存储到一个合适的地方。和Lua main chunk相似，这函数也会初始化所有需要初始化的东西。 Lua通过这个注册过程来了解C函数。一旦一个C函数在Lua中存储并表示出来，Lua通过直接也不应该其地址来调用它，这地址是在我们注册的时候给到Lua的。换句话说，Lua不依赖一个函数名，包位置或可见性规则。典型地，一个C模块只有一个 公共（外部）函数，也就是打开这个库的函数。所有其他函数都可以是私有的，在C中用static声明。 当我们用C函数扩展LUa时，像C模块一样设计我们的代码是非常棒的，即使我们只想注册一个C函数。通常，辅助库提供了一个帮助函数来完成这个任务。宏luaL_newlib把C函数和他们期待的名字放在数组内，然后注册到一个新表中。举个例子，我们想建个库，函数就是我们先前定义的l_dir。 首先，我们必须定义库函数： static int l_dir (lua_State *L) &#123; as before &#125; 然后，我们定义一个数组：数组包含模块内的所有函数和他们期待的名字。数组类型luaL_Reg，包含两个字段的结构：函数名（字符串），函数指针。 static const struct luaL_Reg mylib [] = &#123; &#123;\"dir\", l_dir&#125;, &#123;NULL, NULL&#125; /* sentinel */&#125;; 在我们的函数中，只有一个函数l_dir需要声明。数组的最后一对始终是{NULL, NULL}，用来表示结束。 最后，我们定义一个主函数，使用luaL_newlib： int luaopen_mylib (lua_State *L) &#123; luaL_newlib(L, mylib); return 1; &#125; 调用luaL_newlib创建一个新表，然后用mylib内的键值对进行填充。当其返回时，luaL_newlib将保存库的表留在栈上。luaopen_mylib返回1来向Lua返回这个表。 在完成这个库后，我们必须把它和解释器链接。最方便的就是用动态链接特性，但这要Lua解释器的支持。 这种情况下，必须先把代码建立成一个动态库（mylib.so，Linux-like系统），然后把它放在C路径中。在这些步骤后，可以通过require来加载代码： local mylib = require \"mylib\" 这个调用让mylib动态库与Lua相链接，先找到luaopen_mylib函数，以一个C函数注册，然后调用它打开模块。（这个行为就解释了为什么luaopen_mylib必须和其他C函数一样有类似的原型） 为了找到luaopen_mylib，动态链接器必须知道其名字。总是会使用luaopen_加上模块名来进行查找。因此，如果我们的库是mylib，被调用的函数就会是luaopen_mylib。 如果解释器不支持动态链接，必须使用新库来重新编译Lua。 实际操作把上面的总结一下，得出我们的代码： // mylib.c#include &lt;dirent.h&gt;#include &lt;errno.h&gt;#include &lt;string.h&gt;#include \"lua.h\"#include \"lauxlib.h\"static int l_dir (lua_State *L) &#123; DIR *dir; struct dirent *entry; int i; const char *path = luaL_checkstring(L, 1); /* open directory */ dir = opendir(path); if (dir == NULL) &#123; /* error opening the directory? */ lua_pushnil(L); /* return nil... */ lua_pushstring(L, strerror(errno)); /* and error message */ return 2; /* number of results */&#125; /* create result table */ lua_newtable(L); i = 1; while ((entry = readdir(dir)) != NULL) &#123; /* for each entry */ lua_pushinteger(L, i++); /* push key */ lua_pushstring(L, entry-&gt;d_name); /* push value */ lua_settable(L, -3); /* table[i] = entry name */&#125; closedir(dir); return 1; /* table is already on top */&#125;static const struct luaL_Reg mylib [] = &#123; &#123;\"dir\", l_dir&#125;, &#123;NULL, NULL&#125;&#125;;int luaopen_mylib (lua_State *L) &#123; luaL_newlib(L, mylib); return 1;&#125; 把上面代码保存到一个mylib.c文件内。然后我们的运行环境是macOS，和Linux编译代码有所不同： gcc -fPIC -o mylib.o -c mylib.cgcc -O2 -bundle -undefined dynamic_lookup -o mylib.so mylib.o 我们可以写一个lua脚本t.lua： local mylib = require \"mylib\"local t = mylib.dir(\".\")for k, v in pairs(t) do print(k, v)end 然后，用lua t.lua，看一下输出： 1 .2 ..3 mylib.c4 mylib.o5 mylib.so6 t.lua","categories":[{"name":"Lua","slug":"Lua","permalink":"https://gowa2017.github.io/categories/Lua/"}],"tags":[{"name":"Lua","slug":"Lua","permalink":"https://gowa2017.github.io/tags/Lua/"}],"keywords":[{"name":"Lua","slug":"Lua","permalink":"https://gowa2017.github.io/categories/Lua/"}]},{"title":"skynet-任务调度及消息处理","slug":"skynet-任务调度及消息处理","date":"2018-02-04T04:40:19.000Z","updated":"2018-02-04T04:40:19.000Z","comments":true,"path":"Lua/skynet-任务调度及消息处理.html","link":"","permalink":"https://gowa2017.github.io/Lua/skynet-任务调度及消息处理.html","excerpt":"通过将配置文件传入skynet后，其就会根据我们的脚本逻辑业务单元来启动对应的服务，然后把收到的消息进行分发处理。一般来说，这个框架针对的是网络游戏服务器，所以肯定会面向网络套接字信息这样的，但是也有进程间消息传递的处理机制。下面我们来看一下。","text":"通过将配置文件传入skynet后，其就会根据我们的脚本逻辑业务单元来启动对应的服务，然后把收到的消息进行分发处理。一般来说，这个框架针对的是网络游戏服务器，所以肯定会面向网络套接字信息这样的，但是也有进程间消息传递的处理机制。下面我们来看一下。 从skyent main()函数看起。在文件skynet_main.c文件中，定义了一个main()函数。 intmain(int argc, char *argv[]) &#123; const char * config_file = NULL ; if (argc &gt; 1) &#123; config_file = argv[1]; &#125; else &#123; fprintf(stderr, \"Need a config file. Please read skynet wiki : https://github.com/cloudwu/skynet/wiki/Config\\n\" \"usage: skynet configfilename\\n\"); return 1; &#125; luaS_initshr(); skynet_globalinit(); skynet_env_init(); sigign(); struct skynet_config config; struct lua_State *L = luaL_newstate(); luaL_openlibs(L); // link lua lib int err = luaL_loadbufferx(L, load_config, strlen(load_config), \"=[skynet config]\", \"t\"); assert(err == LUA_OK); lua_pushstring(L, config_file); err = lua_pcall(L, 1, 1, 0); if (err) &#123; fprintf(stderr,\"%s\\n\",lua_tostring(L,-1)); lua_close(L); return 1; &#125; _init_env(L); config.thread = optint(\"thread\",8); config.module_path = optstring(\"cpath\",\"./cservice/?.so\"); config.harbor = optint(\"harbor\", 1); config.bootstrap = optstring(\"bootstrap\",\"snlua bootstrap\"); config.daemon = optstring(\"daemon\", NULL); config.logger = optstring(\"logger\", NULL); config.logservice = optstring(\"logservice\", \"logger\"); config.profile = optboolean(\"profile\", 1); lua_close(L); skynet_start(&amp;config); skynet_globalexit(); luaS_exitshr(); return 0;&#125; 这个函数做了几件事情： 初始化全局参数。skynet_globalinit() 初始化环境变量。skynet_env_init() 载入库。luaL_loadbufferx() 就是读取传入的配置文件，解析参数，然后以skynet_start(&amp;config)进行启动。 skynet_globalinit()这个函数，会初始化全局的节点信息，被设置主线程内的控制键值。 // skynet_server.cstruct skynet_node &#123; int total; int init; uint32_t monitor_exit; pthread_key_t handle_key; bool profile; // default is off&#125;;static struct skynet_node G_NODE;voidskynet_globalinit(void) &#123; G_NODE.total = 0; G_NODE.monitor_exit = 0; G_NODE.init = 1; if (pthread_key_create(&amp;G_NODE.handle_key, NULL)) &#123; fprintf(stderr, \"pthread_key_create failed\"); exit(1); &#125; // set mainthread's key skynet_initthread(THREAD_MAIN);&#125; skynet_env_init()这个文件，初始化一个全局的环境变量E。 // skynet_env.cstruct skynet_env &#123; struct spinlock lock; lua_State *L;&#125;;static struct skynet_env *E = NULL;voidskynet_env_init() &#123; E = skynet_malloc(sizeof(*E)); SPIN_INIT(E) E-&gt;L = luaL_newstate();&#125; 库的载入一些库的载入，是通过Lua脚本的形式载入的。我们看主函数中的代码： // skynet_main.c struct skynet_config config; struct lua_State *L = luaL_newstate(); luaL_openlibs(L); // link lua lib int err = luaL_loadbufferx(L, load_config, strlen(load_config), \"=[skynet config]\", \"t\"); assert(err == LUA_OK); lua_pushstring(L, config_file); err = lua_pcall(L, 1, 1, 0); if (err) &#123; fprintf(stderr,\"%s\\n\",lua_tostring(L,-1)); lua_close(L); return 1; &#125; 先是建立一个新的Lua State，然后把 下面的代码载入其内；接着，把配置文件压入栈，然后执行配置文件。 static const char * load_config = \"\\ local result = &#123;&#125;\\n\\ local function getenv(name) return assert(os.getenv(name), [[os.getenv() failed: ]] .. name) end\\n\\ local sep = package.config:sub(1,1)\\n\\ local current_path = [[.]]..sep\\n\\ local function include(filename)\\n\\ local last_path = current_path\\n\\ local path, name = filename:match([[(.*]]..sep..[[)(.*)$]])\\n\\ if path then\\n\\ if path:sub(1,1) == sep then -- root\\n\\ current_path = path\\n\\ else\\n\\ current_path = current_path .. path\\n\\ end\\n\\ else\\n\\ name = filename\\n\\ end\\n\\ local f = assert(io.open(current_path .. name))\\n\\ local code = assert(f:read [[*a]])\\n\\ code = string.gsub(code, [[%$([%w_%d]+)]], getenv)\\n\\ f:close()\\n\\ assert(load(code,[[@]]..filename,[[t]],result))()\\n\\ current_path = last_path\\n\\ end\\n\\ setmetatable(result, &#123; __index = &#123; include = include &#125; &#125;)\\n\\ local config_name = ...\\n\\ include(config_name)\\n\\ setmetatable(result, nil)\\n\\ return result\\n\\\"; __init_env()接下来的事情就比较奇妙了，在先前建立的Lua State内，已经保存了我们的配置信息，已经载入的库等。接下来就是把这个Lua State内的配置，都设置到全局变量内（事实上这些完全可以在C代码内完成的，为什么要用Lua呢）。 static void_init_env(lua_State *L) &#123; lua_pushnil(L); /* first key */ while (lua_next(L, -2) != 0) &#123; int keyt = lua_type(L, -2); if (keyt != LUA_TSTRING) &#123; fprintf(stderr, \"Invalid config table\\n\"); exit(1); &#125; const char * key = lua_tostring(L,-2); if (lua_type(L,-1) == LUA_TBOOLEAN) &#123; int b = lua_toboolean(L,-1); skynet_setenv(key,b ? \"true\" : \"false\" ); &#125; else &#123; const char * value = lua_tostring(L,-1); if (value == NULL) &#123; fprintf(stderr, \"Invalid config table key = %s\\n\", key); exit(1); &#125; skynet_setenv(key,value); &#125; lua_pop(L,1); &#125; lua_pop(L,1);&#125; skynet_start(&amp;config)在skynet_start.c中，我们可以看到代码： skynet_start(struct skynet_config * config) &#123; // register SIGHUP for log file reopen struct sigaction sa; sa.sa_handler = &amp;handle_hup; sa.sa_flags = SA_RESTART; sigfillset(&amp;sa.sa_mask); sigaction(SIGHUP, &amp;sa, NULL); if (config-&gt;daemon) &#123; if (daemon_init(config-&gt;daemon)) &#123; exit(1); &#125; &#125; skynet_harbor_init(config-&gt;harbor); skynet_handle_init(config-&gt;harbor); skynet_mq_init(); skynet_module_init(config-&gt;module_path); skynet_timer_init(); skynet_socket_init(); skynet_profile_enable(config-&gt;profile); struct skynet_context *ctx = skynet_context_new(config-&gt;logservice, config-&gt;logger); if (ctx == NULL) &#123; fprintf(stderr, \"Can't launch %s service\\n\", config-&gt;logservice); exit(1); &#125; bootstrap(ctx, config-&gt;bootstrap); start(config-&gt;thread); // harbor_exit may call socket send, so it should exit before socket_free skynet_harbor_exit(); skynet_socket_free(); if (config-&gt;daemon) &#123; daemon_exit(config-&gt;daemon); &#125;&#125; 其主要工作为： 设置SIGHUP的信号处理程序。 初始化句柄。skynet_handle_init() 初始化消息队列。skynet_mq_init() 模块加载。skynet_module_init(config-&gt;module_path) 定时器设置。skynet_timer_init() 套接字初始化。skynet_socket_ini() 开启日志服务。 启动bootstrap脚本。bootstrap(ctr, confit-&gt;bootstrap) 启动线程。start(config-&gt;thread)。 skynet_handle_init()handle是什么我一直没有搞清楚，这是干什么的我也没有弄明白。只有参考了一下作者的博客 。 把一个符合规范的 C 模块，从动态库（so 文件）中启动起来，绑定一个永不重复（即使模块退出）的数字 id 做为其 handle 。模块被称为服务（Service），服务间可以自由发送消息。每个模块可以向 Skynet 框架注册一个 callback 函数，用来接收发给它的消息。每个服务都是被一个个消息包驱动，当没有包到来的时候，它们就会处于挂起状态，对 CPU 资源零消耗。如果需要自主逻辑，则可以利用 Skynet 系统提供的 timeout 消息，定期触发。 模块的实例是服务，实例的ID是 handle，每个服务都对应一个唯一的handle_id。 // skynet_handle.cstruct handle_storage &#123; struct rwlock lock; uint32_t harbor; uint32_t handle_index; int slot_size; struct skynet_context ** slot; int name_cap; int name_count; struct handle_name *name;&#125;;static struct handle_storage *H = NULL;voidskynet_handle_init(int harbor) &#123; assert(H==NULL); struct handle_storage * s = skynet_malloc(sizeof(*H)); s-&gt;slot_size = DEFAULT_SLOT_SIZE; s-&gt;slot = skynet_malloc(s-&gt;slot_size * sizeof(struct skynet_context *)); memset(s-&gt;slot, 0, s-&gt;slot_size * sizeof(struct skynet_context *)); rwlock_init(&amp;s-&gt;lock); // reserve 0 for system s-&gt;harbor = (uint32_t) (harbor &amp; 0xff) &lt;&lt; HANDLE_REMOTE_SHIFT; s-&gt;handle_index = 1; s-&gt;name_cap = 2; s-&gt;name_count = 0; s-&gt;name = skynet_malloc(s-&gt;name_cap * sizeof(struct handle_name)); H = s; // Don't need to free H&#125; 设置一个全局控制柄变量H，默认有四个位置可以存储四个 skynet_context服务结构的指针。 skynet_module_init()这个函数定义在skynet_module.c中，其作用，就是载入配置文件中lua_cpath= ...指定的动态库路径。同时，将全局的模块变量M指像这个路径。每个模块的结构定义在skynet_module.h中： // skynet_module.hstruct skynet_module &#123; const char * name; void * module; skynet_dl_create create; skynet_dl_init init; skynet_dl_release release; skynet_dl_signal signal;&#125;; 其中，后面四个函数是由动态库提供的。 // skynet_modlue.cstruct modules &#123; int count; struct spinlock lock; const char * path; struct skynet_module m[MAX_MODULE_TYPE];&#125;;static struct modules * M = NULL;voidskynet_module_init(const char *path) &#123; struct modules *m = skynet_malloc(sizeof(*m)); m-&gt;count = 0; m-&gt;path = skynet_strdup(path); SPIN_INIT(m) M = m;&#125; skynet_mq_init()在文件skynet_mq.c中，定义了这个函数： voidskynet_mq_init() &#123; struct global_queue *q = skynet_malloc(sizeof(*q)); memset(q,0,sizeof(*q)); SPIN_INIT(q); Q=q;&#125; 这是建立了一个全局的消息队列 Q，此队列保存了每个服务的消息队列。 skynet_context 结构在skynet.c中，结构skynet_context为每个服务保存了一个内部结构： struct skynet_context &#123; void * instance; struct skynet_module * mod; void * cb_ud; skynet_cb cb; struct message_queue *queue; FILE * logfile; uint64_t cpu_cost; // in microsec uint64_t cpu_start; // in microsec char result[32]; uint32_t handle; int session_id; int ref; int message_count; bool init; bool endless; bool profile; CHECKCALLING_DECL&#125;; 结构定义了每个服务的实例地址，模块地址，消息队列，日志文件，会话ID，引用数，消息数等字段。 skynet_create_new()skynet.c中，skynet_create_new()函数如下： // skynet.cstruct skynet_context *skynet_context_new(const char * name, const char *param) &#123; // 查询模块是否加载 struct skynet_module * mod = skynet_module_query(name); if (mod == NULL) return NULL; // 用模块建立一个实例 返回的是实例地址 void *inst = skynet_module_instance_create(mod); if (inst == NULL) return NULL; // 建立一个服务结构 struct skynet_context * ctx = skynet_malloc(sizeof(*ctx)); CHECKCALLING_INIT(ctx) ctx-&gt;mod = mod; ctx-&gt;instance = inst; ctx-&gt;ref = 2; ctx-&gt;cb = NULL; ctx-&gt;cb_ud = NULL; ctx-&gt;session_id = 0; ctx-&gt;logfile = NULL; ctx-&gt;init = false; ctx-&gt;endless = false; ctx-&gt;cpu_cost = 0; ctx-&gt;cpu_start = 0; ctx-&gt;message_count = 0; ctx-&gt;profile = G_NODE.profile; // Should set to 0 first to avoid skynet_handle_retireall get an uninitialized handle ctx-&gt;handle = 0; // 注册一个handle ctx-&gt;handle = skynet_handle_register(ctx); struct message_queue * queue = ctx-&gt;queue = skynet_mq_create(ctx-&gt;handle); // init function maybe use ctx-&gt;handle, so it must init at last context_inc(); CHECKCALLING_BEGIN(ctx) // 初始化服务 int r = skynet_module_instance_init(mod, inst, ctx, param); CHECKCALLING_END(ctx) if (r == 0) &#123; struct skynet_context * ret = skynet_context_release(ctx); if (ret) &#123; ctx-&gt;init = true; &#125; skynet_globalmq_push(queue); if (ret) &#123; skynet_error(ret, \"LAUNCH %s %s\", name, param ? param : \"\"); &#125; return ret; &#125; else &#123; skynet_error(ctx, \"FAILED launch %s\", name); uint32_t handle = ctx-&gt;handle; skynet_context_release(ctx); skynet_handle_retire(handle); struct drop_t d = &#123; handle &#125;; skynet_mq_release(queue, drop_message, &amp;d); return NULL; &#125;&#125; 此函数， 首先会查看一下全局服务变量M中是否存在对应模块，然后初始化一个实例； 初始化 服务的 skynet_context 结构，包括会分配一个唯一的 handle。skynet_handle_register(ctx) 建立服务的消息队列。skynet_mq_create 初始化服务。skynet_module_instance_init(mod, inst, ctx, param); 其结果是调用模块自身的 init函数。 然后把消息队列放在全局消息队列中。 模块的初始化每个模块的实例建立了以后，就会调用模块自己的初始化函数进行初始化设置。对于我们所有的Lua服务来说，其都是 snlua模块的一个实例。对于 skyent_context_new()中调用的函数skynet_module_instance_init()，我们看一下它的代码： // skynet_module.cintskynet_module_instance_init(struct skynet_module *m, void * inst, struct skynet_context *ctx, const char * parm) &#123; return m-&gt;init(inst, ctx, parm);&#125; 这个其实就是 snlua模块中的 init函数： snlua// service_src/service_snlua.cstruct snlua &#123; lua_State * L; struct skynet_context * ctx; size_t mem; size_t mem_report; size_t mem_limit;&#125;;intsnlua_init(struct snlua *l, struct skynet_context *ctx, const char * args) &#123; int sz = strlen(args); char * tmp = skynet_malloc(sz); memcpy(tmp, args, sz); // 设置回调函数为 launch_cb skynet_callback(ctx, l , launch_cb); // 注册全局服务为 ctx-&gt;handle const char * self = skynet_command(ctx, \"REG\", NULL); uint32_t handle_id = strtoul(self+1, NULL, 16); // it must be first message skynet_send(ctx, 0, handle_id, PTYPE_TAG_DONTCOPY,0, tmp, sz); return 0;&#125;static intlaunch_cb(struct skynet_context * context, void *ud, int type, int session, uint32_t source , const void * msg, size_t sz) &#123; assert(type == 0 &amp;&amp; session == 0); struct snlua *l = ud; skynet_callback(context, NULL, NULL); int err = init_cb(l, context, msg, sz); if (err) &#123; skynet_command(context, \"EXIT\", NULL); &#125; return 0;&#125;static intinit_cb(struct snlua *l, struct skynet_context *ctx, const char * args, size_t sz) &#123; lua_State *L = l-&gt;L; l-&gt;ctx = ctx; lua_gc(L, LUA_GCSTOP, 0); lua_pushboolean(L, 1); /* signal for libraries to ignore env. vars. */ lua_setfield(L, LUA_REGISTRYINDEX, \"LUA_NOENV\"); luaL_openlibs(L); lua_pushlightuserdata(L, ctx); lua_setfield(L, LUA_REGISTRYINDEX, \"skynet_context\"); luaL_requiref(L, \"skynet.codecache\", codecache , 0); lua_pop(L,1); const char *path = optstring(ctx, \"lua_path\",\"./lualib/?.lua;./lualib/?/init.lua\"); lua_pushstring(L, path); lua_setglobal(L, \"LUA_PATH\"); const char *cpath = optstring(ctx, \"lua_cpath\",\"./luaclib/?.so\"); lua_pushstring(L, cpath); lua_setglobal(L, \"LUA_CPATH\"); const char *service = optstring(ctx, \"luaservice\", \"./service/?.lua\"); lua_pushstring(L, service); lua_setglobal(L, \"LUA_SERVICE\"); const char *preload = skynet_command(ctx, \"GETENV\", \"preload\"); lua_pushstring(L, preload); lua_setglobal(L, \"LUA_PRELOAD\"); lua_pushcfunction(L, traceback); assert(lua_gettop(L) == 1); const char * loader = optstring(ctx, \"lualoader\", \"./lualib/loader.lua\"); int r = luaL_loadfile(L,loader); if (r != LUA_OK) &#123; skynet_error(ctx, \"Can't load %s : %s\", loader, lua_tostring(L, -1)); report_launcher_error(ctx); return 1; &#125; lua_pushlstring(L, args, sz); r = lua_pcall(L,1,0,1); if (r != LUA_OK) &#123; skynet_error(ctx, \"lua loader error : %s\", lua_tostring(L, -1)); report_launcher_error(ctx); return 1; &#125; lua_settop(L,0); if (lua_getfield(L, LUA_REGISTRYINDEX, \"memlimit\") == LUA_TNUMBER) &#123; size_t limit = lua_tointeger(L, -1); l-&gt;mem_limit = limit; skynet_error(ctx, \"Set memory limit to %.2f M\", (float)limit / (1024 * 1024)); lua_pushnil(L); lua_setfield(L, LUA_REGISTRYINDEX, \"memlimit\"); &#125; lua_pop(L, 1); lua_gc(L, LUA_GCRESTART, 0); return 0;&#125; 可以看到，每个snlua结构都有自己的 Lua State，所以所有的代码都是snlua自己的内部执行的，不会影响其他的Lua State。 这个函数都干了什么： 设置对应服务 ctx 的回调函数为 launch_cb； 注册自身； 向 ctx 发送消息。 收到消息后会回调 launch_cb，而这个函数会又取消调回调函数。转而调用 init_cb函数。进行初始化 snlua中的 Lua State; 这个函数才调用loader.lua来真正的加载服务脚本等操作。 bootstrap()从 struct skynet_context *ctx = skynet_context_new(config-&gt;logservice, config-&gt;logger); if (ctx == NULL) &#123; fprintf(stderr, \"Can't launch %s service\\n\", config-&gt;logservice); exit(1); &#125; 默认情况下，会以logger, NULL为参数调用 skynet_context_new(“logger”, NULL)函数，建立一个关于 logger服务的skynet_context的结构，其实就是启动了 logger服务。 然后调用bootstrap(ctx, config-&gt;bootstrap)函数。 //skynet_start.cstatic voidbootstrap(struct skynet_context * logger, const char * cmdline) &#123; int sz = strlen(cmdline); char name[sz+1]; char args[sz+1]; sscanf(cmdline, \"%s %s\", name, args); struct skynet_context *ctx = skynet_context_new(name, args); if (ctx == NULL) &#123; skynet_error(NULL, \"Bootstrap error : %s\\n\", cmdline); skynet_context_dispatchall(logger); exit(1); &#125;&#125; 默认情况下，config-&gt;bootstrap是snlua bootstrap。事实上最终执行的函数是skynet_context_new(&quot;snlua&quot;, &quot;bootstrap&quot;)，如此又建立一个服务结构，并用bootstrap参数进行初始化。如果服务建立失败，就会将所有的信息发送到 logger，并处理全部的 logger服务的消息。 snlua作为沙盒服务，会再入lua脚本并进行执行。 start_thread(config-&gt;thread)此函数用来启动我们设置的线程数。一共启动了config-&gt;thread + 3个线程。 // skynet_start.cstruct monitor &#123; int count; struct skynet_monitor ** m; pthread_cond_t cond; pthread_mutex_t mutex; int sleep; int quit;&#125;;start(int thread) &#123; pthread_t pid[thread+3]; struct monitor *m = skynet_malloc(sizeof(*m)); memset(m, 0, sizeof(*m)); m-&gt;count = thread; m-&gt;sleep = 0; m-&gt;m = skynet_malloc(thread * sizeof(struct skynet_monitor *)); int i; for (i=0;i&lt;thread;i++) &#123; m-&gt;m[i] = skynet_monitor_new(); &#125; if (pthread_mutex_init(&amp;m-&gt;mutex, NULL)) &#123; fprintf(stderr, \"Init mutex error\"); exit(1); &#125; if (pthread_cond_init(&amp;m-&gt;cond, NULL)) &#123; fprintf(stderr, \"Init cond error\"); exit(1); &#125; create_thread(&amp;pid[0], thread_monitor, m); create_thread(&amp;pid[1], thread_timer, m); create_thread(&amp;pid[2], thread_socket, m); static int weight[] = &#123; -1, -1, -1, -1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, &#125;; struct worker_parm wp[thread]; for (i=0;i&lt;thread;i++) &#123; wp[i].m = m; wp[i].id = i; if (i &lt; sizeof(weight)/sizeof(weight[0])) &#123; wp[i].weight= weight[i]; &#125; else &#123; wp[i].weight = 0; &#125; create_thread(&amp;pid[i+3], thread_worker, &amp;wp[i]); &#125; for (i=0;i&lt;thread+3;i++) &#123; pthread_join(pid[i], NULL); &#125; free_monitor(m);&#125; 我们看到，函数先建立了一个监控器m，并初始化了线程数，睡眠数分别为(8, 0)，然后，再为每个线程建立了skynet自己的监控数据。 // skynet_monitor.cstruct skynet_monitor &#123; int version; int check_version; uint32_t source; uint32_t destination;&#125;; 接下来我们可以看到，是通过 互斥量 和条件变量来进行线程的抢占使用的。接着建立了三个线程和thread(默认是8)个工作线程： // skynet_start.cstruct worker_parm &#123; struct monitor *m; int id; int weight;&#125;; create_thread(&amp;pid[0], thread_monitor, m); create_thread(&amp;pid[1], thread_timer, m); create_thread(&amp;pid[2], thread_socket, m); static int weight[] = &#123; -1, -1, -1, -1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, &#125;; struct worker_parm wp[thread]; for (i=0;i&lt;thread;i++) &#123; wp[i].m = m; wp[i].id = i; if (i &lt; sizeof(weight)/sizeof(weight[0])) &#123; wp[i].weight= weight[i]; &#125; else &#123; wp[i].weight = 0; &#125; create_thread(&amp;pid[i+3], thread_worker, &amp;wp[i]); &#125; 建立了一个工作线程参数表struct worker_parm wp[thread];，并设置每个线程的权重，然后启动线程，线程ID保存在pid数组内。 thread_worker工作线程循环从队列内取出消息进行处理，如果没有消息，就从全局消息队列去取。 static void *thread_worker(void *p) &#123; struct worker_parm *wp = p; int id = wp-&gt;id; int weight = wp-&gt;weight; struct monitor *m = wp-&gt;m; struct skynet_monitor *sm = m-&gt;m[id]; skynet_initthread(THREAD_WORKER); struct message_queue * q = NULL; while (!m-&gt;quit) &#123; q = skynet_context_message_dispatch(sm, q, weight); if (q == NULL) &#123; if (pthread_mutex_lock(&amp;m-&gt;mutex) == 0) &#123; ++ m-&gt;sleep; // \"spurious wakeup\" is harmless, // because skynet_context_message_dispatch() can be call at any time. if (!m-&gt;quit) pthread_cond_wait(&amp;m-&gt;cond, &amp;m-&gt;mutex); -- m-&gt;sleep; if (pthread_mutex_unlock(&amp;m-&gt;mutex)) &#123; fprintf(stderr, \"unlock mutex error\"); exit(1); &#125; &#125; &#125; &#125; return NULL;&#125; skynet_initthread(THREAD_WORKER);用于在线程特定数据内保存自己的handlekey。 // skynet_server.cvoidskynet_initthread(int m) &#123; uintptr_t v = (uint32_t)(-m); pthread_setspecific(G_NODE.handle_key, (void *)v);&#125; 每个工作线程，都是调用skynet_context_message_dispatch(sm, q, wight)来从消息队列获取信息，如果获取不到，就进入睡眠状态。直到条件变量条件满足，才进行唤醒。 当线程的消息队列不存在的时候，就会从全局消息队列获取一个消息队列： // skynet_mq.cstruct message_queue &#123; struct spinlock lock; uint32_t handle; int cap; int head; int tail; int release; int in_global; int overload; int overload_threshold; struct skynet_message *queue; struct message_queue *next;&#125;;struct global_queue &#123; struct message_queue *head; struct message_queue *tail; struct spinlock lock;&#125;;struct message_queue *skynet_globalmq_pop() &#123; struct global_queue *q = Q; SPIN_LOCK(q) struct message_queue *mq = q-&gt;head; if(mq) &#123; q-&gt;head = mq-&gt;next; if(q-&gt;head == NULL) &#123; assert(mq == q-&gt;tail); q-&gt;tail = NULL; &#125; mq-&gt;next = NULL; &#125; SPIN_UNLOCK(q) return mq;&#125; // skynet_server.cstruct message_queue *skynet_context_message_dispatch(struct skynet_monitor *sm, struct message_queue *q, int weight) &#123; if (q == NULL) &#123; q = skynet_globalmq_pop(); if (q==NULL) return NULL; &#125; uint32_t handle = skynet_mq_handle(q); struct skynet_context * ctx = skynet_handle_grab(handle); if (ctx == NULL) &#123; struct drop_t d = &#123; handle &#125;; skynet_mq_release(q, drop_message, &amp;d); return skynet_globalmq_pop(); &#125; int i,n=1; struct skynet_message msg; for (i=0;i&lt;n;i++) &#123; if (skynet_mq_pop(q,&amp;msg)) &#123; skynet_context_release(ctx); return skynet_globalmq_pop(); &#125; else if (i==0 &amp;&amp; weight &gt;= 0) &#123; n = skynet_mq_length(q); n &gt;&gt;= weight; &#125; int overload = skynet_mq_overload(q); if (overload) &#123; skynet_error(ctx, \"May overload, message queue length = %d\", overload); &#125; skynet_monitor_trigger(sm, msg.source , handle); if (ctx-&gt;cb == NULL) &#123; skynet_free(msg.data); &#125; else &#123; dispatch_message(ctx, &amp;msg); &#125; skynet_monitor_trigger(sm, 0,0); &#125; assert(q == ctx-&gt;queue); struct message_queue *nq = skynet_globalmq_pop(); if (nq) &#123; // If global mq is not empty , push q back, and return next queue (nq) // Else (global mq is empty or block, don't push q back, and return q again (for next dispatch) skynet_globalmq_push(q); q = nq; &#125; skynet_context_release(ctx); return q;&#125; 处理消息最主要的就是这个函数了： 如果传入的消息队列q为空，就会重新从全局队列弹出一个。 q = skynet_globalmq_pop(); 获得弹出消息队列的 handle，根据handle来找到对应的 服务 ctx； uint32_t handle = skynet_mq_handle(q); 从队列取消息。 如果从特定的消息队列弹出消息失败，就会从全局队列返回一个新的消息队列。 int i,n=1;struct skynet_message msg;for (i=0;i&lt;n;i++) &#123; if (skynet_mq_pop(q,&amp;msg)) &#123; skynet_context_release(ctx); // 弹出消息失败，返回一个新的消息队列 return skynet_globalmq_pop(); // 根据线程权重设置来获取消息数 &#125; else if (i==0 &amp;&amp; weight &gt;= 0) &#123; n = skynet_mq_length(q); n &gt;&gt;= weight; &#125; int overload = skynet_mq_overload(q); if (overload) &#123; skynet_error(ctx, \"May overload, message queue length = %d\", overload); &#125; skynet_monitor_trigger(sm, msg.source , handle); if (ctx-&gt;cb == NULL) &#123; skynet_free(msg.data); &#125; else &#123; dispatch_message(ctx, &amp;msg); &#125; skynet_monitor_trigger(sm, 0,0);&#125; 调用dispatch_message(ctx, &amp;msg)； 此函数会调用注册的回调函数处理消息。 消息处理完毕后，检查全局消息队列是否为空，如果为空的话，就继续返回当前队列；如果全局消息队列不为空， 就返回一个新的消息队列。 也就是说，默认情况下，每个线程每次只会处理全局消息队列中，某一消息队列的一条消息。 thread_socket这个线程，会轮询所有的的套接字，具体的工作在skynet_socket_poll()内完成。 // skynet_start.cstatic void *thread_socket(void *p) &#123; struct monitor * m = p; skynet_initthread(THREAD_SOCKET); for (;;) &#123; int r = skynet_socket_poll(); if (r==0) break; if (r&lt;0) &#123; CHECK_ABORT continue; &#125; wakeup(m,0); &#125; return NULL;&#125; 此函数会获取获取消息类型和消息内容，并进行消息转发。 // skynet_socket.cintskynet_socket_poll() &#123; struct socket_server *ss = SOCKET_SERVER; assert(ss); struct socket_message result; int more = 1; int type = socket_server_poll(ss, &amp;result, &amp;more); switch (type) &#123; case SOCKET_EXIT: return 0; case SOCKET_DATA: forward_message(SKYNET_SOCKET_TYPE_DATA, false, &amp;result); break; case SOCKET_CLOSE: forward_message(SKYNET_SOCKET_TYPE_CLOSE, false, &amp;result); break; case SOCKET_OPEN: forward_message(SKYNET_SOCKET_TYPE_CONNECT, true, &amp;result); break; case SOCKET_ERR: forward_message(SKYNET_SOCKET_TYPE_ERROR, true, &amp;result); break; case SOCKET_ACCEPT: forward_message(SKYNET_SOCKET_TYPE_ACCEPT, true, &amp;result); break; case SOCKET_UDP: forward_message(SKYNET_SOCKET_TYPE_UDP, false, &amp;result); break; case SOCKET_WARNING: forward_message(SKYNET_SOCKET_TYPE_WARNING, false, &amp;result); break; default: skynet_error(NULL, \"Unknown socket message type %d.\",type); return -1; &#125; if (more) &#123; return -1; &#125; return 1;&#125; 这个函数的主要工作还是由 socket_service_poll(ss, &amp;result, &amp;more)来完成的。该函数会返回套接字消息的类型，消息本身及是否有更多消息。 // socket_server.cintsocket_server_poll(struct socket_server *ss, struct socket_message * result, int * more) &#123; for (;;) &#123; if (ss-&gt;checkctrl) &#123; if (has_cmd(ss)) &#123; int type = ctrl_cmd(ss, result); if (type != -1) &#123; clear_closed_event(ss, result, type); return type; &#125; else continue; &#125; else &#123; ss-&gt;checkctrl = 0; &#125; &#125; if (ss-&gt;event_index == ss-&gt;event_n) &#123; ss-&gt;event_n = sp_wait(ss-&gt;event_fd, ss-&gt;ev, MAX_EVENT); ss-&gt;checkctrl = 1; if (more) &#123; *more = 0; &#125; ss-&gt;event_index = 0; if (ss-&gt;event_n &lt;= 0) &#123; ss-&gt;event_n = 0; if (errno == EINTR) &#123; continue; &#125; return -1; &#125; &#125; struct event *e = &amp;ss-&gt;ev[ss-&gt;event_index++]; struct socket *s = e-&gt;s; if (s == NULL) &#123; // dispatch pipe message at beginning continue; &#125; struct socket_lock l; socket_lock_init(s, &amp;l); switch (s-&gt;type) &#123; case SOCKET_TYPE_CONNECTING: return report_connect(ss, s, &amp;l, result); case SOCKET_TYPE_LISTEN: &#123; int ok = report_accept(ss, s, result); if (ok &gt; 0) &#123; return SOCKET_ACCEPT; &#125; if (ok &lt; 0 ) &#123; return SOCKET_ERR; &#125; // when ok == 0, retry break; &#125; case SOCKET_TYPE_INVALID: fprintf(stderr, \"socket-server: invalid socket\\n\"); break; default: if (e-&gt;read) &#123; int type; if (s-&gt;protocol == PROTOCOL_TCP) &#123; type = forward_message_tcp(ss, s, &amp;l, result); &#125; else &#123; type = forward_message_udp(ss, s, &amp;l, result); if (type == SOCKET_UDP) &#123; // try read again --ss-&gt;event_index; return SOCKET_UDP; &#125; &#125; if (e-&gt;write &amp;&amp; type != SOCKET_CLOSE &amp;&amp; type != SOCKET_ERR) &#123; // Try to dispatch write message next step if write flag set. e-&gt;read = false; --ss-&gt;event_index; &#125; if (type == -1) break; return type; &#125; if (e-&gt;write) &#123; int type = send_buffer(ss, s, &amp;l, result); if (type == -1) break; return type; &#125; if (e-&gt;error) &#123; // close when error int error; socklen_t len = sizeof(error); int code = getsockopt(s-&gt;fd, SOL_SOCKET, SO_ERROR, &amp;error, &amp;len); const char * err = NULL; if (code &lt; 0) &#123; err = strerror(errno); &#125; else if (error != 0) &#123; err = strerror(error); &#125; else &#123; err = \"Unknown error\"; &#125; force_close(ss, s, &amp;l, result); result-&gt;data = (char *)err; return SOCKET_ERR; &#125; break; &#125; &#125;&#125; forward_message会被对应类型的消息，压入到对应服务结构中的消息队列去。 // skynet_socket.cstatic voidforward_message(int type, bool padding, struct socket_message * result) &#123; struct skynet_socket_message *sm; size_t sz = sizeof(*sm); if (padding) &#123; if (result-&gt;data) &#123; size_t msg_sz = strlen(result-&gt;data); if (msg_sz &gt; 128) &#123; msg_sz = 128; &#125; sz += msg_sz; &#125; else &#123; result-&gt;data = \"\"; &#125; &#125; sm = (struct skynet_socket_message *)skynet_malloc(sz); sm-&gt;type = type; sm-&gt;id = result-&gt;id; sm-&gt;ud = result-&gt;ud; if (padding) &#123; sm-&gt;buffer = NULL; memcpy(sm+1, result-&gt;data, sz - sizeof(*sm)); &#125; else &#123; sm-&gt;buffer = result-&gt;data; &#125; struct skynet_message message; message.source = 0; message.session = 0; message.data = sm; message.sz = sz | ((size_t)PTYPE_SOCKET &lt;&lt; MESSAGE_TYPE_SHIFT); if (skynet_context_push((uint32_t)result-&gt;opaque, &amp;message)) &#123; // todo: report somewhere to close socket // don't call skynet_socket_close here (It will block mainloop) skynet_free(sm-&gt;buffer); skynet_free(sm); &#125;&#125; 其是通过 skynet_context_push()函数实现的。 // skynet_server.cintskynet_context_push(uint32_t handle, struct skynet_message *message) &#123; struct skynet_context * ctx = skynet_handle_grab(handle); if (ctx == NULL) &#123; return -1; &#125; skynet_mq_push(ctx-&gt;queue, message); skynet_context_release(ctx); return 0;&#125; 通过handle来找到服务的ctx-&gt;queue，然后压进去。 从服务的注册看起。我们通过Lua编写的所有服务，都是通过 skynet.newservice函数注册的。这是一个Lua函数： -- lualib/skynet.luafunction skynet.newservice(name, ...) return skynet.call(\".launcher\", \"lua\" , \"LAUNCH\", \"snlua\", name, ...)endfunction skynet.call(addr, typename, ...) local p = proto[typename] local session = c.send(addr, p.id , nil , p.pack(...)) if session == nil then error(\"call to invalid address \" .. skynet.address(addr)) end return p.unpack(yield_call(addr, session))end 其本质，是通过 skynet.call函数向 .launcher服务，发送 lua类型的消息，加上一系列参数实现的。 而skynet.call则调用的是导出的C函数 skynet_core.send，更具体的C函数就是lsend。具体函数的导出参看另外一篇文章skynet的启动与服务载入流程 // lualib-src/lua-skynet.cstatic intlsend(lua_State *L) &#123; return send_message(L, 0, 2);&#125;static intsend_message(lua_State *L, int source, int idx_type) &#123; struct skynet_context * context = lua_touserdata(L, lua_upvalueindex(1)); uint32_t dest = (uint32_t)lua_tointeger(L, 1); const char * dest_string = NULL; if (dest == 0) &#123; if (lua_type(L,1) == LUA_TNUMBER) &#123; return luaL_error(L, \"Invalid service address 0\"); &#125; dest_string = get_dest_string(L, 1); &#125; int type = luaL_checkinteger(L, idx_type+0); int session = 0; if (lua_isnil(L,idx_type+1)) &#123; type |= PTYPE_TAG_ALLOCSESSION; &#125; else &#123; session = luaL_checkinteger(L,idx_type+1); &#125; int mtype = lua_type(L,idx_type+2); switch (mtype) &#123; case LUA_TSTRING: &#123; size_t len = 0; void * msg = (void *)lua_tolstring(L,idx_type+2,&amp;len); if (len == 0) &#123; msg = NULL; &#125; if (dest_string) &#123; session = skynet_sendname(context, source, dest_string, type, session , msg, len); &#125; else &#123; session = skynet_send(context, source, dest, type, session , msg, len); &#125; break; &#125; case LUA_TLIGHTUSERDATA: &#123; void * msg = lua_touserdata(L,idx_type+2); int size = luaL_checkinteger(L,idx_type+3); if (dest_string) &#123; session = skynet_sendname(context, source, dest_string, type | PTYPE_TAG_DONTCOPY, session, msg, size); &#125; else &#123; session = skynet_send(context, source, dest, type | PTYPE_TAG_DONTCOPY, session, msg, size); &#125; break; &#125; default: luaL_error(L, \"invalid param %s\", lua_typename(L, lua_type(L,idx_type+2))); &#125; if (session &lt; 0) &#123; // send to invalid address // todo: maybe throw an error would be better return 0; &#125; lua_pushinteger(L,session); return 1;&#125; 最终，是通过skynet_server.c中的的 skynet_context_push函数将消息推到对应的skynet_context结构中的消息队列中去，接着就返回 sessionId。 消息分发函数每个业务脚本都会注册一个消息处理函数： -- lualib/skynet.luafunction skynet.start(start_func) c.callback(skynet.dispatch_message) skynet.timeout(0, function() skynet.init_service(start_func) end)end 每次收到消息的时候就会调用这个消息处理函数。","categories":[{"name":"Lua","slug":"Lua","permalink":"https://gowa2017.github.io/categories/Lua/"}],"tags":[{"name":"Lua","slug":"Lua","permalink":"https://gowa2017.github.io/tags/Lua/"},{"name":"skynet","slug":"skynet","permalink":"https://gowa2017.github.io/tags/skynet/"}],"keywords":[{"name":"Lua","slug":"Lua","permalink":"https://gowa2017.github.io/categories/Lua/"}]},{"title":"Skynet的启动与服务载入流程","slug":"skynet的启动与服务载入流程","date":"2018-02-01T09:35:39.000Z","updated":"2018-02-01T09:35:39.000Z","comments":true,"path":"Lua/skynet的启动与服务载入流程.html","link":"","permalink":"https://gowa2017.github.io/Lua/skynet的启动与服务载入流程.html","excerpt":"一直以来很喜欢玩游戏，却一直没有自己开发过游戏，主要是不知道怎么入手。以前接触过的一款游戏就是以C++写程序，然后Lua做脚本和逻辑的。偶然间发现了skynet这个框架，作者居然是多年以前我就已经仰视已久的人物。用这个，加上客户端用cocos2dx的话，似乎确实能做出我自己想做的一些小游戏了。","text":"一直以来很喜欢玩游戏，却一直没有自己开发过游戏，主要是不知道怎么入手。以前接触过的一款游戏就是以C++写程序，然后Lua做脚本和逻辑的。偶然间发现了skynet这个框架，作者居然是多年以前我就已经仰视已久的人物。用这个，加上客户端用cocos2dx的话，似乎确实能做出我自己想做的一些小游戏了。 项目这个项目在github.com开源。是一个用于在线游戏服务器的框架，但是不仅仅用于游戏，很多其他服务端也能用到。其是基与c和lua的。其内部封装了mysql, mongodb, socket等库，用起来确实是很不错的。但是性能方面暂时不知道，但是看云风大大一直追求的性能和效率的话应该不会差。 简介Skynet 的单机模型来说，只有一个进程。然后把用 Lua 编写的每个业务逻辑单元叫做服务。所有的数据，消息的传递只在进程内部，因此的话，效率是有保证的，唯一可能出现考量的地方，就是Lua的虚拟机是否依然高效。这比传统的多进程间的通信模型就简单了许多，不需要用到什么共享内存，消息队列等了。 对于想启动一个服务，只需要调用skynet.newservice(name)，这将会返回一个服务地址，就可以了。name是脚本名。Skynet 会根据我们配置文件中的 luaservice 目录去寻找对应的 name.lua 文件。另外注意，类似 .launcher 这样的服务只是在本机可见， 在节间是不可见的。同时我们可以用skynet.name(name, addr)把一个服务地址给绑定到一个别名，以后凡是用到服务地址的地方都可以使用名字。 服务的三个阶段每个Lua都分为三个阶段： 加载阶段。加载Lua脚本到内存，分配一个实例。 初始化阶段。由skynet.start(function() ... end)注册的初始化函数进行初始化。我们的skynet.newservice(name)会在这个函数执行完毕后才返回。 工作阶段。启动过程skynet的主程序，通过类似： ./skynet config.lua 这样的命令行启动。然后主程序就会读入这个配置文件，进行启动各项服务。 我们先来看一下这个配置文件默认情况下是什么样的。 config.luaroot = \"./\"thread = 8logger = nilharbor = 1address = \"127.0.0.1:2526\"master = \"127.0.0.1:2013\"start = \"main\" -- main scriptbootstrap = \"snlua bootstrap\" -- The service for bootstrapstandalone = \"0.0.0.0:2013\"luaservice = root..\"service/?.lua;\"..root..\"test/?.lua;\"..root..\"examples/?.lua\"lualoader = \"lualib/loader.lua\"snax = root..\"examples/?.lua;\"..root..\"test/?.lua\"cpath = root..\"cservice/?.so\" 单机模型下，我们可以暂时忽略address, master, standalone三个字段。现在把重心放在启动的流程上面，暂时不要管多节点的情况。 thread：线程数，一般设置为和CPU核心数量一致 bootstrap：启动的第一个服务及参数。snlua bootstrap是默认配置，说明的是以bootstrap参数启动snlua服务（ snlua 是 lua 的沙盒服务，相当于开启一个 Lua 虚拟机了），之后的所有服务都直接或间接的由这个服务启动。默认情况下，bootstrap服务文件位于service/bootstrap.lua下。指定服务文件名不需要带上.lua扩展名。 cpath： 用 C 编写的服务模块的位置，通常指 cservice 下那些 .so 文件。如果你的系统的动态库不是以 .so 为后缀，需要做相应的修改。这个路径可以配置多项，以 ; 分割。 luaservice：lua服务文件的位置。也就是说，当我们启动一个服务的时候，去哪里寻找并载入对应的文件。 loader：用哪一段 lua 代码加载 lua 服务。通常配置为lualib/loader.lua ，再由这段代码解析服务名称，进一步加载 lua 代码。snlua 会将下面几个配置项取出，放在初始化好的 lua 虚拟机的全局变量中。具体可参考实现。SERVICE_NAME 第一个参数，通常是服务名。LUA_PATH config 文件中配置的 lua_path 。LUA_CPATH config 文件中配置的 lua_cpath 。LUA_PRELOAD config 文件中配置的 preload 。LUA_SERVICE config 文件中配置的 luaservice 。 lua_path： 将添加到 package.path 中的路径，供 require 调用。 lua_cpath： 将添加到 package.cpath 中的路径，供 require 调用 logger 第一个启动的服务是 logger ，它负责记录之后的服务中的 log 输出。logger 是一个简单的 C 服务， skynet_error 这个 C API 会把字符串发送给它。在 config 文件中，logger 配置项可以配置 log 输出的文件名，默认是 nil ，表示输出到标准输出。 snluasnlua是一个C模块的服务，在cservice/snlua.so下，所有的Lua服务其实都是snlua模块服务的实例，只是承载的Lua脚本不同而已。 bootstrapSkynet运行的第二个服务是snlua bootstrap，表示启动snlua服务，以bootstrap作为参数进行初始化，snlua是lua的沙盒服务。同样，服务名bootstrap指定后，会根据luaservice配置的路径来寻找对应的bootstrap.lua文件并加载执行。 在skynet的源码文件skynet-serc/skynet_start.c中，有bootstrap(ctx, config-&gt;bootstrap)调用。 当前bootstrap.lua文件如下： local skynet = require \"skynet\"local harbor = require \"skynet.harbor\"skynet.start(function() local standalone = skynet.getenv \"standalone\" local launcher = assert(skynet.launch(\"snlua\",\"launcher\")) skynet.name(\".launcher\", launcher) local harbor_id = tonumber(skynet.getenv \"harbor\") if harbor_id == 0 then assert(standalone == nil) standalone = true skynet.setenv(\"standalone\", \"true\") local ok, slave = pcall(skynet.newservice, \"cdummy\") if not ok then skynet.abort() end skynet.name(\".slave\", slave) else if standalone then if not pcall(skynet.newservice,\"cmaster\") then skynet.abort() end end local ok, slave = pcall(skynet.newservice, \"cslave\") if not ok then skynet.abort() end skynet.name(\".slave\", slave) end if standalone then local datacenter = skynet.newservice \"datacenterd\" skynet.name(\"DATACENTER\", datacenter) end skynet.newservice \"service_mgr\" pcall(skynet.newservice,skynet.getenv \"start\" or \"main\") skynet.exit()end) 代码中，首先就执行了: local launcher = assert(skynet.launch(\"snlua\",\"launcher\"))skynet.name(\".launcher\", launcher) 这个就是首先启动一个 C 服务模块 snlua，然后以 launcher进行初始化。 skynet.launch定义在skynet/manager.lua中： local c = require \"skynet.core\"function skynet.launch(...) local addr = c.command(\"LAUNCH\", table.concat(&#123;...&#125;,\" \")) if addr then return tonumber(\"0x\" .. string.sub(addr , 2)) endend 其用处是用来启动一个C模块的服务。 skynet.core其返回值是一个地址。这里我们看到，skynet.core是一个被导入的库，真实执行的就是这个库内导出的函数。在文件lualib-src/lua-skynet.c中，我们看到了这个函数的导出： LUAMOD_API intluaopen_skynet_core(lua_State *L) &#123; luaL_checkversion(L); luaL_Reg l[] = &#123; &#123; \"send\" , lsend &#125;, &#123; \"genid\", lgenid &#125;, &#123; \"redirect\", lredirect &#125;, &#123; \"command\" , lcommand &#125;, &#123; \"intcommand\", lintcommand &#125;, &#123; \"error\", lerror &#125;, &#123; \"tostring\", ltostring &#125;, &#123; \"harbor\", lharbor &#125;, &#123; \"pack\", luaseri_pack &#125;, &#123; \"unpack\", luaseri_unpack &#125;, &#123; \"packstring\", lpackstring &#125;, &#123; \"trash\" , ltrash &#125;, &#123; \"callback\", lcallback &#125;, &#123; \"now\", lnow &#125;, &#123; NULL, NULL &#125;, &#125;; luaL_newlibtable(L, l); lua_getfield(L, LUA_REGISTRYINDEX, \"skynet_context\"); struct skynet_context *ctx = lua_touserdata(L,-1); if (ctx == NULL) &#123; return luaL_error(L, \"Init skynet context first\"); &#125; luaL_setfuncs(L,l,1); return 1;&#125;static intlcommand(lua_State *L) &#123; struct skynet_context * context = lua_touserdata(L, lua_upvalueindex(1)); const char * cmd = luaL_checkstring(L,1); const char * result; const char * parm = NULL; if (lua_gettop(L) == 2) &#123; parm = luaL_checkstring(L,2); &#125; result = skynet_command(context, cmd, parm); if (result) &#123; lua_pushstring(L, result); return 1; &#125; return 0;&#125; 在skynet-src/skynet_server.c中，定义了skynet_command函数： static struct command_func cmd_funcs[] = &#123; &#123; \"TIMEOUT\", cmd_timeout &#125;, &#123; \"REG\", cmd_reg &#125;, &#123; \"QUERY\", cmd_query &#125;, &#123; \"NAME\", cmd_name &#125;, &#123; \"EXIT\", cmd_exit &#125;, &#123; \"KILL\", cmd_kill &#125;, &#123; \"LAUNCH\", cmd_launch &#125;, &#123; \"GETENV\", cmd_getenv &#125;, &#123; \"SETENV\", cmd_setenv &#125;, &#123; \"STARTTIME\", cmd_starttime &#125;, &#123; \"ABORT\", cmd_abort &#125;, &#123; \"MONITOR\", cmd_monitor &#125;, &#123; \"STAT\", cmd_stat &#125;, &#123; \"LOGON\", cmd_logon &#125;, &#123; \"LOGOFF\", cmd_logoff &#125;, &#123; \"SIGNAL\", cmd_signal &#125;, &#123; NULL, NULL &#125;,&#125;;const char *skynet_command(struct skynet_context * context, const char * cmd , const char * param) &#123; struct command_func * method = &amp;cmd_funcs[0]; while(method-&gt;name) &#123; if (strcmp(cmd, method-&gt;name) == 0) &#123; return method-&gt;func(context, param); &#125; ++method; &#125; return NULL;&#125;static const char *cmd_launch(struct skynet_context * context, const char * param) &#123; size_t sz = strlen(param); char tmp[sz+1]; strcpy(tmp,param); char * args = tmp; char * mod = strsep(&amp;args, \" \\t\\r\\n\"); args = strsep(&amp;args, \"\\r\\n\"); struct skynet_context * inst = skynet_context_new(mod,args); if (inst == NULL) &#123; return NULL; &#125; else &#123; id_to_hex(context-&gt;result, inst-&gt;handle); return context-&gt;result; &#125;&#125; 最终返回的是一个服务地址。skynet.name(name, add)则是将一个服务地址绑定为一个别名。 不同可以看到，只有第一个服务 launcher 是以skynet.launch启动，而其他服务都是以pcall(skynet.newservice())来启动的。如.cslave, .cmaster, DATACENTER, service_mgr。最后，bootstrap.lua服务会最后启动start=设置的值，默认情况下是main，当然我们可以设置为其他的。 我们看到，skynet.launch最终是调用的C代码进行了启动服务。而对于 skynet.newservice，其在lualib/skynet.lua中进行了定义： -- lualib/skynet.luafunction skynet.newservice(name, ...) return skynet.call(\".launcher\", \"lua\" , \"LAUNCH\", \"snlua\", name, ...)endfunction skynet.call(addr, typename, ...) local p = proto[typename] local session = c.send(addr, p.id , nil , p.pack(...)) if session == nil then error(\"call to invalid address \" .. skynet.address(addr)) end return p.unpack(yield_call(addr, session))end 是通过向 .launcher发送消息来启动服务的。也即是说，.launcher 就是服务的启动器了。 skynet.call此Lua函数原型是: function skynet.call(addr, typename, ...) ...end 其接受服务地址，消息类型作为参数，调用 打包函数 p.pack(...)打包后调用c.send(addr, p.id, nil, p.pack(...))发送到对应的地址。同样我们在 lualib/skynet.lua，预先注册了几个协议类型： -- lualib/skynet.lualocal skynet = &#123; -- read skynet.h PTYPE_TEXT = 0, PTYPE_RESPONSE = 1, PTYPE_MULTICAST = 2, PTYPE_CLIENT = 3, PTYPE_SYSTEM = 4, PTYPE_HARBOR = 5, PTYPE_SOCKET = 6, PTYPE_ERROR = 7, PTYPE_QUEUE = 8, -- used in deprecated mqueue, use skynet.queue instead PTYPE_DEBUG = 9, PTYPE_LUA = 10, PTYPE_SNAX = 11,&#125;skynet.pack = assert(c.pack)skynet.packstring = assert(c.packstring)skynet.unpack = assert(c.unpack)skynet.tostring = assert(c.tostring)skynet.trash = assert(c.trash)do local REG = skynet.register_protocol REG &#123; name = \"lua\", id = skynet.PTYPE_LUA, pack = skynet.pack, unpack = skynet.unpack, &#125; REG &#123; name = \"response\", id = skynet.PTYPE_RESPONSE, &#125; REG &#123; name = \"error\", id = skynet.PTYPE_ERROR, unpack = function(...) return ... end, dispatch = _error_dispatch, &#125;end 分别是 lua, response, error 三种协议已经是预注册的，同时其使用了对应的打包与解包函数。对于我们常用的 lua 类型的消息，去使用的是 c.pack, c.unpack 两个函数进行消息的打包与解包。 launcher.lua再来看看launcher.lua，其定义在 service目录下： -- service/launcher.luaskynet.dispatch(\"lua\", function(session, address, cmd , ...) cmd = string.upper(cmd) local f = command[cmd] if f then local ret = f(address, ...) if ret ~= NORET then skynet.ret(skynet.pack(ret)) end else skynet.ret(skynet.pack &#123;\"Unknown command\"&#125; ) endend)local function launch_service(service, ...) local param = table.concat(&#123;...&#125;, \" \") local inst = skynet.launch(service, param) local response = skynet.response() if inst then services[inst] = service .. \" \" .. param instance[inst] = response else response(false) return end return instendfunction command.LAUNCH(_, service, ...) launch_service(service, ...) return NORETend 其首先注册了一个消息分发函数，对于 LAUNCH的命令，最终还是通过 skynet.launch来启动对应的C服务。我们来完整的看一下这个过程： skynet.newservice(\"srv\") skynet.call(\".launcher\", \"lua\" , \"LAUNCH\", \"snlua\", \"srv\", ...) c.send(\".launcher\", p.id , nil , p.pack(\"LAUNCH\", \"snlua\", name, ...)) command.LAUNCH(_, \"snlua\", \"srv\", ...) launch_service(\"snlua\", \"srv\", ...) skynet.launch(\"snlua\", table.concat(&#123;\"srv\", ...&#125;, \" \"&#125;)``` 最终，还是调用了 skynet.launch 来进行启动服务。# 初始化我们可以看到，在`bootstrap.lua 和 main.lua`中，都有类似代码：```luaskynet.start(function() local sharestring = tonumber(skynet.getenv \"sharestring\" or 4096) memory.ssexpand(sharestring) ... end ) 类似的代码，其实，任何一个服务都是以skynet.start(function() ... end)这样的形式进行初始化的。 当然，其实我们在main.lua中，也可以通过 skynet.newservice(name, ...)来启动新的服务。 消息分发与回应当一个服务加载，初始化，然后就开始工作了。和大多数的服务一样，其实skynet中的服务做的事情也没有什么特别的。也就是接收消息，处理消息，给出响应这样的操作。 每个服务分三个运行阶段： 首先是服务加载阶段，当服务的源文件被加载时，就会按 lua 的运行规则被执行到。这个阶段不可以调用任何有可能阻塞住该服务的 skynet api 。因为，在这个阶段中，和服务配套的 skynet 设置并没有初始化完毕。 然后是服务初始化阶段，由 skynet.start 这个 api 注册的初始化函数执行。这个初始化函数理论上可以调用任何 skynet api 了，但启动该服务的 skynet.newservice 这个 api 会一直等待到初始化函数结束才会返回。 最后是服务工作阶段，当你在初始化阶段注册了消息处理函数的话，只要有消息输入，就会触发注册的消息处理函数。这些消息都是 skynet 内部消息，外部的网络数据，定时器也会通过内部消息的形式表达出来。 消息处理器，是通过函数skynet.dispatch来进行注册的，在多数的服务文件中都能看到类似代码： local CMD = &#123;&#125; skynet.start(function() skynet.dispatch(\"lua\", function (_, address, cmd, ...) local f = CMD[cmd] if f then skynet.ret(skynet.pack(f(address, ...))) else skynet.ret(skynet.pack(handler.command(cmd, address, ...))) end end) end) 如上所示代码中： skynet.dispatch(\"lua\", function (_, address, cmd, ...) ... end) 就是将lua类型的消息，注册给后面的匿名函数处理，每次收到lua类型的函数时，就会调用这个函数。 通常约定 lua 类消息的第一个元素是一个字符串，表示具体消息对应的操作。我们会在脚本中创建一个 CMD 表，把对应的操作函数定义在表中。每条 lua 消息抵达后，从 CMD 表中查到处理函数，并把余下的参数传入。这个消息的 session 和 source 可以不必传递给处理函数，因为除了主动向 source 发送类别为 “response” 的消息来回应它以外，还有更简单的方法。框架记忆了这两个值。 这仅仅是一个惯用法，你也可以用其它方法来处理消息。skynet 并未规定你必须怎样做。 每个服务最重要的功能就是处理收到的消息，并根据消息产生特定的动作。每个消息都由五个元素构成： session：大部分消息工作在请求回应模式下。即，一个服务向另一个服务发起一个请求，而后收到请求的服务在处理完请求消息后，回复一条消息。session 是由发起请求的服务生成的，对它自己唯一的消息标识。回应方在回应时，将 session 带回。这样发送方才能识别出哪条消息是针对哪条的回应。session 是一个非负整数，当一条消息不需要回应时，按惯例，使用 0 这个特殊的 session 号。session 由 skynet 框架生成管理，通常不需要使用者关心。 source：消息源。每个服务都由一个 32bit 整数标识。这个整数可以看成是服务在 skynet 系统中的地址。即使在服务退出后，新启动的服务通常也不会使用已用过的地址（除非发生回绕，但一般间隔时间非常长）。每条收到的消息都携带有 source ，方便在回应的时候可以指定地址。但地址的管理通常由框架完成，用户不用关心。 type：消息类别。每个服务可以接收 256 种不同类别的消息。每种类别可以有不同的消息编码格式。有十几种类别是框架保留的，通常也不建议用户定义新的消息类别。因为用户完全可以利用已有的类别，而用具体的消息内容来区分每条具体的含义。框架把这些 type 映射为字符串便于记忆。最常用的消息类别名为 “lua” 广泛用于用 lua 编写的 skynet 服务间的通讯。 messsage：消息的 C 指针，在 Lua 层看来是一个 lightuserdata 。框架会隐藏这个细节，最终用户处理的是经过解码过的 lua 对象。只有极少情况，你才需要在 lua 层直接操作这个指针。 size：消息的长度。通常和 message 一起结合起来使用。 消息发送有两个API可以进行消息的发送：skynet.call, skynet.send。 skynet.send(address, typename, ...)这条 API 可以把一条类别为 typename 的消息发送给 address 。它会先经过事先注册的 pack 函数打包 … 的内容。 skynet.send 是一条非阻塞 API ，发送完消息后，coroutine 会继续向下运行，这期间服务不会重入。 skynet.call(address, typename, ...) 这条 API 则不同，它会在内部生成一个唯一 session ，并向 address 提起请求，并阻塞等待对 session 的回应（可以不由 address 回应）。当消息回应后，还会通过之前注册的 unpack 函数解包。表面上看起来，就是发起了一次 RPC ，并阻塞等待回应。call 不支持超时。 尤其需要留意的是，skynet.call 仅仅阻塞住当前的 coroutine ，而没有阻塞整个服务。在等待回应期间，服务照样可以响应其他请求。所以，尤其要注意，在 skynet.call 之前获得的服务内的状态，到返回后，很有可能改变。","categories":[{"name":"Lua","slug":"Lua","permalink":"https://gowa2017.github.io/categories/Lua/"}],"tags":[{"name":"Lua","slug":"Lua","permalink":"https://gowa2017.github.io/tags/Lua/"},{"name":"skynet","slug":"skynet","permalink":"https://gowa2017.github.io/tags/skynet/"}],"keywords":[{"name":"Lua","slug":"Lua","permalink":"https://gowa2017.github.io/categories/Lua/"}]},{"title":"lua中的表及面向对象","slug":"lua中的表及面向对象","date":"2018-01-28T17:14:51.000Z","updated":"2018-01-28T17:14:51.000Z","comments":true,"path":"Lua/lua中的表及面向对象.html","link":"","permalink":"https://gowa2017.github.io/Lua/lua中的表及面向对象.html","excerpt":"在lua中，只有唯一的一种数据结构，表。通过表，却可以用来实现类一样的形式，其关键是对于表的元方法的使用，可以有很多奇妙的用处。","text":"在lua中，只有唯一的一种数据结构，表。通过表，却可以用来实现类一样的形式，其关键是对于表的元方法的使用，可以有很多奇妙的用处。 元表与元方法Lua中，所有的值都可以有一个有一个元表(metatable)，元表中的元素定义了对于值特定操作的方法，就叫做元方法。当然，这些元表是有默认值的，但我们可以通过改变值元表中的元方法来进行特定操作行为的改变。 可以通过setmetatable()函数来修改一个表的元表，而其他类型的值元表只能通过 C API来改变。 默认情况下，值是没有元表的，所以我们手动去设置，但 string库为字符串类型设置了一个元表。 表tablelua中没有复杂的数据结构，只有表。通过代码： t = &#123;&#125; 就建立了一个表。可以验证，其确实是没有元表的： print(getmetatable(t)) getmetatable()用来获取一个表的元表。 输出将是nil。而对于字符串： print(getmetatable(\"hello world\") 其输出会是类似table: 0x ...这样。表示其有一个元表。 元表的元素一个完整的元表，看起来应该是这样的： mt = &#123; \"__ev\" = method, ... &#125; 其中ev可以是，__add, _sub, __mul, __div, __mod, __pow, __unm, __idiv, __band, __bor, __bxor, __bnot, __shl, __shr, __concat, __len, __eq, __lt, __le, __index, __newindex。这里面的键被成为事件。 __index事件我们重点关注一下__index这个事件。 假如我们有一个表 t = {1, x = 2, y = 3,}，那么，t.x 与 t[“x”]的值应该是一样的： t = &#123;1, x = 2, y = 3,&#125;print(t.x, t[\"x\"])print(t.n) 以 键 作为索引访问表的元素时，这是正确的。但如果是整数作为索引来访问表元素的话，这就是不对的。t[1]，不会等于 t.1，而会出现一个错误。 我们特意用t.n来访问一个表中不存在的元素，很明显，其输出是nil。 我们现在来看一下，官方对于 __index事件的说明： 索引访问table[key]。这个事件会在table不是一个表，或key在表中不存在的时候发生。 元方法可以是函数和一个表。如果是函数，以table, key作为参数调用这个元方法，函数返回的结果，就是这个索引访问操作的结果；如果元方法是一个表，那么就以key来索引访问这个 作为元方法的表 中元素。（这个索引访问走的常规流程，也有可能引发另外一次元方法的调用） 我们现在给表t，设置一个元表mt，mt内定义了__index的元方法。 t = &#123;1, x = 2, y = 3,&#125;print(t.x, t[\"x\"])print(t.n)mt = &#123;&#125;mt.__index = function (table, key) print \"this key is not here\"; return 10 endsetmetatable(t, mt)print(t.n) 输出将是： this key is not here 由于访问了不存在的索引，所以触发了__index事件。 现在，我们把mt中__index的元方法设置为一个表： t = &#123;1, x = 2, y = 3, func = print&#125;print \"------------\"mt = &#123;&#125;mt.__index = function (table, key) print \"oh, I'm in table a, but not in table t\"; return 20 endsetmetatable(t, mt)print(t.n)print(t.n)print \"------------\"a = &#123; n = 10&#125;mt.__index = asetmetatable(t, mt)print(t.n)a.n = 10 -- 改变 a.n值print(t.n) 输出将是: ------------oh, I&apos;m in table a, but not in table t20oh, I&apos;m in table a, but not in table t20------------1020 当元方法是一个函数时，索引访问的结果，是元方法调用的结果，同时不存在键不会被加上；而当元方法是一个表时，会从作为元方法的那个表内取出对应的值来 加到当前表上。 到这里，想必你已经发现了什么。 函数是匿名的Lua中，所有的函数都是匿名的。 function foo(v) return vend 其实与: foo = function (v) return v end 是等价的。 调用函数的时候，括号是必须的。但在只有一个参数，且参数是字符串或表的时候可以省略。 也就是说： print(&quot;hello world&quot;) 与 print &quot;hello world&quot;等价。 表中的函数所以： t = &#123;&#125;function t.func () return \"one\"endprint(t.func())t.func = function () return \"one\" endprint(t.func()) 后面对t.func进行赋值的两种形式是等价的，但第一中形式看起来会更加易读一些。 面向对象表也是一个对象。一个对象，简单来说，会具有状态（属性），方法，可以通过方法来改变自身状态等等。 我们来假设一个钱包的情况。 wallet = &#123; remain = 0 &#125;function wallet.pay(v) wallet.remain = wallet.remain - vendprint(a.remain)wallet.pay(10)print(a.remain) 输出是什么？ 0-10 wallet.pay()调用影响了a的值，这说明Lua中，值存储于内存中，变量只是对其的一个引用。 我们再来看另外一个问题： wallet = nila.pay(10) 输出是： attempt to index a nil value (global &#39;wallet&#39;) 我们销毁了wallet变量，这个时候a也无法工作了。这是因为在pay调用中，所操作的对象是wallet。 而我们需要的，是操作a本身。 在面向对象的概念中，一个对象，调用方法，叫做向这个对象发送消息，换言之，对象就是消息的接收着。 在上面的例子者，消息的接收者是a，而操纵的对象却是wallet，这是一种非常不好的做法，我们也应在 方法的内部去 操纵全局变量。 我们需要的，其实是一种操纵消息接收者自身的机制。幸好，Lua提供了这个机制，通过:冒号来调用方法，即可在方法内部使用self这个代表自身的对象。 将上面的代码进行修改: wodediannaodeMacBook-Air:lua shouzheng.zhang$ lua 1.luawallet = &#123; remain = 0 &#125;function wallet:pay(v) self.remain = self.remain - venda = walletprint(a.remain)wallet:pay(10)print(a.remain, wallet.remain)wallet = nila:pay(10)print(a.remain) 如此，通过:调用方法（函数），就少了这么多的麻烦事情了。 继承回到前面那个问题，wallet和a引用的对象都是一样的，所以会造成相互调用间出现影响的情况。 而通过 __index事件一节我们看到，对于 一个表 t，中不存在的元素，其会通过其 元表t.mt中 __index事件的元方法来寻找。而当 元方法是个表时， 还会直接通过 元方法表 中对应的索引值 来初始化自身表内的 键-值对。 那么，我们可以通过把一个 表 ａ 作为表 ｂ 的＿＿index元方法表，这样，b就能 继承到 a 的所有元素。 a = &#123; remain = 0 &#125;function a:new(o) o = o or &#123;&#125; setmetatable(o, self) self.__index = self return oendfunction a:withdraw(v) self.remain = self.remain + vendfunction a:pay(v) self.remain = self.remain - vend 这里，我们可以把ａ 看成一个类，其方法 new() 创建表o，并把表 a 作为其 元表，同时把 元表 __index事件的值设置为 a，就可以让 o从 a 取得任何其不具有的元素。","categories":[{"name":"Lua","slug":"Lua","permalink":"https://gowa2017.github.io/categories/Lua/"}],"tags":[{"name":"Lua","slug":"Lua","permalink":"https://gowa2017.github.io/tags/Lua/"}],"keywords":[{"name":"Lua","slug":"Lua","permalink":"https://gowa2017.github.io/categories/Lua/"}]},{"title":"lua中的基本概念","slug":"lua中的基本概念","date":"2018-01-22T00:56:35.000Z","updated":"2018-01-22T00:56:35.000Z","comments":true,"path":"Lua/lua中的基本概念.html","link":"","permalink":"https://gowa2017.github.io/Lua/lua中的基本概念.html","excerpt":"lua中的基本概念包括：值和类型，环境变量及全局环境变量，错误处理，元表及元方法，垃圾回收，协程等。以前从来没有看过，现在仔细的深入了解一下。","text":"lua中的基本概念包括：值和类型，环境变量及全局环境变量，错误处理，元表及元方法，垃圾回收，协程等。以前从来没有看过，现在仔细的深入了解一下。文章来源，lua官方文档第二章 值和类型Lua是一个动态类型语言。也就是说值变量没有类型；只有值有。语言中没有类型定义。所有的值携带了自身类型。 Lua中的所有值是第一类的值。这是说所有的值都可以被存储在变量内，或者作为参数传递给函数，或者作为函数返回值。 有8种基本的类型：nil, boolean, number, string, function, thread, table, userdate。nil类型只有一个值，nil，这何其他所有的值不同；其常常表示缺少一个可用的值。boolean有两个值，false, true。nil, false都表达否定条件；其他值表示true。number表示整数和实数（浮点）。string代表不可变的字节序列。Lua是8-bit的字符：字符串可以包含任何8-bit的值，包括\\0。Lua与编码无关，其不对字符的内容做任何假设。 number有两种内部表现方式，或者说两种子类型，整数与浮点。关于在什么时候用哪一种形式，Lua有明确的规则，但是也会在需要的时候自动进行转换（3.4.3节）。因此，程序员很多时候可以选择忽略整数和实数间的不同和在两种不同表现形式上进行控制。标准的Lua使用64-bit整数和双精度（double-precision)（64-bit）浮点数，但是你可以自己编译来让Lua使用32-bit整数和单精度（single-precision 32-bit）浮点数，这对于小型设备和嵌入式系统来说是非常有用的。（在文件luaconf.h中查看LUA_32BITS宏） Lua可以调用（和操作）用Lua和C写的函数（3.4.10节）。这两种形式的函数都是function类型。 userdata专门用来在Lua变量内存储C数据。一个userdata的值表示一块物理内存。有两种userdata：full userdata（完全用户数据），Lua管理的对象的一块内存，light userdata（轻量用户数据），一个 C的指针值。userdata没有预定义的操作，除了赋值和相等测试。通过使用metatables，程序员可以对完全用户数据值定义操作。用户数据值不能在Lua内创建或者修改，只能通过C API。这样保证了被宿主程序所有用数据的完整性。 thread代表了一个独立的执行线程，且被用来实现协程（2.6节）。Lua线程和操作系统线程没关系。Lua在所有系统上都支持协程，即使是那些原生不支持线程的系统。 table实现了关联数组，也就是说，数组不止可以用数字进行索引，可以用除了nil和Nan外的所有Lua值来索引。（NaN，Not a Number，是一个特殊的值，用来代表未定义或不可表示不了的数字结果，比如0/0）表可以是异构的，就是说，其可以包含所有类型的值（不包括Nnil）。任何键为nil的值不被认为是表的一部分。换句话说，任何不存在于表内的键，其关联值为nil。 表是Lua中唯一的数据结构；可以用来表示 普通数组、表、符号表、集合、记录 、图、树等。为了表示记录，Lua使用字段名作为索引。LUa通过提供 a.name作为a[&quot;name&quot;]的语法糖来支持这种表示方式。Lua有几种便利建表的方式。 跟索引一样，表的字段可以是任何类型。实际上，因函数是第一类值，所以表字段可以包含函数。因此，表也可以拥有methods(方法)（3.4.11节） 表的索引遵循语言中的直接比较定义。如果，同时也只有i, j直接相等（这是说不是通过方法来比较）的时候，表达式a[i], a[j]表示表中的同一个元素。实际上，含有整型值的浮点数和他们的期待的整型值相等（如， 1.0 == 1）为了消除歧义，使用浮点数作为键时会将其转换为对应的整数。具体说，如果写入的是a[2.0] = true，表中插入的键是整数2。（在另外一方面，2 和”2”是不同的Lua值，因此代表了不同的表中项） 表，函数，线程，和(full)用户数据都是对象：变量并不真正包含他们的值，只是引用他们。赋值，参数传递，函数返回同样总是操作对这些值的引用；这些操作不会进行任何形式的复制。 库函数type()返回给定值的类型描述（6.1节） 环境变量，全局环境变量跟我们将在3.2, 3.3.3节讨论的那些，对一个自由名字（就是说，一个没有被任何声明所限制范围的名字）var的引用语法上被翻译为_ENV.var。此外，每个chunk都被编译到一个叫_ENV的外部本地变量范围内，所以_ENV不会是一个chunk中的自由名字。 不要管_ENV变量的存在和自由名字的翻译，_ENV是一个正常的名字。实际上，你可以用那个名字来定义新变量和参数。每个自由名字的引用程序在那个点可见的_ENV，遵循Lua常规可见性规则（3.5节） _ENV使用来作为值的那张表被称为环境。 Lua保持一个叫做global environment（全局环境）的特别环境。这个值 保存在C注册表内的一个特殊索引下（4.5节）Lua中，全局bmll_G被初始化为这个值（_G在内部从不使用）。 在Lua再入一个chunk时，其_ENV上值的默认值是全局环境（参考load）。因此，默认情况下，Lua中的自由名字指向全局环境中的一项（因此，也被叫做全局变量）。另外，所有的标准库都被载入到全局环境中，而且某些函数还好在环境上进行操作。可以使用load()（或loadfile()）来以一个不同的环境再入chunk。（在C中，必须先加载chunk然后再改变其第一个上值的值来改变环境）。 错误处理因Lua是一个嵌入扩展语言，所有的Lua动作都从宿主程序中调用一个Lua库函数的代码开始。（单独使用Lua的时候，lua就是宿主程序）当在编译或执行Luachunk出现错误的时候，控制返回到宿主，由宿主程序采用何时的方式处理（比如打印错误信息）。 Lua代码可以通过error()函数来显式产生一个错误。如果要在Lua中捕捉错误，可以用pcall(), xpcall()在protected mode（保护模式）来调用一个函数。 但有一个错误的时候，error object（错误对象，也被叫做错误信息）和包含这个错误信息被抛出。Lua只产生错误对象是一个字符串的错误，但是程序可能会产生任何类型的错误对象。这取决于Lua程序或其宿主程序怎么样来处理这些错误对象。 当使用xpcall(), lua_pcall()时，应该提供一个message handler（消息处理器）来处理错误。这两个函数以原始的错误对象进行调用，然后返回一个新的错误对象。其在栈被错误展开前调用，所以其能搜集更多关于错误的信息 ，这通过检查栈和建立一个栈回溯来实现。这个消息处理器也被保护模式保护，所以，在消息处理器内产生的错误会再次调用消息处理器。如果这个循环有点久，Lua会中断它并返回一个合适的信息。（消息处理器只会在常规运行时错误调用。在内存分配错误或运行结束时错误不会调用。 元表，元方法Lua的每个值都可以有一个metatable。metable是一个原始的Lua表，定义了原始值在特定操作下的行为。可以通过设置元表中特定的字段来改变一个值在某些操作下表现的行为。具体点，当一个非数字的值作为加的操作数时，Lua会检查这个值的metatable内的字段__add。如果找到，就调用这个函数来进行加操作。 在metatable内的每个事件的键是__加上前缀 ，对应的值被程为metamethods。在前面的例子中，键就是__add，值就是进行加操作的那个函数。 可以用getmetatable函数来查询整个metatable。Lua使用原始访问（rawget）来查询metatable中的metamethods。所以，要获得对象o中事件ev的元方法，Lua像下面这样操作： rawget(getmetatable(o) or &#123;&#125;, \"__ev\") 可以用setmetatable()函数来替换表的metatable。你不能改变Lua代码中有其他类型的metatable，它们只能通过C API来改变。 表和完整用户数据有单独的metatables（尽管多个表和用户数据可以共享他们的metatables）。每个类型的所有值共享一个metatable。默认情况下，值没有metatable，但字符库为字符类型设置了一个metatable。 local str = \"hello world\"local mt = getmetatable(str)for k, v in pairs(mt) do print(k, v)end-- 直接获取__index 字段print(rawget(getmetatable(str), \"__index\")) 其输出是: __index table: 0x7fa075d028a0table: 0x7fa32fc05170 显示了字符串的元表。 一个元表控制一个对象在数学操作，位移操作，有序比较，连接，长度操作，调用，索引上的行为。一个元表也可以定义一个用户数据或表被垃圾回收的时候执行的函数。 被元表控制的详细事件列表在下面。每个操作被对应的件所指定： __add: + 操作。如果任何加法操作的操作数不是数字（或不能由字符串转换为数字），Lua就会尝试调用这个元方法。首先，Lua会检查第一个操作数（即使其是合法的）。如果这个操作数没有为__add定义一个元方法，Lua会检查第二个操作数。如果Lua这时找到一个元方法，就会以这两个操作数为参数调用元方法，返回值是就是这个操作的结果。否则，这将会产生一个错误。 __sub: - 操作。 __mul: * 操作。 __div: / 操作。 __mod: % 操作。 __pow: ^ 操作。 __unm: 负号 。 __idiv: // 操作。 __band: &amp; 位与操作。行为和加操作类似，但当任何一个操作数不是整数或可转换为整的字符串时会调用一个元方法。 __bor: | 位或操作。 __bxor: ~ 异或操作。 __bnot: ~ 位非操作。 __shl: &lt;&lt; 左移操作。 __shr: &gt;&gt; 右移操作。 __concat: .. 操作。和加操作行为类似，但当任意一个操作数不是字符也不是数字时会调用元方法。 __len: # 长度操作。如果对象不是字符串，Lua会调用元方法。如果有元方法，Lua以这个对象为参数调用元方法，返回结果就是操作的结果。如果没有应该元方法，但是对象是一个表，Lua就使用表长度操作。否则，Lua会产生错误。 __eq: == 等于操作。 __lt: &lt; 小于操作。 __le: &lt;= 操作 _index: 索引访问table[key]。当table不是一个表或key不在当前表中时，事件会被触发。这个元方法会在table内寻找。 不要管名字，这个事件的元方法可以是函数或一个表。如果是个函数，其以table, key作为函数，返回值就是操作的返回值。如果是一个表，最终的结果是以key索引这个表的结果。（这个索引流程是常规流程，不是直接索引，因此这次索引也有可能触发另外一个元方法）。 当__index元方法是一个函数时： -- 当 __index 是一个函数时mt = &#123;&#125;mt.__index = function (table, key) print(\"in t.mt.__index\"); print(table, key); return \"mt.__index return\" endlocal t = &#123; 1, 2, 3, 4&#125;setmetatable(t, mt)print(t[8]) 我们在没有键8的时候进行索引访问，其输出如下: in t.mt.__indextable: 0x7fa797604200 8mt.__index return 在这里面，我们设置的__index事件函数的返回值是一个字符串mt.__index return，结果确实如此。 当__index是一个表的时候： a = &#123; x = 1, y = 2, z = 3&#125;b = &#123; 1, 2 ,3&#125;b.__index = bsetmetatable(a, b)print(a[1]) 其输出是: 1 说明确实是访问了其元表中__index事件中表的对应索引值。确实如上所说。 __newindex: 索引赋值table[key] = value。跟__index事件类似，这个事件在table不是一个表或key不在table中时发生。元方法在table表内寻找。 和索引访问一样，事件的元方法可以是函数和表。如果是函数，以table, key, value为参数进行调用元方法。如果是一个表，Lua以同样的键和值对此表进行赋值操作。（这个赋值是常规流程，非直接，因此可能会触发另外一个元方法）。 如果有一个__newindex元方法，Lua不会进行一个原始的赋值。（如果必要，元方法自身可以调用rawset来进行原始赋值）。 当元方法是一个函数时： mt1 = &#123;&#125;mt1.__newindex = function (table, key, value) print(table, key, value);return \"hello\" endt = &#123;&#125;setmetatable(t, mt1)t.a = \"world\"print(t.a) 输出是: table: 0x7fe611c070c0 a worldnil 如果是一个表呢： a = &#123;&#125;mt = &#123;&#125;mt.__newindex = at = &#123;&#125;setmetatable(t, mt)t.a = \"world\"print(t.a, a.a) 输出是： nil world 其结果就是，赋值赋到了__newindex元方法的表中。 __call: 调用操作func(args)。这在Lua调用一个非函数的值时发生（也就是说，func不是一个函数）。元方法在func内寻找。如果找到，func作为第一个参数调用元方法，后面是原始的参数args。调用结果就是操作的结果。（这是唯一一个允许多个结果的元方法）。 在一个表被设置为其他对象的元表前，添加好所有需要的元方法是非常好的一个实践。实际上，__gc元方法只在按这个顺序写代码的时候工作。 因为元表是常规表，其也能包含任何字段，而不只是事件名。某些标准库中的函数（如,tostring）使用元表中的其他字段来实现特定的目的。 垃圾回收Lua进行自动内存管理。这意味着你不用担心如何给新对象分配内存和在对象不在需要的时候进行释放。Lua通过运行一个垃圾回收器自动搜集所有死亡对象（说的是Lua不能继续访问的对象）来自动管理内存。Lua使用的所有内存都服从自动管理：字符串，表，用户数据，函数，线程，内部结构等。 Lua实现一个增量的标记-扫描搜集器。其通过两个数字来控制垃圾回收循环：garbage-collector pause（垃圾回收暂停）和garbage-collector step multiplier（垃圾回收步进倍率）。这两个字都使用百分比作为单位（例，100在内部表示为值1）。 垃圾回收暂停控制在开始一个新的循环前等待的时间。较大的值让搜集器变得不积极。比100小的值意味着搜集器不会等待一个新的循环。200这个值意味着搜集器会等待直到总共使用的内存达到两倍才开始一个新循环。 垃圾回收步进倍率控制了搜集器相对与内存分配的速度。较大的值会让搜集器非常的积极，但也会增加每个增量步长的大小。不应该使用小于100的值，因为这让收集器非常的慢，还有可能造成这个收集器永远不会完成一个循环。默认值是200，表示收集器的运行速度是内存分配速度的两倍。 如果把步进倍率设置一个非常大的数字（超过程序可能使用最大字节数的10%），收集器的行为就像一个 stop-the-world收集器。然后如果你设置 暂停值 为200，收集器的行为就跟老版本的Lua一样，在Lua使用内存翻倍时，就会进行一次完整的内存收集。 可以通过C中的lua_gc函数 或Lua中的collectgarbage函数来改变这些值。也可以使用这些函数来直接控制收集器（比如停止与重启）。 垃圾回收元名方法可为表设置垃圾回收元方法，而对完全用户数据需要使用C API。这些元方法也被叫做finalizers（终止器）。终止器允许将Lua的垃圾回收和外部的资源管理相结合使用（比如，关闭文件、网络或数据库连接，释放内存等） 对于将要在收集的时候进行终止的对象（表或用户数据），必须 标记其需要终止。当为对象设置一个元表，且元表中有一个字段是以__gc进行索引时，这个对象就被标记为需要终止器。注意，如果设置了一个不含有__gc的元表，而你随后创建了这个字段，这个对象是不会标记为需要终止的。 当一个标记的对象变成垃圾后，其不会立即被垃圾回收器回收。Lua会把它放在一个链表内。回收结束后，Lua会遍历这个链表。对于表中每个对象，检查对象的__gc方法：如果是一个函数，以对象作为参数调用这个函数；如果方法不是一个函数，Lua忽略它。 在每个垃圾回收循环的结束，对象的终止器会以在这个回收循环中对象被标记相反的顺序执行；这就是说，第一个调用的终止器是在程序中最后被标记的对象的__gc方法。每个终止器的秩序可能发生在正常代码执行的任何时刻。 因为回收后的对象必须仍然能被终止器使用，那些对象（和那些只能通过它访问到的对象）必须被Lua复活。通常，复活是短暂的，这个对象的内存会在下一个垃圾回收循环中释放。然而，如果终止器将对象存储在全局位置（如全局变量），这个复活就是永久的了。此外，如果终止器标记了某个对象重复被终止，终止器会这个对象不可访问的下一个循环中被调用。无论什么情况，这个对象的内存只会在此对象不可达且没有被标记为需要终止的GC 循环中释放。 当关闭一个状态(state，lua_close）时，Lua会调用所有标记为需要终止对象的终止器，与其被标记的顺序相反。如果在此过程中有终止器标记对象需要回收，这些标记是无效的。 Weak表一个weak table（弱表）指的是所有元素都是weak references（弱引用）的表。弱表会被垃圾回收器忽略。换句话说，一个对象只有一个弱引用，那么垃圾回收器就会回收那个对象。 弱表可以有弱键，弱值，或者两者都有。有弱值的表允许回收它键的值，但是不允许回收键。有弱值和弱键的表允许回收键和值。无论哪种情况，只要键或值中有一个被回收，整个键值对就从表中移除。表的弱属性由其元表中的__mode字段控制。如果__mode字段的字符串中还有字符k，表中的键就是弱的。如果包含v，那值就是弱的。 一个有弱键强值的表被叫做暂时表。在一个暂时表中，只有在键是可达的时候值才被认为是可达的。实际上，键的唯一引用是其值进行的话，这个键值对会被移除。 对表弱属性的改变只会在下一个回收循环中产生影响。实际上，如果把弱属性改为强的话，Lua会在变化生效前回收表中的某些项目。 有一个显式构建器的对象会从弱表中移除。值，比如数字和轻量C函数，是不服从垃圾回收的，因此不会从弱表中移除（除非他们相关联的值被回收）。尽管字符串服从垃圾回收，他们没有显式的构建器，因此不会从弱表种移除。 复活后的对象（就是说，终止后的对象和只能通过终止后对象访问的对象）在弱表中有一个特殊的行为。他们会在执行他们的终止器前从弱值中移除，但只会在运行完终止器后的下一个回收中从弱键移除，这个时候这些对象已经被释放了。这个行为允许终止器访问通过此对象通过弱表所关联的属性。 如果一个弱表在这个回收循环的复活对象中，在下个循环前，这个对象可能不会被正确地清理。 协程Lua支持协程，也被叫做collaborative multithreading（协作多进程）。一个协程代表了一个独立的执行线程。跟多线程系统中的线程不一样，一个协程只会在显式的执行了一个yield函数后挂起。 通过coroutine.create()来创建一个协程。其唯一的参数是这个协程的主函数。create函数仅仅只是创建一个新的协程然后返回一个句柄（一个thread类型的对象）给主函数；并不会启动协程。 通过coroutine.resume()来执行协程。第一次调用coroutine.resume()，传递coroutine.create()返回的thread作为第一个参数，这个协程通过调用其主函数进行启动。其他的传递到coroutine.resume()的参数被传递给协程主函数。一旦协程开始执行，其会执行到终止或调用yields。 一个协程可以通过两种方式来终止执行：通常，其主函数返回（显式或隐式，在最后一条指令后）；和异常返回，如果有一个不受保护的错误。在正常终止时，coroutine.resume返回true，加上被主函数返回的值。在错误返回时，coroutine.resume返回false和一个错误对象。 通过coroutine.yield()来放弃一个协程。当一个协程放弃，对应的coroutine.resume()立刻返回，即使这个放弃发生在嵌套的函数调用中（就是说，不是在主函数中，但在被主函数直接或非直接调用的函数中）。在放弃的情况下，coroutine.resume()返回true，加上传递给coroutine.yield()的值。在下次重启同样协程的时候，其从其放弃的位置开始重启，调用coroutine.yield()返回任何额外传递给coroutine.resume()的参数。 跟coroutine.create()相似，coroutime.wrap()函数也会创建一个协程，但其会返回一个函数而不是协程自身，调用这个函数的时候会重启协程。传递到这个函数的参数会作为coroutine.resume()的额外参数。coroutine.wrap()返回所有被coroutine.resume()返回的值，不包括第一个（布尔错误代码）。与coroutine.resume不一样的是，coroutine.wrap不会捕捉任何错误；任何错误都会抛给调用者。 我们看一下下面的代码来研究一个协程是怎么工作的： function foo (a) print(\"foo\",a) return coroutine.yield(2*a)endco = coroutine.create(function (a,b) print(\"co-body\", a, b) local r = foo(a+1) print(\"co-body\", r) local r, s = coroutine.yield(a+b, a-b) print(\"co-body\", r, s) return b, \"end\" end) print(\"main\", coroutine.resume(co, 1, 10)) print(\"main\", coroutine.resume(co, \"r\")) print(\"main\", coroutine.resume(co, \"x\", \"y\")) print(\"main\", coroutine.resume(co, \"x\", \"y\")) 当运行的时候，会产生下面的输出： co-body 1 10 foo 2 main true 4 co-body r main true 11 -9 co-body x y main true 10 end main false cannot resume dead coroutine 同样可以通过C API来创建和操作协程：查看函数lua_newthread(), lua_resume, lua_yield。我们来仔细的看一下这个过程。 首先建立一个协程co coroutine.resume(co, 1, 10)会以参数1, 10启动co。首先打印出co-body, 1, 10然后调用foo(1 + 1)。 在foo()中，打印出参数的值这里是2，然后放弃当前协程。放弃协程会返回coroutine.yield()返回的值，已经true。所以输出是main true 4 从调用foo(a+1)的位置重启协程，这会继续执行，被调用coroutine.yield(a+b, a-b)返回值是true 11 -9。","categories":[{"name":"Lua","slug":"Lua","permalink":"https://gowa2017.github.io/categories/Lua/"}],"tags":[{"name":"Lua","slug":"Lua","permalink":"https://gowa2017.github.io/tags/Lua/"}],"keywords":[{"name":"Lua","slug":"Lua","permalink":"https://gowa2017.github.io/categories/Lua/"}]},{"title":"lua中的C-API及代码流程","slug":"lua中的C-API及代码流程","date":"2018-01-21T09:56:30.000Z","updated":"2018-01-21T09:56:30.000Z","comments":true,"path":"Lua/lua中的C-API及代码流程.html","link":"","permalink":"https://gowa2017.github.io/Lua/lua中的C-API及代码流程.html","excerpt":"了解lua的内部实现结构有助于更清楚的各个函数是怎么要操作内容及内容的，就从最开始的lua解释器开始进行查看。","text":"了解lua的内部实现结构有助于更清楚的各个函数是怎么要操作内容及内容的，就从最开始的lua解释器开始进行查看。 介绍Lua提供了一系列API来让宿主程序和Lua进行通信。所有的API函数和相关的类型和常量都在lua.h内声明。 虽然我们使用了函数这个术语，但是API中的某些特性可能是以宏的形式提供的。 和大多数C库一样，Lua API函数不会检查他们参数的有效性和完整性。这可以通过在编译Lua的时候加上LUA_USE_APICHECK来定义。 Lua库是完全可重入的：其没有全局变量。它把所有的信息保存在一个动态数据结构中，我们称之为Lua state。 每个Lua state有一个或多个线程，每个对应每行的执行。lua_State类型（不要管名字）指向了这个线程。（可以认为这个线程也引用了与此线程相关的Lua state）。 一个指向线程的指针必须作为传递给函数的第一个参数，lua_newstate()是个例外，这个函数创建一个lua state并返回指针到主线程。 栈Lua使用一个virtual stack（虚拟栈）来与C进行值传递。栈中的每个元素代表了一个Lua值（nil, numbers, string等等）。API中的函数可以通过其接受的第一个Lua state参数来访问栈。 在Lua调用C的时候，被呼叫的函数获得一个新的栈，这个栈独立于上面提到的那个栈，和依然活跃的C函数的栈。这个栈初始为调用C函数的参数，C函数可以在这里存储临时的Lua值，而且必须把其结果压入这个栈来返回给调用者（lua_CFunction）。 为了方便，大多API中的查询操作不遵从一个严格的栈限制。他们可以通过index（索引）来引用栈中的任何元素：一个正索引表示一个绝对的栈位置（从1开始）；一个负值索引表示从栈顶开始的相对偏移值。更特别一些，如果栈有n个元素，1代表了第一个元素（就这就说，这个元素被第一个压入栈），n代表最后一个元素；-1也代表了最后一个元素（在栈顶的元素），in-n代表了第一个元素。 栈大小当还Lua API交互的时候，你有责任保证完整性。实际上，你需要控制栈的溢出。可以用lua_checkstack()函数来保证栈有足够的空间用来压入新的元素。 当Lua调用C的时候，要保证栈拥有最少LUA_MINSTACK（20）的额外空间。默认值是20，意味着通常情况下不需要担心栈空间，但代码中有循环往栈压入元素的情况例外。 当调用一个Lua函数而没有指定固顶返回结果个数时（lua_call），Lua保证会有足够的空间用来返回值，但不确保其他任何空间。因此，在这种调用后，在压入任何东西入栈前，必须先调用lua_checkstack()。 有效和可接受的索引API中的所有函数只能接受有效索引和可接受的索引。 一个valid index(有效索引）说的是一个指向存储了一个可修改Lua值的位置。其由1到栈顶（1 &lt;= abs(index) &lt;= top）加上一些伪索引（代表某些C代码可以访问的位置，但不在Lua栈内）。伪索引用来访问registry $4.5节和C函数的上值（$ 4.4节）。 函数不需要指定一个可变的位置，需要的只是一个值（比如，查询函数），可以把这个值叫做可接受的索引。一个acceptable index（可接受索引）可以被叫做有效索引，但是其也可以是栈顶后的索引任何正值索引，但这必须保证这个索引指向的位置在为这个栈分配的内存空间中。除非特别指明，API中函数与acceptable indices工作。 在查询栈的时候，可接受的索引可用来避免额外的对栈顶的测试。具体而言，C函数可以查询其第三个参数而不用首先检查是不是已经有第三个参数，也不需要检查3是不是一个有效索引。 那些与acceptable indices相工作的函数而言，任何非有效的索引被当做LUA_TNONE类型，其表现得像一个nil值。 C闭包当一个C函数建立，就可能把它与一些值相关联，这就创建了一个C 闭包（查看lua_pushcclosure）；这些值被称做upvalues（上值），在函数被调用的时候可以被访问。 在调用一个C函数的时候，其upvalues被安排在指定的伪索引内。这些伪索引用宏lua_upvalueindex产生。与函数相关联的第一个upvalue位于索引lua_upvalueindex(1)。任何lua_upvalueindex(n)（n大于当前函数的upvalues值个数，但小于256，256这个值是一个闭包拥有的upvalues值的最大值加1）会产生一个可接受但是无效的索引。 注册Lua提供一个registry，一个予定义的表，C代码可以用来存储任何类型的Lua。注册表总是被安排在伪索引LUA_REGISTRYINDEX。所有的C库都可以在这个表内存储数据，但必须保证所使用的键不与已使用的键冲突。典型的，使用包含库名的字符串来作键。对于变量名字，以一个下划线和大写字母开始的字符键是Lua保留的。 当创建一个新的Lua state，其registry有一些预定义的值。registry中的整数键被 索引机制（luaL_ref）和一些予定义的值使用。因此，整数键不能被用做其他目的。这些预定义在lua.h中的常量，通过整数键来进行索引。下面的常量被定义： LUA_RIDX_MAINTHREAD：在这个索引中，registry拥有这个state的主线程。（主线程是和State一起创建的那个）。 LUA_RIDX_GLOBALS：这个索引拥有了全局环境。 错误处理内部的，Lua使用Clongjump特性来处理错误。（当编译为C++的时候使用的不一样；在源代码内搜索LUAI_THROW来查看细节）当Lua遇到错误时（比如内存分配错误或类型错误）其会raises错误，这就是说，Lua会进行一个 long jump。一个protected environment（受保护的环境）使用setjump来设置一个恢复点；一个错误会跳转到最近活跃的恢复点。 在C函数内可以使用lua_error来raise一个错误。 大多数API函数可以raise一个错误，比如内存分配错误。每个函数的文档表明了其是否可以raise一个错误。 如果错误在受保护的环境外发生，Lua调用一个panic函数（lua_panic）后退出，也就是会退出宿主程序。panic函数可以避免不返回的退出（例如，long jump到一个Lua外的恢复点） panic函数，和其名字一样，是最常出现的问题。程序应该避免使用它。作为一个通用规则，当Lua通过Lua state调用一个C函数时，其可以在Lua state上做任何事情，就跟它已经受保护了一样。然而，当C代码在其他Lua state上操作的时候（例如，Lua参数给函数，registry中的Lua state, lua_newthread()的结果），这是仅有的不能raise错误的情况。 panic函数运行起来就像一个消息处理器；实际上，错误对象位于栈顶。然而，这不会对栈空间有任何保证。为了压入些东西到栈内，panic函数必须首先检查可用空间。 处理C中的放弃内部，Lua使用C的longjump来放弃一个协程。因此，如果一个C函数foo()调用一个API函数，而这个API函数放弃了（直接或非直接通过调用其他函数放弃），Lua就不能再返回到foo()，因为longjump移除了这个函数在C栈上的帧。 为了避免这个类型的问题。Lua会在API调用中试图放弃操作时产生一个错误，有三个函数是例外（lua_yieldk, lua_callk, lua_pcallk。所有这三个函数都接受一个continuation function（接续函数，参数名k）来在放弃操作后继续执行。 我们需要进行更多的解释一下continuations。我们会在Lua中调用一个C函数，我们把他称为original function(原始函数）。这个原始函数调用这三个函数中的一个，我们称之为callee（被调）函数，然后放弃当前进程。（这会在被调函数是lua_yieldk, lua_callk, lua_pcallk和函数被其自身放弃操作时发生） 假设线程在执行被调函数时放弃操作。在进程恢复时，其会继续运行被调函数。然而，这个被调函数不能再返回原始函数了，因为在C栈上的帧已经被放弃操作销毁了。作为替代，Lua调用continuation function，作为被调函数参数传递过去的。就跟名字一样，接续函数继续原始函数的工作。 作为一个模拟，考虑下面的函数： int original_function (lua_State *L) &#123; ... /* code 1 */ status = lua_pcall(L, n, m, h); /* calls Lua */ ... /* code 2 */&#125; 现在我们打算让Lua代码运行lua_pcall来放弃操作。首先，我们可以重写我们的函数： int k (lua_State *L, int status, lua_KContext ctx) &#123; ... /* code 2 */ &#125; int original_function (lua_State *L) &#123; ... /* code 1 */ return k(L, lua_pcall(L, n, m, h), ctx); &#125; 在上面的代码中，函数k是一个continuation function（类型lua_KFunction），它会继续做原始函数在调用lua_pcall后的所有工作。现在，我们必须告诉Lua，在代码执行lua_pcall遇到某些形式中断（错误或放弃操作）的时候必须调用k，所以我们继续重写代码，把lua_pcall替换为lua_pcallk： int original_function (lua_State *L) &#123; ... /* code 1 */ return k(L, lua_pcallk(L, n, m, h, ctx2, k), ctx1); &#125; 注意外部，现式的调用了这个接续函数：Lua只会在需要的时候调用接续函数，也就是发生错误或者让出了CPU（yield）。如果被调用函数正常返回，lua_pcallk（和lua_call）也会正常返回。（当然，不用调用接续函数，你也可以在原始函数中继续工作）。 和Lua state概念相应，接续函数有两个其他参数：调用的最终状态，传递给lua_pcallk的上下文（ctx）。（Lua不会使用这个上下文，它只会把这个值从原始函数传递到接续函数）。lua_callk(）而言，状态和lua_pcallk的返回值一样，在一个yield后返回LUA_YIELD是个例外。对于lua_yieldk, lua_callk，Lua调用接续函数时状态参数总是LUA_YIELD（对这两个函数，在出现错误的时候Lua不会调用接续函数，因为他们不进行错误处理）。类似地，当使用lua_callk时，你应该使用LUA_OK作为状态来调用接续函数。（对于lua_yield，没有直接调用接续函数的方法，因为它通常情况下不返回）。 lua.c 中的main()函数int main (int argc, char **argv) &#123; int status, result; lua_State *L = luaL_newstate(); /* create state */ if (L == NULL) &#123; l_message(argv[0], \"cannot create state: not enough memory\"); return EXIT_FAILURE; &#125; lua_pushcfunction(L, &amp;pmain); /* to call 'pmain' in protected mode */ lua_pushinteger(L, argc); /* 1st argument */ lua_pushlightuserdata(L, argv); /* 2nd argument */ status = lua_pcall(L, 2, 1, 0); /* do the call */ result = lua_toboolean(L, -1); /* get result */ report(L, status); lua_close(L); return (result &amp;&amp; status == LUA_OK) ? EXIT_SUCCESS : EXIT_FAILURE;&#125; 可以看到，main函数所做的事情就是这几样： 调用luaL_newstate()建立一个新的state(我不知道怎么去翻译了)。 把函数 pmain()压入栈 把函数参数个数argc压入栈 把函数参数数组argv压入栈 执行函数pmain() 获取结果 报告状态 关闭state。我们更详细的来看这个过程。 luaL_newstate()在文件lauxlib.c中我们可以看到luaL_newstate()的定义 : LUALIB_API lua_State *luaL_newstate (void) &#123; lua_State *L = lua_newstate(l_alloc, NULL); if (L) lua_atpanic(L, &amp;panic); return L;&#125; 其是利用 lua_newstate()这个函数的封装。而我们 可以看到，lua_newstate()需要一个l_alloc参数，这是一个函数指针。 lua_newstate()lua_newstate()函数定义在lstate.c中： LUA_API lua_State *lua_newstate (lua_Alloc f, void *ud) &#123; int i; lua_State *L; global_State *g; LG *l = cast(LG *, (*f)(ud, NULL, LUA_TTHREAD, sizeof(LG))); if (l == NULL) return NULL; L = &amp;l-&gt;l.l; g = &amp;l-&gt;g; L-&gt;tt = LUA_TTHREAD; g-&gt;currentwhite = bitmask(WHITE0BIT); L-&gt;marked = luaC_white(g); preinit_thread(L, g); g-&gt;allgc = obj2gco(L); /* by now, only object is the main thread */ L-&gt;next = NULL; g-&gt;frealloc = f; g-&gt;ud = ud; g-&gt;mainthread = L; g-&gt;seed = makeseed(L); g-&gt;gcrunning = 0; /* no GC while building state */ g-&gt;strt.size = g-&gt;strt.nuse = 0; g-&gt;strt.hash = NULL; setnilvalue(&amp;g-&gt;l_registry); g-&gt;panic = NULL; g-&gt;version = NULL; g-&gt;gcstate = GCSpause; g-&gt;gckind = KGC_INC; g-&gt;finobj = g-&gt;tobefnz = g-&gt;fixedgc = NULL; g-&gt;survival = g-&gt;old = g-&gt;reallyold = NULL; g-&gt;finobjsur = g-&gt;finobjold = g-&gt;finobjrold = NULL; g-&gt;sweepgc = NULL; g-&gt;gray = g-&gt;grayagain = NULL; g-&gt;weak = g-&gt;ephemeron = g-&gt;allweak = g-&gt;protogray = NULL; g-&gt;twups = NULL; g-&gt;totalbytes = sizeof(LG); g-&gt;GCdebt = 0; setgcparam(g-&gt;gcpause, LUAI_GCPAUSE); setgcparam(g-&gt;gcstepmul, LUAI_GCMUL); g-&gt;gcstepsize = LUAI_GCSTEPSIZE; setgcparam(g-&gt;genmajormul, LUAI_GENMAJORMUL); g-&gt;genminormul = LUAI_GENMINORMUL; for (i=0; i &lt; LUA_NUMTAGS; i++) g-&gt;mt[i] = NULL; if (luaD_rawrunprotected(L, f_luaopen, NULL) != LUA_OK) &#123; /* memory allocation error: free partial state */ close_state(L); L = NULL; &#125; return L;&#125; 这个文件中还定义了结构LG，LX。 LX是一个线程状态和额外空间的组合。 LG是一个线程状态和全局状态的组合，就是一个 LX成员加一个 全局状态 global_State。 typedef struct LG &#123; LX l; global_State g;&#125; LG; LX是一个扩展的本地数据的结构： typedef struct LX &#123; lu_byte extra_[LUA_EXTRASPACE]; lua_State l;&#125; LX; lua_State与global_State这两个结构在lstate.h中分别定义如下: typedef struct global_State &#123; lua_Alloc frealloc; /* function to reallocate memory */ void *ud; /* auxiliary data to 'frealloc' */ l_mem totalbytes; /* number of bytes currently allocated - GCdebt */ l_mem GCdebt; /* bytes allocated not yet compensated by the collector */ lu_mem GCestimate; /* an estimate of the non-garbage memory in use */ stringtable strt; /* hash table for strings */ TValue l_registry; unsigned int seed; /* randomized seed for hashes */ lu_byte currentwhite; lu_byte gcstate; /* state of garbage collector */ lu_byte gckind; /* kind of GC running */ lu_byte genminormul; /* control for minor generational collections */ lu_byte genmajormul; /* control for major generational collections */ lu_byte gcrunning; /* true if GC is running */ lu_byte gcemergency; /* true if this is an emergency collection */ lu_byte gcpause; /* size of pause between successive GCs */ lu_byte gcstepmul; /* GC \"speed\" */ lu_byte gcstepsize; /* (log2 of) GC granularity */ GCObject *allgc; /* list of all collectable objects */ GCObject **sweepgc; /* current position of sweep in list */ GCObject *finobj; /* list of collectable objects with finalizers */ GCObject *gray; /* list of gray objects */ GCObject *grayagain; /* list of objects to be traversed atomically */ GCObject *weak; /* list of tables with weak values */ GCObject *ephemeron; /* list of ephemeron tables (weak keys) */ GCObject *allweak; /* list of all-weak tables */ GCObject *protogray; /* list of prototypes with \"new\" caches */ GCObject *tobefnz; /* list of userdata to be GC */ GCObject *fixedgc; /* list of objects not to be collected */ /* fields for generational collector */ GCObject *survival; /* start of objects that survived one GC cycle */ GCObject *old; /* start of old objects */ GCObject *reallyold; /* old objects with more than one cycle */ GCObject *finobjsur; /* list of survival objects with finalizers */ GCObject *finobjold; /* list of old objects with finalizers */ GCObject *finobjrold; /* list of really old objects with finalizers */ struct lua_State *twups; /* list of threads with open upvalues */ lua_CFunction panic; /* to be called in unprotected errors */ struct lua_State *mainthread; const lua_Number *version; /* pointer to version number */ TString *nfield; /* string \"n\" (key in vararg tables) */ TString *tmname[TM_N]; /* array with tag-method names */ struct Table *mt[LUA_NUMTAGS]; /* metatables for basic types */ TString *strcache[STRCACHE_N][STRCACHE_M]; /* cache for strings in API */&#125; global_State;struct lua_State &#123; CommonHeader; unsigned short nci; /* number of items in 'ci' list */ lu_byte status; StkId top; /* first free slot in the stack */ global_State *l_G; CallInfo *ci; /* call info for current function */ const Instruction *oldpc; /* last pc traced */ StkId stack_last; /* last free slot in the stack */ StkId stack; /* stack base */ UpVal *openupval; /* list of open upvalues in this stack */ GCObject *gclist; struct lua_State *twups; /* list of threads with open upvalues */ struct lua_longjmp *errorJmp; /* current error recover point */ CallInfo base_ci; /* CallInfo for first level (C calling Lua) */ volatile lua_Hook hook; ptrdiff_t errfunc; /* current error handling function (stack index) */ int stacksize; int basehookcount; int hookcount; unsigned short nny; /* number of non-yieldable calls in stack */ unsigned short nCcalls; /* number of nested C calls */ l_signalT hookmask; lu_byte allowhook;&#125;; 可以看到，lua_newstate()通过内存分配函数l_alloc的参数f先分配一个sizeof(LG)大小的结构，并强制转换为LG *，接着本地数据指针、全局数据指针分别指向这个分配结构中的LG-&gt;l.l和LG-&gt;g成员。然后就做一些初始化工作。 f_luaopen()————state分配与初始化最后，通过f_luaopen()来进行初始化，这个函数定义在lstate.c中： /*** open parts of the state that may cause memory-allocation errors.** ('g-&gt;version' != NULL flags that the state was completely build)*/static void f_luaopen (lua_State *L, void *ud) &#123; global_State *g = G(L); UNUSED(ud); stack_init(L, L); /* init stack */ init_registry(L, g); luaS_init(L); luaT_init(L); luaX_init(L); g-&gt;gcrunning = 1; /* allow gc */ g-&gt;gcemergency = 0; g-&gt;version = lua_version(NULL); luai_userstateopen(L);&#125; 其首先通过宏#define G(L) (L-&gt;l_G)获取全局的state，然后进行初始化： statck_init(L, L)此函数定义在lstate.c中:这函数，会分配内存，然后初始化为nil，并设置栈顶，栈底等信息。内存，是分配在堆中的static void stack_init (lua_State *L1, lua_State *L) &#123; int i; CallInfo *ci; /* initialize stack array */ L1-&gt;stack = luaM_newvector(L, BASIC_STACK_SIZE, StackValue); L1-&gt;stacksize = BASIC_STACK_SIZE; for (i = 0; i &lt; BASIC_STACK_SIZE; i++) setnilvalue(s2v(L1-&gt;stack + i)); /* erase new stack */ L1-&gt;top = L1-&gt;stack; L1-&gt;stack_last = L1-&gt;stack + L1-&gt;stacksize - EXTRA_STACK; /* initialize first ci */ ci = &amp;L1-&gt;base_ci; ci-&gt;next = ci-&gt;previous = NULL; ci-&gt;callstatus = CIST_C; ci-&gt;func = L1-&gt;top; setnilvalue(s2v(L1-&gt;top)); /* 'function' entry for this 'ci' */ L1-&gt;top++; ci-&gt;top = L1-&gt;top + LUA_MINSTACK; L1-&gt;ci = ci;&#125; 其通过luaM_newvector()宏来分配内存：其定义是： lmem.h:#define luaM_newvector(L,n,t) cast(t*, luaM_malloc_(L, (n)*sizeof(t), 0)) L1-&gt;stack = luaM_newvector(L, BASIC_STACK_SIZE, StackValue); 而luaM_newvector()是通过执行内存分配函数g-&gt;frealloc(g-&gt;ud, NULL, tag, size)来执行内存分配的。在执行 lua_newstate(l_alloc, NULL); 的时候，内存分配函数被指定为l_alloc()，这函数定义在lauxlib.c中: static void *l_alloc (void *ud, void *ptr, size_t osize, size_t nsize) &#123; (void)ud; (void)osize; /* not used */ if (nsize == 0) &#123; free(ptr); return NULL; &#125; else return realloc(ptr, nsize);&#125; 这个函数只是利用realloc()来重新分配一块内存，或者在nsize为0的时候，释放内存。 init_registry(L, g)；luaS_init(L);初始化 字符串 hash 表G(L)-&gt;strt，代码文件lstring.c: void luaS_init (lua_State *L) &#123; global_State *g = G(L); int i, j; TString *memerrmsg; stringtable *tb = &amp;G(L)-&gt;strt; tb-&gt;hash = luaM_newvector(L, MINSTRTABSIZE, TString*); tablerehash(tb-&gt;hash, 0, MINSTRTABSIZE); /* clear array */ tb-&gt;size = MINSTRTABSIZE; /* pre-create memory-error message */ memerrmsg = luaS_newliteral(L, MEMERRMSG); luaC_fix(L, obj2gco(memerrmsg)); /* it should never be collected */ g-&gt;nfield = luaS_newliteral(L, \"n\"); /* pre-create \"n\" field name */ luaC_fix(L, obj2gco(g-&gt;nfield)); /* it also should never be collected */ for (i = 0; i &lt; STRCACHE_N; i++) /* fill cache with valid strings */ for (j = 0; j &lt; STRCACHE_M; j++) g-&gt;strcache[i][j] = g-&gt;nfield;&#125; luaT_init(L);初始化 标签方法G(L)-&gt;tmname数组，定义文件在ltm.c中： void luaT_init (lua_State *L) &#123; static const char *const luaT_eventname[] = &#123; /* ORDER TM */ \"__index\", \"__newindex\", \"__gc\", \"__mode\", \"__len\", \"__eq\", \"__add\", \"__sub\", \"__mul\", \"__mod\", \"__pow\", \"__div\", \"__idiv\", \"__band\", \"__bor\", \"__bxor\", \"__shl\", \"__shr\", \"__unm\", \"__bnot\", \"__lt\", \"__le\", \"__concat\", \"__call\" &#125;; int i; for (i=0; i&lt;TM_N; i++) &#123; G(L)-&gt;tmname[i] = luaS_new(L, luaT_eventname[i]); luaC_fix(L, obj2gco(G(L)-&gt;tmname[i])); /* never collect these names */ &#125;&#125; luaX_init(L);初始化词法分析器，定义文件在llex.c: void luaX_init (lua_State *L) &#123; int i; TString *e = luaS_newliteral(L, LUA_ENV); /* create env name */ luaC_fix(L, obj2gco(e)); /* never collect this name */ for (i=0; i&lt;NUM_RESERVED; i++) &#123; TString *ts = luaS_new(L, luaX_tokens[i]); luaC_fix(L, obj2gco(ts)); /* reserved words are never collected */ ts-&gt;extra = cast_byte(i+1); /* reserved word */ &#125;&#125; 最后，会打开gc。到此，内存的分配和初始化已经完毕。 lua_pushcfuntion()这个函数在lua.h中被定义为: #define lua_pushcfunction(L,f) lua_pushcclosure(L, (f), 0) 真正的实现是在lapi.c中： LUA_API void lua_pushcclosure (lua_State *L, lua_CFunction fn, int n) &#123; lua_lock(L); if (n == 0) &#123; setfvalue(s2v(L-&gt;top), fn); api_incr_top(L); &#125; else &#123; CClosure *cl; api_checknelems(L, n); api_check(L, n &lt;= MAXUPVAL, \"upvalue index too large\"); cl = luaF_newCclosure(L, n); cl-&gt;f = fn; L-&gt;top -= n; while (n--) &#123; setobj2n(L, &amp;cl-&gt;upvalue[n], s2v(L-&gt;top + n)); /* does not need barrier because closure is white */ &#125; setclCvalue(L, s2v(L-&gt;top), cl); api_incr_top(L); luaC_checkGC(L); &#125; lua_unlock(L);&#125; 可以看到这个函数的操作，是先锁定L，然后把栈顶设置为要压入的函数，然后增加栈顶的值。跟着的两个函数也是压入参数。 lua_pcall()lua_pcall()在lua.h中被定义为lua_pcallk()的一个宏: #define lua_pcall(L,n,r,f) lua_pcallk(L, (n), (r), (f), 0, NULL) 代码中使用的是lua_pcall(L, 2, 1, 0)，表示传入参数为2个，返回参数为1个，错误处理函数为空。参数lua_KContext ctx, lua_KFunction k分别设置为0, NULL。lua_pcallk()函数实现在lapi.c中： LUA_API int lua_pcallk (lua_State *L, int nargs, int nresults, int errfunc, lua_KContext ctx, lua_KFunction k) &#123; struct CallS c; int status; ptrdiff_t func; lua_lock(L); api_check(L, k == NULL || !isLua(L-&gt;ci), \"cannot use continuations inside hooks\"); api_checknelems(L, nargs+1); api_check(L, L-&gt;status == LUA_OK, \"cannot do calls on non-normal thread\"); checkresults(L, nargs, nresults); if (errfunc == 0) func = 0; else &#123; StkId o = index2stack(L, errfunc); func = savestack(L, o); &#125; c.func = L-&gt;top - (nargs+1); /* function to be called */ if (k == NULL || L-&gt;nny &gt; 0) &#123; /* no continuation or no yieldable? */ c.nresults = nresults; /* do a 'conventional' protected call */ status = luaD_pcall(L, f_call, &amp;c, savestack(L, c.func), func); &#125; else &#123; /* prepare continuation (call is already protected by 'resume') */ CallInfo *ci = L-&gt;ci; ci-&gt;u.c.k = k; /* save continuation */ ci-&gt;u.c.ctx = ctx; /* save context */ /* save information for error recovery */ ci-&gt;u2.funcidx = savestack(L, c.func); ci-&gt;u.c.old_errfunc = L-&gt;errfunc; L-&gt;errfunc = func; setoah(ci-&gt;callstatus, L-&gt;allowhook); /* save value of 'allowhook' */ ci-&gt;callstatus |= CIST_YPCALL; /* function can do error recovery */ luaD_call(L, c.func, nresults); /* do the call */ ci-&gt;callstatus &amp;= ~CIST_YPCALL; L-&gt;errfunc = ci-&gt;u.c.old_errfunc; status = LUA_OK; /* if it is here, there were no errors */ &#125; adjustresults(L, nresults); lua_unlock(L); return status;&#125; Calls是一个传递数据给f_call函数的结构。 struct CallS &#123; /* data to 'f_call' */ StkId func; int nresults;&#125;; 结构中 StkId实际是指栈中元素的索引，实际类型是一个StackValue指针。StckValue定义如下: typedef union StackValue &#123; TValue val;&#125; StackValue;typedef StackValue *StkId; /* index to stack elements */ 我们可以看到：c.func = L-&gt;top - (nargs+1); 通过把栈顶减去参数+1个位置，得到了我们先前压入函数的地址，返回元素个数由lua_pcallk()传入。 lua_pcallk()通过调用luaD_pcall(L, f_call, &amp;c, savestack(L, c.func), func);来执行压入函数，这个函数定义在 ldo.c中: luaD_pcall()ldo.c文件中： int luaD_pcall (lua_State *L, Pfunc func, void *u, ptrdiff_t old_top, ptrdiff_t ef) &#123; int status; CallInfo *old_ci = L-&gt;ci; lu_byte old_allowhooks = L-&gt;allowhook; unsigned short old_nny = L-&gt;nny; ptrdiff_t old_errfunc = L-&gt;errfunc; L-&gt;errfunc = ef; status = luaD_rawrunprotected(L, func, u); if (status != LUA_OK) &#123; /* an error occurred? */ StkId oldtop = restorestack(L, old_top); luaF_close(L, oldtop); /* close possible pending closures */ seterrorobj(L, status, oldtop); L-&gt;ci = old_ci; L-&gt;allowhook = old_allowhooks; L-&gt;nny = old_nny; luaD_shrinkstack(L); &#125; L-&gt;errfunc = old_errfunc; return status;&#125; LuaD_pcall()函数通过调用 luaD_rawrunprotected(L, func, u)来执行下一步。其中现在传入的func = f_call, u = &amp;c。这个函数会以保护形式运行函数。 下面是实际执行的函数f_call(L, &amp;c)，这个函数定义在lapi.c。 static void f_call (lua_State *L, void *ud) &#123; struct CallS *c = cast(struct CallS *, ud); luaD_callnoyield(L, c-&gt;func, c-&gt;nresults);&#125; luaD_call()f_call()函数调用luaD_callnoyield()，这个函数和luaD_call()类似，但是在调用期间不能被打断，定义在ldo.c中。 void luaD_callnoyield (lua_State *L, StkId func, int nResults) &#123; L-&gt;nny++; luaD_call(L, func, nResults); L-&gt;nny--;&#125; luaD_call(L, func, nResults)执行被压入的函数func，返回nResults个结果。代码如下： void luaD_call (lua_State *L, StkId func, int nresults) &#123; lua_CFunction f; TValue *funcv = s2v(func); CallInfo *ci; switch (ttype(funcv)) &#123; case LUA_TCCL: /* C closure */ f = clCvalue(funcv)-&gt;f; goto Cfunc; case LUA_TLCF: /* light C function */ f = fvalue(funcv); Cfunc: &#123; int n; /* number of returns */ checkstackp(L, LUA_MINSTACK, func); /* ensure minimum stack size */ ci = next_ci(L); /* now 'enter' new function */ ci-&gt;nresults = nresults; ci-&gt;func = func; ci-&gt;top = L-&gt;top + LUA_MINSTACK; lua_assert(ci-&gt;top &lt;= L-&gt;stack_last); ci-&gt;callstatus = CIST_C; if (L-&gt;hookmask &amp; LUA_MASKCALL) luaD_hook(L, LUA_HOOKCALL, -1); lua_unlock(L); n = (*f)(L); /* do the actual call */ lua_lock(L); api_checknelems(L, n); luaD_poscall(L, ci, L-&gt;top - n, n); break; &#125; case LUA_TLCL: &#123; /* Lua function: prepare its call */ Proto *p = clLvalue(funcv)-&gt;p; int n = cast_int(L-&gt;top - func) - 1; /* number of real arguments */ int fsize = p-&gt;maxstacksize; /* frame size */ checkstackp(L, fsize, func); for (; n &lt; p-&gt;numparams; n++) setnilvalue(s2v(L-&gt;top++)); /* complete missing arguments */ if (p-&gt;is_vararg) luaT_adjustvarargs(L, p, n); ci = next_ci(L); /* now 'enter' new function */ ci-&gt;nresults = nresults; ci-&gt;func = func; ci-&gt;top = func + 1 + fsize; lua_assert(ci-&gt;top &lt;= L-&gt;stack_last); ci-&gt;u.l.savedpc = p-&gt;code; /* starting point */ ci-&gt;callstatus = 0; if (L-&gt;hookmask) hookcall(L, ci, 0); luaV_execute(L, ci); /* run the function */ break; &#125; default: &#123; /* not a function */ func = luaD_tryfuncTM(L, func); /* try to get '__call' metamethod */ luaD_call(L, func, nresults); /* now it must be a function */ break; &#125; &#125;&#125; TValue类型我们先看看TValue类型到底是个什么东西。在lobject.h中，TValue是一个结构: typedef struct TValue &#123; TValuefields;&#125; TValue; 而TValuefields;被定义为宏：#define TValuefields Value value_; lu_byte tt_ 所以TValue的最终结构应该是这样的: typedef struct TValue &#123; Value value_; lu_byte tt_;&#125; TValue; 而Value也是一个联合： typedef union Value &#123; GCObject *gc; /* collectable objects */ void *p; /* light userdata */ int b; /* booleans */ lua_CFunction f; /* light C functions */ lua_Integer i; /* integer numbers */ lua_Number n; /* float numbers */&#125; Value; 可以把TValue理解为Tagged Values，Lua值的基本表示方式，就是一个类型加上一个值。 TValue值访问有一个宏用来把 StackValue类型转换为TValue类型： /* convert a 'StackValue' to a 'TValue' */#define s2v(o) (&amp;(o)-&gt;val) TValue *funcv = s2v(func); 这将func转换为一个TValue值。而有一系列的宏来访问TValue中的值： /* Macros to access values */#define ivalue(o) check_exp(ttisinteger(o), val_(o).i)#define fltvalue(o) check_exp(ttisfloat(o), val_(o).n)#define nvalue(o) check_exp(ttisnumber(o), \\ (ttisinteger(o) ? cast_num(ivalue(o)) : fltvalue(o)))#define gcvalue(o) check_exp(iscollectable(o), val_(o).gc)#define pvalue(o) check_exp(ttislightuserdata(o), val_(o).p)#define tsvalue(o) check_exp(ttisstring(o), gco2ts(val_(o).gc))#define uvalue(o) check_exp(ttisfulluserdata(o), gco2u(val_(o).gc))#define clvalue(o) check_exp(ttisclosure(o), gco2cl(val_(o).gc))#define clLvalue(o) check_exp(ttisLclosure(o), gco2lcl(val_(o).gc))#define clCvalue(o) check_exp(ttisCclosure(o), gco2ccl(val_(o).gc))#define fvalue(o) check_exp(ttislcf(o), val_(o).f)#define hvalue(o) check_exp(ttistable(o), gco2t(val_(o).gc))#define bvalue(o) check_exp(ttisboolean(o), val_(o).b)#define thvalue(o) check_exp(ttisthread(o), gco2th(val_(o).gc)) ttype(funcv)会根据funcv.tt_的值和0x3F进行与计算，得出值类型。然后就可以用上面的宏进行访问对应的值。 我们来看看值类型是LUA_TCCL时的过程，这会调用clCvalue(funcv)-&gt;f来访问其中的值，展开宏的话就是： check_exp(ttisCclosure(funcv), gco2ccl(val_(o).gc)) 而gco2ccl()是这样定义的： lstate.h:#define gco2ccl(o) check_exp((o)-&gt;tt == LUA_TCCL, &amp;((cast_u(o))-&gt;cl.c)) cast_u()把funcv强制转换到GCUnion类型，然后访问其中的cl(Closure联合类型）中的c(常规c语句）。其他类型的访问形式类似。 在代码中，压入的是C 函数pmain()。所以首先会通过代码f = clCvalue(funcv).f 得到函数地址。然后跳转到标签Cfunc: 执行压入函数pmain()我们在main()函数中压入的是函数pmain()，通过pcall()进行执行。我们看一下这个函数是如何执行的。 static int pmain (lua_State *L) &#123; int argc = (int)lua_tointeger(L, 1); char **argv = (char **)lua_touserdata(L, 2); int script; int args = collectargs(argv, &amp;script); luaL_checkversion(L); /* check that interpreter has correct version */ if (argv[0] &amp;&amp; argv[0][0]) progname = argv[0]; if (args == has_error) &#123; /* bad arg? */ print_usage(argv[script]); /* 'script' has index of bad arg. */ return 0; &#125; if (args &amp; has_v) /* option '-v'? */ print_version(); if (args &amp; has_E) &#123; /* option '-E'? */ lua_pushboolean(L, 1); /* signal for libraries to ignore env. vars. */ lua_setfield(L, LUA_REGISTRYINDEX, \"LUA_NOENV\"); &#125; luaL_openlibs(L); /* open standard libraries */ createargtable(L, argv, argc, script); /* create table 'arg' */ if (!(args &amp; has_E)) &#123; /* no option '-E'? */ if (handle_luainit(L) != LUA_OK) /* run LUA_INIT */ return 0; /* error running LUA_INIT */ &#125; if (!runargs(L, argv, script)) /* execute arguments -e and -l */ return 0; /* something failed */ if (script &lt; argc &amp;&amp; /* execute main script (if there is one) */ handle_script(L, argv + script) != LUA_OK) return 0; if (args &amp; has_i) /* -i option? */ doREPL(L); /* do read-eval-print loop */ else if (script == argc &amp;&amp; !(args &amp; (has_e | has_v))) &#123; /* no arguments? */ if (lua_stdin_is_tty()) &#123; /* running in interactive mode? */ print_version(); doREPL(L); /* do read-eval-print loop */ &#125; else dofile(L, NULL); /* executes stdin as a file */ &#125; lua_pushboolean(L, 1); /* signal no errors */ return 1;&#125; 这个函数最终会调用dofile(L, NULL)函数，定义在lua.c中;dofile(L, NULL)会调用luaL_loadfilex(L, name, NULL)：这个函数的主要作用是打开文件，然后忽略注释，然后调用lua_load(L, getF, &amp;lf, lua_tostring(L, -1), mode)``lapi.c中定义函数。 其中，getF()是阅读函数，这会调用底层的fread()来进行实际的读入操作。将数据结构ZIO（lzio.c）用读入函数getF()和文件名初始化后，调用函数luaD_protectedparser(L, &amp;z, chunkname, mode)（lod.c），进行解析。 总结基本的步骤可以归纳为下： 解释器初始化。调用luaL_newstate()，这会利用内存分配函数f_alloc()，其实就是realloc()来进行内存的分配。会在程序堆内分配一个全局和本地的State，然后会在堆内再分配一个Lua自己的栈。 将函数名，参数，压入一个State内。调用lua_pushXXX()函数。 调用lua_pcall()执行 获取结果。","categories":[{"name":"Lua","slug":"Lua","permalink":"https://gowa2017.github.io/categories/Lua/"}],"tags":[{"name":"编程","slug":"编程","permalink":"https://gowa2017.github.io/tags/编程/"},{"name":"Lua","slug":"Lua","permalink":"https://gowa2017.github.io/tags/Lua/"}],"keywords":[{"name":"Lua","slug":"Lua","permalink":"https://gowa2017.github.io/categories/Lua/"}]},{"title":"使用代理让go能get官方网站golang.org的包","slug":"使用代理让go能get官方网站golang.org的包","date":"2018-01-20T13:36:12.000Z","updated":"2018-01-20T13:36:12.000Z","comments":true,"path":"Golang/使用代理让go能get官方网站golang.org的包.html","link":"","permalink":"https://gowa2017.github.io/Golang/使用代理让go能get官方网站golang.org的包.html","excerpt":"开始学golang变成的时候，需要设置一下IDE，用的是vim，然后配合官方推荐的vim-go插件，然后这个插件需要装很多附加的包，有的是从golang.org网站下载的，很多时候都无法下载，国内就是这么蛋疼。后面使用了代理进行了配置才能下载。","text":"开始学golang变成的时候，需要设置一下IDE，用的是vim，然后配合官方推荐的vim-go插件，然后这个插件需要装很多附加的包，有的是从golang.org网站下载的，很多时候都无法下载，国内就是这么蛋疼。后面使用了代理进行了配置才能下载。 代理首先需要开启一个代理，本地用的是ss代理，开启了http代理服务器，然后进行设置。设置环境变量： ss客户端用的是 Shadowsocks-NG。 export http_proxy=https://localhost:1087 export https_proxy=https://localhost:1087 然后使用go get就可以正常下载了。 $go get -v golang.org/x/tools/guruFetching https://golang.org/x/tools/guru?go-get=1Parsing meta tags from https://golang.org/x/tools/guru?go-get=1 (status code 200)get &quot;golang.org/x/tools/guru&quot;: found meta tag get.metaImport&#123;Prefix:&quot;golang.org/x/tools&quot;, VCS:&quot;git&quot;, RepoRoot:&quot;https://go.googlesource.com/tools&quot;&#125; at https://golang.org/x/tools/guru?go-get=1get &quot;golang.org/x/tools/guru&quot;: verifying non-authoritative meta tagFetching https://golang.org/x/tools?go-get=1Parsing meta tags from https://golang.org/x/tools?go-get=1 (status code 200)golang.org/x/tools (download)package golang.org/x/tools/guru: cannot find package &quot;golang.org/x/tools/guru&quot; in any of: /usr/local/go/src/golang.org/x/tools/guru (from $GOROOT) /Users/wodediannao/go/src/golang.org/x/tools/guru (from $GOPATH)wodedianaodeAir:src shouzheng.zhang$ go get -v golang.org/x/tools/cmd/gurugolang.org/x/tools/go/buildutilgolang.org/x/tools/go/types/typeutilgolang.org/x/tools/go/ast/astutilgolang.org/x/tools/cmd/guru/serialgolang.org/x/tools/container/intsetsgolang.org/x/tools/refactor/importgraphgolang.org/x/tools/go/ssagolang.org/x/tools/go/loadergolang.org/x/tools/go/callgraphgolang.org/x/tools/go/ssa/ssautilgolang.org/x/tools/go/pointergolang.org/x/tools/go/callgraph/staticgolang.org/x/tools/cmd/guru 大功告成","categories":[{"name":"Golang","slug":"Golang","permalink":"https://gowa2017.github.io/categories/Golang/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://gowa2017.github.io/tags/Golang/"},{"name":"编程","slug":"编程","permalink":"https://gowa2017.github.io/tags/编程/"}],"keywords":[{"name":"Golang","slug":"Golang","permalink":"https://gowa2017.github.io/categories/Golang/"}]},{"title":"java中的基本IO","slug":"java中的基本IO","date":"2018-01-19T06:51:24.000Z","updated":"2018-01-19T06:51:24.000Z","comments":true,"path":"Java/java中的基本IO.html","link":"","permalink":"https://gowa2017.github.io/Java/java中的基本IO.html","excerpt":"无论哪一种语言，IO都是最重要的一个方面。计算机本来就是读取输入然后进响应，得出输出的一个黑箱子，所以了解一下IO，非常有必要的。就像POSIX中的IO，基本上三分之一的篇幅都是关于IO的。","text":"无论哪一种语言，IO都是最重要的一个方面。计算机本来就是读取输入然后进响应，得出输出的一个黑箱子，所以了解一下IO，非常有必要的。就像POSIX中的IO，基本上三分之一的篇幅都是关于IO的。 概述本节覆盖了Java平台用来进行基本I/O的类。首先聚焦在I/O流上，一个简化了IO操作的强力概念。本节也会讨论串行化，就是让所有的对象可以从一个流输出，然后又读回来。然后再继续讨论文件IO和文件系统操作，包括随机访问文件。 大多数在 I/O Streams节讨论的类都在java.io包中。大多数在File I/O中讨论的类都在java.nio.file包中。 I/O Streams（I/O 流） Byte Streams 处理原始二进制数据I/O Character Streams 处理字符数据的I/O，自动到本地字符集的转换。 Bufferd Streams 通过减少对底层API的调用次数来优化输入/输出。 Scanning and Formatting 允许程序阅读和写出格式化文本 I/O from the Command Line 描述了标准流和控制对象 Data Streams 处理基本类型和String类型数据的二进制I/O Object Streams 控制对象的二进制I/O File I/O(Fetruring NIO.2) 路径是什么？测试一个文件系统上路径的概念。. 路径类介绍了java.nio.file包中基类。 路径操作关注在路径类中的处理句法操作的方法。 文件操作介绍了大多数文件I/O方法都会有的概念。 检查一个文件或目录来显示文件的存在性及访问级别。 删除文件或目录 复制文件或目录 移动文件或目录 元数据管理解释了怎么样来读或设置文件的属性。 读，写，和创建文件显示了流或通道用来读写文件的方法。 随机访问文件显示了怎么样非顺序的读或写一个文件。 Creating and Reading Directories covers API specific to directories, such as how to list a directory’s contents. Links, Symbolic or Otherwise covers issues specific to symbolic and hard links. Walking the File Tree demonstrates how to recursively visit each file and directory in a file tree. Finding Files shows how to search for files using pattern matching. Watching a Directory for Changes shows how to use the watch service to detect files that are added, removed or updated in one or more directories. Other Useful Methods covers important API that didn’t fit elsewhere in the lesson. Legacy File I/O Code shows how to leverage Path functionality if you have older code using the java.io.File class. A table mapping java.io.File API to java.nio.file API is provided. The I/O Classes in Action在接下来的例子中Custom Networking使用在本节内描述的 I/O 流来读或写到网络连接。 I/O流一个I/O流代表了一个输入源和一个写出目标。一个流可以代表不同类型的源和目标，包括磁盘文件，设备，其他程序和内存数组。 流支持各种不同类型的数据，包括简单的字节，基本数据类型，本地化字符，对象。某些流只是简单传输数据；其他会以常用的方式操作和传输数据。 不论内部是怎么工作，所有的流对使用它的程序来说都是模型都是简单的：一个流是一系列的数据。一个程序使用input stream(输入流)来从一个源读取数据，一次一个项目： 程序使用output stream(输出流)来写出数据，一次一个项目： 本节我们会遇到处理所有类型的数据的流，从基本数据类型到高级对象。 上面图片中的数据源和数据目的地可以是保留，产生或消耗数据的任何类型。很明显，这包括磁盘文件，但一个源或目的也可能是其他程序，一个外围设备，一个网络套接字或者数组。 在下一节，我们会使用最基本的流，byte streams，来展示对I/O流的常规操作。对于输入，我们将使用示例文件xanndu.txt，包含了以下的单词： In Xanadu did Kubla KhanA stately pleasure-dome decree:Where Alph, the sacred river, ranThrough caverns measureless to manDown to a sunless sea. Byte Streams程序使用byte streams来进行8-bit字节的输入输出。所有的字节流类都从InputStream, OutputStream衍生。 有很多字节流类。为了展示字节流怎么工作，我们将会聚焦在文件I/O字节流，FileInputStream, FileOutputStream。其他类型的字节流使用方式也相似；主要的不同就是他们构成的方式。 使用字节流我们会通过测试一个叫CopyBytes的程序来查看FileInputStream, FileOutputStream，这程序一次一个字节的复制xanadu.txt文件。 import java.io.FileInputStream;import java.io.FileOutputStream;import java.io.IOException;public class CopyBytes &#123; public static void main(String[] args) throws IOException &#123; FileInputStream in = null; FileOutputStream out = null; try &#123; in = new FileInputStream(\"xanadu.txt\"); out = new FileOutputStream(\"outagain.txt\"); int c; while ((c = in.read()) != -1) &#123; out.write(c); &#125; &#125; finally &#123; if (in != null) &#123; in.close(); &#125; if (out != null) &#123; out.close(); &#125; &#125; &#125;&#125; CopyBytes的大多数时间都花在：从输入流读一个字节，写一个字节到输入流上： 总是要关闭流在不需要使用一个流的时候关闭它是非常重要的————因此CopyBytes使用了一个finally块来保证所有的流即使出现错误也会关闭。这会帮助避免严重的资源泄漏。 一个可能的错误就是CopyBytes不能打开输入或输出文件。当这样的情况发生时，流中对应那个文件的变量就不会从其初值null改变到其他值。这就是为什么CopyBytes在close以前确保每个流变量都包含一个对象引用的原因。 什么时候不用字节流CopyBytes看起来像一个正常的程序，但实际上是应该避免使用这样的低级I/O。xanadu.txt包含的是字符数据，所以最好的方式是使用character stream，下一节会介绍。同样也有更加复杂的数据类型流。字节流应该只在最基本的I/O时使用。 那我们为什么要讨论字节流？因为所有的其他流都是从字节流上建立的。 字符流Java平台用Unicode存储字符。字符流I/O自动将这内部的格式翻译为本地字符集。在西文字符集中，本地字符集通常是 8-bit的 ASCII的一个超集。 大多数应用中，字符流IO不会比字节流IO复杂多少。输入输出通过流类进行，并且会自动转换成本地字符集。一个使用字符流而不是字节流的程序会自动使用本地字符集而且已经准备好国际化————不需要程序员的其他工作。 如果国际化的优先级不高，我们可以简单的关注字符流类。在后面国际化变得重要的时候，不需要太多的代价就能做到。查看Internationalization一节。 使用字符流所有的字符流类都从Reader, Writer衍生。和字节流样，也有针对文件IO的字符流：FileReader, FileWriter。CopyCharacters应用了这些类： import java.io.FileReader;import java.io.FileWriter;import java.io.IOException;public class CopyCharacters &#123; public static void main(String[] args) throws IOException &#123; FileReader inputStream = null; FileWriter outputStream = null; try &#123; inputStream = new FileReader(\"xanadu.txt\"); outputStream = new FileWriter(\"characteroutput.txt\"); int c; while ((c = inputStream.read()) != -1) &#123; outputStream.write(c); &#125; &#125; finally &#123; if (inputStream != null) &#123; inputStream.close(); &#125; if (outputStream != null) &#123; outputStream.close(); &#125; &#125; &#125;&#125; CopyCharacters 和CopyBytes非常相似。最重要的区别就是CopyCharacters使用FileReader, FileWriter来进行输入输出而不是使用FileInputStream,FileOutputStream。要注意到，CopyBytes, CopyCharacters都使用一个int变量来进行输入输出。然而，在CopyCharacters中int变量存储一个字符值是16-bits；而在CopyBytes中使用的int存储一个8-bits的byte值。 字符流使用的是字节流字符流通常是字节流的封装。字符流使用字节流来进行物理I/O，字符流处理在字符和字节间的转换。FileReader使用FileInputStream，FileWriter使用FileOutputStream。 有两个常规目的的 字节到字符的桥梁流：InputStreamReader, OutputStreamWriter。在没有预先打包好的字符流时候用他们来创建字符流。后面的章节会介绍通过 套接字类提供的字节流来建立字符流。 面向对象的I/O字符I/O通常在大的单元发生，而不是单个字符。一个经常出现的情况就是行：一系列字符后面跟上一个行终止符。行终止符经常是\\r\\n(carriage-retun/line-feed)，\\r，\\n。支持所有类型的终止符就允许程序员读取在各种系统上建立的文本。 我们修改CopyCharacters来读取行。为了干这活，我们要使用两个先前没有提到的类，BufferedRead, PrintWriter，更详细的东西我们在Buffered I/O和Formatting一节再说。现在，我们只关注行的I/O。 CopyLines例子使用BufferedReader.readLine, PrintWriter.println来每次输入输出一行： import java.io.FileReader;import java.io.FileWriter;import java.io.BufferedReader;import java.io.PrintWriter;import java.io.IOException;public class CopyLines &#123; public static void main(String[] args) throws IOException &#123; BufferedReader inputStream = null; PrintWriter outputStream = null; try &#123; inputStream = new BufferedReader(new FileReader(\"xanadu.txt\")); outputStream = new PrintWriter(new FileWriter(\"characteroutput.txt\")); String l; while ((l = inputStream.readLine()) != null) &#123; outputStream.println(l); &#125; &#125; finally &#123; if (inputStream != null) &#123; inputStream.close(); &#125; if (outputStream != null) &#123; outputStream.close(); &#125; &#125; &#125;&#125; readLine返回一行。CopyLines使用println来输出行，在每行后面加上一个终止符。这和输入文件中的终止符可能不同。 有很多中在字符和行间构造输入输出文本的方式，详细参考Scanning and Formatting一节。 Buffered Streams前面用的流都是不缓存的。意思就是每个读/写请求都会直接的请求一个OS级别的底层请求。这就让程序非常的低效，因为每个请求都会进行磁盘访问，网络检测，或者一些其他昂贵的操作。 为了减少这些消耗，Java实现了buffered I/O流。缓存的输出流从一个叫buffer的内存区域读取数据，只有在buffer空了以后才会呼叫底层API。类似的，只有输出缓存区满了以后才会呼叫底层API进行写入磁盘操作。 程序可以把不缓存的IO转换成缓存的IO，前面我们已经用过几次。将不缓存的流对象传输给缓存流类的构建器就行。这就是上文我们修改来使用缓存IO的地方： inputStream = new BufferedReader(new FileReader(&quot;xanadu.txt&quot;));outputStream = new BufferedWriter(new FileWriter(&quot;characteroutput.txt&quot;)); 有四个缓存流类用来封装未缓存的流：BufferedInputStream, BufferedOutputStream建立缓存的字节流，BufferedReader, BuffereWriter用来建立缓存字符流。 刷新缓存流要在缓存没有满的时候写出buffer，我们称之为刷新。 某些缓存的输出类支持自动刷新，通过指定一个可选的构建器参数。当开启自动刷新的时候，特定事情就会触发缓存的刷新。比如，一个开启了自动刷新的PrintWriter对象会在每个println, format后刷新缓存。参考Formatting一节。 手动刷新一个流的时候，使用flush方法。所有的输出流都有这个方法，但只有在流是缓存的时候有用。 扫描和格式化scannerAPI将输出打碎成不同的符号，formatting把数据组织成人类易读的形式展示。 扫描Scanner对象会将格式化的输入根据数据类型翻译成不同的符号形式。 将输出打散成符号默认情况，一个scanner使用空白符来分隔符号。（空白符号包括：空白，tab，行终止符）完整列表可以参看Character.isWhitespace的文档。想知道扫描怎么样工作的话，我们看看ScanXan这个程序，这用来读取xanadu.txt中独立的单词，然后输出他们，一次一行： import java.io.*;import java.util.Scanner;public class ScanXan &#123; public static void main(String[] args) throws IOException &#123; Scanner s = null; try &#123; s = new Scanner(new BufferedReader(new FileReader(\"xanadu.txt\"))); while (s.hasNext()) &#123; System.out.println(s.next()); &#125; &#125; finally &#123; if (s != null) &#123; s.close(); &#125; &#125; &#125;&#125; ScanXan调用了Scanner的close方法。即使scanner不是一个流，但是我们也需要进行关闭来表示我们已经不需要底层的流。 输出：InXanadudidKublaKhanAstatelypleasure-dome... 想要使用一个不同的分隔符，调用useDelimiter()，指定一个正则表达式。比如，想要使用,作为分隔符，后面还可能跟上空白符： s.useDelimiter(&quot;,\\\\s%&quot;); 转换各符号ScanXan把输入都当做String值。Scanner支持所有的Java语言基本类型（除了char），BigInteger, BigDecimal也支持。同样，数值可以使用千位分隔符。因此，在US字符集中，Scanner可以正确的读取32,767这个整数值。 必须提到本地化，因为千位分隔符和十位符号根据本地化而不同。如果我们没有指定scanner应该使用US本地化的时候，下面的例子可能不会在所有的地方工作得正常。这不应该是经常担心的事情，因为输入和你一般都使用同样的本地化设置。但是这个例子全世界的人可能都会看到。 ScanSum例子读取一系列double的值，并且求和。 import java.io.FileReader;import java.io.BufferedReader;import java.io.IOException;import java.util.Scanner;import java.util.Locale;public class ScanSum &#123; public static void main(String[] args) throws IOException &#123; Scanner s = null; double sum = 0; try &#123; s = new Scanner(new BufferedReader(new FileReader(\"usnumbers.txt\"))); s.useLocale(Locale.US); while (s.hasNext()) &#123; if (s.hasNextDouble()) &#123; sum += s.nextDouble(); &#125; else &#123; s.next(); &#125; &#125; &#125; finally &#123; s.close(); &#125; System.out.println(sum); &#125;&#125; 输入文件usnumbers.txt:8.532,7673.141591,000,000.1 输出是1032778.74159。句点可能有所不同，因为System.out是PrintStream对象，这个流类型不支持重写默认字符集。我们可以重写整个程序的本地化设置————或者我们只能使用 formatting，就跟下一节Formatting介绍的一样。 格式化实现格式化的流对象是PrintWriter（字符流类），PrintStream（字节泪类）的实例。 只会需要的PrintStream对象可能是System.out, System.err。查看命令行来的I/O来了解。当要建立一个格式化的输出流时，使用PrintWriter，而不是PrintStream。 跟所有的字节和字符流对象相似，PrintStream, PrintWriter实现了一些标准的write方法来进行简单的字节、字符输出。更多地，PrintStream, PrintWriter都实现了相同的用来转换内部数据到格式化输出的方法。两个等级的格式化被提供： print, println把不同的值以标准方式格式化 format通过格式化字符串来格式化各种值，还有更多的选项可以支持。 print println方法print,println会简单的将一个值调用toString方法后进行输出。我们看一下Root例子： public class Root &#123; public static void main(String[] args) &#123; int i = 2; double r = Math.sqrt(i); System.out.print(\"The square root of \"); System.out.print(i); System.out.print(\" is \"); System.out.print(r); System.out.println(\".\"); i = 5; r = Math.sqrt(i); System.out.println(\"The square root of \" + i + \" is \" + r + \".\"); &#125;&#125; 输出： Here is the output of Root:The square root of 2 is 1.4142135623730951.The square root of 5 is 2.23606797749979. i, r变量被格式化了两次：第一次是使用print的时候，第二次是被Java编译器的转换代码，也是利用toString。我们可以用这样的方式进行格式化，但是对于结果我们没有什么控制力。 format 方法format方法基于format string(格式化字符串)格式化多个参数。格式化字符串由格式化字符嵌入的静态文本组成。格式化字符串支持多个特性；在这个文档里，我们只讨论一些基本的。完整的讨论参考API中format string syntax。 Root2用一个format语句来格式化两个值： public class Root2 &#123; public static void main(String[] args) &#123; int i = 2; double r = Math.sqrt(i); System.out.format(\"The square root of %d is %f.%n\", i, r); &#125;&#125; 输出： The square root of 2 is 1.414214. 跟本例中使用的一样，所有的格式化指示符都用%开始，然后加上一个或2个字符的转换说明。三个使用到的指示符是： d 整数到十进制 f 浮点到十进制 n 平台相关的行终止符更多： x 整数到十六进制 s 转换为字符串 tB 整数到本地月名 除来%%, %n所有的指示符都要匹配一个参数。如果没有的话就会出错。在Java中，\\n产生一个换行符\\u000A。在不是一定要使用这个值的时候，不建议使用\\n，使用%n来获得平台上正确的行分隔符。 格式化指示符还可能包含几个附加的元素用来自定义输出。下面就是一个例子。Format，使用每个可能的元素。 public class Format &#123; public static void main(String[] args) &#123; System.out.format(\"%f, %1$+020.10f %n\", Math.PI); &#125;&#125; 输出： 3.141593, +00000003.1415926536 元素必须按以下的顺序：从右至左： 精度：对于浮点数，这是格式化值的数学精度。对于s，这是指定的最大宽度，如果超过的话，截短右边。 宽度：最小宽度；必要时填充。默认情况是填充左边。 标志：+表示带符号；0表示当做填充符；-从右填充；,本地千位分隔符。 参数索引：这允许明确的指定匹配的参数。也可以使用&lt;来指定匹配和前一个相同的参数。因此：System.out.format(“%f, %&lt;+020.10f %n”, Math.PI)。命令行I/O程序经常从命令行运行，和用户通过命令行变量来交互。Java支持两种方式的命令行交互：通过 标准流 和 Console。 标准流标准流是很多系统的特性。默认情况下，从键盘输人，从显示器输出。同样支持文件I/O和程序间I/O，但这个特性是被命令行解释器控制，而不是程序。 Java支持三个标准流：Standard Input，通过System.in访问；Standard Output, 通过 System.out访问; Standard Error, 通过 System.err访问。这些对象是自动定义的，不需要进行打开。标准错误和标准输出都是输出。 你可能会希望标准流是一个字符流，但是，因为历史原因，他们就字节流。System.out, System.err被定义成PrintStream对象。尽管技术上来说这是一个字节流，但是PrintStream有一个内部的字符流对象来表现出很多字符流的特性。 相反，System.in是一个具有字符流特性的字节流。想叫标准输入当做字符流使用，在InputStreamReader中封装System.in。 InputStreamReader cin = new InputStreamReader(System.in); The Console一个更加高级可选的标准流选择是Console。这是一个单一的，预先定义的Console类型的对象，其提供了标准流提供的大部分特性，和其他一些功能。Console对于密码安全是非常的实用。Console对象提供字符流进行输入输出，通过reader, writer方法。 在使用Console前，必须通过System.console()来获取Console对象。如果返回NULL，说明这个Console操作不被允许，或者系统不支持，或者程序是以非交互模式运行的。 Console通过其自身的readPassword方法来支持密码安全。这个方法以两种方式进行帮助。首先，减少回显，所以密码在用户屏幕上是不可见的。第二，readPassword返回一个字符数组，而不是String，所以密码可以在不需要的时候马上被重写，移除。 Password例子是一个修改用户密码的原型。展示了几个Console方法： import java.io.Console;import java.util.Arrays;import java.io.IOException;public class Password &#123; public static void main (String args[]) throws IOException &#123; Console c = System.console(); if (c == null) &#123; System.err.println(\"No console.\"); System.exit(1); &#125; String login = c.readLine(\"Enter your login: \"); char [] oldPassword = c.readPassword(\"Enter your old password: \"); if (verify(login, oldPassword)) &#123; boolean noMatch; do &#123; char [] newPassword1 = c.readPassword(\"Enter your new password: \"); char [] newPassword2 = c.readPassword(\"Enter new password again: \"); noMatch = ! Arrays.equals(newPassword1, newPassword2); if (noMatch) &#123; c.format(\"Passwords don't match. Try again.%n\"); &#125; else &#123; change(login, newPassword1); c.format(\"Password for %s changed.%n\", login); &#125; Arrays.fill(newPassword1, ' '); Arrays.fill(newPassword2, ' '); &#125; while (noMatch); &#125; Arrays.fill(oldPassword, ' '); &#125; // Dummy change method. static boolean verify(String login, char[] password) &#123; // This method always returns // true in this example. // Modify this method to verify // password according to your rules. return true; &#125; // Dummy change method. static void change(String login, char[] password) &#123; // Modify this method to change // password according to your rules. &#125;&#125; Password类遵循以下步骤： 尝试获取Console对象，如果对象不可用，退出； 通过Console.readLine来提示和获取用户的登录名； Console.readPassword提示和读取用户现在的密码； verify来确定用户被授权修改密码（在这里，verify总是返回true）； 一直循环，直到用户输出了同样的密码两次，然后重写密码： 用空白重写旧密码 数据流数据流支持基本数据类型值的（boolean, char, byte, short, int, long, fload, double）和String二进制I/O。所有的数据流都实现了DataInput, DataOutput接口。本节聚焦在广泛使用的这两个接口的实现，DataInputStream, DataOutputStream。 DataStreams例子展示了数据流，其通过写出一系列数据记录，然后读出来。每个记录由三个值构成，如下表所示： order type des output method input method value 1 double Item price DataOutputStream.writeDouble DataInputStream.readDouble 19.99 2 int Unit count DataOutputStream.writeInt DataInputStream.readInt 12 3 String Item des DataOutputStream.writeUTF DataInputStream.readUTF “Java T-Shirt” 我们先来测试在DataStreams内重要的代码。首先，程序定义了一些包含数据文件名字的常量和要写出的数据： static final String dataFile = \"invoicedata\";static final double[] prices = &#123; 19.99, 9.99, 15.99, 3.99, 4.99 &#125;;static final int[] units = &#123; 12, 8, 13, 29, 50 &#125;;static final String[] descs = &#123; \"Java T-shirt\", \"Java Mug\", \"Duke Juggling Dolls\", \"Java Pin\", \"Java Key Chain\"&#125;; 然后 DataStreams打开一个输出流。因为DataOutputStream只能被创建为一个已存在字节流的封装对象，DataStreams提供了一个缓存的文件输出字节流。 out = new DataOutputStream(new BufferedOutputStream(new FileOutputStream(dataFile))); DataStreams写出记录然后关闭输出流： for (int i = 0; i &lt; prices.length; i ++) &#123;out.writeDouble(prices[i]);out.writeInt(units[i]);out.writeUTF(descs[i]);&#125; writeUTF方法以一种修改过的UTF-8格式写出String值。这是一个变长的编码，对于普通的西文字符只需要一个字节。 in = new DataInputStream(new BufferedInputStream(new FileInputStream(dataFile)));double price;int unit;String desc;double total = 0.0; 现在DataStreams可以从流中读取每个记录，然后报告其遇到的数据。 try &#123; while (true) &#123; price = in.readDouble(); unit = in.readInt(); desc = in.readUTF(); System.out.format(\"You ordered %d\" + \" units of %s at $%.2f%n\", unit, desc, price); total += unit * price; &#125;&#125; catch (EOFException e) &#123;&#125; 注意到DataStreams通过捕捉EOFException来检测文件结束条件，而不是通过测试一个不合法的返回值。DataInput的所有实现方法都使用EOFException而不是返回值。 也要注意到，DataStreams中每个特殊的write确切的匹配对应的特殊的read。确保输出类型和输入类型是这样匹配的是程序员的责任：输入流由简单的二进制数据组成，没有什么东西来表明它是什么类型的数据，或者他们从流什么地方开始。 DataStreams使用了一个非常不好的编程技术：使用浮点数来表示货币值。一般来说 ，对于精确的数值来说浮点值不太好。十进制的分数也是很不好的，因为普通的值（如0.1)没有一个二进制的表达方式。 现在正确的表达货币的方式应该是java.math.BigDecimal。不幸的是，BigDecimal是一个对象类型，其与数据对象并不工作。然而，BigDecimal会在对象流中工作，下一节介绍。 对象流就跟数据流支持基本数据类型的IO一样，对象流支持对象的IO。大部分，不是所有的标准类支持其对象的串行化。也就是说实现了接口Serializable。 对象流类是ObjectInputStream, ObjectOutputStream。这些类实现了ObjectInput, ObjectOutput方法，这是DataInput, DataOutput的子接口。这就意味着基本数据的IO方法在对象流内也已实现。所以一个对象流可以包含基本和对象值的混合。ObjectStreams例子显示这点。 ObjectStreams如DataStreams一样创建类似的应用，但有一些变化。首先，价格现在是BigDecimal对象，为了更好的来表示小数。然后，Calendar对象被写到数据文件，表示一个统计时间。 如果readObject()返回了期待的对象类型，尝试把它转换到一个正确的类型会抛出一个ClassNotFoundException错误。在这个例子中，这不会发生，所以我不试图捕捉这个异常。作为替代，我们通过增加一个ClassNotFoundException在main方法中来通知编译器我们要捕捉的问题。 混合对象的输入输出writeObject, readObject方法的使用是非常简单的，不过其具有非常复杂的对象管理逻辑。对于Calendar这种只封装了基本类型值的类这是不重要的。但是某些对象包含了对其他对象的引用。如果readObject会重新从一个流建立一个对象，它必须能重建所有原始对象参考的对象。这些对象又会拥有他们自己的引用对象等等。在这种情况下，writeObject遍历整个对象引用网络，并把网络中的所有对象写到流。那么，一个简单writeObject就会导致很多对象被写到流内。 下面的图边展示了这一点，这里writeObject准备写一个叫做a的对象。这个对象包括了对对象 b, c的引用，而b 包含了对d, e的引用。wirteObject(a)不止写出a，还包含所有重建a需要的对象，所以其他四个在此网络中的对象也会被写出。当a被readObject读回时，这些对象也被读了回来，并且所有的原始对象引用被保留。 你可能会担心如果一个流内的两个对象引用了同一个对象会发生什么。是不是他们在读回的时候都引用一个单一的对象？答案是肯定的。一个流只能包含一个对象的一份拷贝，但可以包含任意多个对它的引用。因此，如果你显式的把一个对象写到一个流两次，实际上只是写出了两次引用而已。比如，下面的代码写出对象ob两次到一个流： Object ob = Object();out.write(ob);out.write(ob); 每个writeObject比如被一个readObject匹配，所以从流中读回的代码看起来跟下面差不多： Object ob1 = in.readObject();Object ob2 = in readObject(); 这会获得两个变量，ob1, ob2，都引用同一对象。 然而，如果一个对象被写到两个不同的流，这是非常重复了。一个程序读回两个流会看到两个不同的对象。 文件IOjava.nio.file包及其相关包java.nio.file.attribute对访问默认文件系统的文件I/O提供了有力的支持。尽管API有很多 类 ，但我们只需要关注很少的一部分进入点就行了。你会发现这些API非常的直观和易用。 这节以 什么是路径？ 这个问题开始。然后，路径类，这个包的进入点。路径类(Path Class) 中和 句法操作 相关的方法被解释。接着就转移到其他基类，文件类(File Class)，此类中包含了处理文件操作的方法。首先先介绍一些文件操作上的一般性概念。然后，覆盖了 检查，删除，复制和移动文件的方法。 路径是什么？一个文件系统在某些形式的媒体上组织和存储文件，一般来说是硬盘，这样的话会方便获取。多数文件系统都使用的是 树形结构，或者层级结构。在树的顶端是一个（或多个）根节点。在根节点下，是文件和目录（在windows是文件夹）。每个目录都能包含文件和子目录。 The Path ClassPath类，是 java.nio.file包的基本进入点之一。如果应用程序使用文件I/O，那么你就应该学习一下这个类的强大特性。 跟其名字一样，Path 类是 一个文件系统路径的程序表达。 一个Path 对象包含文件名和组成这个路径的目录列表，可以用来测试，定位和操作文件。 一个 Path 实例反映了底层的平台。在Solaris OS中，Path 使用 Solaris 语法（/home/joe/foo），而在windows中，Path使用的是windows 语法（C:\\home\\joe\\foo）。一个 Path 不是系统独立的。你不能从一个Solaris文件系统的 Path 匹配到一个 windows 文件系统的 Path。 Path 对应的文件和目录可能不存在。你而可以建立一个 path实例，然后以多种方法操纵它：可以对它附加内容，和其他路径对比等。在合适的时候，可以使用Files类中的方法来检查与 path 对应的文件是否存在，或者创建这个文件，打开它，删除它，改变它的权限等。 下一节更详细的测试Path类。 Path OperationsPath类包含了很多方法，这些方法用来获取路径信息，访问路径元素，转换路径格式，或者取出路径的一部分。同样也有方法来匹配路径字符串的方法和移除一个路径中过多内容的方法。本节关注 Path类的方法，某些时候叫做 句法 操作，因为这些方法只是操纵路径自身而不访问文件系统。 建立路径Path 实例包含用来指定文件或目录位置的信息。当路径在被定义的时候，其会被给予一个或多个名字。一个根元素或者一个文件名可能被包含，但是都不是必须的。一个 Path 可能只有一个目录或一个文件名组成。 可以用下面的 get 方法（Paths 帮助类中）来建立一个 Path 对象： Path p1 = Paths.get(\"/tmp/foo\");Path p2 = Paths.get(args[0]);Path p3 = Paths.get(URI.create(\"file:///Users/joe/FileTest.java\")); Paths.get其实是下面代码的简短化： Path p4 = FileSystems.getDefault().getPath(\"/users/sally\"); 下面的例子假设你的用户目录是 /u/joe，建立 /u/joe/logs/foo.log，如果是在windows上则是 c:\\joe\\logs\\foo.log Path p5 = Paths.get(System.getProperty(\"user.home\"), \"logs\",\"foo.log\"); 获取路径信息可以想象Path以顺序化存储这些名字。目录结构中最高级别的元素位于索引0.最低级别的元素位于索引[n-1]，n 是path中名字元素的数量。path中包含了用来获取这些元素的方法。 如图： 下面的代码片段定义了一个Path实例，然后使用了几个方法来获取路径信息： // None of these methods requires that the file corresponding// to the Path exists.// Microsoft Windows syntaxPath path = Paths.get(\"c:\\\\home\\\\joe\\\\foo\");//Solaris syntaxPath path = Paths.get(\"/home/joe/foo\");System.out.format(\"toString: %s%n\", path.toString());System.out.format(\"getFileName: %s%n\", path.getFileName());System.out.format(\"getName(0): %s%n\", path.getName(0));System.out.format(\"getNameCount: %d%n\", path.getNameCount());System.out.format(\"subpath(0,2): %s%n\", path.subpath(0,2));System.out.format(\"getParent: %s%n\", path.getParent());System.out.format(\"getRoot: %s%n\", path.getRoot()); File Operations Checking a File or Directory Deleting a File or Directory Copying a File or Directory Moving a File or Directory Managing Metadata (File and File Store Attributes) Reading, Writing, and Creating Files Random Access Files Creating and Reading Directories Links, Symbolic or Otherwise Walking the File Tree Finding Files Watching a Directory for Changes Other Useful Methods Legacy File I/O Code Summary","categories":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/tags/Java/"},{"name":"编程","slug":"编程","permalink":"https://gowa2017.github.io/tags/编程/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}]},{"title":"sed几个有意思的例子","slug":"sed几个有意思的例子","date":"2018-01-19T04:20:35.000Z","updated":"2018-01-19T04:20:35.000Z","comments":true,"path":"SED-AWK/sed几个有意思的例子.html","link":"","permalink":"https://gowa2017.github.io/SED-AWK/sed几个有意思的例子.html","excerpt":"sed一般经常用做比较小的操作但是有时候也会遇到需要进行一些比较头疼的操作的时候，比如，反转行，反转文件等等。本节就对这些例子进行一个演示。","text":"sed一般经常用做比较小的操作但是有时候也会遇到需要进行一些比较头疼的操作的时候，比如，反转行，反转文件等等。本节就对这些例子进行一个演示。 反转行#!/usr/bin/sed -f# 空行无条件跳转，也就是直接开始下一个循环。/../! b# 在行的前后加上换行符s/^.*$/\\&amp;\\/# 跳转到标签 x，这里没有成功执行 s 命令，所以不会跳转过去。在 标签定义之前使用 t 命令，是为了重置条件tx# 标签定义及循环:xs/\\(\\n.\\)\\(.*\\)\\(.\\n\\)/\\3\\2\\1/tx# 删除加到行内的换行符s/\\n//g 把上面这个程序存为 reverse.sed我们以以下代码来进行说明: $ cat tmp.txt 123456789 执行命令： ./reverse.sed tmp.txt 987654321 确实跟我们想象的一样。 为了更清楚的展示一下这个过程，我们在 s命令中加上一个p命令，也就是: s/\\(\\n.\\)\\(.*\\)\\(.\\n\\)/\\3\\2\\1/p 然后再执行命令： ./reverse.sed tmp.txt 9 2345678 1 98 34567 21 987 456 321 9876 5 4321 987654321 可以看到，要反转的内容，永远都是被包含在 \\n … \\n 中的，通过对调 前一个 \\n和其后的字符 及后一个\\n和其后的字符 来保证永远在 \\n … \\n内。 反转文件内的行 注意，这个程序在非 GNU 的sed可能会溢出。 #!/usr/bin/sed -nf# 第二行开始，把 hold buffer中的内容附到 模式空间1! G#在最后一行打印模式空间$ p# 把所有内容存到 hold buffer内去h 流程是： 读入第一行，然后放到 buffer 读入第二行，然后把 buffer 附到 模式空间 把模式空间存储到buffer 清空模式空间，读入第三行，再把buffer的内容附到模式空间 ……. 最后一行，附加buffer内容 打印出来","categories":[{"name":"SED&AWK","slug":"SED-AWK","permalink":"https://gowa2017.github.io/categories/SED-AWK/"}],"tags":[{"name":"sed","slug":"sed","permalink":"https://gowa2017.github.io/tags/sed/"}],"keywords":[{"name":"SED&AWK","slug":"SED-AWK","permalink":"https://gowa2017.github.io/categories/SED-AWK/"}]},{"title":"sed中的分支与流程控制","slug":"sed中的分支与流程控制","date":"2018-01-19T03:32:22.000Z","updated":"2018-01-19T03:32:22.000Z","comments":true,"path":"SED-AWK/sed中的分支与流程控制.html","link":"","permalink":"https://gowa2017.github.io/SED-AWK/sed中的分支与流程控制.html","excerpt":"sed是一个非常强大的工具，对于文本编辑来说。然而，很多时候可能我们用不到这节介绍的分支跳转与流程控制，但是某些时候又是非常有用的。因为有些sed需要比较复杂来实现的功能，已经被用c来实现成了程序命令，所以不太实用了，不过对于想要专注于sed的同学们来说，学习这个是非常有必要的。","text":"sed是一个非常强大的工具，对于文本编辑来说。然而，很多时候可能我们用不到这节介绍的分支跳转与流程控制，但是某些时候又是非常有用的。因为有些sed需要比较复杂来实现的功能，已经被用c来实现成了程序命令，所以不太实用了，不过对于想要专注于sed的同学们来说，学习这个是非常有必要的。 概述分支命令:b, t, T可以用来改变sed的工作流程。 默认流程：读入一行到 pattern space，按序执行命令进行处理。没有地址指定的命令应用到所有行。 sed并不支持 if/then/else 语句。其使用几个命令来进行条件检测或改变执行流程： d 清理当前 模式空间， 忽略后面未执行命令，并不打印模式空间，重新开始循环处理。 D 删除模式空间的内容直到第一个换行符，不打印模式空间，忽略后面的命令，重新开始循环。[addr]X[addr]&#123; X ; X ; X &#125;/regexp/X/regexp/&#123; X ; X ; X &#125; 地址和正则式可以用来作为 if/then 的条件：如果 [addr] 匹配当前的模式空间，执行命令。比如：/^#/d 表示 ： 如果当前的模式空间匹配正则式^#（以 # 开头的行），然后就执行d命令：删除模式空间内的这行，不打印到标准输出，然后开始下一个循环。 b 无条件分支（跳转到标签，跳过或重复其他命令，并不重新开始一个循环）。结合地址使用，这个分支动作可以在特定的行上使用。 t 条件分支。读入一行后，当一个s///命令成功执行或其他条件分支动作后为真。 T 条件分支。与t相似，但是正好相反，只有当读入一行，并且没有成功的 s命令执行为真。 接下来的两个sed程序是等价的。第一个例子中，用b命令在包括l的行上跳过s///命令。第二个例子使用一个地址和!符号来在指定的行上进行替换。y///命令在所有行上执行。 $ printf &apos;%s\\n&apos; a1 a2 a3 | sed -E &apos;/1/bx ; s/a/z/ ; :x ; y/123/456/&apos;a4z5z6$ printf &apos;%s\\n&apos; a1 a2 a3 | sed -E &apos;/1/!s/a/z/ ; y/123/456/&apos;a4z5z6 分支与循环b, t, T后面可以跟随一个标签（一般是单个字母）。标签用一个冒号后跟一个或几个字母定义（比如，:x）。如果忽略了标签，那么会重新开始一个循环。要注意区别分支到标签和重新开始循环：当循环重新开始的时候，sed首先打印出当前的模式空间内容，然后读入下一行到模式空间。跳转到一个标签（即使是在程序开头）不会打印模式空间也不会读入下一行。 下面的程序是没有操作的。b命令（程序中唯一的命令）不带标签，所以其只是简单的重新开始一个循环。在每个循环中，模式空间内容被打印出来，并读取下一行： $ seq 3 | sed b123 下面的例子是一个无限循环—不会终止也不会打印任何东西。b命令跳转到x标签，但一个新的循环却永远不会开始： $ seq 3 | sed &apos;:x ; bx&apos;# The above command requires gnu sed (which supports additional# commands following a label, without a newline). A portable equivalent:# sed -e &apos;:x&apos; -e bx 分支几乎 用n, N命令配合完成的：两个命令都会读入下一行到模式空间，也都不等待循环重启。 在读入下一行前，n打印当前模式空间内容并清空，N附加一个换行符和下一行到当前的模式空间。 看看下面的两个例子： $ seq 3 | sed &apos;:x ; n ; bx&apos;123$ seq 3 | sed &apos;:x ; N ; bx&apos;123 两个例子都不是无限的，也不开始一个新的循环。 第一个例子中，n先打印模式空间内容，清空模式空间，再读入下一行。 第二个例子中，N把下一行附加到模式空间（前面添加一个换行符）。行被累计起来直到无新行可读，然后N结束sed。在sed终止的时候，循环结束动作被执行，打印出整个模式空间。 第二个例子需要 GNU sed，因为其使用的是非 POSIX-std 行为的N命令。 为了更多的测试这两个例子，看看下面的命令：printf &apos;%s\\n&apos; aa bb cc dd | sed &apos;:x ; n ; = ; bx&apos;printf &apos;%s\\n&apos; aa bb cc dd | sed &apos;:x ; N ; = ; bx&apos;printf &apos;%s\\n&apos; aa bb cc dd | sed &apos;:x ; n ; s/\\n/***/ ; bx&apos;printf &apos;%s\\n&apos; aa bb cc dd | sed &apos;:x ; N ; s/\\n/***/ ; bx&apos; 分支例子：连接行作为现实世界中使用分支的一个例子，在以=进行分行的文件中：$ cat jaques.txtAll the wor=ld&apos;s a stag=e,And all the= men and wo=men merely =players:They have t=heir exits =and their e=ntrances;And one man= in his tim=e plays man=y parts. 下面的程序使用/=$/作为条件：如果当前模式空间以=结尾，就会用N读取下一行，替换所有的=和后面的换行符，接着无条件分支b到程序开头，这并不会开始一个新的循环处理。如果模式空间不是以=结尾，执行默认动作：打印模式空间，开始新的循环： $ sed &apos;:x ; /=$/ &#123; N ; s/=\\n//g ; bx &#125;&apos; jaques.txtAll the world&apos;s a stage,And all the men and women merely players:They have their exits and their entrances;And one man in his time plays many parts. 还有个不同的办法：在所有行上（除了最后一行），N附加行到模式空间。一个s命令移除=\\n。如果s成功执行，t跳转到程序开头（不完成也不重启循环）。如果s失败，t就不会跳转。然后，P会打印模式空间中第一个换行符前的内容，D删除到第一个换行符。 $ sed &apos;:x ; $!N ; s/=\\n// ; tx ; P ; D&apos; jaques.txtAll the world&apos;s a stage,And all the men and women merely players:They have their exits and their entrances;And one man in his time plays many parts.","categories":[{"name":"SED&AWK","slug":"SED-AWK","permalink":"https://gowa2017.github.io/categories/SED-AWK/"}],"tags":[{"name":"sed","slug":"sed","permalink":"https://gowa2017.github.io/tags/sed/"}],"keywords":[{"name":"SED&AWK","slug":"SED-AWK","permalink":"https://gowa2017.github.io/categories/SED-AWK/"}]},{"title":"水管常用配件图解","slug":"水管常用配件图解","date":"2018-01-18T15:09:02.000Z","updated":"2018-01-18T15:09:02.000Z","comments":true,"path":"杂项/水管常用配件图解.html","link":"","permalink":"https://gowa2017.github.io/杂项/水管常用配件图解.html","excerpt":"家里装修，要整水了，才发觉水电工说的那些名词我一个都不懂，我就知道一个什么三通啊，四通，两通什么的，然后特意在网络上搜寻了一下，发现讲这些知识的有点少啊，所以特意把找到的知识重新做了一个记录。","text":"家里装修，要整水了，才发觉水电工说的那些名词我一个都不懂，我就知道一个什么三通啊，四通，两通什么的，然后特意在网络上搜寻了一下，发现讲这些知识的有点少啊，所以特意把找到的知识重新做了一个记录。 名称 图片 说明 应用场景 90度弯头 用于连接管转弯处 45度弯头 用于连接管转弯处 直接 又名套管，当管道不够长时，连接两根管道所用 三通 用于三路水管相接 绕曲管、过桥 用于两根水管在同一平面相交而不对接时使 内丝弯头 又名阴口弯头，内螺纹弯头，带丝接口用于连接龙头、水表、软管等，另一头连接 PP-R水管。带丝接口的配件较贵，一个带丝接头有时比一米水管的价格都贵 内丝三通 又名阴口三通，内螺纹三通，带丝接口用于连接龙头、水表、软管等，另两端头连接PP-R水管。带丝接口的配件较贵，一个带丝接头有时比 一米 水管的价格都贵 管堵 也叫闷头，水管安装好用于暂时封闭出水口，装水龙头时取下 管卡 用于固定水管用 管卡 用于固定水管用 生料带 用于带丝接口与龙头、水表、软管等连接处，密封防水作用 内丝直接 又名阴口直接，内螺纹直接，带丝接口用于连接龙头、水表、软管等，另一头连接 PP-R水管。带丝接口的配件较贵，一个带丝接头有时比 一米 水管的价格都贵 外丝弯头 又名阳口弯头，外螺纹弯头，带丝接口用于直接连接热水器，另两端头连接 PP-R 水管。 外丝三通 又名阳口三通，外螺纹三通，带丝接口用于直接连接热水器，另两端头连接PP-R 水管。 外丝直接 又名阳口直接，外螺纹直接，带丝接口用于直接连接热水器，另两端头连接PP-R 水管。 截止阀 启闭水流用 球阀 启闭水流用 保温套 如果管子装在室外，最好装上保温套，以免管子冻坏掉","categories":[{"name":"杂项","slug":"杂项","permalink":"https://gowa2017.github.io/categories/杂项/"}],"tags":[{"name":"弯头","slug":"弯头","permalink":"https://gowa2017.github.io/tags/弯头/"},{"name":"管件","slug":"管件","permalink":"https://gowa2017.github.io/tags/管件/"},{"name":"水管","slug":"水管","permalink":"https://gowa2017.github.io/tags/水管/"}],"keywords":[{"name":"杂项","slug":"杂项","permalink":"https://gowa2017.github.io/categories/杂项/"}]},{"title":"java中的包","slug":"java中的包","date":"2018-01-18T01:37:03.000Z","updated":"2018-01-18T01:37:03.000Z","comments":true,"path":"Java/java中的包.html","link":"","permalink":"https://gowa2017.github.io/Java/java中的包.html","excerpt":"有的时候需要把具有相关关系的类组织在一起，而且对于可见性而言，同一个包内的类和方法默认是相互可见，所以将其组织成为一个包是非常的有必要的。","text":"有的时候需要把具有相关关系的类组织在一起，而且对于可见性而言，同一个包内的类和方法默认是相互可见，所以将其组织成为一个包是非常的有必要的。 创建和使用包为了让类型更加的容易查找和使用，避免命名冲突，权限控制，程序员可以把相关的类型组织到包里面。 定义：一个包是一系列相关联的类型的集合来提供权限保护和命名空间管理。这里的类型指的是类，接口，枚举和注释类型。枚举和注释是特殊的类和接口，因此，在这里我们说的类型一般是指 类 和 接口。 Java平台本身的类型被是很多通过函数组织类的包成员；基础的类在java.lang内，读写I/O类在java.io。 假设你编写了一系列代表图形对象的类，比如，圆、矩形、线和点。同时还有一个接口Draggable，如果某类可以被鼠标拖动，就实现了这个接口。 //in the Draggable.java filepublic interface Draggable &#123; ...&#125;//in the Graphic.java filepublic abstract class Graphic &#123; ...&#125;//in the Circle.java filepublic class Circle extends Graphic implements Draggable &#123; . . .&#125;//in the Rectangle.java filepublic class Rectangle extends Graphic implements Draggable &#123; . . .&#125;//in the Point.java filepublic class Point extends Graphic implements Draggable &#123; . . .&#125;//in the Line.java filepublic class Line extends Graphic implements Draggable &#123; . . .&#125; 可能会因为以下的原因把这些类和接口组织在一个包内： 你或者其他程序员可以了解哪些类型是相关的 你或者其他程序员可以知道到哪找到支持图形功能的类 类型里面的命名和其他包内的命名不会产生冲突 包内的类间具有不限制的权限，而包外的访问则不被允许。 创建为创建一个包，为包选择一个名字，然后在需要添加到包的每个源文件（包含了类，接口，枚举和注解）的第一行增加一个package声明。 package声明语句必须在源文件的第一行，同时一个文件只能有一个package声明，应用到文件中的所有类型。 如果在一个文件中放置了多个类型的话，只能使用一个public来定义其中类型，同时必须和源文件名一致。比如，可以定义public class Circle在 Circle.java文件内，定义public interface Draggable在Draggable.java文件内等等。也可以在同一文件中把non-public的类型指定为一个public类型（不推荐这种做法，除非这个non-public类型非常小而且和public类型关系很强），但只有和文件名相同的那个才能在外部访问。 如果把前文中的图形接口和类放在一个叫做 graphics ，大概需要6和文件： //in the Draggable.java filepackage graphics;public interface Draggable &#123; . . .&#125;//in the Graphic.java filepackage graphics;public abstract class Graphic &#123; . . .&#125;//in the Circle.java filepackage graphics;public class Circle extends Graphic implements Draggable &#123; . . .&#125;//in the Rectangle.java filepackage graphics;public class Rectangle extends Graphic implements Draggable &#123; . . .&#125;//in the Point.java filepackage graphics;public class Point extends Graphic implements Draggable &#123; . . .&#125; //in the Line.java filepackage graphics;public class Line extends Graphic implements Draggable { . . .} 如果不使用一个package声明，那么所有的类型默认在一个未命名的包内。未命名包只会在非常小或者临时的应用或刚刚开始一个项目的时候使用，更多时候应该以命名的包开始一个文件。 命名全世界都程序员都在用java编写类和接口，就会出现不同的程序员对不同的类型使用同样的命名。实际上，前一个例子只做了这个事情：在java.awt包已有一个Rectangle类的情况下定义了一个类Rectangle。编译器允许具有不同包的类具有同样的名字。对于Rectangle类的完整引用包含了包名。因此，对于graphics包中的Rectangle类的完整引用是graphics.Rectangle，而在java.awt中是java.awt.Rectangle。 这会工作得很好，但在不同程序员使用相同的包名和类名的时候就不行了。怎么样防止这样的情况呢？有约定。 命名约定包名全部小写，避免与类名或接口名冲突。 公司会使用他们域名的反转来左右包名开头————比如，com.example.mypackage这个包名表明mypackage这个包是由example.com上的程序员编写的。 在一个公司内出现命名的冲突由他们自己的约定来控制，或许在公司名后面加上区域或项目名（比如，com.example.region.mypackage）。 java本身的基础包由java. or javax 开头。 某些情况下，域名可能不是一个有效的包名。这在域名包含特殊符号或者连字符。以数字或者其他非法字符开头的包名是不允许的，包名也不能包含保留的关键字，如int。在这种情况下，建议的约定是加上一个下划线。比如： 域名 包名前缀 hyphenated-name.example.org org.exambple.hyphenated_name example.int int_.example 123name.example.com com.example._123name 使用包成员组成包的类型被称作包成员(package members)。 在包外想使用一个public的包成员，必须做下面其中一项： 通过完整引用成员 Import包成员 Import成员所属的整个包。 不同的情况适用不同的办法，接下来的章节会说到。 通过完整引用来使用截止现在，大多数例子都是通过简单的名字来引用类型，比如Rectangle和StackOfInts。在编写的代码属于同一个包，或那个包成员已经被导入。 如果想引用一个没有被导入的包成员，必须使用完整的引用，这包含了包名。下面是一个对定义在graphics包中的Rectangle类的完整引用例子： graphics.Rectangle 可以用完整引用来创建 graphics.Rectangle的一个实例： graphics.Rectangle myRect = new graphics.Rectangle(); 完整引用是不经常使用的。但是，当一个名字重复使用的时候，重复的敲同样的代码就非常的烦躁，代码也会变得难以阅读。因此，我们可以import这个成员，或者整个包，以便用简单的名字进行引用。 导入一个包成员要在当前文件导入一个成员，在任何定义之前，package声明（如果有）之后使用import声明。下面是如何在graphics中导入Rectangle类： import graphics.Rectangle 现在就可以用简单名字来引用Rectangle： Rectangle myRectangle = new Rectangle(); 在只使用graphics中少数几个成员的时候这工作得很好。但当你要使用一个包类的很多类型的时候，应该import整个包。 导入整个包下面是导入整个包： import graphics.*; 现在就可以通过简单名字来引用graphics中的所有类和接口了： Circle myCircle = new Circle(); Rectangle myRectangle = new Rectangle(); import声明中的*只能用来指定包内的所有类。其不能用来匹配包类的一些类。比如，下面的例子就不会匹配graphics包中以A开头的类： // does not workimport graphics.A*; 这将会产生一个编译错误。在import中，我们一般导入一个成员，或者整个包。 另外，很少使用的一种import格式允许导入 public嵌套的类。比如，在graphics.Rectangle类中包含了实用的嵌套类，比如Rectangle.DoubleWide和Rectangle.Square，可以用下面的语句导入Retangle及其嵌套的类：import graphics.Rectangle;import graphics.Rectangle.*;第二个语句将不会导入*Rectangle*。另外一个不常用的import形式，static import声明，将会在本节最后介绍。 为了方便，Java编译器会为每个源文件导入两个包： java.lang 当前包（当前文件的包） 包的层级首先，包看起来是分层的，但其实不是。比如，Java API包含了一个java.awt包，一个java.awt.color包，一个java.awt.font包，还有其他以java.awt开始的包。然后，java.awt.color， java.awt.font包，还有其他java.awt.xxxx包并不包含在java.awt包内。前缀java.awt(the Java Abstract Windows Toolkit)用来表示一大堆有关联的包，但并不表示包含关系。 导入java.awt.**会导入java.awt包中的所有类型，但是不会导入java.awt.color, java.awt.font或其他以java.awt.xxxx开头的包。如果现在我们想使用java.awt.color*中的类型，那么我们必须也进行导入。 import java.awt.*;import java.awt.color.*; 命名混乱如一个包内的成员名与另外一个包内的成员名相同，而两个包都已导入，那么必须用完整的引用来进行区别。比如，graphics包定义了一个类Rectangle。java.awt包也定义了一个Rectangle类。如果graphics, java.awt都已导入，下面的代码是不确定的： Rectangle rect; 在这样的情况下，必须使用完整引用来表示我们到底是用使用的是哪个包中的Rectangle类： graphics.Rectangle rect; 静态导入声明有些情况下，我们需要经常访问一些静态的字段(static final fields， 常量)和静态方法。 在这些类上加上前缀会导致一大堆代码。static import声明可以让我们导入要使用的静态方法和常量而不用在类前加上前缀。 java.lang.Math包定义了PI常量和很多静态方法，包括sin(), cos(), tan(), square(), max(), min(), exp(),等。比如： public static final double PI = 3.141592653589793;public static double cos(double a)&#123;...&#125; 我们要在其他类中使用这些对象的时候，要加上类名： double r = Math.cos(Math.PI * theta); 但我们可以使用static import声明来导入java.lang.Math的静态成员而避免使用前缀名。Math类的静态成员可以被分别导入： import static java.lang.Math.PI; 或按组： import static java.lang.Math.*; 一旦导入了，这些静态成员就不用进行完整引用了。比如，前面的例子可以用下面的来表示： double r = cos(PI * theta); 很明显，我们也可以编写包含静态常量和静态方法的类，以便经常使用。比如： import static mypackage.MyConstants.*; 谨慎的使用import static。频繁的使用这个语句会导致代码难以阅读和维护，因为阅读者很难清楚的知道到底哪个类定义了一个实际上的静态对象。合适的使用，import static通过移除类名重复让代码更易读。 管理源文件和类文件很多Java 平台的实现依赖分层的文件系统来管理源和类文件，即使这并不是Java Language Specification要求的。约束如下。 将类，接口，枚举，注解类型的代码放到一个一个 .java 结尾的文本内。比如： // in the Rectangle.java filepackage graphics;public class Rectange &#123;...&#125; 然后，将源文件放在一个包名对应的目录内。 .../graphics/Rectangle.java 对包成员名字的引用和对文件名字的路径是对应的（UNIX）： class name-graphics.REctangle pathname to file-graphics/Rectangle.java 可能你会意识到，一个公司会用他们反转的域名作为包名。比如我们在所有的包名前加上com.example。而包名的每个部位对应了一个子目录。因此，com.example.graphics包有一个Rectangle.java源文件，可能会像下面这样的形式在文件系统内体现： .../com/example/graphics/Rectangle.java 在编译源文件的时候，编译器会为每个定义的类型创建一个不同的输出文件。基本的名字是类型的名字，后缀是.class。比如，源文件是这样的： // in the Rectangle.java filepackage com.example.graphics;public class Rectangle &#123;...&#125;class Helper &#123;...&#125; 编译后的文件将会如下: &lt;path to the parent directory of the output files&gt;/com/example/graphics/Rectangle.class &lt;path to the parent directory of the output files&gt;/com/example/graphics/Helper.class 和.java源文件类似，编译后的.class文件也会有一系列的子目录来表示对应的包名。然后，.class文件不一定一定要和.java的路径一样。可以把源文件和类文件放在不同的目录中，如： &lt;path_one&gt;\\sources\\com\\example\\graphics\\Rectangle.java&lt;path_two&gt;\\classes\\com\\example\\graphics\\Rectangle.class 这样做的话，可以将classes目录给其他程序员而他们不能访问源文件。 我们应该这样来管理源和类文件以便编译器和JVM可以找到所有我们使用的类型。 classes目录的完整路径，path_to/classes，被称做class path，以环境变量CLASSPATH来设置。编译器和JVM都通过在这个路径后面加上类文件名来组成完整路径。比如： &lt;path_to&gt;/classes 是你的CLASSPATH，包名是com.example.graphics，那么，编译器和JVM就会在 &lt;path_to&gt;/classes/com/example/graphics 中去寻找.class文件。 默认情况下，编译器和JVM会搜索当前目录和包含 java 平台类的JAR文件，这些目录相当于自动包含到了类路径中。 设置 CLASSPATH 系统变量为了显示CLASSPATH变量，使用命令来进行展示： In Windows: C:\\&gt; set CLASSPATHIn UNIX: % echo $CLASSPATH 删除变量：In Windows: C:\\&gt; set CLASSPATH=In UNIX: % unset CLASSPATH; export CLASSPATH 设置变量：In Windows: C:\\&gt; set CLASSPATH=C:\\users\\george\\java\\classesIn UNIX: % CLASSPATH=/home/george/java/classes; export CLASSPATH 问题和练习假设你已经写了一些类。然后，你决定把他们放三个包内，如下表。而且现在这些类在默认包内（没有package语句）。 包名 类名 mygame.server Server mygame.shared Utilities mygame.client Client 为了将每个源文件放在正确的包内，要添加什么代码？ 我们需要创建一些子目录，并把源文件放在相应的地方。哪些目录是必须创建的？每个子目录对应哪个源文件？ 需要不需要更多的改变来使编译器正确运行？如果需要，为什么？","categories":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/tags/Java/"},{"name":"编程","slug":"编程","permalink":"https://gowa2017.github.io/tags/编程/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}]},{"title":"macOS中的服务管理launchdctl手册","slug":"macOS中的服务管理launchdctl手册","date":"2018-01-16T15:09:43.000Z","updated":"2018-01-16T15:09:43.000Z","comments":true,"path":"macOS/macOS中的服务管理launchdctl手册.html","link":"","permalink":"https://gowa2017.github.io/macOS/macOS中的服务管理launchdctl手册.html","excerpt":"对于CentOS中用systemctl来进行服务管理，又或者Solaris用的是SMF，但是对于macOS呢，其用的就是launchd来进行服务管理的，而用launchctl命令来进行服务的设置。本文是对launchctl手册的一个翻译。","text":"对于CentOS中用systemctl来进行服务管理，又或者Solaris用的是SMF，但是对于macOS呢，其用的就是launchd来进行服务管理的，而用launchctl命令来进行服务的设置。本文是对launchctl手册的一个翻译。 NAMElaunch — launchd的接口 命令格式launchctl *subcommand* *[arguments ...]* 描述launchctl接口通过launchd服务来管理和检查守护进程，代理服务和XPC服务。 SUBCOMMANDSlaunchctl 允许对 launchd 端口的详细测试。 一个domain（域）管理了一系列服务的执行策略。 一个服务可能会考虑称为一个虚拟进程以便其总能对请求进行响应。 每个服务有一系列端点，对这些端点发送消息会让服务启动。 主机建议这些端点在一个共享的命名空间内，并作为 Mach bootstrap子集同义。 很多子命令都用一个指示符来表明目标域或服务。指示符可能是以下形式： system/[service-name] 指定域或域中的服务。system域管理Mach 根启动器，其被认为是一个特权上下文。任何用户都可以读取或查询system域，但是修改的话就需要特权。user/\\/[service-name] 目标域为UID指定的user域，或为域中服务。每个登录的用户都有一个用户域独立存在。User域在iOS内不存在。login/\\/[service-name] 指定一个user-login域或此域中某一服务。当一个用户在GUI登录，并被与此次登录相关联的审计会话标识符所区别的时候进行创建一个user-login域。如果一个user域与一个login域相关联，print子命令会显示这个login域的ASID。user-login在iOS内不存在。gui/\\/[service-name] login标识符的另外一种形式。这个标识符基于用户来指定目标域，而不是通过ASID来指定user-login，这会更加的方便。 GUI域和user域共享很多资源。为了对Mach bootstrap名字进行寻找，他们共享同样注册名字的集合。但他们依然有不同的服务。所以呢，当打印user域的内容时，可能会看到很多在那个用户gui域中存在的Mach bootstrap名字注册，但是却看不到服务本身。 session/\\/[service-name] 指定目标域为给定的审计会话ID或者此域中的一个服务。对于更多关于审计会话的信息，参考auditon(2)和libbsm(3).pid/\\/[service-name] 指定目标域为指定的PID或者是此域中某一服务。系统中每个进程都有一个PID域与其关联，这由xpc_connection_create(3)函数能到达的进程可见的XPC服务组成。 bootstrap | bootout domain-target [service-path service-path2 ...] | service-target引导或移除域和服务。服务可能被一系列的路径或服务标识符区分。路径可能会指向XPC服务集（launchd.plist(5)），或者一个包含两者集合目录。如果在启动或者移除服务的时候出现错误，出现错误的路径将会与其发生的错误一起被打印出来。若没有指定路径或目标服务，这些命令可以启动或者移除域。某些域会隐式的启动一些预定义的路径，这作为域创建的一部分。 enable | disable service-target在请求的域内启用/停用服务。一个服务被禁止后将不能在特定的域内载入，比如在重新启动后才能载入。这个状态持久存在，即使设备重启。这个子命令只能指定system, user, user-login域中的服务。 uncache service-name让 launchd 绕过服务缓存，直接从磁盘读取服务的配置文件。launchd 维护一个 XCP服务配置文件的缓存区来减少磁盘I/O。这个命令删除一个缓存对象，开发者可以快速的观察服务的配置文件。在生产环境中不要使用。 kickstart [-kp] service-target立即启动指定的服务。-k 服务在运行，kill 了后重启服务。-p 成功时打印新进程的PID，或者打印已运行的PID到标准输出 attach [-ksx] service-target将系统调试器附在指定服务的进程上。默认情况下，如果服务未运行，这个子命令会睡眠直到服务启动。-k 服务运行的话，杀死后重启。-s 强制服务启动。-x 在执行和成为服务进程前先附到xpcproxy(3)。这个标志一般没有，只对 launchd 维护者有意义。 debug service-target [--program &lt;program path&gt;] [--guard-malloc] [--malloc-stack-logging] [--debug-libraries] [--introspection-libraries] [--NSZombie] [--32] [--stdin] [--stdout] [--stderr] [--environment] [--] [argv0 argv1 argv2 ...]配置下一个服务的调试。这个子命令允许将服务的可执行程序用另外一个路径进行替换，启动libgmalloc(3)，设置环境变量，设置参数向亮等等。这是对编辑launchd.plist(5)并进行重载的另外一个方便选择，附加的调试属性在服务运行一次后就进行清楚。—program launchd(8)使用 program-path作为服务的可执行程序。—guard-malloc 为服务启用libgmalloc(3)。—malloc-stack-logging 对服务开启malloc(3)的栈记录。 kill signal-name | signal-number service-target发送指定信号到服务。 blame service-target如果服务运行，以人类可读的形式打印出为什么 launchd 会运行这个服务。服务可能会因为多种原因而运行；这个命令只会打印最近的那个。如果一个服务是因为定时器超时，这个子命令就会打印此原因，而不会考虑此服务是否在多个端点上有信息。生产环境中不应该依赖这个命令的输出。 print domain-target | service-target打印域或服务的信息。域输出包括很多关于域的属性和服务列表与到达每个服务端点。服务输出包含很多属性，在磁盘上的原始信息，当前状态，执行上下文，最后退出状态。 IMPORTANT: 这些输出不是 API。不要依赖输出的结构。因为这可能在版本间变化而不会进行警告。 print-cache打印 launchd 服务的缓存内容。 print-disabled domain-target打印指定域中禁用的服务列表。 plist [segment, section] Mach-0打印嵌入到Mach-0目标中__TEXT, __info_plist段/节中的属性列表。 proinfo pid打印指定PID的执行上下文，需要特权。 hostinfo主机信息。需要特权。 resolveport owner-pid port-name需要特权。通过PID和属性port来获得端点。 examine [tool arg0 arg1 @PID ...] config system | user parameter value对launchd(8)域设置持久的配置信息。只能配置system, user域。持久存储的位置因实现而不同，对存储的改动只能通过 子命令进行。 要让变动生效，需要进行 reboot。支持的配置参数是：umask 将目标域中服务的umask(2)设置为value。path 将目标域内的所有服务的PATH环境变量设置为value。格式的话和environ(7)保持一致。如果某个服务设置了自己的PATH，其优先级将高于这个设置。 reboot [system | userspace | halt | logout | apps]卸载用户空间。无参数或者提供的是system参数，launchd会在用户空间卸载后调用reboot(2)。指定halt参数，会在用户空间卸载后调用reboot(2)系统调用和传递RB_HALT标志，挂起系统而不初始化一次重启。 指定userspace参数，launchd在用户空间卸载重新执行其自身，然后再唤醒用户空间。这在内核数据和硬件不需要重新初始化的时候进行快速启动非常有效。 指定logout参数，launchd 会关闭调用者的GUI登录会话，就跟从Apple菜单按钮上注销一样。不同的是，这会比点菜单快，也不会给应用展示一些其他信息的机会，这有可能造成一切数据冲突的可能。当你在确定没有未存储数据的时候再使用这个命令。 指定apps参数，launchd会终止所有才调用者GUI登录会话中运行的且不是来自硬盘上launchd.plist(5)中的程序。像Finder, Dock, SystemUIServer这些应用不受影响。-s 重启机器的时候（无论是完整的重启或用户空间重启），让接下来的启动会话进入单用户模式。 error [posix | mach | bootstrap] code对给定错误码打印出人类可读的信息。默认情况下，launchctl会尝试猜测错误代码属于哪一个错误域。也可以指定一个 error 域来对指定错误代码进行解释。 variant打印 launchd 中在系统上活跃的 变量。可能包含RELEASE, DEVELOPMENT, DEBUG。 version打印版本。 传统命令 load [-wF] [-S 会话类型] [-D domain] paths ...载入指定的配置文件或目录中的配置文件。 所有指定的工作会在允许启动前就被载入。Jobs that are not on-demand will be started as soon as possible.每个用户的配置文件（LaunchAgents）必须被其用户所拥有以便载入。所有系统级的服务（LaunchDaemons）必须被被root所拥有。配置文件不能是 组 或 其他可写的。基于安全目的进行这些限制，因为允许对launchd配置文件的写入也就允许某个用户指定启动其他的一些程序。 允许非root用户对/System/Library/LaunchDaemeons目录具有写权限将会导致系统无法启动。 -w 覆盖Disabled key并设置其为false。早些版本中，这个选项会修改配置文件。现在Disabled key的状态存储在磁盘的其他地方。-F 强制载入plist。忽略Disabled key。-S sessiontype 某些工作只对特定上下文敏感。这个标志会让launchctl在加上-D标志的时候在不同的位置去寻找工作，并允许launchctl来限制工作会再入哪种会话类型。当前已知的会话类型有：Aqua, LoginWindow, Background, StandardIO, System-D domain 在给定的主机上寻找以 *.plist结尾的 plist(5)文件。有效的主机包括system, local, network, all。 在指定一个会话类型的时候，一个额外的主机user可以被使用。举个例子，在没有指定会话类型的时候，-D system会在/System/Library/LaunchDaemons这个目录中的 属性列表文件（plists, property list files）载入文件。如果指定了会话类型的话，这会载入/System/Library/LaunchAgents下的plist文件。 unload [-W] [-S sessiontype] [-D domain] paths ... 卸载指定的配置文件或者目录。这会停止正在运行的任务。 -w 覆盖Disabled key并设置其为true。早些版本中，这个选项会修改配置文件。现在Disabled key的状态存储在磁盘的其他地方。-S sessiontype 某些工作只对特定上下文敏感。这个标志会让launchctl在加上-D标志的时候在不同的位置去寻找工作，并允许launchctl来限制工作会再入哪种会话类型。当前已知的会话类型有：Aqua, LoginWindow, Background, StandardIO, System-D domain 在给定的主机上寻找以 *.plist结尾的 plist(5)文件。有效的主机包括system, local, network, all。 在指定一个会话类型的时候，一个额外的主机user可以被使用。举个例子，在没有指定会话类型的时候，-D system会在/System/Library/LaunchDaemons这个目录中的 属性列表文件（plists, property list files）载入文件。如果指定了会话类型的话，这会载入/System/Library/LaunchAgents下的plist文件。 submit -l *label* [-p executable] [-o path] [-e path] -- command [args]一个不在配置文件内进行设置而使某个程序运行的简单方式。这会告诉launchd在出现失败事件时保持程序存活。-l label 为这个任务指定的唯一标签（传递给launchd）。-p program 要执行的程序。无论在submit子命令中 — 后面的任何参数。-o path 指定程序输出位置。-e path 指定程序的错误输出位置。 remove job_label 移除一个任务（通过标签）。 start job_label 通过标签启动特定任务。这个命令主要是用来调试和测试以便用户能手动启动某个被需要的服务。 stop job_label 通过标签来停止指定服务。如果这个任务是有需求的，launchd会在这个任务满足条件的时候立即重新启动。不是立即需求的基本工作总是会被重启。这个命令不推荐使用。任务自己会超时停止。 list [-x] [label] 没有参数的时候，用三列（PID, Status, Label）列出所有 launchd 载入的任务。PID会在运行的时候显示，否则就是一个-号。第二列指出任务上次的退出状态，如果是负值，则指定的是杀死任务的信号。比如，-15代表任务是被SIGTERM信号终止。第二列指的是任务标签。 可能某些任务的风格是0xdeadbeef.anony-mous.program。这些是没有被 launchd 管理的任务但在某些时候对其发生了请求。 launchd 对这些任务没有权限也不保证什么。这些任务单纯只是做了一个记录。 某些标签是0xdeadbeef.mach_init.program的任务是在mach_init模拟器下运行的任务。这个特性会在将来版本移除，所有的mach_init任务都会转换到launchd。 如果 [label] 指定，那就打印特定的任务信息。如果[-x]指定，那么将以XML属性列表的形式输出信息。 setenv key valud 为 launchd 程序设置环境变量 unsetenv key 移除 launchd 程序的环境变量 getenv key 获取环境变量的值 export 导出所有的环境变量，以便在 shell的一个 eval 声明中使用 getusage self l children 获取 launchd 的资源使用状态或 其子进程的资源使用状态 log [level loglevel] [onley | mask loglevels...] 获取及设置syslog(3) 日志等级掩码。可用的级别是7个：debug, info, notice, warning, error, critical, alert, emergency limit [cpu | filesize | data | stack | core | rss | memlock | maxproc | maxfiles] [both [sort | hard]] 没有参数时，这打印出所有通过getrlimit(2)系统调用获取的资源限制信息。当指定了其中的一个资源作为参数，就打印对应参数的信息。当有第三个参数的时候，软、硬限制设置为同一值。当有第四个参数是，第三、四参数分别代表了要设置的软、硬限制。 参考setrlimt(2)系统调用 shutdown 通知 launchd 移除所有任务，准备关闭。 umask [newmask] 获取或设置 launchd 的umask(2) 文件掩码 bslist [PID | ..] [-j] 被print命令代替。 bsexec PID command [args] asuser PID command [args] bstree print命令进行了替代。 managerpid manageruid managername help 警告命令的输出不应该被脚本或者程序所依赖，因为其格式和内容是会变化的。 反对和移除的功能launchctl 不再有交互模式，也不从标准输出接受命令。/etc/launchd.conf文件不再查询子命令执行；这是因为安全原因而移除。 launchd不再使用 Unix domain sockets来进行通信。 launchd 不再从网络载入配置文件。 文件 ~/Library/LaunchAgents Per-user agents provided by the user. /Library/LaunchAgents Per-user agents provided by the administrator. /Library/LaunchDaemons System wide daemons provided by the administrator. /System/Library/LaunchAgents OS X Per-user agents. /System/Library/LaunchDaemons OS X System wide daemons. 退出状态成功返回0，如果失败的话，返回的错误码可以给 error子命令进行解析。 相关阅读launchd.plist(5), launchd(8), audit(8), setaudit_addr(2) 配置文件(launchd.plist(5))一个被launchd管理的守护进程或代理期望以特定的方式表现。 我们在这把 守护进程或代理 称为服务。 一个通过 launchd 启动的服务的进程必须不能在其进程内： 调用daemon(3) 与daemon(3)等价的事情，包括fork(2), exit(3), _exit(2)。 一个服务在初始化的时候不应该执行下面的过程，因为launchd总是会自动在进程中进行： 重定向stdio(3)到/dev/null 一个服务在初始化的时候不需要进行下面的操作，launchd会根据launchd.plist设置的键来确定是否需要执行： 设置 userID/group ID 设置 CWD chroot(2) setsid(2) 关闭迷路的文件描述符 用setrlimit(2)设置资源限制 用setpriority(2) 设置调度优先基 一个服务应该： 在XML 属性列表中给定条件满足的时候启动。更多信息见后面。 捕捉SIGTERM信号，首选的是dispatch(3)，完成工作后快速的退出。 XML属性列表键下面的键用来描述服务的配置细节。属性列表是苹果的标准配置文件格式。查看plist(5)获取更多信息。 属性列表文件的名字应该用.plist结尾。如果服务的标签是com.apple.sshd，那么plist文件应该是com.apple.sshd.plist。 Lable 唯一的标识 launchd 中的一个任务。 Disable 设置默认是否载入。可以用 launchctl(3) enable Lable进行重新配置，但不会写入配置文件。 UserName 指定运行服务的用户。只有对载入到特权的系统域中的服务有效。 GroupName 指定运行组。特权系统域中有效。如果指定UserName而不指定GroupName，那么其会被设置为UserName的组。 inetdCompatibility 用来表明是不是要从 inetd 启动那样运行服务。新的项目应该避免使用这个键。 Wait 对应 inetd中的wait, nowait。 LimitLoadToHost 不再支持 LimitLoadFromHost 不再支持 LimitLoadToSessionType 此配置文件只对指定会话类型应用。这一般只对代理程序应用。在特权的系统上下文中没有区别会话。 LimitLoadToHardware 配置文件只应用到指定的硬件上。在字典内的每个键定义了sysctl(3) hw域中的一个子域。例如，键machine的值是MacBookPro4,2只会在机器的hw.machine值为MacBookPro4，2时应用。 Program 可执行程序绝对路径。execv(3)的第一个参数。如果这个键不存在，那么提供给ProgramArguments键的第一个元素就会被作为程序使用。如果没有ProgramArguments键，这个值是必须的。 ProgramArguments execvp(3)的第二个参数，指定了参数向量。没有Program键时是需要的。 如果有些迷惑的话，仔细阅读execvp(3)。Program必须是绝对路径。 EnableGlobbing 使用glob(3)来更新程序参数后再执行。 EnableTransactions 搞不动了，自己参考 man 文档吧。","categories":[{"name":"macOS","slug":"macOS","permalink":"https://gowa2017.github.io/categories/macOS/"}],"tags":[{"name":"macOS","slug":"macOS","permalink":"https://gowa2017.github.io/tags/macOS/"},{"name":"launchd","slug":"launchd","permalink":"https://gowa2017.github.io/tags/launchd/"}],"keywords":[{"name":"macOS","slug":"macOS","permalink":"https://gowa2017.github.io/categories/macOS/"}]},{"title":"Word2007利用模板和快速样式进行格式化文档","slug":"Word2007利用模板和快速样式进行格式化文档","date":"2018-01-15T18:12:30.000Z","updated":"2018-01-15T18:12:30.000Z","comments":true,"path":"Office/Word2007利用模板和快速样式进行格式化文档.html","link":"","permalink":"https://gowa2017.github.io/Office/Word2007利用模板和快速样式进行格式化文档.html","excerpt":"其实对于经常性的要对文档进行排版，或者撰写的文档具有某一相似的格式的话，那么其实可以修改一下默认的模板，然后进行一个统一性的方便设置的。而对于已经编辑好了的文档，想要对其进行格式化的话也是具有好办法的。","text":"其实对于经常性的要对文档进行排版，或者撰写的文档具有某一相似的格式的话，那么其实可以修改一下默认的模板，然后进行一个统一性的方便设置的。而对于已经编辑好了的文档，想要对其进行格式化的话也是具有好办法的。 修改默认模板对于Word2007，其会有一个名叫做Normal.dotm的模板文件，这就是你的默认设置。想要直接编辑这个文件，有一个不错的技巧。步骤如下： 点击左上角的图标。 点击打开。 选择受信任的模板。 打开Normal.dotm文件。 对字体、边距、间距以及其他设置进行任意所需更改。可以使用更改文件所用的命令和功能，但请记住，对 Normal.dotm 所作的任何更改都将应用于以后创建的文档。 完成后，单击Office 按钮图像 ，然后单击“保存”。 也可以参考这个页面的说明：如何修改默认word2007模板 接下来我们就可以在打开的装个文档内进行修改页边距、字体、样式等等内容，然后进行保存，下一次打开的新文档将会以此为基础进行创建了。 典型的，我们会修改： 页面设置（页边距、页眉、页脚、页码、页面大小） 样式设置（标题样式、正文样式、默认段落样式） 已建立文档都格式化对于已经编辑完毕了，但是格式并不符合我们要求的文档，那么就需要手动进行来操作了。我们可以利用一下快速访问工具栏和自动以快捷键的方法来进行。首先我们要知道，所有菜单上、功能区上可以用鼠标点击的地方，都可以通过右键点击然后添加到自定义功能区。如： 点击插入--&gt;页眉--&gt;右键删除页眉--&gt;添加到快速访问工具栏。 点击插入--&gt;页眉--&gt;右键删除页脚--&gt;添加到快速访问工具栏。 点击页面布局--&gt;页边距--&gt;右键上次的自定义设置--&gt;添加到快速访问工具栏 点击开始--&gt;更改样式--&gt;样式集--&gt;右键重置为模板中的快速样式--&gt;添加到快速访问工具栏 点击开始--&gt;右键更改样式右下角的小箭头--&gt;添加到快速访问工具栏 现在我们如果要格式化一个已经编辑好的文档，那么顺序点击上面几个步骤添加到快速访问工具栏上的图标。同时会打开格式格局栏菜单，这里我们可以看到所有我们定义的样式和文档中存在的样式。 我们可以： 选中内容，点击样式工具栏中的样式应用样式。 右键样式，选中样式的实例，在点击其他样式进行修改。 修改样式。 对于一个结构安排的很好的文档，其内容和样式是非常简单干净的。可以通过上面的第二部就能干完所有的事情。但往往很多文档并不是这样的，所以这才是最头疼的事情。这个时候，没有办法，只能通过清楚所有样式，然后重新进行排版和应用样式；或者在现有的格式上进行修改了。因此，做一个结构好的文档修改起来非常的方便的。 如何组织文档内容？ 预先定义好要使用的各种样式。如标题的字体、行距、大小、对齐、缩进等等。 撰写内容，然后对内容个部分应用样式。 不要对可以用定义好样式进行排版的内容，采用一步步进行改变其字体、行距、对齐等的操作，这是非常没有效率而且不好维护的。","categories":[{"name":"Office","slug":"Office","permalink":"https://gowa2017.github.io/categories/Office/"}],"tags":[{"name":"Word","slug":"Word","permalink":"https://gowa2017.github.io/tags/Word/"},{"name":"Office","slug":"Office","permalink":"https://gowa2017.github.io/tags/Office/"}],"keywords":[{"name":"Office","slug":"Office","permalink":"https://gowa2017.github.io/categories/Office/"}]},{"title":"java语言基础","slug":"java语言基础","date":"2018-01-10T15:19:21.000Z","updated":"2018-01-10T15:19:21.000Z","comments":true,"path":"Java/java语言基础.html","link":"","permalink":"https://gowa2017.github.io/Java/java语言基础.html","excerpt":"介绍了一些语言的基础，如变量，操作符，表达式，语句，块，流程控制等基本的语言元素。有点基础的可能看起来比较简单。","text":"介绍了一些语言的基础，如变量，操作符，表达式，语句，块，流程控制等基本的语言元素。有点基础的可能看起来比较简单。 变量在前面的例子中我们学到，一个对象在fields内存储状态。 int cadence = 0;int speed = 0;int gear = 1; 可能依然有几个迷惑的问题：命令一个字段的规则和约定是什么？除了int，还有什么数据类型？定义fields的时候是不是一定要进行初始化？如果没有显式初始化的话是不是会获得一个默认值？我们将在这一节来回答这些问题，在这之前，有几个技术上的区别要首先注意到。在Java中，field和变量(variable)都会用到；这是新开发者长会混淆的地方，因为它们经常看起来指的是同一样东西。 Java定义了下面的几种类型的变量： 实例变量(non-Static Fields)：技术上讲，对象将不同的状态存储在non-static fields，这就是说，域（field）的声明不需要static关键词。Non-static fields也经常被叫做instance variables，因为对每个类的实例来说，其值是唯一的（换句话说，就在每个对象内值不一样）；如，一个自行车currentSpeed与另外一个自行车的currentSpeed是不一样的。 Class Variables(Static Fields)：一个class variables是一个被static修饰符进行声明的域，这将告知编译器这里只会存在此变量的一个副本，而不管这个类有多少个实例。对一个特定类型的自行车来说，定义档位数量的域可以被static关键词进行标记，因为所有的同样的档位数量会应用到所有实例。代码static int numGears = 6;会创建一个这样的静态域。然后，final关键词可以被添加来表明这个值将永远不会改变。 Local Variables（本地变量）：和对象存储状态到域类似，方法经常存储其内的临时变量到local variables。声明一个本地变量的语法和声明一个域相似（如，int count = 0;）。没有特殊的关键词来指定一个变量是本地变量，这只和声明变量的位置有关————在一个方法的大括号内。因此，本地变量只能在声明它的方法内可见，在类的其他地方是不可访问的。 参数：你已经看到了参数的例子，在Bicycle类和Hello World!应用 的main方法内都有。main方法的签名是public static void main(String[] args)。这里，args变量是方法的参数。需要注意的一点就是，参数经常是指定成变量而不是域。那些接受参数的构造器（constructs)一样。 这个文章接下来在讨论域和变量的时候会使用以下一般性的说明。如果我们在谈论一般域（不包括本地变量和参数）的时候，我们简单的称呼为域。如果讨论包括了以上所有的情况，我们简单的称做变量。如果上下文需要进行区别的话，我们会用限定术语（static field, local variables, 等等）。某些时候可能会偶尔遇到使用成员(member)的地方。一个类型的 域，方法，嵌套类型都统一叫做成员。 命名(Naming） 变量名大小写敏感。变量名可以是任意数量的合法字符————不限制长度的Unicode字母和数字序列，以一个字母开始，`，`_`。约定是总是以字母开头，而不要使用`和_。$永远不要使用它。某些时候你会看到自动生成的名字会包含美元符号，但是自己的变量避免使用它。下划线也不要用来开头，虽然是合法的，但不鼓励。空白字符是不允许使用的。 后续的字符可能是字母，数字，美元符号，下划线。命名变量的时候，使用单词全写而不是简写。这样会让代码更加容易阅读和理解。很多情况下也会让你的代码是自文档的；域名字cadence, speed, gear总比简写的s, c, g合适。同时不要使用关键词或保留字。 如果选择的名字只有一个单词，全部都使用小写字母。如果是有多个单词组成，后续单词的第一个字母大写，其他小写。如gearRatio和currentGear就是例子。如果变量是存储一个常量，static final int NUM_GEARS = 6;，那么就把所有字母大写，单词间用下划线分隔开。除了这里，不用在其他情况下使用下划线。 基本数据类型Java是静态类型的，这意味着所有变量都必须先声明然后再使用。首先要声明变量的类型和名字： int gear = 1; 一个变量的类型决定了其包含的值，和其能进行的操作。除了int，Java支持7种其他类型的基本数据类型。一个基本类型是被语言预定义的，并且以一个保留关键字进行命名。基本值和其他的基本值不共享状态。下面是8种基本的数据类型： byte short int long float double boolean char 除了上面这8种类型，Java通过java.lang.String包来支持字符串。用双引号&quot;包含字符串会自动建立一个String对象；比如，String s = &quot;this is a string&quot;;，String对象是不变的，一旦创建的话值就不会变化。String类并不是一个基本数据类型，但是由于语言给予它的特殊支持，可以这样认为。将会在Simple Data Objects一章学到更多关于String类的内容。 默认值在声明一个域的时候并非一定要赋一个初值。编译器会对没有赋初值的域进行初始化为相关默认值。一般来讲，这默认值将会是 0 或者null，根据数据类型而定。然而，依赖这些默认的值被认为是一种不好的编程风格。 下面这个表格显示了各类型的默认值： 数据类型 默认值(for fields) byte 0 short 0 int 0 long 0L float 0.0f double 0.0d char ‘\\u0000’ String(任何对象) null boolean false 本地变量有所不同，编译器不会对未初始化的本地变量给予默认值。所以，如果必须要在你使用本地变量前给予它一个值。访问一个未初始化的自动变量会得到一个 编译时 错误。 字面值你可能会注意到在初始化基本类型的变量时没有使用new关键词。基本类型是语言内建的数据类型；他们不是从类创建的对象。一个literal(字面值)代表了一个固定值的源代码；字面值在代码内不需要进行计算。如下所示，可以对基本类型给予一个字面值： boolean result = true;char capitalC = &apos;C&apos;;byte b = 100;short s = 10000;int i = 100000; 整数字面值以l,L结尾的是long类型的整数字面值，不然的话就是int整型字面值。建议使用L，因为l看起来和数字1很相似。 byte, short, int, long的值都可以通过int的字面值创建。long的值超过了int的范围，可以用long字面值创建。整数字面值可以用以下的数字系统表示： 十进制：以10为基，数字[0-9]。 十六进制：16为基，数字[0-9A-F]。 二进制：2为基。就包含0，1。 一般来说都是用的十进制。可以用前缀0x,0b分别来表示16进制和二进制。 // The number 26, in decimalint decVal = 26;// The number 26, in hexadecimalint hexVal = 0x1a;// The number 26, in binaryint binVal = 0b11010; 浮点值以F, f结尾的浮点值是fload类型；否则其类型是double，无论是否有D, d后缀。 浮点类型（fload, double）可以用e, E（科学计数法）表示，F, f（32-bit浮点值）, D, d（64-bit浮点值，默认值，经常是省略的）。 double d1 = 123.4;// same value as d1, but in scientific notationdouble d2 = 1.234e2;float f1 = 123.4f; 字符和字符串值char, String的值可能包含任何Unicode(UTF-16)中的任意字符。如果编辑器或系统允许，可以直接在代码类使用这些字符。不然的话，就只能用\\u0108（有音调符号的大写字母C），S\\u00ED Se\\u00F1 (Sí Señor in Spanish)这种形式来表示。对char使用&#39;，对String使用&quot;。Unicode 反引序列可以在任何地方使用。 Java也支持一些特殊的反引序列。\\b(backspace), \\t(tab), \\n(line feed), \\f(form feed), \\r(carriage return), \\&quot;(double quote), \\&#39;(single quote),and \\\\(backslash)。 一个特殊的值null可以用来做任何类型的值。null可以赋给任何变量，除了基本类型的变量。null经常被用来在程序中编辑某些对象不可用。 最后，有一个特殊类型的值叫做class literal，通过在一个类型名字后面加上一个.class后缀，如String.class。这指代类型本身。 在数字值内使用下划线字符在Java SE 7以上，可以在数字中出现下划线。这可以让你分隔数字来提高阅读性。 long creditCardNumber = 1234_5678_9012_3456L;long socialSecurityNumber = 999_99_9999L;float pi = 3.14_15F;long hexBytes = 0xFF_EC_DE_5E;long hexWords = 0xCAFE_BABE;long maxLong = 0x7fff_ffff_ffff_ffffL;byte nybbles = 0b0010_0101;long bytes = 0b11010010_01101001_10010100_10010010; 只能在数字中间放下划线，不能在这些地方放下划线： 数字的开始或结束 浮点值内靠近数字的地方 F, l之前 需要数字字符串的地方 下面的例子演示了有效和无效的下划线放置： / Invalid: cannot put underscores// adjacent to a decimal pointfloat pi1 = 3_.1415F;// Invalid: cannot put underscores // adjacent to a decimal pointfloat pi2 = 3._1415F;// Invalid: cannot put underscores // prior to an L suffixlong socialSecurityNumber1 = 999_99_9999_L;// OK (decimal literal)int x1 = 5_2;// Invalid: cannot put underscores// At the end of a literalint x2 = 52_;// OK (decimal literal)int x3 = 5_______2;// Invalid: cannot put underscores// in the 0x radix prefixint x4 = 0_x52;// Invalid: cannot put underscores// at the beginning of a numberint x5 = 0x_52;// OK (hexadecimal literal)int x6 = 0x5_2; // Invalid: cannot put underscores// at the end of a numberint x7 = 0x52_; 数组数字是一个容器对象，存储了单一类型固定数量的值。数组的长度在建立时就已确定。创建后，长度就不会变化。 数字的每个项目被称做元素，每个元素通过索引访问。如上所示，索引从0开始。在这个例子中，第9个元素可以通过 索引8 进行访问。 接下来程序，ArrayDemo，创建一个整数数组，放了一些值在里面，然后打印出这些值来： class ArrayDemo &#123; public static void main(String[] args) &#123; // declares an array of integers int[] anArray; // allocates memory for 10 integers anArray = new int[10]; // initialize first element anArray[0] = 100; // initialize second element anArray[1] = 200; // and so forth anArray[2] = 300; anArray[3] = 400; anArray[4] = 500; anArray[5] = 600; anArray[6] = 700; anArray[7] = 800; anArray[8] = 900; anArray[9] = 1000; System.out.println(\"Element at index 0: \" + anArray[0]); System.out.println(\"Element at index 1: \" + anArray[1]); System.out.println(\"Element at index 2: \" + anArray[2]); System.out.println(\"Element at index 3: \" + anArray[3]); System.out.println(\"Element at index 4: \" + anArray[4]); System.out.println(\"Element at index 5: \" + anArray[5]); System.out.println(\"Element at index 6: \" + anArray[6]); System.out.println(\"Element at index 7: \" + anArray[7]); System.out.println(\"Element at index 8: \" + anArray[8]); System.out.println(\"Element at index 9: \" + anArray[9]); &#125;&#125; 这个程序的输出是：Element at index 0: 100Element at index 1: 200Element at index 2: 300Element at index 3: 400Element at index 4: 500Element at index 5: 600Element at index 6: 700Element at index 7: 800Element at index 8: 900Element at index 9: 1000 在真实的编程情况下，我们应该使用一种 循环语句来遍历数组中的每个元素，而不像例子里这样一个元素使用一个语句。你将会在Control Flow一章学到循环控制。 声明引用数组的变量上面的例子声明了一个数组（名字是 anArray）： // declares an array of integers int[] anArray; 和声明其他类型变量一样，数组的声明有两个组件：类型和名字。数组类型写做 type[]，type是数组里面包含的数据类型；[]是一个特殊的符号来表示这是一个数组。数组的大小不是类型的一部分（这就是为什么[]是空的原因）。这并不会真正创建一个数组，这只是告诉编译器这个变量将会指向一个特定类型的数组。 类似的，可以声明其他类型的数组：byte[] anArrayOfBytes;short[] anArrayOfShorts;long[] anArrayOfLongs;float[] anArrayOfFloats;double[] anArrayOfDoubles;boolean[] anArrayOfBooleans;char[] anArrayOfChars;String[] anArrayOfStrings; 还可以把方括号放在数组名后面： // this form is discouraged float anArrayOfFloats[]; 创建，初始化和访问一个数组用new操作符可以创建一个数组。// create an array of integersanArray = new int[10]; 如果没有这条语句的话，编译器会打印一条错误： ArrayDemo.java:4: Variable anArray may not have been initialized. 接下来的几行为数组内的元素赋值： anArray[0] = 100; // initialize first elementanArray[1] = 200; // initialize second elementanArray[2] = 300; // and so forth 还可以用更简短的方式来创建和初始化一个数组： int[] anArray = &#123; 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000&#125;; 这里，数组的长度由括号的值数量确定。 也可以声明数组的数组，比如String[][]。每个元素，必须通过一个合适的数字索引进行访问。 在Java中，多维数组的所有组件都是数组。这和C或Fortan不同。多维数组中的行长度是可变的，就跟如下程序所示一样： class MultiDimArrayDemo &#123; public static void main(String[] args) &#123; String[][] names = &#123; &#123;&quot;Mr. &quot;, &quot;Mrs. &quot;, &quot;Ms. &quot;&#125;, &#123;&quot;Smith&quot;, &quot;Jones&quot;&#125; &#125;; // Mr. Smith System.out.println(names[0][0] + names[1][0]); // Ms. Jones System.out.println(names[0][2] + names[1][1]); &#125;&#125; 最后，可以用内建的length属性来得到数组的长度。 System.out.println(anArray.length); 复制数组System类有一个arraycopy方法用来高效的在数组间进行复制： public static void arraycopy(Object src, int srcPos, Object dest, int destPos, int length) 下面的程序，ArrayCopyDemo，声明了一个char数组，包含单词decaffeinated。使用System.arraycopy方法来从这个数组中复制数据到其他数组： class ArrayCopyDemo &#123; public static void main(String[] args) &#123; char[] copyFrom = &#123; 'd', 'e', 'c', 'a', 'f', 'f', 'e', 'i', 'n', 'a', 't', 'e', 'd' &#125;; char[] copyTo = new char[7]; System.arraycopy(copyFrom, 2, copyTo, 0, 7); System.out.println(new String(copyTo)); &#125;&#125; 输出是：caffein 数组操作数组是一个非常有用和实用的概念。Java SE提供某些非常常用的操作数组的方法。这样用一行代码就可以进行某些常用的操作，而不用手工进行逐个的复制。 为了方便，Java SE在 java.util.Arrays提供了一些方法来进行数组操作。上面一个例子可以修改来使用copyOfRange方法来达成同样的目的。区别就是使用copyOfRange方法不需要在复制之前创建目标数组，这个数组由方法进行返回： class ArrayCopyOfDemo &#123; public static void main(String[] args) &#123; char[] copyFrom = &#123;'d', 'e', 'c', 'a', 'f', 'f', 'e', 'i', 'n', 'a', 't', 'e', 'd'&#125;; char[] copyTo = java.util.Arrays.copyOfRange(copyFrom, 2, 9); System.out.println(new String(copyTo)); &#125;&#125; 可以看到，输出的结果是一致的（caffein），但使用了更少的代码。要注意的是，copyOfRange的第2，3个参数分别指定了复制开始和结束的位置，左开右闭。在这里，索引9代表的元素a并没有被复制。 一些java.util.Arrays提供的方法有下面： binarySearch：在数组中返回值的索引。 equals：比较两个数组是否相等。 fill：用某个值来填充数组。 sort,parallelSort(Java SE 8)：升序排列数组。Parallel排序方法，在用多处理器进行大数组排序的时候会比普通的sort更快。 操作符现在我们已经知道怎么样去声明和初始化一个变量，但是我们可以对它做更多的事情。研究一下Java的操作符是一个非常不错的开始。操作符是对一个，两个，或者三个操作属进行特定操作的符号，并且会返回值。 高优先级的操作符会优先进行计算，如果同样的操作符在一起出现的话，必须指明哪一个先进行计算。二元操作符（排除=）从左至右进行结合，赋值（=）从右至左结合。下面是Java的操作符有限级由高到低的表格： 操作符 优先级 后缀 expr++ expr— 一元操作符 ++expr —expr +expr -expr ~ ! 乘/除/模 \\ / %* 加/减 + - 位移 &gt;&gt; &lt;&lt; &gt;&gt;&gt; 条件 &lt; &gt; &lt;= &gt;= instanceof 相等 == != 位与 &amp; 异或 ^ 或 \\ 逻辑与 and 逻辑或 &#124;&#124; 三元符 ?: 赋值 = += -= *= /= %= ^= &#124;= &lt;&lt;= &gt;&gt;= &gt;&gt;=","categories":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/tags/Java/"},{"name":"The Java Tutorial","slug":"The-Java-Tutorial","permalink":"https://gowa2017.github.io/tags/The-Java-Tutorial/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}]},{"title":"关于面向对象（OOP）编程的一些概念","slug":"关于面向对象（OOP）编程的一些概念","date":"2018-01-10T13:35:01.000Z","updated":"2018-01-10T13:35:01.000Z","comments":true,"path":"Java/关于面向对象（OOP）编程的一些概念.html","link":"","permalink":"https://gowa2017.github.io/Java/关于面向对象（OOP）编程的一些概念.html","excerpt":"介绍了一些基本的概念，如对象，类，接口，继承，包等。比较简单，但是理解起来还是很必要的。一些例子与后面的章节有连续性。","text":"介绍了一些基本的概念，如对象，类，接口，继承，包等。比较简单，但是理解起来还是很必要的。一些例子与后面的章节有连续性。 对象对象是理解面向对象的关键。看看你周围，就会发现一些真实世界里对象的例子：狗，桌子，电视，自行车。 真实世界的对象有两个特点：他们都有状态（state）和行为（behavior）。狗有状态（名字，颜色，饥饿）和行为（吠，乞求，摇尾巴）。自行车也有状态（档位，脚踏板节奏，当前速度）和行为（改变后视镜，改变踏板，刹车）。对真实世界对象的状态和行为进行区别是开始进行面向对象编程的一个好方式。 花几分钟时间来看看你马上能看到的真实世界的对象。对每个对象问一下自己：“这个对象可能处于哪些状态？这些对象可能有哪些行为？”记录下我们的观察。你会发现，真实世界的对象是非常的复杂；台灯可能只有两个可能的状态（开或关）和两个可能的行为（打开和关闭），但是收音机就可能还有更多的状态（开，关，音量，频率）和行为（打开，关闭，加大音量，查找台，扫描，微调）。还有其他对象可能包含了其他对象。这些真实世界的观察可以转换到面向对象的编程。 软件对象概念上和真实世界的对象相似：同样包含状态和行为。一个对象在字段（fields）里存储状态，通过方法（methods）来表现行为。方法对对象的内部状态进行操作并且作为对象间传递信息的根本方法。隐藏内部状态并且要求所有的沟通都通过对象的方法进行被称做数据封装————面向对象编程的一个基本原则。 考虑一辆自行车，如下：归纳出状态（速度，脚踏板节奏，档位）并提供改变状态的方法，这就跟真实世界控制自行车一样。比如，如果自行车只有6个档位，一个改变档位的方法应该拒绝任何小于1或者大于6的操作。 把代码打包到单独的软件对象中会带来很多好处： 模块性：每个对象的源代码独立编写和维护。创建后的对象可以很方便地在系统内进行分发。 隐藏信息：一个对象只能通过其提供的方法进行交互，内部的实现细节就隐藏了起来。 代码重用：如果一个对象已经存在（其他开发者编写好的），我们就可以在我们的程序内使用。类在真实世界中，有很多同种类的不同对象。比如，有上千种自行车，具有相同的构造和模型。因为用相同的设计和进行制造，所以具有同样的组件。用OOP的术语来说，那就是 一辆自行车 是 被称做自行车类的一个实例。一个类是对象产生的框架。 下面的Bicycle类是自行车的一个可能实现： class Bicycle &#123; int cadence = 0; int speed = 0; int gear = 1; void changeCadence(int newValue) &#123; cadence = newValue; &#125; void changeGear(int newValue) &#123; gear = newValue; &#125; void speedUp(int increment) &#123; speed = speed + increment; &#125; void applyBrakes(int decrement) &#123; speed = speed - decrement; &#125; void printStates() &#123; System.out.println(\"cadence:\" + cadence + \" speed:\" + speed + \" gear:\" + gear); &#125;&#125; 字段(field)cadence, speed, gear代表对象的状态，方法(methods)changeCadence, changeGear, speedUp定义了一些操作。 Bicycle亮不包含一个main方法。这是因为这并不是一个完整的应用；这只是一个对于自行车在应用中可能用到的框架。至于怎么样样创建和使用Bicycle对象是其他类的责任。 下面是一个BicycleDemo类，创建两个独立的Bicycle对象，并调用方法： class BicycleDemo &#123; public static void main(String[] args) &#123; // Create two different // Bicycle objects Bicycle bike1 = new Bicycle(); Bicycle bike2 = new Bicycle(); // Invoke methods on // those objects bike1.changeCadence(50); bike1.speedUp(10); bike1.changeGear(2); bike1.printStates(); bike2.changeCadence(50); bike2.speedUp(10); bike2.changeGear(2); bike2.changeCadence(40); bike2.speedUp(10); bike2.changeGear(3); bike2.printStates(); &#125;&#125; 编译这个程序后的输出是： cadence:50 speed:10 gear:2cadence:40 speed:20 gear:3 继承不同种类的对象经常有一些共性。山地自行车，公路自行车，双人自行车都具有自行车的特点（速度，脚踏板节奏，档位）。当然，他们也各自定义了更多的特性所以显得不同：双人自行车有两个座位和两个方向盘等等。 面向对象的编程允许类从其他类继承（inherit）共有常用的状态和行为。在这个例子中，类Bicycle成为了MountainBike, RoadBike，TandemBike的基类(superclass)。在java语言中，每个类都可以有一个直接的superclass，然后每个 superclass潜在的拥有无限的subclass。 创建一个子类的语法非常的简单。在类定义的开始处，使用extends关键词，后面跟着superclass： class MountainBike extends Bicycle &#123; // new fields and methods defining // a mountain bike would go here&#125; 这样就给予了MountainBike所有Bicycle具有的字段和方法，也允许里面包含一下独有的代码。这样的话就让这个子类的代码易于阅读。然后，你必须要小心每个superclass定义的状态和行为，因为这些代码并不会在子类中出现。 接口（Interface）就跟已经介绍的一样，对象通过其提供的方法与外界进行交互。方法（些）形成了对象的接口（interface）；电视遥控器上的按钮是你与电视的接口。可以通过电源按钮来开关电视。 在更通常的情况下，一个接口是一组没有主体的相关方法的集合。一个自行车的行为，如果定义成一个接口的话，可能像下面这样： interface Bicycle &#123; // wheel revolutions per minute void changeCadence(int newValue); void changeGear(int newValue); void speedUp(inte increment); void applyBrakes(int decrement);&#125; 为了实现这些接口，设计的类的名字需要改变（例如一个特定品牌的自行车，ACMEBicycle），同时在类定义内使用implements关键词：class ACMEBicycle implements Bicycle &#123; int cadence = 0; int speed = 0; int gear = 1; // The compiler will now require that methods // changeCadence, changeGear, speedUp, and applyBrakes // all be implemented. Compilation will fail if those // methods are missing from this class. void changeCadence(int newValue) &#123; cadence = newValue; &#125; void changeGear(int newValue) &#123; gear = newValue; &#125; void speedUp(int increment) &#123; speed = speed + increment; &#125; void applyBrakes(int decrement) &#123; speed = speed - decrement; &#125; void printStates() &#123; System.out.println(&quot;cadence:&quot; + cadence + &quot; speed:&quot; + speed + &quot; gear:&quot; + gear); &#125;&#125; 实现一个接口让一个类变得更加正式的声明其提供的行为。接口在类和外部建立了一个约定，这个约定在编译器在编译时强制执行。如果一个类请求实现一个接口，那么所有接口定义的方法的源码必须在这个类里出现。 想要编译ACMEBicycle类，应该在接口实现方法前面加上public关键词。后面的章节Classes and Objects和Interfaces and Inheritance章节中会学到原因。 包一个包是一个组织一系列相关类和接口的命名空间。概念上的可以认为包跟你电脑上的不同目录一样。我们会把HTML页面放在一个目录，图片放在另外一个目录，脚本或应用在另外一个目录。用java编写的软件可能会由成百上千个类组成，所以把相关的类和接口放在一个包内是非常有意义的。 Java平台提供了非常庞大的类库，这被称做API。只怕包呢包括了一些为了常规目的经常使用的类集合。比如，String对象包含了字符串的状态和行为；一个File对象允许程序员很方便的创建，删除，检查，比较或修改文件系统上的文件；一个Socket对象允许创建和使用网络套接字； Java Platform API Specification列出了所有Jave SE平台应用的包，接口，类，字段，和方法。打开浏览器看看。这将成为一个程序员最重要的参考文档。","categories":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/tags/Java/"},{"name":"The Java Tutorial","slug":"The-Java-Tutorial","permalink":"https://gowa2017.github.io/tags/The-Java-Tutorial/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}]},{"title":"jdk9安装及与前版本的不同","slug":"jdk9安装及与前版本的不同","date":"2018-01-09T06:44:00.000Z","updated":"2018-01-09T06:44:00.000Z","comments":true,"path":"Java/jdk9安装及与前版本的不同.html","link":"","permalink":"https://gowa2017.github.io/Java/jdk9安装及与前版本的不同.html","excerpt":"以前就是了解过这个，但是由于生活需要，不能只干自己想干的，还必须干必须干的事情。那么就开始学习了一下java。java se 最新的jdk是 jdk9，这与以前的有些不同呢，对于安装和配置都简单了很多很多了。","text":"以前就是了解过这个，但是由于生活需要，不能只干自己想干的，还必须干必须干的事情。那么就开始学习了一下java。java se 最新的jdk是 jdk9，这与以前的有些不同呢，对于安装和配置都简单了很多很多了。 安装jdk9前往官网下载最新的 jdk: java官方网站下载 这里我们选择了Linux下的二进制包jdk-9.0.1_linux-x64_bin.tar.gz 进行安装（之所以不选择 rpm 包，是为了能安装多个版本）。 安装的过程颇为简单，根据官方的路走就行了。将下载下来的 jdk-9.0.1_linux-x64_bin.tar.gz解压即可： tar xzf jdk-9.0.1_linux-x64_bin.tar.gz 然后看一下目录，会发现与以前的不太一样，已经没有了jre目录，因为这两个已经放在一个地方去了。然后因此，已经不需要设JRE_HOME和CLASSPATH变量了，只需要设置JAVA_HOME变量就OK了。 echo &#39;export JAVA_HOME=/usr/local/jdk-9.0.1&#39; &gt;&gt; /etc/profile echo &#39;export PATH=$PATH:$JAVA_HOME/bin&#39; &gt;&gt; /etc/profile 我在安装的时候就是按以前的方式，设置了CLASSPATH变量，结果根本总是提示无法加载主类。后面取消了这个变量才OK的。","categories":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/tags/Java/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://gowa2017.github.io/categories/Java/"}]},{"title":"关于macOS使用的工具","slug":"关于macOS使用的工具","date":"2018-01-06T11:56:43.000Z","updated":"2018-01-06T11:56:43.000Z","comments":true,"path":"macOS/关于macOS使用的工具.html","link":"","permalink":"https://gowa2017.github.io/macOS/关于macOS使用的工具.html","excerpt":"macOS下一些工具更加好用易用的设置记录。","text":"macOS下一些工具更加好用易用的设置记录。 brew 源替换homebrew官方网页替换为中科大源 修改屏幕截图屏幕截图名称defaults write com.apple.screencapture name \"macscreen\"killall SystemUIServer 屏幕截图格式defaults write com.apple.screencapture type jpgkillall SystemUIServer 去掉日期后缀defaults write com.apple.screencapture \"include-date\" 0killall SystemUIServer 批量查看图片/视频 选中一个图片（视频） 空格键 左/右键移动，option放大，鼠标拖动","categories":[{"name":"macOS","slug":"macOS","permalink":"https://gowa2017.github.io/categories/macOS/"}],"tags":[{"name":"brew","slug":"brew","permalink":"https://gowa2017.github.io/tags/brew/"}],"keywords":[{"name":"macOS","slug":"macOS","permalink":"https://gowa2017.github.io/categories/macOS/"}]},{"title":"Mysql的索引与B-tree","slug":"Mysql的索引与B-tree","date":"2017-12-31T01:13:04.000Z","updated":"2017-12-31T01:13:04.000Z","comments":true,"path":"MySQL/Mysql的索引与B-tree.html","link":"","permalink":"https://gowa2017.github.io/MySQL/Mysql的索引与B-tree.html","excerpt":"","text":"MySQL查找效率的提高是通过为表建立索引来实现的，InnoDB更是如此，而其索引据说使用的是B-tree，一直不知道这是个什么东西，晚上抽空查看并了解了一下。 MySQL查询数据的过程试想，MySQL把数据存储到磁盘上，查询的时候需要读取数据，如果没有建立一个索引的情况下。那么MySQL不得不逐个读取存储在数据文件内的内容，然后与查询进行匹配也得出数据，这是极其没有效率的事情。 在建立了索引的情况下，那么首先通过索引找到数据的位置，然后直接去磁盘上读取指定位置数据即可。 b-tree这棵树与我们生活中理解的有点不同的，它只有Node（节点）和叶子（leaf）。所有的数据存储在叶子上，并且所有的叶子都距离根节点的距离相同。每个Node存储了当前Node的键，子节点信息，父节点信息；叶子节点存储了数据。图中的蓝色方格内的是节点内的键，P[n]是子节点的指针。通过这样的格式，就把数据有序的组织了起来。试想我们想要读取一个一行，其在ID上建立了索引，此行的索引值为75的情况下，这个过程是怎么样的。 MySQL会读取索引根节点，然后与节点内的键进行比较，确定下一个节点在何处。这里 35 &lt; 75，所以将会读取的下一个节点由指针P[3]确定。 读取子节点后，继续与节点内的键进行比较，确定指向的叶子节点，这里65 &lt; 75 &lt; 87，将会读取P[2]指向的叶子。 读取叶子后与气其内的键进行比较，得到数据。B-tree在叶子内存储的不是数据，而是数据的位置指针。 MySQL定位到数据文件的对应位置，读取数据。 通过三次读取磁盘上的文件，就获得了真正的文件，效率大大的提高。 B-tree的性质上图中是一个M为3的B树。 一个M阶的树满足下列条件： 1. 定义任意非叶子结点最多只有M个儿子；且M&gt;2； 2. 根结点的儿子数为[2, M]； 3. 除根结点以外的非叶子结点的儿子数为[M/2, M]； 4. 每个结点存放至少M/2-1（取上整）和至多M-1个关键字；（至少2个关键字） 5. 非叶子结点的关键字个数=指向儿子的指针个数-1； 6. 非叶子结点的关键字：K[1], K[2], …, K[M-1]；且K[i] &lt; K[i+1]； 7. 非叶子结点的指针：P[1], P[2], …, P[M]；其中P[1]指向关键字小于K[1]的子树，P[M]指向关键字大于K[M-1]的子树，其它P[i]指向关键字属于(K[i-1], K[i])的子树； 8. 所有叶子结点位于同一层； MySQL索引MySQL使用 B-tree作为索引结构，每次读取磁盘上的一页，大小为16K。每一页，都是以键-指针的形式进行组织。 InnoDB使用 14-bit的指针。 聚簇索引这个索引在叶子内保存的不是指针位置，而是数据了，更减少了一次磁盘IO。 二级索引二级索引的叶子保存的行的主键，然后通过主键在聚簇索引中进行查询读取数据。如果主键很长的话，二级索引就会需要更多的空间，所以使用一个短的主键是非常有必要的。 MySQL索引的物理结构（官方文档 14.11.10节）所有的InnoDB索引都B-tree，索引记录存储在叶子页上。默认索引页大小是16KB。 当新记录被插入到InnoDB聚簇索引的时候，InnoDB会尝试把当前页的1/16保留以便将来的插入或者更新。如果索引记录是按序插入的，那么插入页将会15/16充满。如果是随机的顺序插入的，其可能是在[1/2, 15,16]。如果索引页的充满比例不及1/2，InnoDB会试图压缩索引树来释放这一页。 改变InnoDB索引页大小是不支持的，也无法保证与非16KB索引页大小正常工作。编译和运行时InnoDB可能会出问题。实际上，被称为Barracuda新行格式ROW_FORMART=COMPRESSED假设索引页大小最大16KB，并且使用14-bit的指针。 g用不同索引页大小的数据文件和日志文件无法在实例之间无法移植。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://gowa2017.github.io/categories/MySQL/"}],"tags":[],"keywords":[{"name":"MySQL","slug":"MySQL","permalink":"https://gowa2017.github.io/categories/MySQL/"}]},{"title":"Mysql-Backup-and-Recovery 中文翻译","slug":"Mysql_backup_and_recovery-5.5","date":"2017-12-28T14:16:19.000Z","updated":"2017-12-28T14:16:19.000Z","comments":true,"path":"MySQL/Mysql_backup_and_recovery-5.5.html","link":"","permalink":"https://gowa2017.github.io/MySQL/Mysql_backup_and_recovery-5.5.html","excerpt":"本文来源于对Mysql 5.5官方手册的翻译版本，逐渐更新中。","text":"本文来源于对Mysql 5.5官方手册的翻译版本，逐渐更新中。 前言备份对于在出现系统崩溃、 硬件故障、错误删除数据等情况下进行数据恢复是非常重要的。同时，备份也可以作为升级的时候做一个数据保障，或者用来设置一个复制服务器。 MySQL提供多种备份方式，你可以根据自己的需求来进行选择怎么备份。本章谈论几个你可能已经熟悉了的关于备份与恢复主题： 备份方式： 逻辑 VS 物理，完整 VS 增量等等。 创建备份的方式。 恢复的方法，包括时间点恢复 备份调度，加密，压缩。 表维护，对于异常表的恢复。 备份和恢复的方式物理备份（RAW）与逻辑备份物理备份由组成数据库的目录和文件的原始副本构成。这种方式适合大型数据库和需要快速恢复的重要数据库的备份。 逻辑备份以逻辑数据库信息存储数据，也就是一系列的SQL语句（CREATE DATABASE, CREATE TABLE）和内容（INSERT）。这种方式适合数据量不大，或者你想要进行修改数据和在其他机器上进行重新建库的业务场景。 物理备份有以下特点： 包括数据文件和目录的备份。典型地，可以是数据目录的全部或者部分。 比逻辑备份快，因为只进行文件复制而不用进行转换。 输出更紧凑。 对于繁忙、重要的数据库，速度和压缩是非常重要的，MySQL Enterprise Backup Product采用的就是物理备份。 备份和恢复的粒度从整个数据目录到单个文件。根据存储引擎的不同，有可能会提供表级别的粒度。举例说，Innodb每个表可以在一个数据文件内，也可以共享同一个表空间；MyISAM的话，每个表会使用好几个文件。 作为补充，这个备份可以包含所有的日志文件或者配置文件。 使用MEMORY引擎的表是很难备份的，因为他们并不存储在磁盘上。（MySQL Enterprise Backup Product有个选项可以让你备份的时候从MEMORY引擎的表内获取数据。） 备份只能在具有相同的架构或特点的机器上是可移植的。 物理备份工具包括 Mysql Enterprise Backup 的mysqlbackup（可以备份InnoDB表和其他任何类型表），文件系统级别的命令（cp，scp，tar, rsync）,还有对MyISAM表使用的mysqlhotcopy工具。 恢复：MySQL Enterprise Backup可以恢复InnoDB表和任何其他其备份的表。ndb_restore恢复NDB表。在文件系统级别进行复制的备份或者用mysqlhotcopy的备份可以用文件系统命令将其拷贝回原来的地方。 逻辑备份特点： 通过查询服务器来获得数据库的结构和内容信息。 备份的速度比物理备份慢。因为服务器必须访问数据库信息并且转换为逻辑格式。如果输出是在客户端，那么服务器还需要把这些数据发送给客户端。 备份输出比物理备份大，因为是以text格式进行存储。 备份和恢复的粒度从系统级（所有库）、 数据库级（某一库的所有表）、到表级别。这个是无论表使用的是什么引擎。 以逻辑备份格式存储的备份是与机器无关、高度可移植的。 逻辑备份可以在服务器运行时进行，不用关机下线。 逻辑备份工具包括 mysqldump 和SELECT ... INTO OUTFILES语句。这可以对所有引擎使用，包括MEMORY引擎表。 为了恢复逻辑备份，SQL格式的转储文件可以使用mysql客户端进行，对于text格式的转储文件，可以使用 LOAD DATA INFILE或者 mysqlimport工具。 在线 VS 离线备份本地备份是在服务器运行的机器上进行备份，远程备份的话就是在非服务器运行的另外一台机器上进行备份。对于某些类型的备份，可以在远程机器上执行，然后输出到服务器主机上。 mysqldump可以连接到本地或者远程主机。对于 SQL语句的输出（CREATE和INSERT语句），本地或者远程的都能成功，并且在客户端产生输出。对于格式化的文本输出（--tab选项），数据文件只在服务器上产生。 mysqlhotcopy只进行本地备份：其连接到服务器并进行锁定以避免数据的修改，然后复制表数据文件。 SELECT ... INTO OUTFILE可以在本地或者远程执行，但是其输出是在服务器上。 物理备份一般是在本地执行的，这样服务器就可以下线，及时我们备份后是要输出到其他服务器。 快照备份某些系统实现启用了“快照”功能。这允许在某一时间对文件系统进行逻辑复制而不用对整个文件系统进行物理复制。（比如，系统实现可能会使用 copy-on-write技术只复制在快照备份后产生的变化）。MySQL本身并不提供文件系统快照。其是通过第三方解决方案达成的，如 Veritas, LVM, ZFS。 完整 VS 增量备份 一个完整备份包括在某一时间点由MySQL服务器所管理的所有文件。增量备份包括在某一时间间隔内的数据变化。MySQL包括不同的完整备份方式，如前文所述。增量备份通过启用服务器的二进制日志（服务器用来记录数据改变的）。 完整 VS 时间点（增量）恢复 一个完整恢复从一个完整备份还原数据，这会将数据库实例还原到其备份的状态。如果完整备份不同达到想要的状态，那么接下来会进行一个增量备份的恢复，以保证实例到达最新状态。 增量恢复就对一个在时间间隔内的备份进行恢复。这也被叫做时间点恢复，因为它将使服务器从当前状态转变到一个时间点时的状态。时间点恢复是以二进制日志为基础的，典型情况下其都是跟随在一个完整备份之后，这样写在二进制日志里的数据变化就会被重放，以让数据库到达希望的时间点状态。 表维护在表出现故障的时候数据完整性无法得到保障。对于 InnoDB来说，这不是一个问题。对于在MyISAM出现问题是进行检查和修复的工具，查看7.6节 MyISAM表维护及崩溃恢复。 备份调度，压缩，加密备份调度对于自动备份来说是非常有用的。压缩的会使备份占用更少的磁盘空间，加密能提供更好的安全性以避免未授权的对备份数据的访问。MySQL本身不提供这些功能。MySQL Enterprise Backup可以压缩InnoDB备份，能通过系统工具集进行加密或者压缩。有某些第三方工具可以进行使用达成这样的目的。 数据库备份方式这一节介绍了一些常用的备份方式。 用MySQL Enterprise Backup 进行热备份 Customers of MySQL Enterprise Edition can use the MySQL Enterprise Backup product to do physical backups of entire instances or selected databases, tables, or both. This product includes features for incremental and compressed backups. Backing up the physical database files makes restore much faster than logical techniques such as the mysqldump command. InnoDB tables are copied using a hot backup mechanism. (Ideally, the InnoDB tables should represent a substantial majority of the data.) Tables from other storage engines are copied using a warm backup mechanism. For an overview of the MySQL Enterprise Backup product, see Section 25.2, “MySQL Enterprise Backup Overview”. 用mysqldump 或 mysqlhotcopy备份 mysqldump可以备份任意类型的表，所以更为常用，而mysqlhotcopy只能备份某些存储引擎表。对于InnoDB表，通过--single-transaction选项可以实现在线无锁表的备份。 通过复制文件实现备份表 对于某些存储引擎类型的表，每个表使用其自己的数据文件，就可以使用复制文件的方式进行备份。MyISAM表就是以文件的形式进行存储的，所以很方便的就可以通过复制文件进行备份（.frm, .MYD, .MYI文件）。为了获得一致性的备份，停止服务器或者*锁定办刷新要备份的表： FLUSH TABLES tbl_list WITH READ LOCK; 只需要读锁；这样就允许其他客户端在你进行备份的时候继续查询数据库。刷新是必须的，这用来保证在备份之前所有活跃的索引页都被写入磁盘。 我们也可以在服务器没有进行任何更新的时候复制所有的表文件来制造一个二进制备份。mysqlhotcopy就是这样做的。 注意：在包含InnoDB表的时候，这样做是没有意义的。mysqlhotcopy无法在InnoDB表上工作，因为并不一定把数据存储在数据目录内。而且，尽管服务器没有更新数据，InnoDB依然可能有改变的数据在内存而还未写至磁盘。 格式化的文本文件备份 如果要获得一个包含表数据的文本文件，可以使用 SELECT * INTO OUTFILE &#39;file_name&#39; FROM tbl_name。这个输出会产生在服务器上，而不是在客户端。输出的文件必须是不存在的，因为允许重写已存在的文件是一个安全隐患。这种方式对于任何形式的表都能工作，但不存储表结构。 另外一个用来获得文本数据格式（包括CREATE TABLE语句）的方法是使用mysqldump加上--tab选项。 为了重新载入一个文本格式的备份，使用LOAD DATA INFILE或者mysqlimport。 通过启用二进制日志获得增量备份 MySQL支持增量备份：必须为服务器开启--log-bin选项来启用二进制日志。二进制日志记录了所有的数据变化信息。在需要进行增量备份的时刻（包含所有自上次完整或增量备份以来的变化），我们可以用FLUSH LOGS来回转日志文件。这样，就可以把想要备份的文件复制到备份位置。这些二进制日志就是增量备份。至于在恢复的时候怎么使用，参考7.5 通过二进制日志进行时间点恢复。在下一次进行完整备份的时候，我们一样要回转日志，用FLUSH LOGS, mysqldump --flush-logs, mysqlhotcopy --flushlog。参考4.5.4 mysqldump—一个数据库备份程序， 4.6.9 mysqlhotcopy— 一个数据库备份程序。 通过复制进行备份 如果在进行主服务器备份的时候产生了性能问题，一个好的建议就是设置从服务器并且从服务器上进行备份操作。17.3.1 用复制来进行备份。 在备份从服务器的时候，不管采用什么方式，也要备份master.info和relay-log.info文件。这些信息在你重新设置从服务器的时候总是需要的。如果在备份的时候，从服务器正在执行LOAD DATA INFILE语句，那就要备份所有的从服务器载入的文件，因为备份后从服务器需要用这些文件来重新进行载入以继续LOAD DATA INFILE操作。一般来说，这个文件的位置是在tmpdir系统变量中，或者由--slave-load-tmpdir选项在服务器启动时指定。 恢复故障表 如果要恢复出现故障的MyISAM表，尝试使用REPARI TABLE或者myisamchk -r，这在99.9%的情况下都能工作。如果myisamchk失败了，参考7.6节 MyISAM表维护和崩溃恢复。 用文件系统快照进行备份 如果在使用Veritas文件系统，可以按如下步骤做： 从一个客户端，执行 FLUSH TABLES WITH READ LOCK;； 从另外一个shell，执行 mount vxfs snapshot； 从 第1.部的客户端，执行UNLOCK TABLES；； 从快照复制文件。 卸载快照。 类似的快照能力在其他文件系统可能也有，比如LVM, ZFS。 备份和恢复策略举例这一节讨论了如何备份，以便在遇到一些类型的错误后进行恢复。 操作系统崩溃 电源故障 文件系统崩溃 硬件问题（驱动，主板等等） 示例的命令中，mysqldump和mysql不包含--user或--password选项。当你自己在使用的时候，你需要加上必要的选项来连接上服务器。 假设，数据存储在InnoDB引擎，它支持事务和自动崩溃恢复。 对于操作系统故障或者电源故障的情况，我们可以假设MySQL的磁盘数据在重启后是可用的。因为崩溃，InnoDB数据文件不一定包含一致的数据，但InnoDB会阅读其重做日志，并且找出那些没有并刷新到数据文件的挂起的提交事务和未提交的事务。InnoDB会自动回滚未提交的事务，刷新提交了的事务到数据文件。下面是一个可能的例子： InnoDB: Database was not shut down normally.InnoDB: Starting recovery from log files...InnoDB: Starting log scan based on checkpoint atInnoDB: log sequence number 0 13674004InnoDB: Doing recovery: scanned up to log sequence number 0 13739520InnoDB: Doing recovery: scanned up to log sequence number 0 13805056InnoDB: Doing recovery: scanned up to log sequence number 0 13870592InnoDB: Doing recovery: scanned up to log sequence number 0 13936128...InnoDB: Doing recovery: scanned up to log sequence number 0 20555264InnoDB: Doing recovery: scanned up to log sequence number 0 20620800InnoDB: Doing recovery: scanned up to log sequence number 0 20664692InnoDB: 1 uncommitted transaction(s) which must be rolled backInnoDB: Starting rollback of uncommitted transactionsInnoDB: Rolling back trx no 16745InnoDB: Rolling back of trx no 16745 completedInnoDB: Rollback of uncommitted transactions completedInnoDB: Starting an apply batch of log records to the database...InnoDB: Apply batch completedInnoDB: Startedmysqld: ready for connections 对于文件系统崩溃或者硬件问题，我们假设在服务器重启后，磁盘数据是不可用的。这就意味着MySQL会启动失败，因为部分磁盘块已经不可读。这样的情况下，只能重新格式化磁盘，或者解决硬件问题等。然后通过备份来进行恢复，这样就要求数据已经备份。那么，为了保证在这样的情况下不会丢失数据，设计和实现一个备份策略。 和备份策略通信为了实用，备份必须是常规性的。一个完整备份（某一时间点的数据快照）可以用几个工具来做到。例如，MySQL Enterprise Backup可以对一个实例进行物理备份，然后进行优化以避免在备份InnoDB的时候出现中断；mysqldump提供在线的逻辑备份。这里我们用mysqldump进行讨论。 假设我们要做一个对所有数据库的所有InnoDB表在星期1的下午1点进行一个完整备份： shell&gt; mysqldump --single-transaction --all-databases &gt; backup_sunday_1_pm.sql 生成的 *.sql 文件包含了一系列的INSERT语句可以在后面的时间内用来插入数据。 这个备份操作在开始之前需要一个全局的对所有表的读锁。（FLUSH TABLES WITH READ LOCK）。当这个锁获得后，这个二进制日志的坐标就会被记录，然后释放锁。如果在FLUSH语句执行期间正在执行一个耗时很长的更新语句，那么这个操作就只有到更新完毕才会进行。在此之后，这个过程就不再需要锁，同时也不会打扰其他客户端的读与写了。 先前假设我们讨论的表是InnoDB表，所以--single-transaction使用一致性读并且保证被mysqldump看到的数据不会改变（其他客户端所做的变化mysqldump看不到）。如果备份中包括非事务表，那么必须保证在这过程中表不会改变。比如，在mysql库内的所有MyISAM表，必须没有对MySQL账号管理的改变。 完整备份是必要的，但是很多时候其并不方便。它会产生很大的备份文件并且耗时不少。每一个完整备份都包含备份之间没有改变的数据，这是非常低效的。更高效的做法是先做一个初始的完整备份，再产生增量备份。增量备份更小，更快。但是相对的，在恢复的时候就不能只恢复完整备份，同样需要恢复增量备份。 为了制作增量备份，我们就要备份增量变化。MySQL是以二进制日志来进行实现的，所以mysqld应该总是以--log-bin选项启动。这样在更新数据的时候就会把数据变化写到二进制日志内。查看一下已经以--log-bin选项运行了几天的MySQL的数据目录，可以找到几个二进制日志： -rw-rw---- 1 guilhem guilhem 1277324 Nov 10 23:59 gbichot2-bin.000001-rw-rw---- 1 guilhem guilhem 4 Nov 10 23:59 gbichot2-bin.000002-rw-rw---- 1 guilhem guilhem 79 Nov 11 11:06 gbichot2-bin.000003-rw-rw---- 1 guilhem guilhem 508 Nov 11 11:08 gbichot2-bin.000004-rw-rw---- 1 guilhem guilhem 220047446 Nov 12 16:47 gbichot2-bin.000005-rw-rw---- 1 guilhem guilhem 998412 Nov 14 10:08 gbichot2-bin.000006-rw-rw---- 1 guilhem guilhem 361 Nov 14 10:07 gbichot2-bin.index 每当mysqld重启的时候就会创建一个新的二进制文件，序号会递增。在服务器运行中你也可以让服务器关闭当前的二进制日志而重新建立一个，使用FLUSH LOGS语句或mysqladmin flush-logs。mysqldump也有类似的选项。 .index文件记录了所有的二进制文件名列表。 二进制文件组成了增量备份，所以是非常重要的。如果你确定要在完整备份的时候刷新日志，后面建立的二进制日志就包含了所有你完整备份后的数据变化信息。让我们来修改一下先前的代码，这次我们会刷新日志，这样转储后的文件就会包含下一个二进制的文件名： shell&gt; mysqldump --single-transaction --flush-logs --master-date=2\\ --all-databases &gt; backup_sunday_1_pm.sql 在执行这个命令之后，数据目录下包含了一个新的二进制日志gbichot2-bin.000007，因为--flush-logs选项让服务器进行了刷新。--master-data选项让mysqldump将二进制日志信息写到输出，所以这次生成的 .sql 文件包含： -- Position to start replication or point-in-time recovery from -- CHANGE MASTER TO MASTER_LOG_FILE=&#39;gbichot2-bin.000007&#39;,MASTER_LOG_POS=4; 因为mysqldump做了一个完整备份，这两行意味着： 转储文件包含在gbichot2-bin.000007前的所有数据及变化。 所有在备份后产生的数据变化都写在gbichot2-bin.000007日志内。 在周一下午1点，我们可以通过刷新日志产生一个新日志来进行增量备份。mysqladin flush-logs命令将会产生gbichot28-bin.000008。所有从周日下午一点到周一下午一点的数据变化都在gbichot2-bin.000007。增量备份是重要的，所以要把他复制到一个安全的地方。周二下午一点，可以同样执行mysqladmin flush-logs来产生一个新的日志gbichot2-bin.000009，这样从周一下午一点到周二下午一点的所有数据变化都在gbichot2-bin.000008内了。 二进制日志非常占磁盘空间。为了释放空间的话，就要及时删除不用的二进制日志文件，在做了一个完整备份后： shell&gt; mysqldump --single-transactio --flush-logs --master-data=2 \\ --all-databases --delete-master-logs &gt; backup_sunday_1_PM.sql 注意：用--delete-master-logs选项在主服务器上是非常危险的，因为无法保证从服务器已经把所需要的二进制文件读取完毕。PURGE BINARY LOG语句解释了在删除二进制日志之前需要确认的事项。13.4.1.1 PURGE BINARY LOGS 语法 用备份进行恢复现在，假设我们在周三早上8点发生了一个意外，此时需要进行用备份进行恢复。首先我们进行完整备份的恢复： shell&gt; mysql &lt; backup_sunday_1_pm.sql 这时，数据已经存储成为周一下午1点的状态。要恢复从这个时候开始的数据变化，必须使用增量备份；也就是gbichot2-bin.000007和gbichot2-bin.000008文件。 shell&gt; mysqlbinlog gbichot2-bin.000007 gbichot2-bin.000008 | mysql 这样我们就已经把数据恢复到了周二的下午1点，但还缺少从这个时间点到崩溃点的数据。为了不丢掉这些数据，我们必须已经让mysql把二进制日志存储到了一个安全的地方（RAID，SAN …）反正不能和出现问题的硬盘放在一起。如果这样做了。我们现在应该是有一个gbichot2-bin.000009或者更大序号的文件，我们可以继续这样： shell&gt; mysqlbinlog gbichot2-bin.000009 | mysql 更多使用mysqlbinlog的信息，请参考7.5 用二进制进行时间点（增量）恢复。 备份策略总结在操作系统或者电源故障，InnoDB会自己进行恢复工作。但是为了保证你自己睡得安逸，确认一下下面的事项： 总是让mysqld以 --log-bin选项或者--log-bin= _log_name_运行，并且二进制要指定在与数据目录不一样的安全的磁盘上。如果这样做了，这也是一个非常不错的磁盘负载均衡。 进行间段性的完整备份。用mysqldump来进行一个在线的，不阻塞的备份。 进行间段性的增量备份，同时FLUSH LOGS或者mysqladmin flush-logs。 用mysqldump进行备份这一节描述了怎么样用mysqldump来产生转储文件，已经怎么样使用它。有下面几种方式来使用转储文件： 数据恢复 复制设置 实验 mysqldump产生两种形式的输出，取决于是否指定了--tab选项。 没有--tab选项。mysqldump把SQL语句写到标准输出这些输出由CREATE语句来创建转储对象（数据库，表，过程等等），INSERT语句来载入数据到表。这个输出可以存储到一个文件然后被用mysql用来重建数据对象。 有--tab。将会为每个dump产生两个文件。一个个 .sql文件，包含CREATE TABLE语句；一个 .txt 文件，表的每个记录一行。 Dump SQL格式数据shell&gt; mysqldump [ arguments ] &gt; file_name 备份所有库： shell&gt; mysqldump --all-databases &gt; dump.sql 备份指定库： shell&gt; mysqldump --databases db1 db2 db3 &gt; dump.sql 在没有 —databases 的情况下，db1 被认为是库，而db2 db3会被看做是表。 在使用--databases或--all-databases的情况下，mysqldump会将 CREATE DATABASE和USE语句写在每个使用库前。这样就保证了在重新载入的时候，没有库就建立库，然后让这数据从哪里来的，就到哪个库去。如果想要在重建之前强制删除掉库，加上--add-drop-databas选项。 备份某一个库： shell&gt; mysqldump --databases test &gt; test.sql shell&gt; mysqldump test &gt; test.sql 这两个语句的不同是：后者将不会产生CREATE DATABASE语句和USE语句。那么： 在使用dump文件的时候，必须指定库名。 可以指定与原来库名不一样的库。 如果库不存在，你必须先手动建立。 因为不产生CREATE DATABASE语句，所以--add-drop-database是无效的。 备份某库的某些表，在库名后指定表名即可： shell&gt; mysqldump test t1 t3 t7 &gt; dump.sql 重载SQL格式的备份为了重载一个转存文件，将它作为mysql客户端的输入即可。如果，在生成转储文件的时候，指定了--all-databases或--databases选项，文件内会包含CREATE DATABASE和USE语句，这样就不用在使用的时候指定库名了。 shell&gt; mysql &lt; dump.sql 或者可以在登录mysql后： mysql&gt; source dump.sql 如果要指定库名： shell&gt; mysql db1 &lt; dump.sql 如果生成的dump文件内不含有 CREATE DATABASE语句，那么首先我们就要建立好库，再使用dump文件。 mysql&gt; create database db1; mysql&gt; use db1; mysql&gt; source dump.sql; 用mysqldump生成格式化文本转储如果在使用mysql的时候指定--tab=dir_name选项，那么会把dir_name指定的目录作为输出目录，每个表会在这个目录下生成两个文件。对于一个表t1，会生成t1.txt和t1.sql两个文件，t1.sql包含CREATE TABLE语句，t1.txt包含数据，每个记录一行。 比如我们要转储 数据库 db1到 /tmp目录： shell&gt; mysqldump --tab=/tmp db1 .txt文件是由mysqld进行写入的，所以其被运行mysqld的账户所有用。实际上mysqld是使用SELECT ... INTO OUTFILE语句进行写入文件的，所以必须对目录具有这个权限，而且，t1.txt必须是不存在的。t1.sql同样。 最好只在本地使用--tab选项。如果在客户端指定远程服务器上的--tab选项，那么--tab后面的目录在客户端和服务端都必须存在。.txt文件只会写出到远程服务器，而.sql文件在本地和远程服务器都会生成。 对于mysqldump --tab，默认情况下每个记录一行，字段间用tab键进行分割，\\n被作为换成符，对值不会以引号进行引用。这和SELECT ... INTO OUTFILE类似。 如果想以一种不同的格式来转储文件，有几个选项可以进行指定： —fields-terminated-by=str 指定分列字符 (default: tab). —fields-enclosed-by=char 指定列值被什么符号包围 (default: no character). —fields-optionally-enclosed-by=char 指定非数值被什么所包围 (default: no character). —fields-escaped-by=char 反引特殊字符的字符 (default: no escaping). —lines-terminated-by=str 指定换行符 (default: newline). 有时候，我们指定的符号，可能会被shell当作特殊字符对待，这样我们就要对它进行引用。或者， 这几个选项我们可以用16进制代码来指定。现在假设我们想要这个列值被双引号&quot;所包围，但这个符号一般会被shell给特殊对待，所以我们必须对他进行引用。 --fields-enclosed-by=&#39;&quot;&#39; 在任何平台上，我们可以用16进制值： --fields-enclosed-by=0x22 同时指定几个选项很正常。比如，要用逗号分割列，用\\r\\n进行换行，用&quot;包围值： shell&gt; mysqldump --tab=/tmp --fields-terminated-by=,\\ --fields-enclosed-by=&#39;&quot;&#39; --lines-terminated-by=0x0d0a db1 不过在使用这个文件的时候，我们需要对mysql指定同样的选项哦。 使用文本格式化转储因为文本化转储使用的是两个文件分别存储了表结构和数据，所以我们也需要进行两步来使用他。 shell&gt; mysql db1 &lt; t1.sql shell&gt; mysqlimport db1 &lt; t1.txt 也可以在mysql客户端内用LOAD DATA INFILE语句来使用： mysql&gt; use db1; mysql&gt; LOAD DATA INFILE &#39;t1.txt&#39; INTO TABLE t1; 如果在生成转储的时候指定了不一样的格式，那么我们这时候也要指定同样的格式： shell&gt; mysqlimport --fields-terminated-by=,\\ --fields-enclosed-by=&#39;&quot;&#39; --lines-terminated-by=0x0d0a db1 t1.txt 或者： mysql&gt; USE db1; mysql&gt; LOAD DATA INFILE &#39;t1.txt&#39; INTO TABLE t1 -&gt; FIELDS TERMINATED BY &#39;,&#39; FIELDS ENCLOSED BY &#39;&quot;&#39; -&gt; LINES TERMINATED BY &#39;\\r\\n&#39;; mysqldump 建议这一节来解决一些使用mysqldump的问题： 如何复制一个数据库 如何复制一个数据库到另一台服务器 如何转储程序（触发器、过程、函数、事件） 如何分别转储定义和数据 复制一个数据库管 shell&gt; mysqldump db1 &gt; dump.sql shell&gt; mysqladmin create db2 shell&gt; mysql db2 &lt; dump.sql 这里就不要使用--databases选项，这样的话转储文件内的USE语句会将包含USE db1语句，将不会把数据导入到db2。 复制数据库到另外一个服务器Server1: shell&gt; mysqldump --databases db1 &gt; dump.sql 把dump.sql复制到Server2，执行: shell&gt; mysql &lt; dump.sql --databases选项的使用会让dump.sql文件内包含USE db1语句和CREATE DATABASE语句，如果想把数据导入一个不同名字的库，那么，不要指定--databases选项。 Server1: shell&gt; mysqldump db1 &gt; dump.sql Server2: shell&gt; mysqladmin create db2; shell&gt; mysql db2 &lt; dump.sql 转储存储程序几个选项来帮助mysqldump转储程序（过程、函数、事件、触发器等）。 —events：事件 —routines：过程和函数 —triggers：触发器 --triggers选项是默认开启的，其他两个则不是，需要明确指定。如果不想使用这三个选项，那么--skip-events, --skip-routines, --skip-triggers可以帮助你。 分开存储定义好数据--no-data， -D选项告诉mysqldump不要存储数据，所以其转储文件将只包含表的创建。对应的--no-create-info就会让mysqldump不要生成创建表语句，将只包含数据。 下面我们假设想要将test库的表好数据单独导出： shell&gt; mysqldump --no-data test &gt; dump-defs.sql shell&gt; mysqldump --no-create-info test &gt; dump-data.sql 对于一个只有定义的导出，指定--events, --routines将会把过程、函数、事件一起导出： shell&gt; mysqldump --no-data --routines --events test &gt; dump-defs.sql 用MySQLdump来测试升级兼容性在准备升级mysql版本的时候，在一个单独的测试服务器看上安装新版本的服务器，再把现在的库给导出过去进行测试是否正常。在生产服务器上： shell&gt; mysqldump --all-databases --no-data --routines --events &gt; dump-defs.sql 在升级服务器上： shell&gt; mysql &lt; dump-defs.sql 因为dump文件只包含定义，不包含数据，所以这个过程是非常快速的。这样就可以在不等待长时间数据载入操作就能测试兼容性。在过程中仔细观察出现的错误或者警告。 如果一切正常从，那么把数据给导出，然后导入新服务器： 生产服务器上： shell&gt; mysqldump --all-databases --no-create-info &gt; dump-data.sql 升级服务器上： shell&gt; mysql &lt; dump-data.sql 然后检查一下表内容和一些其他测试就OK了。 时间点（增量）恢复（使用二进制日志）事件点恢复一般是在一个完整备份的恢复后，利用二进制日至来进行数据变化的重放。 我们这里用mysql客户端来处理mysqlbinlog解析日志后的输出。但如果二进制日至包括 \\0(null)字符，mysql只有在指定了--binary-mode选项是才能正常工作。 时间点恢复基于以下几个规则： 时间点恢复的数据源是在某要完整备份后二进制日至所做的增量备份。因此，服务器必须以--log-bin选项启动来启动二进制日志。为了从二进制日志恢复数据，我们必须知道当前二进制的名字和位置（坐标）。默认情况下，服务器在数据目录生成二进制日志，但可以用--log-bin=选项来指定一个不一样的位置。想观察二进制日志列表，用以下语句： mysql&gt; SHOW BINARY LOGS; 想知道当前使用的日志是哪个，用下面这个语句： mysql&gt; SHOW MASTER STATUS; mysqlbinlog程序将二进制日志内的事件变化解析为文本格式以方便识别和使用。同时其也含有一系列选项可以根据事件时间或者位置来进行范围选择。4.6.7节 mysqlbinlog - 处理二进制日志工具 执行二进制日志内的事件变化相当于事件的重放。为了这样，将mysqlbinlog的输出传递给mysql客户端的输入 。 shell&gt; mysqlbinlog binlog_files | mysql -u root -p 当你想在某一个时间或者位置进行数据恢复的时候，看一下binlog的内容是非常有用的。 shell&gt; mysqlbinlog binlog_files | more 或者将输出重定向到一个文件： shell&gt; mysqlbinlog binlog_files &gt; tmpfile shell&gt; ... edit tmpfile ... 把输出重定向到一个文件，这时我们就可以在文件内删除特定的事件或者内容，然后再用mysql导入，这是非常有用的。 shell&gt; mysql -u root -p &lt; tmpfile 如果不止一个二进制日志文件需要处理，安全的办法是在一个连接内进行处理，而不是分开处理。下面就是一个不怎么安全的方法： shell&gt; mysqlbinlog binlog.000001 | mysql -u root -p # DANGER!! shell&gt; mysqlbinlog binlog.000002 | mysql -u root -p # DANGER!!` 这所以这样在两个连接内处理不安全的原因，是因为第一个连接可能包含一个CREATE TEMPORARY TABLE语句，然后第二个连接可能会需要这个临时表。当第一个连接关闭的时候，mysql进程就会删除临时表。这样，第二个连接要使用这个临时表的时候就会出现unknown table。 下面这种方法才是推荐的: shell&gt; mysqlbinlog binlog.000001 binlog.000002 | mysql -u root -p 或者将所有的二进制日志解析输出到一个单独的文件： shell&gt; mysqlbinlog binlog.000001 &gt; /tmp/statements.sql shell&gt; mysqlbinlog binlog.000002 &gt;&gt; /tmp/statements.sql shell&gt; mysql -u root -p -e &quot;source /tmp/statements.sql&quot; 利用事件时间来进行恢复为了指定开始时间和结束时间，用DATETIME格式为mysqlbinlog指定--start-time和--end-time选项。假如我们在2005年4月20日的上午10点删除了一个大表。我们可以这样来进行恢复： shell&gt; mysqlbinlog --stop-datetime=&quot;2005-04-20 9:59:59&quot; \\ /var/log/mysql/bin.123456 | mysql -u root -p 这会将数据恢复到--stop-time指定的时间，但如果我们是在之后某几个小时内进行恢复的话，之后的数据也需要进行恢复进来。 shell&gt; mysqlbinlog --start-datetime=&quot;2005-04-20 10:01:00&quot; \\ /var/log/mysql/bin.123456 | mysql -u root -p 如此，就跳过了我们执行的那个删除表的语句了。 有的时候，我们忘记了在什么时间执行了错误的操作，我们可以把将二进制日志解析后进行观察。通过跳过指定时间来排除要执行重放的语句并不一定工作得很好，因为有可能在那时间内执行了多个操作。 利用事件位置进行恢复--start-position, --stop-position选项可以指定开始和结束的位置。这样能更精确的控制想要执行和不执行的语句，这在对于相同时间内执行多个语句是非常有用的，因为位置是被串行化进行记录的。我们可以通过指定时间解析二进制日志后，查看那些错误操作的语句位置，然后跳过它： shell&gt; mysqlbinlog --start-datetime=&quot;2005-04-20 9:55:00&quot; \\ --stop-datetime=&quot;2005-04-20 10:05:00&quot; \\ /var/log/mysql/bin.123456 &gt; /tmp/mysql_restore.sql 打开mysql_restory.sql文件，找到我们执行错误语句的位置，然后下面的两个例子将会跳过368312到368315位置之间的语句。 shell&gt; mysqlbinlog --stop-position=368312 /var/log/mysql/bin.123456 \\ | mysql -u root -p shell&gt; mysqlbinlog --start-position=368315 /var/log/mysql/bin.123456 \\ | mysql -u root -p MyISAM表的维护及崩溃恢复这一节讨论用myisamchk程序来修复MyISAM表。对于基本知识的话，看一下4.6.3 myisamchk - MyISAM表维护工具。其他表修复信息可以查看2.11.4 重建或修复表或索引。 可以用myisamchk来修复、检查、优化数据库表。接下来的章节讨论了这几个问题和怎么样设置一个表维护调度。关于怎么样使用myisamchk来获取表的信息，参考4.6.3.5 用myisamchk获取表信息。 尽管myisamchk来修复表是安全的，但是做一个备份，也是非常必要的操作。在其他对表进行操作的时候一样这样考虑。 myisamchk操作影响索引的话，会导致用full-text参数来重建FULLTEXT索引，这与MYSQL使用的值不兼容。为了避免这个问题，参考4.6.3.1 myisamchk 一般建议。 MyISAM表可以通过SQL语句的执行来达到myisamchk同样的结果： 用CHECK TABLE来检查MyISAM表 用REPAIR TABLE来修复MyISAM表 用OPTIMIZE TABLE来优化MyISAM表 用ANALYZE TABLE来分析MyISAM表关于这些语句的信息，查看13.7.2 表维护语句。这些语句其实可以通过mysqlcheck语句来执行。使用这个的语句就是所有的事情都由myisamchk来执行。在使用myisamchk的时候，必须确定服务器没有使用对应的表，以避免两者之间的交互。 用myisamchk来进行崩溃恢复这一节描述了怎么样检查和处理数据错误。如果你的数据库经常出现问题，应该尝试着找出原因。B.5.3.3 为什么MYSQL总是崩溃。对于为什么MyISAM表会出现问题的解释，看一下15.3.4 MyISAM表问题。 当以禁止外部锁定方式运行mysqld（默认就是这样）时，在mysqld使用同一个表的时候执行myisamchk是不可靠的。如果你能确定在使用myisamchk之间没有人会使用那个表，你只需要在执行命令之前执行mysqladmin flush-tables。如果无法保证，那么必须先停止mysqld再执行检查。当在执行myisamchk的时候mysqld正在执行更新，那么你就会得到一个警告会产生冲突。 如果mysqld以外部锁启用的形式运行，可以在任何时候使用myisamchk。在这样的情况下，如果mysqld试图更新表，它必须等待myisamchk执行完毕。 在用myisamchk修复或者优化表的时候，必须总是保证mysqld不会使用这个表。在没有停止mysqld的情况下，必须先执行mysqladmin flush-tables。如果myisamchk和mysqld同时访问表的会话出现问题。 当进行崩溃恢复的时候，必须要清楚，一个MyISAM表包括三个文件。 tbl_name.frm 定义文件 tbl_name.MYD 数据文件 tbl_name.MYI 索引文件多数情况下都是MYD和MYI文件产生问题。myisamchk通过逐行复制.MYD文件创建副本，创建完成的时候就会删除原来的MYD文件，并重新命名新建的文件。如果加上--quick选项，myisamchk假设.MYD文件是正常的，只是产生一个新的索引文件。这是安全的，因为myisamchk会自动检查.MYD文件是否有问题，有问题会自动停止。可以指定--quick两次，这样，在出现某些错误（重复键错误）的时候它并不会停止，而是会试图修改。MYD文件进行解决。一般只有在拥有很小的空闲磁盘空间的情况下会加上两个--quick，不过在这样的情况下，最好先做好表的备份。 如何检查MyISAM表的错误以下命令： myisamchk tbl_name这会找出99.99%的错误。不能找出的一般就是只是.MYD文件的错误。一般来说，会不带任何选项，或者-s（slient）选项运行myisamchk。 myisamchk -m tbl_name这会找出99.999%的错误。首先会检查所有的索引错误，然后再读取所有行。会对所有的键值计算一个校验和并与索引树内的进行对比。 myisamchk -e tbl_nameThis does a complete and thorough check of all data (-e means “extended check”). It does a check-read of every key for each row to verify that they indeed point to the correct row. This may take a long time for a large table that has many indexes. Normally, myisamchk stops after the first error it finds. If you want to obtain more information, you can add the -v (verbose) option. This causes myisamchk to keep going, up through a maximum of 20 errors. myisamchk -e -i tbl_name与前面类似，不过-i选项会打印出附加的状态信息。 多数情况下，简单的一个不带选项参数的命令就够了。 如何修复一个MyISAM表本节讨论如何在MyISAM表上使用myisamchk。我们依然可以使用SQL语句来CHECK TABLE和REPAIR TABLE来检查和修复表 故障一般会有类似的错误： tbl_name.frm 锁定无法改变 找不到tbl_name.MYI(错误码:nnn) 非期望的文件结尾 记录文件已经崩溃 从表控制处获得nnn错误。为了获得关于错误更多的信息，执行perror nnn。下面的例子展示了大多数的错误： shell&gt; perror 126 127 132 134 135 136 141 144 145 MySQL error code 126 = Index file is crashed MySQL error code 127 = Record-file is crashed MySQL error code 132 = Old database file MySQL error code 134 = Record was already deleted (or record file crashed) MySQL error code 135 = No more room in record file MySQL error code 136 = No more room in index file MySQL error code 141 = Duplicate unique key or constraint on write or update MySQL error code 144 = Table is crashed and last repair failed MySQL error code 145 = Table was marked as crashed and should be repaired 135、136通过一个简单的修复就可以解决。这种情况下，必须用ALTER TABLE来增加MAX_ROWS和AVG_ROW_LENGTH表选项： ALTER TABLE tbl_name MAX_ROWS=xxx AVG_ROW_LENGTH=yyy; 如果你不知道当前表的选项值，使用SHOW CREATE TABLE语句。对于其他错误，你必须修复你的表。myisamchk可以检查并修复大多数出现的错误。 修复过程有四步。在操作之前，先切换到数据目录，并检查对文件的权限。在UNIX必须保证运行mysqld的用户具有渡权限，如果要进行修改操作的话，还必须具有写权限。 这节来讨论检查失败，或者想要使用一些myisamchk提供的扩展选项。 如果想要开始修复一个表，首先要停止mysqld。 你对远程服务器执行mysqladmin shutdown的时候，服务器还有一段时间是可用的，必须等待正在执行的语句完毕，数据刷新到磁盘才会关闭。 Stage 1: 检查表用 myisamchk *.MYI 或 myisamchk -e *.MYI如果世界足够的话。用-s选项来避免不必要的信息。如果mysqld说停止的，那么用--update-state来告诉myisamchk表明表已经检查过了。只需要修复myisamchk报错的表，进入Stage 2。如果遇到了未知的错误（如内存溢出问题），或者myisamchk崩溃，进入Stage 3。 Stage 2:简单的安全修复首先，尝试myisamchk -r q tbl_name（-r -q是快速恢复模式的意思）。这会尝试修复索引文件，不会创建数据文件。如果数据文件包含了其应该包含的所有数据以及在数据文件中当前未知的删除连接点？这将会工作，表就会被修复。否则的话按照以下过程处理： 备份数据文件。（*.MYD） 用myisamchk -r tbl_name命令。这将会删除错误的行，并重建索引文件。 如果第二部失败了。使用myisamchk --save-recover tbl_name。安全恢复模式使用一种老的恢复方法来对付几种情况，常规恢复方法不会处理。（但是更慢） 如果想要修复速度更快，设置sort_buffer_size, key_buffer_size分别为你内存的25%。遇到一些意外的问题，进入Stage 3。 Stage 3:困难的修复到打这一步的可能是索引文件的开始16KB已经被销毁或者出现了错误信息，或者索引文件丢失。这样的情况下，创建一个新的索引文件是必须的。按下操作： 备份数据文件。（*.MYD） 用表描述文件来创建新的（空的）数据文件好索引文件。 shell&gt; mysql db_namemysql&gt; SET autocommit=1;mysql&gt; TRUNCATE TABLE tbl_name;mysql&gt; quit 把备份的数据文件覆盖到现在新建的空的数据文件。 在使用复制服务器的时候，要首先停止复制服务器。因为这些属于文件系统的操作，mysql并不会记录到日志。 回到 Stage 2。同样可以使用REPAIR TABLE tbl_name USE_FRM语句，这与上述操作一样。 Stage 4：非常困难的修复到达这一步的话，唯一的可能就是连*.frm文件都崩溃了。这应该从不会发生，因为当表创建后，这个文件就不会再改变。 从备份恢复描述文件，然后回到Stage 3。也可以恢复索引文件然后会开采Stage 2。稍后，你就可以使用myisamchk -r。 如果没有备份描述文件，但是确切的知道表是怎么样创建的，在另外一个数据库创建同样的表。删除新建的数据文件，把新建的.MYI好.frm文件复制到崩溃的数据库。然后回到 Stage2，尝试重建索引文件。 MyISAM表优化为了整理碎片行好避免磁盘空间的浪费，运行： shell&gt; myisamchk -r tbl_name 可以用OPTIMIZE TABLE语句达到相同的目的。OPTIMIZE TABLE进行一个表修复和键分析，同事排序索引树以便搜索更快。myisamchk提供很多选项用来提高表的性能： —analyze or -a: Perform key distribution analysis. This improves join performance by enabling the join optimizer to better choose the order in which to join the tables and which indexes it should use. —sort-index or -S: Sort the index blocks. This optimizes seeks and makes table scans that use indexes faster. —sort-records=index_num or -R index_num: Sort data rows according to a given index. This makes your data much more localized and may speed up range-based SELECT and ORDER BY operations that use this index. 设置一个MyISAM表维护调度计划进行常规的检查儿不是在出现问题的时候在检查是个非常好的主意。检查和修复表的一个办法是使用REPAIR TABLE好CHECK TABLE语句。 另外一个方式就是使用myisamchk程序。为了维护的目的，可以用myisamchk -s，这会只在出现错误的时候打印出来信息。进行自动的MyISAM表检查也是非常棒的。比如说，当一个服务器在更新时发生了重启，你必须要检查所有的表是不是收到了影响。如果要让服务器自动的检查MyISAM表，一--myisam-recover-options选项。 也可以设置一个cron任务来定时的进行检查表： 35 0 * * 0 /path/to/myisamchk --fast --slient /pat/to/datadir/*/*.MYI 通常情况下，MYSQL表需要更少的维护工作。如果对MyISAM表进行了许多动态行更新（具有varchar, BLOB, TEXT列的表）或者表已经进行了很多删除工作，你可能想要及时进行碎片整理或者释放空间。可以用OPTIMIZE TABLE来达成目的。当然，如果你能停止mysqld一会儿，切换到数据目录，然后执行下面的命令： shell&gt; myisamchk -r -s --sort-index --myisam_sort_buffer_size=16M */*.MYI","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://gowa2017.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://gowa2017.github.io/tags/MySQL/"}],"keywords":[{"name":"MySQL","slug":"MySQL","permalink":"https://gowa2017.github.io/categories/MySQL/"}]},{"title":"家庭装修中常见工程及注意事项","slug":"家庭装修中常见工程及注意事项","date":"2017-12-26T13:54:39.000Z","updated":"2017-12-26T13:54:39.000Z","comments":true,"path":"杂项/家庭装修中常见工程及注意事项.html","link":"","permalink":"https://gowa2017.github.io/杂项/家庭装修中常见工程及注意事项.html","excerpt":"买房子，装修房子，这样的事情，很多人可能一辈子只有一次，就没有第二次了，所以很多问题，事情都是在道听途说的情况下知道一些东西，但是不知道很多东西。等到开始装修的时候就会发现很多坑爹的地方，然后等到装完了才会发现更多坑爹的地方。对于房子，如果是自建房，在开始建立就做好设计方案，后面会减少很多很多不必要的问题；对于房开处购买的房子，装修也要一定事先规划好，不然后悔莫及啊。","text":"买房子，装修房子，这样的事情，很多人可能一辈子只有一次，就没有第二次了，所以很多问题，事情都是在道听途说的情况下知道一些东西，但是不知道很多东西。等到开始装修的时候就会发现很多坑爹的地方，然后等到装完了才会发现更多坑爹的地方。对于房子，如果是自建房，在开始建立就做好设计方案，后面会减少很多很多不必要的问题；对于房开处购买的房子，装修也要一定事先规划好，不然后悔莫及啊。 等到我开始的时候，房子基本已经建立好了，就剩下装修好没有搞了。当时是没有任何图的，农村房子嘛，都是做到什么随口问一句，差不多就那么定了，所以遗留了很多让人难以改变的痛苦。下面就来一一说一说遇到的问题。 门一个装修常用的就是：室内门、厕所门、入户门（一般都用防盗门了），下面重点来说一下室内门。 厕所门这个一般现在大多数都选择的是铝合金+钢化玻璃门。防潮耐用，保温隔音也还过得去。一般来说这个没有什么坑的，铝材注意说好1.2就是1.2不要整个1.0的给你就行了。至于说用50还是70的，看自己喜好。当然70的要贵些。 室内门室内门大多都会选择实木复合门。真正的实木门，就是门扇、门锁、门套、门线，全部都用实木做的，这样的门，就是用普通的杉木来做，也是一千多起步，挂个牌子的，大几千了扇。 复合门么，就是主要结构部分用实木，然后填充部分用其他物的。基本做法是：门边的那宽的门冒用的是木芯指接板，外面搞一层密度板，最外面再搞一层材料做花纹，防潮，防刮什么的；然后门扇中间用的就是蜂窝纸、桥洞力学纸或者带间隔的木条填充。门线、门框的话一般都是用的密度板或者胶合板。这样 门几百块钱一扇。 问题就是，比较坑爹的就是，我们家找的是厂家去做门，然后量门尺寸的是另外找的人，结果量的人把尺寸递过去了以后，厂家把尺寸缩了一点，门就小了，和门洞之间的距离就大了。就算打上发泡胶，贴上线条，门套与门洞间还是有缝隙，这是超级恶心的事情。想找售后都只能遇到相互推诿的情况。 所以说，下次搞门的话，一定要找同一个厂家来进行测量、制作、安装，否则会郁闷到死。 水电麻烦在水电设计的时候，一定要提前预留好孔位，埋好地线、水管不然整都整不了。 排水一般来说应该有统一的排水，但是自建房的时候要弄清楚，厨房、厕所在哪里，哪个方位排水，厨房布局、厕所各部件配置是怎么样的，留好的地漏必须得合理，不然到最后房屋放灶台、马桶、浴缸什么的就会发现怎么摆怎么不行。 电点这个没得说的，弄得方便就好了，一般为了避讳“灯压床”的说法，卧室灯不要正对着床头或者床腰，尽量往床尾放，或者不要直照着床。","categories":[{"name":"杂项","slug":"杂项","permalink":"https://gowa2017.github.io/categories/杂项/"}],"tags":[{"name":"装修","slug":"装修","permalink":"https://gowa2017.github.io/tags/装修/"}],"keywords":[{"name":"杂项","slug":"杂项","permalink":"https://gowa2017.github.io/categories/杂项/"}]},{"title":"curl 使用入门","slug":"curl-使用入门","date":"2017-12-22T06:45:58.000Z","updated":"2017-12-22T06:45:58.000Z","comments":true,"path":"Shell/curl-使用入门.html","link":"","permalink":"https://gowa2017.github.io/Shell/curl-使用入门.html","excerpt":"curl 是一个命令行工具和「库」，目的是用来通过urls传输数据。其支持多个协议，多用来在命令行或者脚本来传输数据。通过其官方的这个入门的Tutorial可见其用处的广泛。 最新版本的curl可以通过其官方网站 curl.haxx.se获取","text":"curl 是一个命令行工具和「库」，目的是用来通过urls传输数据。其支持多个协议，多用来在命令行或者脚本来传输数据。通过其官方的这个入门的Tutorial可见其用处的广泛。 最新版本的curl可以通过其官方网站 curl.haxx.se获取 简单用法 获取Netscape网站的首页： curl http://www.netscape.com/ 获取某个FTP服务器上的README文件： curl ftp://ftp.funet.fi/README 获取使用非标准端口网站的首页： curl http://www.weirdserver.com:8000/ 获取FTP服务器的目录列表： curl ftp://cool.haxx.se/ 从一个词典网站获取对curl的定义： curl dict://dict.org/m:curl 同时获取两个文件： curl ftp://cool.haxx.se/ http://www.weirdserver.com:8000/ 获取FTPS服务器上的文件： curl ftps://files.are.secure.com/secrets.txt 或者使用更适合的FTPS方式获取同样的文件： curl --ftp-ssl ftp://files.are.secure.com/secrets.txt 从SSH服务器上通过SFTP获取文件： curl -u username sftp://example.com/etc/issue 从SSH服务器上用SCP协议通过私钥（没有密码保护）认证获取文件： curl -u username: --key ~/.ssh/id_rsa \\ scp://example.com/~/file.txt 从SSH服务器上用SCP协议通过私钥（有密码保护）认证获取文件： curl -u username: --key ~/.ssh/id_rsa --pass private_key_password \\ scp://example.com/~/file.txt 获取IPv6网站的首页： curl &quot;http://[2001:1890:1112:1::20]/&quot; 从SMB服务器获取文件： curl -u &quot;domain\\username:passwd&quot; smb://server.example.com/share/file.txt 下载到一个文件 获取一个网页，然后保存到本地，用一个指定的名字： curl -o thatpage.html http://www.netscape.com/ 保存为和服务器一样的名字： curl -O http://www.netscape.com/index.html 同时获取两个文件，但是保存名字不变： curl -O www.haxx.se/index.html -O curl.haxx.se/download.html 使用密码FTP有两种方式： curl ftp://name:passwd@machine.domain:port/full/path/to/file 或者： curl -u name:passwd ftp://machine.domain:port/full/path/to/file FTPS 和用FTP一样，但是你应该加上 SSL选项 --ftp-ssl。 不建议用ftps:// 这样的方式，而建议使用： curl --ftp-ssl ftp:// 这样的方式。 SFTP / SCP 和FTP使用也类似，但是你可以用 --key选项指定一个私钥，而不使用密码。（私钥有可能是受密码保护的，这个时候就要用--pass选项来指定保护私钥的密码）。 HTTP curl 也支持用户名和密码的网页，但是现在用得已经很少了。 curl http://name:passwd@machige.domain/full/path/to/file 或者用-u指定用户名和密码： curl -u name:passwd http://machine.domain/full/path/to/file HTTP支持很多不同方式的认证，curl支持其中的几种：Basic, Digest, NTLM和Negotiate。在没有指定方式的情况下，默认使用 Basic。可以通过--anyauth选项来让服务器选择哪一种方式。 根据 URL标准，HTTP URLS不能在连接内包含用户名和密码，通过代理的时候，这就会出问题。这时候，必须使用 -u这样的格式来指定。 HTTPS 看后面有介绍。 代理 curl支持HTPP和SOCKS代理服务器，即使包括认证。FTP代理也是支持的，但是现在没有一个统一的标准，大多数情况下也能工作得很好。 从ftp服务器上通过代理的888端口获取一个文件： curl -x my-proxy:888 ftp://ftp.leachsite.com/README 用和上面一样的代理从HTTP服务器通过用户名和密码进行认证获取文件： curl -u user:passwd -x my-proxy:888 http://www.get.this/ 有些代理需要一些特定的认证，用-U选项进行指定： curl -U user:passwd -x my-proxy:888 http://www.get.this/ 要指定某些域名或主机不使用认证的话可以像下面一样样--noproxy和逗号分割： curl --noproxy localhost,get.this -x my-proxy:888 http://www.get.this/ 如果代理是用--proxy1.0指定，而不是用--proxy或-x，那么curl会使用HTTP/1.0，而不是HTTP/1.1。 curl通过--socks4 --socks5支持 SOCKS4和SOCKS5代理。 大多数FTP代理服务器被设置为在客户端看起来他们就像一个正常的FTP服务器，通过特定的命令来选择远程FTP服务器。 curl支持-u, -Q, --ftp-account选项来设置通过很多ftp代理进行传输数据。举例说明，一个文件可以通过Blue Coat FTP代理传输到一个远程FTP服务器： curl -u “Remote-FTP-Username@remote.ftp.server Proxy-Username:Remote-Pass” \\ —ftp-account Proxy-Password —upload-file local-file \\ ftp://my-ftp.proxy.server:21/remote/upload/path/ 查看你的FTP代理手册来了解哪一种形式的传输，同时用curl -v选项看一下到底发送出去了什么。 范围 HTTP 1.1 介绍了字节范围。通过这个，一个客户端可以请求获得某个文档的一个字节或者一部分。curl通过-r选项进行支持。 获取文档的前100个字节： curl -r 0-99 http://www.get.this/ 获取文档的最后500字节： curl -r -500 http://www.get.this/ curl同样支持简单的对FTP文件的范围指定。我们可以指定起止位置： 获取开始的100字节通过FTP： curl -r 0-99 ftp://www.get.this/README 上传FTP / FTPS / SFTP / SCP 把标准输入的所有内容传输到一个服务器： curl -T - ftp://ftp.upload.com/myfile 通过用户名和密码登录，把某一文件进行上传： curl -T uploadfile -u user:passwd ftp://ftp.upload.com/myfile 上传一个本地文件到远程网站，文件名不变： curl -T uploadfile -u user:passwd ftp://ftp.upload.com/ 上传一个本地文件，并附加到某一文件： curl -T localfile -a ftp://ftp.upload.com/remotefile curl也支持通过代理上传到FTP，但这样的前提是代理设置为允许这种隧道。如果这样设置了代理的话，可以用如下类似的方式上传： curl --proxytunnel -x proxy:port -T localfile ftp.upload.com SMB / SMBS curl -T file.txt -u &quot;domain\\username:passwd&quot; smb://server.example.com/share/ HTTP 上传标准输入到一个HTTP网站： curl -T - http://www.upload.com/myfile 注意：网站必须被配置为允许put。 对于上传HTTP数据的其他方式，查看POST一节。 VERBOSE / DEBUG 这两个选项主要用来调试用： curl -v ftp://ftp.upload.com/ 如果需要更加详细的信息，那么用--trace 或者 --trace-ascii选项来将信息保存到一个文件： curl --trace trace.txt www.haxx.se DETAILED INFORMATION 不同协议支持不同的方式来获取指定文档的详细信息。为了让curl来展示单独一个文件的详细信息，你要用-I/--head选项。这将会展示单独一个文件的所有可用信息（HTTP、FTP）。HTTP信息可是非常广泛的。 对于 HTTP，我们用-i/--include选项可以让头部信息在数据之前显示。curl对FTP和HTTP协议识别-D/--dump-header选项，然后会把头部信息存放在这个选项指定的文件内。 存储HTTP头部在一个单独的文件（例子中是放在headers.txt中）： curl --dump-header headers.txt curl.haxx.se 将头部信息存放在一个单独我文件是非常有用的，特别是当你后面要让curl使用cookies的时候。更详细的查看cookies一节。 POST (HTTP) 通过curl来POST数据非常简单的。用-d选项就可以了，post过去的数据会被加密。 Post一个简单的”name”和”phone”顾客表： curl -d &quot;name=Rafael%20Sagula&amp;phone=3320780&quot; \\ http://www.where.com/guest.cgi 怎么样Post一个表单，请看 lesson #1: 找出想要填写表单的所有标签。（有一个叫做formfind.pl的perl程序可以帮助我们，curl官方网站有下载）。 如果是一个”常规的“Post，使用-d选项。-d使用一个完整的”post string”，用下面这种形式： &lt;variable1&gt;=&lt;data1&gt;&amp;&lt;variable2&gt;=&lt;data2&gt;&amp;... ‘varialbe’名字是在标签中的”name=”后面的值，数据就是你想要填进这个input里面的值。数据必须是 URL encoded。也就是说，用-来替换空格，然后用%XX这样的形式来代替奇怪的符号。 例子： (page located at http://www.formpost.com/getthis/ &lt;form action=&quot;post.cgi&quot; method=&quot;post&quot;&gt; &lt;input name=user size=10&gt; &lt;input name=pass type=password size=10&gt; &lt;input name=id type=hidden value=&quot;blablabla&quot;&gt; &lt;input name=ding value=&quot;submit&quot;&gt; &lt;/form&gt; 我们想输入用户名’foobar’，密码’12345’。 想要post这两个数据，我们可以： curl -d &quot;user=foobar&amp;pass=12345&amp;id=blablabla&amp;ding=submit&quot; (continues) http://www.formpost.com/getthis/post.cgi -F选项接受像-F &quot;name=contents&quot;这样的参数。如果想要内容来自于文件的话，用&lt;@filename&gt;替代内容。当指定一个文件的时候，同时可以指定文件内容的类型，通过附加:type=&lt;mime type&gt;在文件名字后面。当然，我们也可以把几个文件在一个字段来进行post。比如，字段coolfiles被用来发送三个文件，但是文件具有不同的内容类型： curl -F &quot;coolfiles=@fil1.gif;type=image/gif,fil2.txt,fil3.html&quot; \\ http://www.post.com/postit.cgi 如果内容类型没有指定，curl会尝试从文件的扩展名进行猜测（只有部分能猜出来），或者用之前指定的类型（从前些个指定的文件类型），或者使用默认的application/octet-stream类型。 仿真一下用-F来填充一个表单。假设我们要填充某一表单的三个字段。文件名，用户名，文件描述。我们要post我们已经写好的名字叫cooltext.txt的文件。现在我们用curl而不是浏览器来完成这个任务，在此之前我们必须阅读一下这个表单页面的HTML源代码来找到输入字段的名字。我们的例子里，这三个输入字段分别为：file,yourname,filedescription。 curl -F &quot;file=@cooltext.txt&quot; -F &quot;yourname=Daniel&quot; \\ -F &quot;filedescription=Cool text file with cool text inside&quot; \\ http://www.post.com/postit.cgi 如果想在一个POST请求中发送两个文件有两种方式可以做到： 在一个字段内指定多个文件： curl -F “pictures=@dog.gif,cat.gif” 在两个字端内指定两个文件： curl -F “docpicture=@dog.gif” -F “catpicture=@cat.gif” 如果我们想传输字面意义的字符的时候，比如@,&lt;,或者;type=的时候，用--form-string选项，而不是-F。 REFERRER 一个HTTP请求有应该包含从哪里链接到了实际的访问地址。curl可以让我们在命令行上就指定。这是非常实用的一个功能，可以用来愚弄依靠这个引用信息来返回一些信息的愚蠢的服务器或者CGI脚本。 curl -e www.coolsite.com http://www.showme.com/ NOTE: The Referer: [sic] field is defined in the HTTP spec to be a full URL. USER AGENT 一个HTTP请求有一个选项来包含是哪个浏览器产生了这个请求。curl可以通过命令行来指定。这个你懂的。 例子： curl -A ‘Mozilla/3.0 (Win95; I)’ http://www.nationsbank.com/ Other common strings: &apos;Mozilla/3.0 (Win95; I)&apos; Netscape Version 3 for Windows 95 &apos;Mozilla/3.04 (Win95; U)&apos; Netscape Version 3 for Windows 95 &apos;Mozilla/2.02 (OS/2; U)&apos; Netscape Version 2 for OS/2 &apos;Mozilla/4.04 [en] (X11; U; AIX 4.2; Nav)&apos; NS for AIX &apos;Mozilla/4.05 [en] (X11; U; Linux 2.0.32 i586)&apos; NS for Linux``` &gt; Note that Internet Explorer tries hard to be compatible in every way: &apos;Mozilla/4.0 (compatible; MSIE 4.01; Windows 95)&apos; MSIE for W95 Mozilla is not the only possible User-Agent name: &#39;Konqueror/1.0&#39; KDE File Manager desktop client &#39;Lynx/2.7.1 libwww-FM/2.14&#39; Lynx command line browser ``` COOKIES Cookies经常被服务器用来保存客户端侧的状态信息。服务器通过在头部发送一个响应行，类似Set-Cookie: &lt;data&gt;，然后内数据部分典型的包含一系列 NAME=VALUE的键值对。（用;分割） 服务器也能指定哪个路径使用这个cookie（path-value)，什么时候过期(expire=DATE)，哪个域名使用（domain=NAME），在安全连接上是否使用（secure）。 如果你收到了一个包含类似下面头部的页面： Set-Cookie: sessionid=boo123; path=&quot;/foo&quot;; 这是说服务器希望在get任何一个以/foo开头的路径是要通过sessionid boo123来匹配。 比如，获取一个希望名字进行匹配cookie的页面： curl -b &quot;name=Daniel&quot; www.sillypage.com curl同样具有使在接下来的sessions里面使用以前接受到的cookies。如果你用下面的方式保存收到的cookies： curl --dump-header headers www.example.com 我们可以在马上用这个cookies来连接网站： curl -b headers www.example.com 把头部信息存储到一个文件是个保存cookies的一个方式，但却不是一个方便的方式。我们可以把cookies以广为人知的netscape cookie格式进行保存。 curl -c cookies.txt www.example.com 注意，-b选项会启用cookie awareness，-L选项可以让curl跟随一个位置：（常常用来结合cookies使用）。因此如果一个站点发送了一个cookie和一个位置，我们就可以用一个不存在的文件来触发cookie awareness： curl -L -b empty.txt www.example.com 用来读取cookies的文件必须是HTTP头部信息格式或者netscape格式的cookie文件，curl通过内容来判定属于哪一种格式。在上面那个代码中，curl会解析头部并且存储从www.example.com收到的cookie信息。curl在请求匹配那个位置的时候把已保存的cookie发送到服务器。empty.txt文件必须保证是不存在的。 为了读写一个netscape的cookie文件，可以用-b 和-c选项在同一个文件上进行。 curl -b cookies.txt -c cookies.txt www.example.com PROGRESS METER 进度测量用来表明某些事情正在发生。不同的字段含有的意义如下： % Total % Received % Xferd Average Speed Time Curr. Dload Upload Total Current Left Speed 0 151M 0 38608 0 0 9406 0 4:41:43 0:00:04 4:41:39 9287 从左至右： % - 整体完成百分比。 Total - 要求传输的全部大小。 % - 当前下载完成度 Received - 当前下载字节数。 % - 当前上传百分比 Xferd - 当前上传字节数。 Average Speed Dload - 平均下载速度 Average Speed Upload - 平均上传速度 Time Total - 预计完成时间 Time Current - 当前经过时间 Time Left - 预计剩余时间 Curr.Speed - 5秒内进行的平均速度。 -#选项会显示更少的解释。 速度限制 Curl允许我们设置继续传输必须匹配的条件。通过-y和-Y选项，我们可以让curl在某一连续时间内速度太慢的话就退出。 为了让在连续一分钟内速度低于3000b/s的时候curl中断下载，运行： curl -Y 3000 -y 60 www.far-away-site.com 进行超时设置也是一个非常不错的做法，让上面这个操作必须在30分钟内完成： curl -m 1800 -Y 3000 -y 60 www.far-away-site.com 强制要求curl必须不能超过一个给定的数值也是可以的，在你使用一个带宽受到限制的连接，你可能并不想让curl全部使用它。 让curl每秒的传输速度不要超过10KB： curl --limit-rate 10K www.far-away-site.com or curl --limit-rate 10240 www.far-away-site.com 或者不让curl上传速度超过1M/s： curl -T upload --limit-rate 1M ftp://uploadshereplease.com 配置文件 curl在启动时，会自动读取用户目录下的.curlrc文件（_curlrc在win32系统上）。 配置文件由常规命令行开关组成，但是我们也可以指定长选项来使其更具有可读性。可以把选项和参数用空格、=、：进行分隔。注释以#放在行首开始。 如果在参数内包含空格，必须用双引号来包围起来&quot;。在这个引用内，继续包含引用的话要用\\&quot;。 必须在同一行指定选项和参数。 举例，设置默认超时时间和代理在一个配置文件内： 我们需要超时时间是30分钟： -m 1800 … 对所有的访问使用同一代理： proxy = proxy.our.domain.com:8080 行尾的空白符是重要的，但是所有行首字母前的空格都会被忽略。 有时候我们又不想让curl来读取默认的配置文件，那么可以将-q作为第一各选项： curl -q www.thatsite.com 在curl没有URL的时候，可以从个本地帮助页面获取并显示，可以这样进行配置： Force curl to get and display a local help page in case it is invoked without URL by making a config file similar to: 默认获取地址： url = &quot;http://help.with.curl.com/curlhelp.html&quot; 我们还可以通过-K/--config选项指定另外一个配置文件。如果我们把配置文件命名成-的话，curl就会从标准输入读入配置，当你想要在配置文件内隐藏某些东西的时候这是非常不错的办法： echo &quot;user = user:passwd&quot; | curl -K - http://that.secret.site.com 额外头部 在自定义的程序里面的时候可能会需要传输一些自己定义的头部信息。这时候我们就可以使用 -H标志。 比如，在获取一个页面的时候，发送头部”X-you-and-me: yes”： curl -H &quot;X-you-and-me: yes&quot; www.love.com 假入我们想让curl发送一个与正常情况不同的文本也是很实用的。-H header代替了curl在正常情况下要发送的信息。如果用空的来替代一个内部headr，就组织了这个头部信息的发送。我们想要阻止Host:头部被发送的话： curl -H &quot;Host:&quot; www.server.com FTP and PATH NAMES 要注意到当我们在用ftp://URL来获取文件的时候，后面的路径是相对于进入目录的。为了获取README文件，我们这样： curl ftp://user:passwd@my.site.com/README 但是如果我们想从根目录里面获取同样名字的文件的话，使用： curl ftp://user:passwd@my.site.com//README 在文件名前面加上一个斜线。 SFTP and SCP and PATH NAMES 对于sftp:和scp:的地址标识，给出的路径名应该是绝对路径名。如果想要获取远程机器用户目录下的一个文件，像下面这样： curl -u $USER sftp://home.example.com/~/.bashrc FTP and firewalls FTP协议需要参与连接的一端在传输数据之前打开一个新的连接。有两个方式可以达成。 curl默认的方式叫做PASV，这会让服务器来打开一个端口，让客户端来进行连接。在客户端在防火墙后的时候，这是非常实用的。 curl ftp.download.com 如果是服务器在防火墙后面，被封禁了除21外其他所有端口的时候（或者只支持PASV命令），另外一种方式就是使用PORT命令让服务器来连接到给定的客户端了ip好端口。（和PORT命令类似） -P标志让curl支持一些不同的选项。我们的机器可能会拥有几个ip或者几个网卡，可以让curl来选择使用哪一个。默认的可以这样使用： curl -P - ftp.download.com 用PORT模式下载，但是使用’le0’网卡的IP地址（这种方式在windows下并不能工作）： curl -P le0 ftp.download.com 用PORT模式下载，但是用192.168.0.10作为我们的IP地址： curl -P 192.168.0.10 ftp.download.com NETWORK INTERFACE（网络接口） 从指定的接口接收一个网页： curl --interface eth0:1 http://www.netscape.com/ or curl --interface 192.168.1.10 http://www.netscape.com/ HTTPS 安全HTTP要求在编译的时候安装SSL库。如果支持，curl就可以用过 https协议收发数据或文档。 比如： curl https://www.secure-site.com Curl也支持使用合法的个人证书来 get/post 文件。唯一的缺点就是证书格式必须是PEM的。PEM是一个标准的、开放的存储证书的格式，但是并不并大多数浏览器所使用（Netscape和MSIE都使用的是PKCS#12）。如果你想让curl使用你在其他浏览器上已经使用的证书，那么你就得下载一个转换器来将它转换成PEM格式。这种工具在最近的OPENSSL工具里面已经包含了，老版本的话，有一个叫做SSLeay的工具可以使用。 下面是怎么样使用一个含有密码的证书来获取网站数据： curl -E /path/to/cert.pem:password https://secure.site.com/ If you neglect to specify the password on the command line, you will be prompted for the correct password before any data can be received. Many older SSL-servers have problems with SSLv3 or TLS, which newer versions of OpenSSL etc use, therefore it is sometimes useful to specify what SSL-version curl should use. Use -3, -2 or -1 to specify that exact SSL version to use (for SSLv3, SSLv2 or TLSv1 respectively): curl -2 https://secure.site.com/ Otherwise, curl will first attempt to use v3 and then v2. To use OpenSSL to convert your favourite browser’s certificate into a PEM formatted one that curl can use, do something like this: In Netscape, you start with hitting the &#39;Security&#39; menu button. Select &#39;certificates-&gt;yours&#39; and then pick a certificate in the list Press the &#39;Export&#39; button enter your PIN code for the certs select a proper place to save it Run the &#39;openssl&#39; application to convert the certificate. If you cd to the openssl installation, you can do it like: ./apps/openssl pkcs12 -in [file you saved] -clcerts -out [PEMfile]In Firefox, select Options, then Advanced, then the Encryption tab, View Certificates. This opens the Certificate Manager, where you can Export. Be sure to select PEM for the Save as type. In Internet Explorer, select Internet Options, then the Content tab, then Certificates. Then you can Export, and depending on the format you may need to convert to PEM. In Chrome, select Settings, then Show Advanced Settings. Under HTTPS/SSL select Manage Certificates. RESUMING FILE TRANSFERS To continue a file transfer where it was previously aborted, curl supports resume on HTTP(S) downloads as well as FTP uploads and downloads. Continue downloading a document: curl -C - -o file ftp://ftp.server.com/path/file Continue uploading a document(*1): curl -C - -T file ftp://ftp.server.com/path/file Continue downloading a document from a web server(*2): curl -C - -o file http://www.server.com/ (*1) = This requires that the FTP server supports the non-standard command SIZE. If it doesn’t, curl will say so. (*2) = This requires that the web server supports at least HTTP/1.1. If it doesn’t, curl will say so. TIME CONDITIONS HTTP allows a client to specify a time condition for the document it requests. It is If-Modified-Since or If-Unmodified-Since. Curl allows you to specify them with the -z/—time-cond flag. For example, you can easily make a download that only gets performed if the remote file is newer than a local copy. It would be made like: curl -z local.html http://remote.server.com/remote.html Or you can download a file only if the local file is newer than the remote one. Do this by prepending the date string with a ‘-‘, as in: curl -z -local.html http://remote.server.com/remote.html You can specify a “free text” date as condition. Tell curl to only download the file if it was updated since January 12, 2012: curl -z &quot;Jan 12 2012&quot; http://remote.server.com/remote.html Curl will then accept a wide range of date formats. You always make the date check the other way around by prepending it with a dash ‘-‘. DICT For fun try curl dict://dict.org/m:curl curl dict://dict.org/d:heisenbug:jargon curl dict://dict.org/d:daniel:web1913 Aliases for ‘m’ are ‘match’ and ‘find’, and aliases for ‘d’ are ‘define’ and ‘lookup’. For example, curl dict://dict.org/find:curl Commands that break the URL description of the RFC (but not the DICT protocol) are curl dict://dict.org/show:db curl dict://dict.org/show:strat Authentication is still missing (but this is not required by the RFC) LDAP If you have installed the OpenLDAP library, curl can take advantage of it and offer ldap:// support. On Windows, curl will use WinLDAP from Platform SDK by default. Default protocol version used by curl is LDAPv3. LDAPv2 will be used as fallback mechanism in case if LDAPv3 will fail to connect. LDAP is a complex thing and writing an LDAP query is not an easy task. I do advise you to dig up the syntax description for that elsewhere. One such place might be: RFC 2255, “The LDAP URL Format” https://curl.haxx.se/rfc/rfc2255.txt To show you an example, this is how I can get all people from my local LDAP server that has a certain sub-domain in their email address: curl -B &quot;ldap://ldap.frontec.se/o=frontec??sub?mail=*sth.frontec.se&quot; If I want the same info in HTML format, I can get it by not using the -B (enforce ASCII) flag. You also can use authentication when accessing LDAP catalog: curl -u user:passwd &quot;ldap://ldap.frontec.se/o=frontec??sub?mail=*&quot; curl &quot;ldap://user:passwd@ldap.frontec.se/o=frontec??sub?mail=*&quot; By default, if user and password provided, OpenLDAP/WinLDAP will use basic authentication. On Windows you can control this behavior by providing one of —basic, —ntlm or —digest option in curl command line curl --ntlm &quot;ldap://user:passwd@ldap.frontec.se/o=frontec??sub?mail=*&quot; On Windows, if no user/password specified, auto-negotiation mechanism will be used with current logon credentials (SSPI/SPNEGO). ENVIRONMENT VARIABLES Curl reads and understands the following environment variables: http_proxy, HTTPS_PROXY, FTP_PROXY They should be set for protocol-specific proxies. General proxy should be set with ALL_PROXY A comma-separated list of host names that shouldn’t go through any proxy is set in (only an asterisk, ‘*’ matches all hosts) NO_PROXY If the host name matches one of these strings, or the host is within the domain of one of these strings, transactions with that node will not be proxied. When a domain is used, it needs to start with a period. A user can specify that both www.example.com and foo.example.com should not uses a proxy by setting NO_PROXY to “.example.com”. By including the full name you can exclude specific host names, so to make www.example.com not use a proxy but still have foo.example.com do it, set NO_PROXY to “www.example.com” The usage of the -x/—proxy flag overrides the environment variables. NETRC Unix introduced the .netrc concept a long time ago. It is a way for a user to specify name and password for commonly visited FTP sites in a file so that you don’t have to type them in each time you visit those sites. You realize this is a big security risk if someone else gets hold of your passwords, so therefore most unix programs won’t read this file unless it is only readable by yourself (curl doesn’t care though). Curl supports .netrc files if told to (using the -n/—netrc and —netrc-optional options). This is not restricted to just FTP, so curl can use it for all protocols where authentication is used. A very simple .netrc file could look something like: machine curl.haxx.se login iamdaniel password mysecret CUSTOM OUTPUT To better allow script programmers to get to know about the progress of curl, the -w/—write-out option was introduced. Using this, you can specify what information from the previous transfer you want to extract. To display the amount of bytes downloaded together with some text and an ending newline: curl -w &#39;We downloaded %{size_download} bytes\\n&#39; www.download.com KERBEROS FTP TRANSFER Curl supports kerberos4 and kerberos5/GSSAPI for FTP transfers. You need the kerberos package installed and used at curl build time for it to be available. First, get the krb-ticket the normal way, like with the kinit/kauth tool. Then use curl in way similar to: curl --krb private ftp://krb4site.com -u username:fakepwd There’s no use for a password on the -u switch, but a blank one will make curl ask for one and you already entered the real password to kinit/kauth. TELNET The curl telnet support is basic and very easy to use. Curl passes all data passed to it on stdin to the remote server. Connect to a remote telnet server using a command line similar to: curl telnet://remote.server.com And enter the data to pass to the server on stdin. The result will be sent to stdout or to the file you specify with -o. You might want the -N/—no-buffer option to switch off the buffered output for slow connections or similar. Pass options to the telnet protocol negotiation, by using the -t option. To tell the server we use a vt100 terminal, try something like: curl -tTTYPE=vt100 telnet://remote.server.com Other interesting options for it -t include: XDISPLOC= Sets the X display location. NEW_ENV= Sets an environment variable. NOTE: The telnet protocol does not specify any way to login with a specifieduser and password so curl can’t do that automatically. To do that, you needto track when the login prompt is received and send the username andpassword accordingly. PERSISTENT CONNECTIONS Specifying multiple files on a single command line will make curl transfer all of them, one after the other in the specified order. libcurl will attempt to use persistent connections for the transfers so that the second transfer to the same host can use the same connection that was already initiated and was left open in the previous transfer. This greatly decreases connection time for all but the first transfer and it makes a far better use of the network. Note that curl cannot use persistent connections for transfers that are used in subsequence curl invokes. Try to stuff as many URLs as possible on the same command line if they are using the same host, as that’ll make the transfers faster. If you use an HTTP proxy for file transfers, practically all transfers will be persistent. MULTIPLE TRANSFERS WITH A SINGLE COMMAND LINE As is mentioned above, you can download multiple files with one command line by simply adding more URLs. If you want those to get saved to a local file instead of just printed to stdout, you need to add one save option for each URL you specify. Note that this also goes for the -O option (but not —remote-name-all). For example: get two files and use -O for the first and a custom file name for the second: curl -O http://url.com/file.txt ftp://ftp.com/moo.exe -o moo.jpg You can also upload multiple files in a similar fashion: curl -T local1 ftp://ftp.com/moo.exe -T local2 ftp://ftp.com/moo2.txt IPv6 curl will connect to a server with IPv6 when a host lookup returns an IPv6 address and fall back to IPv4 if the connection fails. The —ipv4 and —ipv6 options can specify which address to use when both are available. IPv6 addresses can also be specified directly in URLs using the syntax: http://[2001:1890:1112:1::20]/overview.html When this style is used, the -g option must be given to stop curl from interpreting the square brackets as special globbing characters. Link local and site local addresses including a scope identifier, such as fe80::1234%1, may also be used, but the scope portion must be numeric or match an existing network interface on Linux and the percent character must be URL escaped. The previous example in an SFTP URL might look like: sftp://[fe80::1234%251]/ IPv6 addresses provided other than in URLs (e.g. to the —proxy, —interface or —ftp-port options) should not be URL encoded. METALINK Curl supports Metalink (both version 3 and 4 (RFC 5854) are supported), a way to list multiple URIs and hashes for a file. Curl will make use of the mirrors listed within for failover if there are errors (such as the file or server not being available). It will also verify the hash of the file after the download completes. The Metalink file itself is downloaded and processed in memory and not stored in the local file system. Example to use a remote Metalink file: curl --metalink http://www.example.com/example.metalink To use a Metalink file in the local file system, use FILE protocol (file://): curl --metalink file://example.metalink Please note that if FILE protocol is disabled, there is no way to use a local Metalink file at the time of this writing. Also note that if —metalink and —include are used together, —include will be ignored. This is because including headers in the response will break Metalink parser and if the headers are included in the file described in Metalink file, hash check will fail. MAILING LISTS For your convenience, we have several open mailing lists to discuss curl, its development and things relevant to this. Get all info at https://curl.haxx.se/mail/. Some of the lists available are: curl-users Users of the command line tool. How to use it, what doesn&#39;t work, new features, related tools, questions, news, installations, compilations, running, porting etc. curl-library Developers using or developing libcurl. Bugs, extensions, improvements. curl-announce Low-traffic. Only receives announcements of new public versions. At worst, that makes something like one or two mails per month, but usually only one mail every second month. curl-and-php Using the curl functions in PHP. Everything curl with a PHP angle. Or PHP with a curl angle. curl-and-python Python hackers using curl with or without the python binding pycurl. Please direct curl questions, feature requests and trouble reports to one of these mailing lists instead of mailing any individual.","categories":[{"name":"Shell","slug":"Shell","permalink":"https://gowa2017.github.io/categories/Shell/"}],"tags":[{"name":"curl","slug":"curl","permalink":"https://gowa2017.github.io/tags/curl/"}],"keywords":[{"name":"Shell","slug":"Shell","permalink":"https://gowa2017.github.io/categories/Shell/"}]},{"title":"vim-利用Vundle管理插件","slug":"vim-利用Vundle管理插件","date":"2017-12-17T07:58:23.000Z","updated":"2017-12-17T07:58:23.000Z","comments":true,"path":"Shell/vim-利用Vundle管理插件.html","link":"","permalink":"https://gowa2017.github.io/Shell/vim-利用Vundle管理插件.html","excerpt":"Vundle是Vim bundle的一个简称，一个Vim插件管理器。开源项目地址位于Vundle.vim.git只需要在.vimrc文件内加上几行，你就可以使用它来下载、卸载、管理各种位于github、官方插件仓库等地方的插件。","text":"Vundle是Vim bundle的一个简称，一个Vim插件管理器。开源项目地址位于Vundle.vim.git只需要在.vimrc文件内加上几行，你就可以使用它来下载、卸载、管理各种位于github、官方插件仓库等地方的插件。 下面是一张截图： 安装 安装需要git的支持，采用克隆的方式先克隆到本地。 git clone https://github.com/VundleVim/Vundle.vim.git ~/.vim/bundle/Vundle.vim 在配置文件内加上几行。 set nocompatible &quot; be iMproved, requiredfiletype off &quot; required&quot; set the runtime path to include Vundle and initializeset rtp+=~/.vim/bundle/Vundle.vimcall vundle#begin()&quot; alternatively, pass a path where Vundle should install plugins&quot;call vundle#begin(&apos;~/some/path/here&apos;)&quot; let Vundle manage Vundle, requiredPlugin &apos;VundleVim/Vundle.vim&apos;&quot; The following are examples of different formats supported.&quot; Keep Plugin commands between vundle#begin/end.&quot; plugin on GitHub repoPlugin &apos;tpope/vim-fugitive&apos;&quot; plugin from http://vim-scripts.org/vim/scripts.html&quot; Plugin &apos;L9&apos;&quot; Git plugin not hosted on GitHubPlugin &apos;git://git.wincent.com/command-t.git&apos;&quot; git repos on your local machine (i.e. when working on your own plugin)Plugin &apos;file:///home/gmarik/path/to/plugin&apos;&quot; The sparkup vim script is in a subdirectory of this repo called vim.&quot; Pass the path to set the runtimepath properly.Plugin &apos;rstacruz/sparkup&apos;, &#123;&apos;rtp&apos;: &apos;vim/&apos;&#125;&quot; Install L9 and avoid a Naming conflict if you&apos;ve already installed a&quot; different version somewhere else.&quot; Plugin &apos;ascenator/L9&apos;, &#123;&apos;name&apos;: &apos;newL9&apos;&#125;&quot; All of your Plugins must be added before the following linecall vundle#end() &quot; requiredfiletype plugin indent on &quot; required&quot; To ignore plugin indent changes, instead use:&quot;filetype plugin on&quot;&quot; Brief help&quot; :PluginList - lists configured plugins&quot; :PluginInstall - installs plugins; append `!` to update or just :PluginUpdate&quot; :PluginSearch foo - searches for foo; append `!` to refresh local cache&quot; :PluginClean - confirms removal of unused plugins; append `!` to auto-approve removal&quot;&quot; see :h vundle for more details or wiki for FAQ&quot; Put your non-Plugin stuff after this line 运行:PluginInstall命令就会将指定的插件进行安装。","categories":[{"name":"Shell","slug":"Shell","permalink":"https://gowa2017.github.io/categories/Shell/"}],"tags":[{"name":"Vim","slug":"Vim","permalink":"https://gowa2017.github.io/tags/Vim/"}],"keywords":[{"name":"Shell","slug":"Shell","permalink":"https://gowa2017.github.io/categories/Shell/"}]},{"title":"curl-http脚本","slug":"curl-http脚本","date":"2017-12-11T11:37:34.000Z","updated":"2017-12-11T11:37:34.000Z","comments":true,"path":"Shell/curl-http脚本.html","link":"","permalink":"https://gowa2017.github.io/Shell/curl-http脚本.html","excerpt":"","text":"HTTP Scripting背景这个文档假设你对HTTP和一些网络知识有了基本的了解。随着越来越多的应用转移到了Web服务上，“HTTP Scripting”已经变得越来越被人们所需要。为了能自动的从网站上获得信息、伪造用户、传输数据或者上传数据到服务器上都是非常重要的任务。Curl是一个命令行工具，用来进行所有类型的URL操作或者数据传输，但这个文档只把重心放在怎么用它来和一实际的HTTP服务器进行通信。我们假设你会使用curl --help或者curl --manual来获得一些更加基本的参考信息。当然，Curl并不是万能的。它可以模拟请求，获取数据，发送数据，获得网站信息。你可能需要一些其他的脚本语言来把这些东西汇总在一起，或者你会需要做一些重复性的工作呢。 HTTP 协议HTTP协议建立在TCP/IP之上，用来从网页服务器获取数据。这个协议也允许客户端以几种不同的方式向服务器发送数据，接下来我们就会看到。HTTP是一个解释性的ASCII文本行由客户端发送到服务器以请求一个实际的动作，然后服务器会在返回客户端真正需要的内容之前返回一些文本行。现在，curl充当一个客户端，发送一个请求。这个请求包含一种方式（GET, POST, HEAD等），一些请求头部或者请求主体。服务器返回状态行，响应头部和响应主体。这个“主体”怎么解释，由你的请求而定，比如会是HTML数据，或者一张图片。 观察协议用curl的--verbose(-v)选项会展示出curl发送的是何种数据以及一些其他信息。一般情况下这个选项已经够用，但如果还不够详细的时候，可以用--trace和--tarce-ascii会更加详细。 curl --trace-ascii debugdump.txt http://www.baidu.com curl --verbose http://www.baidu.com 观察时间大多数时候我们确实想知道在整个请求回应过程中发生了什么，但某些时候我们可能只关注一下这耗费了多少时间。这个时候--trace-time选项就起了作用了。这个选项会在每个跟踪输出的行前打印时间。 观察响应默认情况下，curl会把响应发送到标准输出。你可以用-o或者-O选项来进行重定向。 URLURL（Uniform Resource Locator）格式指的是你怎么样指定在网络上的地址或者资源。比如 www.baidu.com这样的地址。RFC 3986是对这个的规范性文档。但是呢，你可能会发现，它的称呼是URI，而不是URL。 主机大多数时候我们用主机名而不会直接指定IP地址，为了方便记忆。这个主机名到IP地址的解析，是由DNS来进行解析的，可能是公共的，也可能是内部的。在某些时候，为了调试的需要，我们可以用--resolve为主机名指定一个不同的IP地址，而不是其原来定义的地址。如 curl --resolve www.baidu.com:80:www.163.com http://www.baidu.com 端口号多数情况下，每个服务都有一个标准的端口号，比如HTTP的标准端口是80,但有的时候可能你会使用非标准的端口号如： curl http://www.baidu.com:1234 有的时候，你也想指定一个代理： curl --proxy http://proxy.example.org:4321 http://www.baidu.com 用户名与密码在使用中可能有些网站需要账号密码才能进行访问。那你就可以这样： curl http://user:password@www.baidu.com/ curl -u user:password http://www.baidu.com 但是，在当前的网站，可能已经不在用这样的方式进行用户的权限性验证了。而采用cookies或者表单了。 获取一个页面GET这是最简单的情况，如： curl www.baidu.com 服务器返回的头部信息一般情况下是隐藏的，你可以用 --include(-i)选项让他显示出来。 HEAD","categories":[{"name":"Shell","slug":"Shell","permalink":"https://gowa2017.github.io/categories/Shell/"}],"tags":[{"name":"curl","slug":"curl","permalink":"https://gowa2017.github.io/tags/curl/"}],"keywords":[{"name":"Shell","slug":"Shell","permalink":"https://gowa2017.github.io/categories/Shell/"}]},{"title":"Mysql的Information_Schema 元数据库与Show语句","slug":"Mysql的Information-Schema-元数据库与Show语句","date":"2017-12-07T07:16:19.000Z","updated":"2017-12-07T07:16:19.000Z","comments":true,"path":"MySQL/Mysql的Information-Schema-元数据库与Show语句.html","link":"","permalink":"https://gowa2017.github.io/MySQL/Mysql的Information-Schema-元数据库与Show语句.html","excerpt":"仔细阅读了MySQL的官方参考文档，才会仔细的查看MySQL的这些元数据保存在什么地方。其实全都在INFORMATION_SCHEMA数据库内。我们可以从这里看到所有的信息。事实上我们用show {database | table} ... 语句展示的就是这里面的内容。","text":"仔细阅读了MySQL的官方参考文档，才会仔细的查看MySQL的这些元数据保存在什么地方。其实全都在INFORMATION_SCHEMA数据库内。我们可以从这里看到所有的信息。事实上我们用show {database | table} ... 语句展示的就是这里面的内容。 各个表先看看里面保存的是什么东西。 mysql&gt; use information_schema;mysql&gt; show tables;+---------------------------------------+| Tables_in_information_schema |+---------------------------------------+| CHARACTER_SETS || COLLATIONS || COLLATION_CHARACTER_SET_APPLICABILITY || COLUMNS || COLUMN_PRIVILEGES || ENGINES || EVENTS || FILES || GLOBAL_STATUS || GLOBAL_VARIABLES || KEY_COLUMN_USAGE || PARTITIONS || PLUGINS || PROCESSLIST || PROFILING || REFERENTIAL_CONSTRAINTS || ROUTINES || SCHEMATA || SCHEMA_PRIVILEGES || SESSION_STATUS || SESSION_VARIABLES || STATISTICS || TABLES || TABLE_CONSTRAINTS || TABLE_PRIVILEGES || TRIGGERS || USER_PRIVILEGES || VIEWS |+---------------------------------------+ 包含了这些内容：字符集、排序、各字符集使用的排序、列、列权限、引擎、正在执行的事件、打开的文件、全局状态、全局变量、分区、插件、进程信息、PROFILING(不知道什么)、外键约束、过程、数据库信息、数据库权限、会话状态、会话变量、表索引信息、表、表约束、表权限、触发器、用户权限、视图。对于某些表，不用什么讲的，你可以用: select * from 表名\\G; 自己观察一下就知道了。 show 语句SHOW有多种形式，可以提供有关数据库、表、列或服务器状态的信息。本节叙述以下内容： SHOW CHARACTER SET [LIKE &#39;pattern&#39;] SHOW COLLATION [LIKE &#39;pattern&#39;] SHOW [FULL] COLUMNS FROM tbl_name [FROM db_name] [LIKE &#39;pattern&#39;] SHOW CREATE DATABASE db_name SHOW CREATE TABLE tbl_name SHOW DATABASES [LIKE &#39;pattern&#39;] SHOW ENGINE engine_name {LOGS | STATUS } SHOW [STORAGE] ENGINES SHOW ERRORS [LIMIT [offset,] row_count] SHOW GRANTS FOR user SHOW INDEX FROM tbl_name [FROM db_name] SHOW INNODB STATUS SHOW [BDB] LOGS SHOW PRIVILEGES SHOW [FULL] PROCESSLIST SHOW [GLOBAL | SESSION] STATUS [LIKE &#39;pattern&#39;] SHOW TABLE STATUS [FROM db_name] [LIKE &#39;pattern&#39;] SHOW [OPEN] TABLES [FROM db_name] [LIKE &#39;pattern&#39;] SHOW TRIGGERS SHOW [GLOBAL | SESSION] VARIABLES [LIKE &#39;pattern&#39;] SHOW WARNINGS [LIMIT [offset,] row_count] 还有主从控制的语句： SHOW BINLOG EVENTS SHOW MASTER LOGS SHOW MASTER STATUS SHOW SLAVE HOSTS SHOW SLAVE STATUS","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://gowa2017.github.io/categories/MySQL/"}],"tags":[],"keywords":[{"name":"MySQL","slug":"MySQL","permalink":"https://gowa2017.github.io/categories/MySQL/"}]},{"title":"MySQL备份介绍及实施","slug":"MySQL-backup","date":"2017-12-07T06:12:19.000Z","updated":"2017-12-07T07:16:19.000Z","comments":true,"path":"MySQL/MySQL-backup.html","link":"","permalink":"https://gowa2017.github.io/MySQL/MySQL-backup.html","excerpt":"","text":"MySQL 备份的方式 为什么需要备份因为谁都无法保证，我们的存储设备，或者电源，或者是硬件等会在什么时候出问题，所以做一个备份，将有助于我们的数据的安全性的提高。如果你不在乎怎么给老板解释数据永久丢失无法找回，那么备份不备份并不重要了。 数据的存储方式数据是以文件的格式存放在磁盘上，这些文件，由 mysqld 程序进行读取、写入等等操作。当然，我们也可以用文件系统上的命令来进行操作它，比如：复制、删除、修改等等操作，不过通常情况下是不推荐也不会这样去做的。由此而来，备份也多了另外一种方式。 备份的方式逻辑备份与物理备份从操作对象上来讲，我们可以对数据库最终的底层文件进行复制并转移到其他位置来进行备份；或者，我们可以用查询语句的方式，得到我们想要的结果，然后在需要的时候进行插入到新的位置来进行备份。这就是所谓的： 基于语句的备份（逻辑备份）和基于文件[块]的备份（物理备份）。 完整备份与增量备份有的时候，我们需要目标数据库所有的数据集合，而某些时候，我们只需要备份目标数据库从某一时间开始来变化过的数据。这就称为 完整备份 和 增量备份。 可能忽略的问题对于 mysqld 而言，底层数据、存储引擎、查询解析及缓存从上而下抽象分层。试想一下，我们采用逻辑备份 与 物理备份 的时候可能会出现什么问题。当我们需要查询读取数据的时候，存储引擎会去读取磁盘文件上的数据，这没有什么问题；但当我们进行更新查询的时候，问题就出现了，如果我们在进行文件复制进行备份的时候，有人在对数据进行更新，那很明显，就会引起数据的不一致性产生；同样，当我们在进行逻辑备份的查询更新的时候，也会有人在对数据更新，这同样会产生不一致。就我理解而言，所谓的一致，是指在开始备份至备份完成这个时间窗口内所看到的数据没有产生变化。 考量我们在备份的时候，有的时候，可能想要快速的备份，而有的时候，我们则需要考虑一下兼容性。所以在逻辑备份和物理备份间会进行权衡考虑。而当我们是不是要停止程序以中断服务的时候，就考虑采用热备份还是冷备份。当数据太大的时候，每次都采用完整备份并不是一个明智的选择，经常性增量备份配合偶尔的完整备份是一个不错的执行方式。 对数据一致性的保证为了保证我们备份数据的一致性，我们必须保证在备份时间窗口内没有数据更新 或者 我们看到的数据始终是不变的。已经有一些方法来达成这个目的。 flush配合读锁表mysql&gt; flush tables with read lock; 这个语句会将缓存刷新到磁盘，关闭所有打开表，读锁定所有表。 1.建立一个测试表。 mysql&gt; create table ssdd.tbl( id int auto_increment, name varchar(20), primary key (id)) engine=MyISAM; mysql&gt; insert into ssdd.tbl(name) values(&#39;angel&#39;); 我们不妨自己测试一下，首先我对 ssdd.tbl 表进行查询一下，这会导致 mysqld 打开这个表。 mysql&gt; select id from ssdd.tbl; +----+ | id | +----+ | 1 | +----+ 2.查看打开文件然后我们用 Linux的 lsof 命令看一下 打开的文件情况。 [root@VM_0_6_centos ~]# lsof | grep tbl COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME mysqld 14634 mysql 16u REG 252,1 2048 368758 /var/lib/mysql/ssdd/tbl.MYI mysqld 14634 mysql 17u REG 252,1 20 368759 /var/lib/mysql/ssdd/tbl.MYD 3.锁 mysql&gt; flush tables with read lock; 4.查看文件打开情况 [root@VM_0_6_centos ~]# lsof | grep tbl [root@VM_0_6_centos ~]# 输出表明，这表文件已经被关闭了。5.查询数据（另外一个终端） mysql&gt; select id from ssdd.tbl; +----+ | id | +----+ | 1 | +----+ 6.更新一下数据试试 mysql&gt; update ssdd.tbl set id=id+1; 你会发现，卡住了，是的，因为表是被读锁定的。那么我们下一步解锁。 7.解锁 mysql&gt; unlock tables; 这样第6步更新才会成功。对于MyISAM表，mysqlhotcopy采用的就是这种方式进行备份。当然，我们可以自己手动执行给表上锁被刷新语句后，自行进行复制文件进行备份。 对于事务表对于InnoDB，最好看一下其简单的概念。MySQL架构简介常规概念上来说，MyISAM与InnoDB引擎，一个不支持事务，一个支持事务。但在数据的存储方式上，也有不同。MyISAM表的数据保存在三个文件内 tbl.{frm,MYD,MYI}InnoDB表的数据并存储在由多个数据文件构成的表空间内，同时，重做日志会存储在重做日志文件内。数据文件与重做文件是两个非常重要的概念，对于InnoDB表而言。注意：二进制日志与重做日志是不同滴。我们可以通过实例来查看一下其中的一些细节。1.创建一个 innodb 表。 create table ssdd.tbl2 ( a int auto_increment, b char(20), primary key (a)) engine=innodb; 2.查看表的存储文件 shell&gt; ls -1 /var/lib/mysql/ssdd --/var/lib/mysql/ssdd 是数据库目录 db.opt t_ability.frm t_ability.MYD t_ability.MYI tbl2.frm tbl.frm tbl.MYD tbl.MYI 我们只看到了 tbl2.frm 也就是表和列定义文件，而并没有 如同 MyISAM表那样的数据文件和索引文件，这都存储于表 InnoDB的表空间内，默认情况下，是在datadir 中的 ibdata1 文件。有人可能会反对，说innodb_file_per_table 配置可以每个表使用不同的 表空间文件，这当然是可以的。 对那些想把特定表格移到分离物理磁盘的用户，或者那些希望快速恢复单个表的备份而无须打断其余InnoDB表的使用的用户，使用多表空间会是有益的。 但我们要意识到，innodb_file_per_table选项只会影响表的创建。也就是说，对于已在共享表空间创建的表，不会受到这个选项的影响；而如果在创建表后，关闭这个选项，已创建的使用单独表空间的表，也不会受到影响。共享表空间，依然是需要的，因为InnoDB把内部数据词典和未作日志放在这个文件中。 配置innodb_file_per_table选项，并重启服务器,然后建立一个表。 create table ssdd.tbl3 ( a int auto_increment, b char(20), primary key (a)) engine=innodb; 查看目录: [root@VM_0_6_centos mysql]# ls -1 /var/lib/mysql/ssdd db.opt t_ability.frm t_ability.MYD t_ability.MYI tbl2.frm tbl3.frm tbl3.ibd tbl.frm tbl.MYD tbl.MYI 表tbl3有了自己的.ibd表空间数据文件。但是，即使是这样，我们在进行物理备份的时候依然会很头疼。因为我们不仅要备份表的数据文件，还要备份一些数据字典文件（位于系统共享表空间内），还有重做日志（ib_logfile0/1）等等。而且，从概念上讲，磁盘上的数据文件与InnoDB引擎在内存中的缓存池、二次缓存的数据并不一定是一致的。在事务已提交到重做日志，但还未更新到数据文件之间的时间窗口会产生很大的问题。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://gowa2017.github.io/categories/MySQL/"}],"tags":[],"keywords":[{"name":"MySQL","slug":"MySQL","permalink":"https://gowa2017.github.io/categories/MySQL/"}]},{"title":"Linux Coreutilitys","slug":"coreutilitys","date":"2017-12-07T06:12:19.000Z","updated":"2017-12-07T07:16:19.000Z","comments":true,"path":"Linux/coreutilitys.html","link":"","permalink":"https://gowa2017.github.io/Linux/coreutilitys.html","excerpt":"","text":"tr 字符翻译tr [option] ... set1 [set2] -c 不在 c后跟集合字符 -d 删除 -s 压缩 -t 替换 cut 只显示指定内容cut option ... file -b 按字节 -c 按字符 -d 替换分域符（默认TAB），与f配合使用 -f 指定显示字段(field) -n 配合-b，不分割多字节字符 —complement 取补 -s 不显示不含分域符的行 -output-delimited=STRING 输出分域符，默认与输入相同对于范围的指定 N 第N个 N- N到行尾 N-M N到M -M 行首到第M expr 计算表达式expr EXPRESSION expr OPTION 表达式可能的值是： ARG1 | ARG2 ARG1 &amp; ARG2 ARG1 &lt; ARG2 ARG1 &lt;= ARG2 ARG1 = ARG2 ARG1 != ARG2 ARG1 &gt;= ARG2 ARG1 &gt; ARG2 ARG1 + ARG2 ARG1 - ARG2 ARG1 * ARG2 ARG1 / ARG2 ARG1 % ARG2 STRING : REGEXP/match STRING REGEXP substr STRING POS LENGTH index STRING CHARS length STRING + TOKEN ( EXPRESSION )","categories":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}],"tags":[],"keywords":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}]},{"title":"InnoDB的架构介绍","slug":"InnoDB-Architecture","date":"2017-12-04T06:02:38.000Z","updated":"2018-03-12T02:48:21.000Z","comments":true,"path":"MySQL/InnoDB-Architecture.html","link":"","permalink":"https://gowa2017.github.io/MySQL/InnoDB-Architecture.html","excerpt":"架构图这是对官方文档 5.5版本第十四章的一个翻译。先理解一下InnoDB的架构，然后对几个基本的概念有个理解，对后面的各种操作就会有比较直观的感觉，而不会感觉非常的抽象。下面是转自网络的一个架构图。","text":"架构图这是对官方文档 5.5版本第十四章的一个翻译。先理解一下InnoDB的架构，然后对几个基本的概念有个理解，对后面的各种操作就会有比较直观的感觉，而不会感觉非常的抽象。下面是转自网络的一个架构图。 14.1 InnoDB的介绍InnoDB是一个在可靠性好高性能之间进行平衡后设计的一个存储引擎。从MySQL5.5开始，默认的存储引擎就从MyISAM转到了InnoDB。在没有特别指定一个默认存储引擎的情况下，用Create Table语句不附加ENGINE=语句就会创建一个InnoDB表。 InnoDB包括了在MySQL5.1中作为插件存在的 InnoDB Plugin的所有功能，加上MySQL5.5或者更高版本增加的其他新功能。 mysql和INFORMATION_SCHEMA库这些MySQL的内部实现还使用MyISAM。实际上，不能把授权表改为InnoDB引擎。 InnoDB的关键优势 DML语句遵守ACID模型，事务的特性提交、回滚、崩溃恢复保护用户数据。参考14.5 InnoDB和ACID模型一节。 行级别的锁定和Oracle-Style的一致性读增强了多用户并发和性能。参考14.8 InnoDB锁定和事务模型。 InnoDB会用主键对磁盘表数据进行查询优化。每个InnoDB表还有一个主键索引被称为clustered index，这被用来组织数据以实现主键搜索的最小化I/O。参考14.11.2.1 Clustered and Secondary Indexes。 为了保证数据完整性，InnoDB支持外键约束。通过外键约束，插入、更新和删除都会被检查以保证跨表间的一致性。参考14.11.1.6 InnoDB and FOREGIN KEY Constraints。table 14.1 InnoDB Storage Engine Features Storage Limits 64TB Transactions Yes Locking granularity yes[a] MVCC yes Geospatial data type support yes Geospatial indexing support yes B-tree indexes yes T-tree indexes No Hash indexes No[b] Full-text search indexes[c] Yes Clustered Indexes Yes Data caches Yes Index caches Yes Compressed data Yes[d] Encrypted data[e] Yes Cluster database support No Replication support[f] Yes Foreign key support Yes Backup/point-in-time recovert[g] Yes Query cache support Yes Update statistics for data dictionary Yes [a] InnoDB support for geospatial indexing is available in MySQL 5.7.5 and higher.[b] InnoDB utilizes hash indexes internally for its Adaptive Hash Index feature.[c] InnoDB support for FULLTEXT indexes is available in MySQL 5.6.4 and higher.[d] Compressed InnoDB tables require the InnoDB Barracuda file format.[e] Implemented in the server (via encryption functions). Data-at-rest tablespace encryption is available in MySQL 5.7 and higher.[f] Implemented in the server, rather than in the storage engine.[g] Implemented in the server, rather than in the storage engine. 想要比较InnoDB和其他存储引擎的特性的话，详见15章， Alternative Storage Engines InnoDB增强和特性MySQL5.5版本的InnoDB引擎包括了很多性能的提高，这些内容在MySQL5.1版本只能通过安装 InnoDB Plugin来实现。最新版本的InnoDB提高了性能和可扩展性，增强了可靠性和新的扩展能力，并且更加易用。 关于更多MySQL5.5 版本中InnoDB增强和新特性，请参考： 1.4节 What is New in MySQL 5.5? Release Notes. 更多的InnoDB信息和资源 InnoDB相关条目和定义，参考 MySQL Glossary 关于InnoDB存储引擎的论坛，MySQL Forums::InnoDB InnoDB是在GBL 2.0协议下发布的。关于更多MySQL的声明，查看https://www.mysql.com/about/legal/ 14.1.1 使用InnoDB表的好处如果你正在使用MyISAM表但是因为技术上的原因对它并不是很放心的，那么你会发现InnoDB有以下的好处： 如果服务器因为硬件或者软件的问题崩溃，不过崩溃的时候数据库在做什么，你只需要重启服务器而不需要做更多其他工作。InnoDB crash recovery自动完成那些在崩溃时提交的改变，回滚未提交但在处理的改变。只需要重启然后继续工作。现在这个过程比在5.1版本及以前版本都要快了很多 InnoDB在缓冲池内存储被访问过的数据和索引。经常使用的数据可以直接从内存获取，这会大大提高速度。在一个单一的数据库服务器上，经常会被缓冲池大的小设置为物理内存的80%。 如果把相关性的数据分隔到不同的表内，可以设置外键来强制进行相关完整性。更新或者删除数据，在其他表内的数据会被自动的更新或者删除。当在一个次表内插入一个在主表内并不对应的数据时，错误的数据将会被自动踢出。 如果数据在磁盘或者内存上出现损坏，一个校验和算法会在你使用数据前对你进行警告。 当你把你的表设置为含有一个合适的主键列的时候，这些列会被自动优化。在WHERE，ORDER BY，GROUP BY语句和JOIN内引用这些列会非常快速。 插入，更新，删除会被change buffering自动优化。InnoDB不止允许对同一个表的并发读写，还会将改变的数据线性排队到磁盘IO。 对于执行长时间查询的巨大表性能的提升是无限制的。当表上同样的行被多次访问，一个叫做ADI（adaptive Hash Index）的特性会让这个查找更快，就像数据从hash表出来的一样。 可以自由的把InnoDB表和其他表混用，即使是在同一个语句内。比如说，可以在一个查询内用Join操作来结合InnoDB表数据与Memory表数据。 InnoDB表被设计来在处理大量数据的时候提高CPU的效率和更大的性能提升。 InnoDB可以操控大量数据，即使在文件大小被限制在2GB的操作系统上。 关于在应用内可以使用的InnoDB调整技术，查看8.5 优化InnoDB表 14.1.2 InnoDB表的最佳实践这节描述了使用InnoDB表时的最佳实践： 把每个表最常查询的列作为表的主键，如果没有主键的话设置一个auto-increment值。 当要从多个表内通过特定的ID值获取数据时，使用join操作。为了提高join性能，对join的列定义foregin keys，并把这些列定位为相同的数据类型。增加外键可以保证引用的列都会被索引，这样就能提高性能。外键会将更新或者删除操作传递到所有受影响的表，同时在父表内无对应数据时，会阻止对子表的数据插入。 关闭autocommit。一秒内提交事务上百次是对性能的巨大浪费（这收到写入到存储设备速度的限制）。 将相关的DML操作在事务内进行分组，用START TRANSACTION和COMMIT语句包围。尽管你不想太过频繁提交，你同样也不希望在一个巨大包括INSERT,UPDATE,DELETE的语句运行几个小时而不提交。 不要使用LOCK TABLES语句。InnoDB可以控制多个会话同时读写同样的表，不用担心可靠性和性能的问题。如果要对某些行获得读占的写权限，使用SELECT ... FOR UPDATE来锁定你打算操作的行。 开启innodb_file_per_table让每个InnoDB把自己的数据和索引存储在单独的文件内，而不是放在共享的表空间内。这个特性设置对于使用某些特性是必须的，比如 表压缩 和 快速 截断。 评估一下你的表和访问模式是否能从 InnoDB表的压缩特性（ROW_FORMAT=COMPRESSED）上受益。可以压缩 InnoDB表却不用担心读/写性能。 为了避免你在使用CREATE TABLE语句的时候指定ENGINE=语句而使用不同的存储引擎，给服务器启动添加--sql_mode=NO_ENGINE_SUBSTITUTION选项 14.1.3 检查 InnoDB可用性为了确定你的服务器是否支持InnoDB： 执行命令SHOW ENGINE;然后查看所有的MySQL存储引擎。查找InnoDB行看是否有DEFAULT字样，。或者，可以查询INFORMATION_SCHEMA ENGINES表。（5.5版本以后，INNODB已经是默认的存储引擎，只有在非常特殊的情况下才不是） 执行SHOW VARIABLES LIKE &#39;have_innodb&#39;;确认InnoDB可用。 如果InnoDB不存在，那么你所获得的版本不支持InnoDB。需要重新获得另外一个支持的版本。 如果InnoDB是禁止的，回到启动选项文件，然后去掉任何skip-innodb选项。 14.1.4 向上和向下兼容性在MYSQL 5.5 介绍了一个使用 InnoDB表压缩的能力，还有使用这个能力必须使用的新的行格式，叫做Barracuda。以前的那种格式被称做Antelope，不支持表压缩能力，不过支持其他能力。 14.1.5 测试和benchmarking InnoDb在完成升级到MySQL5.5之前，应该先试试现在的数据库是否能在InnoDB作为默认引擎的情况下工作得很好。如果要在更早一些的版本上把InnoDB设置为默认引擎，在命令行加入--default-storage-engine=InnoDB选项，或者在my.cnf文件内[mysqld]节加上default-storage-engine=innodb选项，然后重启服务器。 因为修改默认引擎只会影响新表的建立，首先确认应用程序已经全部安装完毕。然后测试一下数据的载入，修改和查询工作OK。如果表依靠某些MyISAM特定的特性，你就会收到错误；对建立表CREATE TABLE加上ENGINE=MyISAM语句来避免这样的错误。（比如，需要全文搜索的表必须使用MyISAM而不是InnoDB） 如果你不是很确定到底用哪一个引擎，只是想看一下特定的表在InnoDB下工作得怎么样，执行命令ALTER TABLE table_name ENGINE=InnoDB.或者可以执行语句制造一个表的备份： CREATE TABLE InnoDB_Table (...) ENGINE=InnoDB AS SELECT * FROM MyISAM_Table; 因为InnoDB在MySQL5.5版本进行了很多性能提升，想要在特定的工作情况下来决定是否使用的话，安装MySQL5.5然后benchmark一下。 测试整个程序的所有环节，安装，高负载使用，服务器重启等等。 在服务器繁忙的时候杀死服务器进程来模拟一个电源问题，然后验证数据会在重启服务器的时候成功自动恢复。 测试任何复制设置，特别是在主从服务器间使用一个不同的MySQL版本的时候。 14.1.6 关闭 InnoDb总体还是建议使用InnoDB作为默认存储引擎，从个人博客或者高端服务器都可以。如果实在不想使用的话： 用--innodb=OFF或--skip-innodb选项启动服务器来禁止InnoDB存储引擎。 因为默认存储引擎就是InnoDB，同时还需要指定--default-storage-engine选项指定新的默认引擎才会成功启动。 为了避免服务器在查询InnoDB相关的information_schema表时崩溃，还需要关闭一些其他的属性。在配置文件的[mysqld]节下面加上： loose-innodb-trx=0 loose-innodb-locks=0 loose-innodb-lock-waits=0 loose-innodb-cmp=0loose-innodb-cmp-per-index=0loose-innodb-cmp-per-index-reset=0loose-innodb-cmp-reset=0loose-innodb-cmpmem=0loose-innodb-cmpmem-reset=0loose-innodb-buffer-page=0loose-innodb-buffer-page-lru=0loose-innodb-buffer-pool-stats=0 14.2 安装InnoDB存储引擎如果在使用MySQL 5.5以上版本，或者使用InnoDB1.1以上版本，那么没有什么需要特别做的：所有东西都已经作为MySQL源代码和二进制版本的一部分配置好了。这和早期的InnoDB Plugin不同。 从MySQL 5.1.38开始，InnoDB就已经包含在里面了。 为了更好的利用现在InnoDB的特性，强烈建议在配置文件内加上下面的配置： innodb_file_per_table=1innodb_file_format=barracudainnodb_strict_mode=1 14.5 InnoDb和ACID模型ACID模型是一系列的数据库设计规则，这些规则强调了商业数据和极端环境下对可靠性各方面。MySQL包含如InnoDB存储引擎这样的组件来符合ACID模型，用来保证在意外情况如软件崩溃、硬件问题发生的时候数据不会损坏，查询结果不会混乱。如果你依赖于ACID兼容特性，不需要重新造一个一致性检查和崩溃恢复方法的轮子。假入你有一些附家的软件保护，硬件冗余，或者一个可以容忍少量数据丢失或不一致的应用，你可以调整MySQL在ACID可靠性和提高性能和吞吐量上进行平衡。 接下来的章节讨论了MySQL特性，实际上就是InnoDB存储引擎，与ACID模型分类的交互。 A：原子性（atomicity） C：一致性（consistency） I：隔离性（isolation) D：持久性（durability） Atomicity（原子性）ACID模型的原子性与InnoDB的事务联系。相关MySQL特性包括： 自动提交设置（autocommit) COMMIT语句 ROLLBACK语句 从INFORMATION_SCHEMA表上操作数据。 Consistency（一致性）ACID的一致性与InnoDB保护数据崩溃联系。相关特性包括： InnoDB double buffer InnoDb crash recovery Isolation（隔离性）ACID的隔离性主要与InnoDB的事务联系，实际上是每个事务的isolation level（隔离级别）。相关特性包括： 自动提交设置（Autocommit） SET ISOLATION LEVEL语句 InnoDB锁的最低级别。在调整性能期间，可以通过INFORMATION_SCHEMA表看到细节信息。 Durability（持久性）ACID的持久性由MySQL的软件与实际硬件配置来支持。根据CPU、网络、存储设备的不同，这有多种可能，所以说对这个持久性提供明确的指南是最复杂的一部分。（这个指南可能还涉及购买“新硬件”）。相关特性包括： InnoDB doubule buffer，通过innodb_doublewrite配置进行开关。 innodb_flush_log_at_trx_commit配置选项 sync_binlog配置选项 innodb_file_per_table 配置选项 将缓存写入存储设备，如磁盘，SSD，或者RAID阵列。 存储设备电源备份 运行MySQL的操作系统，实际上是要其支持fsync()系统调用。 不间断电源（UPS）保护所有运行MySQL的服务器和存储设备。 备份策略，比如经常性和备份类型，以及备份保留时间 14.6 InnoDB 多版本控制InnoDB是一个多版本的存储引擎：它会保留改变行数据的老版本信息，用以支持事务性的特性，如一致性和回滚。这些信息保存在表空间一个叫回滚段（rollback segment）的数据结构中。InnoDB用回滚段内的信息来对事务的回滚进行撤销操作。同样，也用这里面的信息来建立一个早期版本以支持一致性读。 内部实现，InnoDB对每个行增加三个字段。一个 6byte 的DB_TRX_ID字段来表明上一个插入或者更新这行的事务ID。一个删除操作也被当作一个更新操作，但是一个特殊的bit会被设置来表明实际是一个删除操作。同样每行也包含一个 7byte 的DB_ROLL_PTR字段叫做滚动指针。这个滚动指针指向一个写在回滚段的撤销日志记录。如果一行被更新了，这个撤销日志记录会包含将此行恢复到原来状态的所有信息。还有一个 6byte 的DB_ROW_ID在新行插入的时候会自动增长。如果InnoDB会自动生成一个 clustered index，这个索引就会包含行ID的值。否则，DB_ROLL_ID不会出现在任何索引内。 回滚段内的撤销日志被分为插入和更新撤销日志。插入撤销日志只会被事务回滚需要，当事务提交的时候就可以丢弃。更新撤销日志在一致性读的时候也需要，但只有在没有被InnoDB在一致性读内分配了快照的事务活跃的时候丢弃。一致性读需要更新撤销日志来建立对这行的早期版本。 正常提交事务，及时是需要一致性读的事务。否则，InnoDB不能丢弃更新撤销日志，回滚段就会越来越大，充满表空间。 回滚段内的一个撤销日志的物理大小通常会比其对应插入或更新的行小。可以用这些信息来计算回滚段需要的空间。 在InnoDB的多版本中，用SQL删除一行的时候，这一行并不会立刻物理地从数据库内删除。只有在丢弃了对应更新撤销日志时InnoDB才会物理删除行和索引。这个操作被称作purge，非常快。 如果在一个小的脚本内插入或者删除行，这个purge线程会落后，然后表就会越来越大，因为有很多dead行。这样的情况下，控制新行操作，并且分配更多的资源给purge线程。通过innodb_max_purge_lag系统变量设置。 多版本与二级索引InnoDB多版本并发控制对待二级索引(Secondary index)和聚簇索引(clustered index)不同。对聚簇索引的更新是立即的，同时更新其指向撤销日志（这些日志可以用来重建早期版本记录）的隐藏系统列。跟聚簇索引不同，二级索引不会被立即更新，也不包括系统隐藏列。 当一个二级索引列被更新时，老的二级索引记录就标记为删除，新的索引被插入，然后删除标记为删除的老的索引记录。当一个二级索引记录被标记为删除或者二级索引页被一个新的事务更新的时候，InnoDB在聚簇索引内寻找记录。在聚簇索引中，这条记录的DB_TRX_ID被检查，如果记录是在读取事务初始化后修改的，对应版本的记录会从撤销日志内读取。 如果一个二级索引记录被标记为删除或者二级索引页被一个新的事务更新，covering index技术就不会被使用。InnoDB会从聚簇索引读取记录而不是从索引结构内获取值。 14.7 InnoDB架构本节介绍InnoDB存储引擎的主要组件。 14.7.1 Buffer Pool缓存池被InnoDB在内存中存储被访问的数据和索引，这样常用数据就能直接从内存读取，而不用访问磁盘，大大的提高了速度。一个专门的数据库服务器，80%的物理内存经常会被分配来做缓存池。对于大量的区操作来说，缓存池被分割成页来容纳更多的行。在实现上，是将页做成一个页链表；不常用的数据，采用LRU算法进行清理出缓存。 14.7.2 Change Bufferchange buffer是一个特殊的数据结构，在二级索引页发生改变，同时这些页不存在于缓存池的时候，就会缓存到change buffer。已缓存的变化（可能是由INSERT, UPDATE, DELETE操作引起，DML），在后期某些操作将这些页读入缓存池的时候会被合并。 与聚簇索引不同，二级索引是不唯一的，对二级索引的插入以一个相对随机的顺序进行。类似的，删除和更新将会影响索引树内并不相邻的二级索引页。合并缓存的变化会在后面进行，当受影响的页被其他操作读取到缓存池的时候，这将会避免读取二级索引页时需要的大量随机IO操作。 周期性滴，清理操作（purge）会在系统空闲或者在一个 slow shutdown的时候进行，把更新的索引页写到磁盘。这个清理操作会将一系列的索引值写入磁盘，而不是每个值都立即写到磁盘，这样会大大提高效率。 change buffer的合并操作有可能会花费几个小时，当有很多二级索引页被更新影响很多行的时候。在这个时间段内，磁盘 I/O增加，然后对于需要读取磁盘数据的查询产生很大影响。change buffer合并也可以在一个事务提交后进行。实际上，change buffer合并有可能发生在服务器个人关闭或者重启后。（14.23.2 Forcing InnoDB Recovery） 在内存中，change buffer是buffer pool的一部分。在磁盘上，它是系统表空间的一部分，这样就可以在数据库重启之间保留已缓存的索引变化。 在change buffer内缓存的数据由innodb_change_buffering配置选项进行控制。更多信息参考14.9.4 Configuring InnoDb Change Buffering 监控Change Buffer以下选项对于监控 change buffer是可用的： InnoDB标准监控输出包括了change buffer的状态信息。如果要查看监控器数据，执行命令SHOW ENGINE INNODB STATUS; mysql&gt; SHOW ENGINE INNODB STATUS\\G Change buffer状态信息在INSERT BUFFER AND ADAPTIVE HASH INDEX头部后面，看起来和下面有些类似： -------------------------------------INSERT BUFFER AND ADAPTIVE HASH INDEX-------------------------------------Ibuf: size 1, free list len 0, seg size 2, 0 mergesmerged operations: insert 0, delete mark 0, delete 0discarded operations: insert 0, delete mark 0, delete 0Hash table size 276707, node heap has 1 buffer(s)15.81 hash searches/s, 46.33 non-hash searches/s 更多信息，参考14.20.3 InnoDB Standard Monitor and Lock Monitor Output INFORMATION_SCHEMA.INNODB_BUFFER_PAGE表提供了所有在缓存池内页的信息，包括change buffer索引页和bitmap页。change buffer页用PAGE_TYPE区分。IBUF_INDEX是change buffer的索引页类型，IBUFF_BITMAP是change buffer的bitmap页类型。 查询INNODB_BUFFER_PAGE表会造成巨大的性能开销。为了避免影响性能，在一个测试的实例上运行的检查。举例说明，你可以查询INNODB_BUFFER_PAGE表来决定IBUF_INDEX和IBUF_BITMAP的大概数量站总共缓存池页的百分比： SELECT(SELECT COUNT(*) FROM INFORMATION_SCHEMA.INNODB_BUFFER_PAGEWHERE PAGE_TYPE LIKE &apos;IBUF%&apos;) AS change_buffer_pages,(SELECT COUNT(*)FROM INFORMATION_SCHEMA.INNODB_BUFFER_PAGE) AS total_pages,(SELECT ((change_buffer_pages/total_pages)*100)) AS change_buffer_page_percentage;+---------------------+-------------+-------------------------------+| change_buffer_pages | total_pages | change_buffer_page_percentage |+---------------------+-------------+-------------------------------+| 25 | 8192 | 0.3052 |+---------------------+-------------+-------------------------------+ Performance Schema提供了change buffer 互斥量等待方法来监控进阶性能。想查看change buffer的使用方法，执行下面的查询： mysql&gt; SELECT * FROM performance_schema.setup_instrumentsWHERE NAME LIKE &apos;%wait/synch/mutex/innodb/ibuf%&apos;;+-------------------------------------------------------+---------+-------+| NAME | ENABLED | TIMED |+-------------------------------------------------------+---------+-------+| wait/synch/mutex/innodb/ibuf_bitmap_mutex | YES | YES || wait/synch/mutex/innodb/ibuf_mutex | YES | YES || wait/synch/mutex/innodb/ibuf_pessimistic_insert_mutex | YES | YES |+-------------------------------------------------------+---------+-------+ 14.7.3 Adaptive Hash Index为缓存池配置大量缓存加上配置一定的工作量，AHI（adaptive hash index）自适应哈希索引让InnoDB更像一个内存数据库，这样就不用牺牲事务性特性和可靠性。这个特性是被innodb_adaptive_hash_index选项开启的，可以用--skip-innodb_adaptive_hash_index在启动服务器禁止。 基于观察到的搜索模式，MySQL用索引键的前缀来建立一个hash索引。这个键的前缀可以是任何长度，可能只有部分在B-tree内的值会出现在hash索引内。哈希索引只为那些需要经常性访问的索引页建立。 如果一个表全部都在主内存内，哈希索引可以通过启动直接查询任何元素提高速度，将所有索引值设置为指针。InnoDB有一个监控索引搜索的方法。如果InnoDB注意到采用哈希索引很有好处的会，就会自动的建立。 在某些工作负载下，哈希索引查询速度的提升的价值远远超过了其需要用来监控索引查找及维护哈希索引结构的额外工作。某些时候，在高负载时，读/写锁来保护对AHI的访问是一个巨大的争议问题，比如多并发的join。用LIKE和%操作符的查询也不能从AHI受益。在不需要AHI的工作下，关闭AHI可以减少不必要的性能开销。对于一个系统AHI是否适用是很难预测的，在真实的工作负载下进行开启或关闭AHI的benchmark，得出自己想要的结果。 哈希索引总是基于表上已存在的B-tree索引。InnoDB可以用在B-tree上定义的键的任何长度前缀来建立哈希索引，这依赖于InnoDB观察到的对B-tree索引搜索模式。一个哈希索引可以是局部的，只覆盖了经常访问的那些索引页。 可以监控AHI的使用和争论在命令SHOW ENGINE INNODB STATUS命令的SEMAPHORES节。如果观察到很多线程在等待RW锁在btr0sea.c创建，那么，关闭AHI应该非常有用。 关于更多哈希索引的性能问题，参考8.3.8 Comparison of B-Tree and Hash Indexes 14.7.4 Redo Log Buffer重做日志缓存器在内存中缓存即将被写入redo log的数据，用innodb_log_buffer_size。缓存器会周期性的刷新到磁盘redo log文件。一个大点的缓存器允许一个大型事务提交后，在没有将redo log写到磁盘前就开始运行。因此，如果你有事务需要更新，插入或删除很多行，使用更大的 Redo log buffer来减少磁盘I/O。 innodb_flush_log_at_trx_commit选项控制缓存器的内容怎么写到redo log文件。innodb_flush_log_at_timeout选项控制缓存器的内容刷新周期。 14.7.5 System Tablespace系统表空间包含了InnoDB的数据字典（InnoDB关联对象元数据）和doublewrite buffer, change buffer, undo logs。同时也包含用户在共享表空间内创建的表的数据和索引。多个表，可共享同系统表空间。系统表空间由多个数据文件组成，默认情况下是ibdata1，当然，可以用innodb_data_file_path用来设置系统表空间的数量和大小。 更多信息参考14.9.1 Resizing The InnoDb System Tablespace。 14.7.6 InnoDB Data Dictionary数据字典由包含用来跟踪对象（比如表、索引、列）的元数据的系统表组成。这些元数据存储在系统表空间内。历史原因，数据字典元数据一定程序上与表元数据文件（tbl.frm）有重叠。 14.7.7 Doublewrite Buffer这是表空间内的一个区域，用来存储从缓存池刷新过来，但还没有写到数据文件的页。只有在刷新并且写到二次写入缓存器后，InnoDB才会将数据写到数据文件。 如果在一个页写入期间发生了系统崩溃、存储系统崩溃、或者mysqld进程崩溃，InnoDB可以在恢复期间从二次写入缓存找到一个完整的数据副本。虽然数据都要写入两次，但事实上是在多量数据写入二次缓存后，再采用fsync()再同步到磁盘。 默认情况下二次写入缓存是开启的，可以用innodb_doublewrite设置为0来关闭。如果系统表空间数据文件部署在支持原子写入的Fusion-io设备上，此选项将会被自动关闭，而启用Fusion-io的原子写入到所有数据文件。二次写入缓存是否开启这个选项是全局的，这样，在没有使用Fusion-io设备的数据文件也会被关闭二次写入缓存。这个特性只支持Fusion-io设备。 14.7.8 Undo Logs撤销日志是一系列每个事务的撤销日志记录（undo log record）的集合。一个撤销日志记录包含了如何撤销一个事务对聚簇（clustered index）最近作出的改变。如果其他事务想要看到原始的数据（读操作一致性的一部分），未修改的数据是从撤销日志记录中获取。撤销日志存在与撤销日志段（undo log segments）中，撤销日志段存在与回滚段中（rollback segments）。回滚存留在系统表空间、临时表空间、和撤销表空间。 从5.5.4版本之前，InnoDB支持单一回滚段（支持最大1023个并发数据修改事务，只读事务不会增加这个最大限制）。在MySQL5.5.4，单一回滚段被分割为128个回滚段，每个回滚段支持1023个并发数据修改 事务修改，这样限制就增加到了大概128k并发的数据修改事务限制。innodb_rollback_segments选项定义了在系统表空间内为InnoDB事务使用多少个回滚段。 每个事务被分配一个回滚段，然个少的后后面就一直使用这个段。这个增加的并发修改限制提高了伸缩性（更高的并发）和性能（更少的对于回滚段使用的竞争）。InnoDB支持128个回滚段，其中32个保留用于针对临时表事务的非重做的回滚段。每个更新临时表的事务都会被分配两个回滚段，一个重做回滚段和非重做回滚段；只读事务只会分配非重做的回滚段，只读事务只允许修改临时表。这样就留下96个可用的回滚段，每个支持1023个并发的数据修改事务，合计就是96K。这里假定所有事务都不会修改临时表，如果所有事务都会修改临时表，限制就会降低到32K。对于更多保留用于临时表事务的回个段信息，参考下一节。innodb_rollback_segments选项定义了InnoDB使用的回滚段数。 14.7.9 File-Per-Table Tablespaces这个选项允许让每个表单独存在在自己的表空间文件内。innodb_file_per_table可以启用这个功能。 14.7.10 Redo Log重做日志是基于磁盘的数据结构用来在崩溃恢复的时候纠正被未完成事务修改的数据。常规操作下，重做日志对SQL语句或者底层的API请求进行编码，然后请求InnoDB表修改。因意外关闭而未完成的对数据文件的修改将会在重新启动，接受连接之前重放。在崩溃恢复的时候，重做日志担当的角色，请查看InnoDB 恢复 默认情况下，重做日志文件就是数据目录中的ib_logfile0和ib_logfile1。MySQL以环行的方式写入重做日志文件。和其他ACID兼容的数据引擎一样，在提交事务前刷新重做日志。InnoDB采用组提交的方式，多个同时间的事务的提交请求集中到一个写请求上。 14.7.10.1 组提交重做日志进行刷新InnoDB，跟其他ACID兼容的数据库引擎一样，在一个事务提交以前刷新重做日志。InnoDB使用 group commit功能来将多个这样的请求组合在一起以避免每个提交都需要一个刷新。这样，InnoDB就可以将多个用户的在同样时间内的多个事务在一次进行刷新，大大提高了吞吐量。 General Tablespaces通用表空间：用CREATE TABLESPACE语句创建的InnoDB表空间，可以在MySQL数据目录外。用create table tbl_name ... tablespace [=] tablespace_name 或者 alter table tbl_name tablespace [=] tablespace_name。 Undo Tablespace撤销表空间由一个或者多个包含重做日志的文件组成。innodb_undo_tablespace设置了InnoDB使用多少个重做表空间。这个选项将来应该会被删除。 Temporary Tablespace临时表空间用来存储非压缩的InnoDB临时表和相关对象。innodb_temp_data_file_path为临时表空间数据文件指定了一个相对路径，如果没有配置，一个自动扩展的12MB的 ibtmp1文件在数据目录被创建。临时表空间在器启动和接收到一个动态空间ID的时候会重新创建，这样就可以避免和已存的空间ID发生冲突。临时表空间不能存在于裸设备上。如果无法创建临时表空间，服务器将不能启动。临时表空间在正常关闭和异常初始化的时候会自动移除，但发生崩溃的时候不会。这个情况下，管理员要手动移除临时表空间然后重新启动服务器上重新创建临时表空间。INFORMATION_SCHEMA.INNODB_TEMP_TABLE_INFO提供了InnoDB活跃临时表空间的元数据， 14.8 InnoDB锁和事务模型要实现一个大规模，繁忙或高可用的数据库应用，或者提高MySQL的性能，了解InnoDB的锁和事务模型是非常重要的。 这一节讨论了几个关于InnoDB锁和事务模型的主题，你应该熟悉他们才行。 14.8.1 InnoDB 锁本节讨论了InnoDB使用的锁类型。 (Shared and Exclusive Locks)共享和独占锁 (Intention Locks)意图锁（Intention） (Record Locks)记录锁 (Gap Locks)间隙锁 (Next-Key Locks)Next-Key锁 (Insert Intention Locks)插入意图锁 (AUTO-INC Locks)AUTO-INC锁 共享和独占锁 InnoDB实现了标准的行级锁，有两种类型的锁，shared(S)和exclusive(X)锁，我们称事务为T。 S 允许持有锁的事务T读取一行 X 允许持有锁的事务T更新或者删除一行。 如果事务 T1 在行 r 上持有一个 共享锁 S，那么其他不同事务 T2请求在行 r 上获得一个锁遵守以下规则： T2 可以立刻 S 锁。这样，T1, T2 都会对 r 获得 S 锁 T2 不能立刻获得 X 锁 如果 T1 在行 r 上持有 X 锁，那么 T2 不管是想要一个 S 锁还是 X 锁都无法立即获得。相反，T2 必须等待 T1 释放在 r 上的锁。 意图锁 InnoDB支持多个粒度的锁，以允许行级锁和表级锁共同工作。在实际场景下，对表级锁被InnoDB称为 意图锁。意图锁是用来表明接下来事务会在表中某一行上请求某个类型的锁（共享或独占）。有两种类型的意图锁。（假设事务 T 在 表 t 上请求一个类型的锁）： IS：事务 T 想要在表 t 上的某一行请求 s 锁。 IX：事务 T 想要在表 t 上的某一行请求 x 锁。 比如，SELECT ... LOCK IN SHARE MODE会设置一个IS锁，而SELECT ... FOR UPDATE会设置一个 IX 锁。 意图锁遵从以下协议： 在事务 T 从表 t 中某一行持有 S 锁前，其必须先在 t 上获得 IS 或 IX。 在事务 T 从表 t 中某一行持有 X 锁前，其必须先在 t 上获得 IX 锁。 可以用以下表来归纳 意图锁与 行级所间的兼容性： X IX S IS X 冲突 冲突 冲突 冲突 IX 冲突 兼容 冲突 兼容 S 冲突 冲突 兼容 兼容 IS 冲突 兼容 兼容 兼容 如果某个事务请求的锁与已存在的锁兼容，那么就可以获得这把锁，如果与已存锁冲突，那就必须等到已存在的导致冲突的锁释放后才能获得。 因此，意图锁除了全表请求之外（例如 LOCK TABLES ... WRITE）并不会阻塞任何事情。IX 和 IS 的主要目的只是用来表明，某些客户端正在锁定表中一行，或者即将锁定表中的某一行。 一个事务中的意图锁，会在 SOHW ENGINE INNODB STATUS和 InnoDB 监控输出中以以下类似的形式显示： TABLE LOCK table `test`.`t.` trx id 10080 lock mode IX 记录锁记录锁是一个在索引记录上的锁。例如，SELECT c1 FROM t WHERE c1 = 10 FOR UPDATE; 将会阻止在 t.c1的值是10的行上的 插入，更新或删除操作。 记录锁总是锁定索引记录，即使表没有定义索引。在这样的情况下，InnoDB会创建一个隐藏的聚簇索引，并用它来进行记录锁。参考14.11.2.1 Clustered and Secondary Indexes。 用SHOW INNODB ENGINE STATUS或 InnoDB 监控输出类似以下： RECORD LOCKS space id 58 page no 3 n bits 72 index `PRIMARY` of table `test`.`t` trx id 10078 lock_mode X locks rec but not gapRecord lock, heap no 2 PHYSICAL RECORD: n_fields 3; compact format; info bits 00: len 4; hex 8000000a; asc ;;1: len 6; hex 00000000274f; asc &apos;O;;2: len 7; hex b60000019d0110; asc ;;`iRECORD LOCKS space id 58 page no 3 n bits 72 index `PRIMARY` of table `test`.`t` trx id 10078 lock_mode X locks rec but not gapRecord lock, heap no 2 PHYSICAL RECORD: n_fields 3; compact format; info bits 00: len 4; hex 8000000a; asc ;;1: len 6; hex 00000000274f; asc &apos;O;;2: len 7; hex b60000019d0110; asc 间隙锁间隙锁是在索引记录之间的锁定，或者是第一个索引记录之前、最后一个索引记录之后的锁定。比如，SELECT c1 FROM t BETWEEN 10 and 20 FOR UPDATE; 会阻止其他事务在列 t.c1上插入值 15，不管这一列是不是有这个值，因为在所有在间隙间的值已经被锁定。 一个间隙里可有只有一个值，或者多个值，也可能是空的。 间隙锁实在性能和并发性间平衡的结果，只是在某些 隔离级别上使用。 在使用一个唯一的索引搜索一个唯一的值的的语句中，间隙锁是不需要的。（但这不包括在多列唯一索引上进行进行查询某些列的情况）。比如，如果一个id列有一个唯一索引，接下来的语句对id值是100的行使用一个记录锁，同时并不关心其他会话会不会在100之前的间隙中插入数据： SELECT * FROM child WHERE id = 100; 如果id没有索引或者是非唯一的索引，那么这个语句就会锁定之前间隙。 值得注意的是，相冲突的锁可能在一个间隙中被不同的事务所持有。比如，事务 A 在某个间隙上持有一个 共享的间隙锁（gap S-lock），事务 B 在同样的间隙上持有一个独占的间隙锁（gap X-lock）。允许这样的原因是，如果一个记录从索引内清理，被不同事务持有的在这个记录上的锁必须合并。 间隙锁在InnoDB中说“完全抑制的”，也就是说只是会阻止其他事务插入行到这个间隙。并不会阻止其他事务在同样的间隙上获得间隙锁。因此 gap X-lock和gap S-lock有同样的影响。 间隙锁可以明确的禁止。当你把事务隔离级别设置为READ COMMITTED，或者设置innodb_locks_unsafe_for_binlog系统变量启用就会禁止。在这样的情况下，搜索好索引扫描不会使用间隙锁，只会在外键约束和重复键检查时使用间隙锁。 使用READ COMMITTED和innodb_locks_unsafe_for_binlog有其他影响。在MySQL执行完WHERE语句后如果没有匹配的行的记录锁就会被释放。对于UPDATE语句，InnoDB执行一个“半完整性读”，这样会返回最近提交的版本给MySQL，MySQL以此来判断UPDATE中的WHERE条件是否匹配。 Next-Key锁一个next-key锁是在某个索引记录上的记录锁和这个索引记录前的间隙锁的结合。当搜索或扫描一个表索引的时候，InnoDB以这样的方式来进行行级锁：在其搜索到的索引记录上设置共享或独占锁。实际上，行级锁就是记录锁。一个在索引记录上的next-key锁也会影响在索引记录之前的间隙。因此，一个Next-key锁就是一个索引记录锁加上在索引记录之前范围的间隙锁。如果一个会话在索引中的一个记录 R 上持有一个共享或独占的锁，另外一个会话就不能在 索引上 R 记录前锁定的间隙中插入新的索引记录。 假设一个索引包含 10，11，13，20。在这个索引上可能出现的Nexk-key锁有这些（左开右闭： (negative infinity, 10](10,11](11,13](13,20](20,positive infinity) 对于最后一种情况，Next-key锁锁定了这个索引中最大值和最大上界（supremum一个比索引中任何值大的伪记录）间的间隙。supremum不是一个真实的索引记录，因此，实际上，Next-Key锁锁定了在最大值之后的间隙。 默认情况下，InnoDB工作在REPEATABLE READ隔离级别下，同时innodb_locks_unsafe_for_binlog系统变量禁止。这样的情况下，InnoDB使用Next-key锁来搜索或扫描索引，这样能防止幻行（两次插入同一间隙出现了多出来的结果）。参考14.8.4 Phantom Rows 在SHOW ENGINE INNODB STATS;下的输出类似如下： RECORD LOCKS space id 58 page no 3 n bits 72 index `PRIMARY` of table `test`.`t` trx id 10080 lock_mode XRecord lock, heap no 1 PHYSICAL RECORD: n_fields 1; compact format; info bits 0 0: len 8; hex 73757072656d756d; asc supremum;;Record lock, heap no 2 PHYSICAL RECORD: n_fields 3; compact format; info bits 0 0: len 4; hex 8000000a; asc ;; 1: len 6; hex 00000000274f; asc &apos;O;; 2: len 7; hex b60000019d0110; asc ;; 插入意图锁 一个插入意图锁是一种间隙锁，由INSERT操作在插入行之前设置。这个锁，允许不同的事务在同一个间隙的不同位置插入索引记录。假设这里有索引记录，值从4到7。不同的事务试图插入值5，6，每个事务都会在4-7的间隙上获得独占插入意图锁来锁定插入行，但是不会让其他事务等待，因为行并不冲突。 接下来的例子展示了一个事务在获取插入记录上的独占锁之前设置一个插入意图锁。这个例子和两个客户端，A B相关。 A 建立了一个表，包括两个索引记录（90，102），然后开始一个事务，在ID比100大的索引记录上放一个独占锁。这个独占锁包括一个到102记录前的间隙锁。 ysql&gt; CREATE TABLE child (id int(11) NOT NULL, PRIMARY KEY(id)) ENGINE=InnoDB;mysql&gt; INSERT INTO child (id) values (90),(102);mysql&gt; START TRANSACTION;mysql&gt; SELECT * FROM child WHERE id &gt; 100 FOR UPDATE;+-----+| id |+-----+| 102 |+-----+ B开始一个事务，意图在间隙内插入一个记录。在获得独占锁之前，事务先获得一个插入意图锁。 mysql&gt; START TRANSACTION;mysql&gt; INSERT INTO child (id) VALUES (101); 插入意图锁的在SHOW ENGINE INNODB STATUS中的输出类似下面： RECORD LOCKS space id 31 page no 3 n bits 72 index `PRIMARY` of table `test`.`child`trx id 8731 lock_mode X locks gap before rec insert intention waitingRecord lock, heap no 3 PHYSICAL RECORD: n_fields 3; compact format; info bits 0 0: len 4; hex 80000066; asc f;; 1: len 6; hex 000000002215; asc &quot; ;; 2: len 7; hex 9000000172011c; asc r ;;... 自增锁 一个AUTO_INC锁是一个特殊的表级别的锁，这在事务插入具有AUTO_INCREMENT列的表时获取。在最简单的情况下，如果A事务正在插入数据到表中，其他事务必须等待A事务获得了连贯的主键值后才能完成插入。 innodb_autoinc_lock_mode配置选项控制自增锁的算法。这允许你选择如何在可预测的序号和最大的插入操作并发性间进行平衡。 14.8.2 InnoDB Transaction Model 14.8.3 Locks Set by Different SQL Statements in InnoDB一个锁定读，一个UPDATE，DELETE通常会在处理SQL语句过程中锁定所有扫描过的索引记录。并不关心这些行是不是被一个WHERE条件语句所排除。InnoDB不会记住正确的WHERE条件，只会记住扫描过的索引范围。通常，锁是Nexk-key锁，这会立刻锁住对这条记录前的插入操作。但是呢，Next-key锁可以被禁止。对于更多信息，参考14.18.1 InnoDB Locking。事务隔离级别也会影响设置什么锁，参考14.8.2.1 Transaction Isolation Levels。 如果在搜索中对一个二级索引记录上了独占锁，InnoDB会获取对应的聚簇索引记录。 对于 共享锁 和 独占锁 的不同在 14.8.1 InnoDB Locking中有介绍。 如果执行SQL语句时没有合适的索引，MySQL就必须扫描全表，表中所有行都会被锁定，其他用户的插入操作全部需要等待。创建合适的索引以避免不必要的行锁定是非常重要的。 对于SELECT ... FOR UPDATE 或 SELECT ... LOCK IN SHARE MODE，被扫描的行需要锁，如果在搜索后的结果集中不会被引用就应该被释放（比如，并不符合在WHERE语句中指定的条件）。但是，在某些情况下，行不会被立即解锁，因为在查询期间一个结果行和其来源的关系已经丢失。比如，在一个UNION中，扫描过（已锁定）的行可能在验证其是否会在结果集中被引用之前就已经被插入在一个临时表中。在这种情况下，临时表中的行和源表中的行已经没有了关系，所以源表中的行只有在查询结束时被解锁（是不是最后被引用，是对临时表进行条件筛选，而不是源表，这时候）。 InnoDB按以下方式设置锁的类型： SELECT ... FROM 是一个一致性读，阅读数据库的一个快照，只在事务隔离级别是SERIALIZABLE的时候设置锁。在SERIALIZABLE级别下，搜索会在其遇到的索引记录上加上shared next-key锁。然而，在一个语句使用一个唯一索引来搜索一个唯一行的时候，只需要一个记录锁。 select ... from ... lock in share mode会在搜索遇到的索引记录上加shared next-key锁。然而，在一个语句使用一个唯一索引来搜索一个唯一行的时候，只需要一个记录锁。 select ... from ... for update会在搜索遇到的索引记录上加exclusive next-key。然而，在一个语句使用一个唯一索引来搜索一个唯一行的时候，只需要一个记录锁。 对于搜索遇到的索引记录，select ... from ... for update会阻塞其他会话执行select ... from ... lock in share mode和在特定的事务隔离级别下进行读操作。一致性读会忽略在阅读试图上记录上设置的任何锁。 update ... where ...会在搜索遇到的任何记录上设置exclusive next-key锁，在一个语句使用一个唯一索引来搜索一个唯一行的时候，只需要一个记录锁。 当update语句更新一个聚簇索引记录的时候，一个隐式的锁会加在受影响的二级索引记录上。update操作也会在插入新二级索引记录前做重复检测扫描时，和插入新的二级索引记录过程中，将受影响的二级索引记录上加共享锁。 delete from ... where ...会在搜索遇到的任何记录上加上exclusive next-key,然而，在一个语句使用一个唯一索引来搜索一个唯一行的时候，只需要一个记录锁。 insert语句在被插入的行上加exclusive lock。这是一个记录锁，而不是next-key锁（也就是说，没有gap锁），所以不会阻止其他会话在插入行的前后插入新行。在插入行之前，一个叫做插入意图间隙锁的间隙锁被设置。这个锁允许以这样的方式进行插入行：允许不同的事务在同一个间隙内在不同位置插入行而不需要等待。假设这里值为4到7的索引记录。不同的事务方便要插入5，6，在获得对插入行的独占锁之前，都可以同时获得插入意图锁，而不用等待其他事务的完成，因为要插入的行是不冲突的。 如果重复键错误出现，在重复那个索引记录上会设置共享锁。这有可能导致死锁，因为在某个会话已经拥有一个独占锁的情况下，可能有多个会话试图插入相同的行。这种情况可能在其他会话删除行的时候出现。假设 InnoDB 表 t1 有以下结构： create table t1 (i int, primary key (i)) engine = innodb; 下面有三个会话按以下的顺序进行操作： Session 1: start transaction; insert into t1 values(1); Session 2: start transaction; insert into t1 values(1); Session 3: start transaction; insert into t1 values(1); Session 1: rollback; Session 1 在行上请求一个独占锁。Session2, Session3 都会得到一个 duplicate-key错误，然后都对这个行上请求一个共享锁。当Session 1回滚，同时释放了独占锁，接下来Session2, Session3所请求的共享锁都会被授权。 在这个时刻，Session2, Session3就发生了死锁：任意一个会话都无法获得独占锁，因为彼此都拥有一个共享锁。 一个类似的情况可能发生：还有值 1 的行已经存在，然后按以下的方式进行操作： Session 1: start transaction; delete from t1 where i =1; Session 2: start transaction; insert into t1 values(1); Session 3: start transaction; insert into t1 values(1); Session 1: commit; Session 1的操作需要一个独占锁。Session2, Session3 获得一个 重复键错误 然后同时请求一个共享锁。 当Session 1提交，释放独占锁，Session2, Session3请求的共享锁被授权。 在这个时刻，Session2, Session3发生死锁：由于同时拥有共享锁，所以都等待着获取独占锁。 INSERT ... ON DUPLICATE KEY UPDATE和一个简单的INSERT操作不一样，在一个重复键错误发生的时候，会放置一个独占的Next-key锁而不是一个共享锁在将被更新的行上。 REPLACE在一个唯一键没有冲突的情况下表现得和INSERT一样。否则的话，一个独占的Next-key锁会被放在将被替换的行上。 insert into T select ... from S where ...会在每一个插入到 T 的行上设置记录锁（没有间隙锁）。如果事务的隔离级别是READ COMMITTED，或者innodb_locks_unsafe_for_binlog变量已启用且事务隔离级别不是SERIALIZABLE，InnoDB在 表 S 上以一致性读进行搜索（没有锁）。否则，InnoDB在表 S 的行上设置一个共享的Next-key。InnoDB必须在这种情况下加锁：在恢复数据前滚时，每个SQL语句必须以原来同样的方式执行。create table ... select ...以一个共享next-key锁或一致性读执行SELECT语句，和insert ... select一样。当在replace into t select ... from s where ...或update t ... where col in (select ... from s ...)中使用select时，InnoDB会在表 s 的行上设置共享的next-key锁。 在初始化一个表中指定了AUTO_INCREMENT的列时，InnoDB在与AUTO_INCREMENT列关联的索引尾部设置一个独占锁。I在访问 自增计数器时，InnoDB使用一个叫做AUTO-INC的表锁模式，这个锁只持续到语句执行期间，而不是持续到事务结束。在AUTO-INC锁持有期间，其他会话不能插入数据到这个表。 14.8.2 InnoDB Transaction Model。InnoDB获取前一个初始化的AUTO_INCREMENT列，不会设置任何锁。 如果在表上设置了外键约束，所有的插入，更新，删除操作需要进行约束条件检测的时候，会其找到来检查约束条件的记录上设置共享的 record-level锁。即使是约束检测失败也会设置这些锁。 LOCK TABLES设置表锁，但这是在MySQL层而不是在之下的InnoDB层设置。如果innodb_table_lock=1（默认设置）和autocommit=0，InnoDB能识别表锁，MySQL也知道行级锁。否则，InnoDB的自动死锁检测在这些表锁被设置的时候无法检测到死锁。因此，在这样的情况下MySQL层不知道行级锁，那么在其他会话在持有一个行级锁的时候可以过得一个表锁。然而，这并不会造成事务完整性的危险，这在14.8.5.2 死锁检测和回滚中讨论。同样可以参考14.11.8 Limits On InnoDB Tables 14.8.4 Phantom Rows所谓的幻行指的是同一个事务在不同时间的两次查询或者了不同的结果。比如，一个select执行两次，第二次的时候获得了第一次没有返回的一行，这后面出来的行就是幻行。假设，表 child 的 id 列上有一个索引，然后我们想要读取并锁定id&gt;100的所有行，接下来打算更新选中的列上的某些列： select * from child where id &gt; 100 for update; 这个查询从 id &gt; 100 的第一个记录开始扫描索引。我们让这个表包含id的值90，102。如果在扫描过的范围上的记录锁不锁定间隙（这个情况下的间隙是90-102）内的插入，另外一个会话就可以在表内插入一个id=101的行。如果要在同一个事务中执行select，你就会看到一个 id=101的新行（幻行）。如果我们把一系列行视做一个数据条目，这个新的幻行就违背了关于事务的隔离原则：在事务中已读取的数据是不应该改变的。 为了阻止幻行，InnoDB使用一个结合了索引行锁定和间隙锁的叫做next-key的方法。InnoDB以这样的方式实现行级锁，当在搜索或者扫描一个表索引时，会在遇到的索引记录上设置共享或者独占锁。因此，行级锁就是索引记录锁。作为补充，一个索引记录上的next-key锁一样影响在索引记录前的间隙。这就是说，Next-key锁就是一个索引记录锁加上这个索引记录前的间隙锁。如果一个会话在索引记录 R 上有一个共享或者独占锁，其他会话就不能立刻在R前的这个间隙内插入一个新的索引记录。 在InnoDB扫描一个索引时，同样可以锁定最后一个记录后的间隙。在前面那个例子中这个情况下出现：为了阻止 id比100大的插入，被InnoDB设置的锁包括了在 id=102后面的间隙。 可以应用 next-key 锁来在应用中实现一个不唯一的检测：如果你以共享模式读取数据，同时看不到你想要插入的行，你可以安全地插入你的行；因为会在阅读期间对插入的行设置Next-key锁以阻止其他人插入一个重复的行进来。这就是说，这个Next-key锁可以让你“锁定”表中并不存在的东西。 间隙锁可以在14.8.1 InnoDB Locking中讨论的那样禁止。这会导致幻行问题，因为多个会话可以在间隙内插入新行。 14.8.5 Deadlocks in InnoDB死锁发生在不同的事务都需要获取被对方持有的锁来继续的时候。而因为彼此都需要等待资源可用，所以事务此时也无法释放其获取的锁。 死锁会在事务通过UPDATE或SELECT ... FOR UPDATE语句进行锁定多个表的行时发生，以相对的顺序（不懂）。死锁也会在这些语句锁定索引记录范围和间隙的时候发生。死锁例子参考14.8.5.1 An InnoDB Deadlock Example 为了减少死锁的可能，使用事务而不是使用lock tables语句；让事务在更新或者插入的时候影响尽量少的数据，并且打开的时间尽量少；当不同事务更新多个表或者很多行的时候，用相同的顺序进行操作（比如select ... for update）;在被select ... for update语句和update ... where语句使用到的列上创建索引。死锁的可能不会被隔离级别影响，因为隔离级别改变了读操作的行为，而死锁经常是由写操作引发。更多关于死锁可能产生的信息，参考14.8.5.3 How to Minimize and Handle Deadlocks 如果死锁发生，InnoDB检测条件，回滚其中一个事务。因此，即使你的引用逻辑是正确的，必须控制一个事务必须重新进行的情况。为了查看上一个出现的死锁的用户事务，使用show engine innodb status;命令。如果为了找出经常出现死锁的事务结构或应用错误，设置innodb_print_all_deadlocks选项以打印所有的死锁信息到mysql错误日志。关于更多死锁如何自动检测和控制的信息，参考14.8.5.2 Deadlock Detectiong and Rollback 14.8.5.1 An InnoDB Deadlock Example接下来的例子显示了当一个锁请求会产生死锁的时候一个错误是怎么样出现的。这个例子和两个客户端相关，A，B。 首先，A 创建一个含有一行的表，然后开始一个事务。在这个事务中，A 通过在共享模式选择这行在这个行上获得 S 锁： ysql&gt; CREATE TABLE t (i INT) ENGINE = InnoDB;Query OK, 0 rows affected (1.07 sec)mysql&gt; INSERT INTO t (i) VALUES(1);Query OK, 1 row affected (0.09 sec)mysql&gt; START TRANSACTION;Query OK, 0 rows affected (0.00 sec)mysql&gt; SELECT * FROM t WHERE i = 1 LOCK IN SHARE MODE;+------+| i |+------+| 1 |+------+``` 然后，B 开始一个事务并尝试从表中删除这一行： mysql&gt; START TRANSACTION;Query OK, 0 rows affected (0.00 sec) mysql&gt; DELETE FROM t WHERE i = 1;删除操作需要一个 X 锁。因为 A 拥有一个 S 锁所以这个 X 锁不能获得，因此这个锁会被加入锁请求队列，B会被阻塞。最后，A也尝试删除这行： mysql&gt; DELETE FROM t WHERE i = 1;ERROR 1213 (40001): Deadlock found when trying to get lock;try restarting transaction``` 死锁就发生了，因为A需要一个X锁来删除这行。然而，这个锁无法被授权因为B也有一个请求X锁在排队等待A来释放S锁。这样被A持有的S锁无法被更新到X锁，因为B对行上X锁的请求排列在前。作为结果，InnoDB会对其中一个锁报错并释放其持有的锁。客户端返回这样的错误： ERROR 1213 (40001): Deadlock found when trying to get lock; try restarting transaction 这个时候，其他为删除这行而请求的锁请求可以被授权。 14.8.5.2 死锁检测和回滚InnoDB自动检测事务死锁并且回滚[多个]事务以退出死锁。InnoDB选择小的事务进行回滚，大小是由事务所插入，更新或者删除的行数量来决定。 当 innodb_table_locks=1（默认）或autocommit=0的时候，InooDB对表锁是敏感的，而且MySQL层也知道行级锁。否则，InnoDB就不能检测到 MySQLLOCK TABLES设置的表锁或非InnoDB引擎设置的锁 引发的死锁。 解决这个情况的办法是设置innodb_lock_wait_timeout系统变量。 当InnoDB完整回滚一个事务的时候，所有这个事务设置的锁都会被释放。然而，只是因为错误而回滚了一个SQL语句的时候，某些被这个语句设置的锁可能会保留。这是因为InnoDB存储表锁以后，其存储的格式无法知道哪个锁是被哪个语句设置的。 如果select在一个事务内执行函数，而在函数中的一个语句失败，这个语句会回滚。接下来执行rollback的话，整个事务被回滚。 如果InnoDB的监控输出的LATEST DETECTED DEADLOCK节包一个信息，TOO DEEP OR LONG SEARCH IN THE LOCK TABLE EAITS-FOR GARPH, WE WILL ROCK BACK FOLLOWING TRANSACTION，这表明在等待列表中的事务数已经达到了200的限制。 等待列表中超过200事务被认为是一个死锁，试图检测等待列表的事务被回滚。差不多的情况出现在锁定线程发觉在等待列表中事务拥有的锁超过了1000000个的时候。 关于如何通过组织数据库操作来避免死锁，参考14.8.5 Deadlocks in InnoDB 14.8.5.3 How to Minimize and Handle Deadlock14.9 InnoDB Configuration14.9.1 InnoDB Startup Configuration14.9.2 InnoDB Buffer Pool Configuration14.9.3 Configuring the Memory Allocator for InnoDB14.9.4 Configuring InnoDB Change Buffering14.9.5 Configuring Thread Concurrency for InnoDB14.9.6 Configuring the Number of Background InnoDB I/O Threads14.9.7 Configuring the InnoDB Master Thread I/O Rate14.9.8 Configuring Spin Lock Polling14.9.9 Configuring InnoDB Purge Scheduling14.9.10 Configuring Optimizer Statistics for InnoDB14.10 InnoDB Tablespaces14.10.1 Resizing the InnoDB System Tablespace14.10.2 Changing the Number or Size of InnoDB Redo Log Files14.10.3 Using Raw Disk Partitions for the System Tablespace14.10.4 InnoDB File-Per-Table Tablespaces14.11 InnoDB Tables and Indexes14.11.1 Creating InnoDB Tables14.11.2 Role of the .frm File for InnoDB Tables14.11.3 Physical Row Structure of InnoDB Tables14.11.4 Moving or Copying InnoDB Tables to Another Machine14.11.5 Converting Tables from MyISAM to InnoDB14.11.6 AUTO_INCREMENT Handling in InnoDB14.11.7 InnoDB and FOREIGN KEY Constraints14.11.8 Limits on InnoDB Tables14.11.9 Clustered and Secondary Indexes14.11.10 Physical Structure of an InnoDB Index14.12 InnoDB Table Compression14.12.1 Overview of Table Compression14.12.2 Enabling Compression for a Table14.12.3 Tuning Compression for InnoDB Tables14.12.4 Monitoring Compression at Runtime14.12.5 How Compression Works for InnoDB Tables14.12.6 SQL Compression Syntax Warnings and Errors14.13 InnoDB File-Format Management14.13.1 Enabling File Formats14.13.2 Verifying File Format Compatibility14.13.3 Identifying the File Format in Use14.13.4 Downgrading the File Format 14.14 InnoDB Row Storage and Row Formats这一节讨论了InnoDB的某些特性是如何被create table声明中的ROW_FORMAT语句控制的，这些特性包括 表压缩 和对于 较长动态长度列值的跨页存储。 14.14.1 Overview of InnoDB Row Storage对行和相关列的存储影响着查询和DML操作的性能。如果多行放在一个磁盘页上，查询和索引查找会更快，innoDB的buffer bool也会需要更少的内存进行缓存, 写出对数字列与短字符列的更新值也会需要更少的I/O。 每个InnoDB表中的数据都被分隔成页。组成每个表的页以树行数据结构进行组织（B-tree索引）。表数据和二级索引都使用这种类型的数据结构。这个代表所有表数据的B-tree索引被称做聚簇索引，根据 主键 列进行组织。索引数据结构的节点包含了行中所有列的值（聚簇索引）或索引列与主键列（二级索引）。 变长列是一个例外。BLOB和VARCHAR列因太长而不能放在一个B-tree中，其被放在分别分配的磁盘页上（溢出页）。我们称这些列叫跨页列。这些列的值被存储在一个包含溢出页的单向链表中，每个链表有一个或多个溢出页。在某些情况下，这些列值的部分前缀或者全部被存储在B-tree来避免空间浪费和读取多个分离的页。 Barracuda文件格式支持了一个KEY_BLOCK_SIZE选项来控制列数据的多少会被存储在聚簇索引中，多少被放在溢出页中。 接下来的节描述了怎么样来配置InnoDB的行格式来控制变长列值的存储方式。行格式也决定了表压缩特性是否支持。 14.14.2 Specifying the Row Format for a Table用ROW_FORMAT语句在CREATE TABLE或ALTER TABLE声明中来指定行格式。例如： create table t1 (f1 int unsigned) ROW_FORMAT=DYNAMIC engine=INNODB; InnoDB行格式有COMPAT，REDUNDANT，DYNAMIC，COMPRESSED。对于 InnoDB表，COMPACT是默认格式。参考CREATE TABLE文档来获得更多关于行格式这个表选项的信息。 行的物理结构依赖于行格式。参考14.11.3 Physical Row Structure of InnoDB Tables 14.14.3 DYNAMIC and COMPRESSED Row Formats这节讨论InnoDB表的DYNAMIC和COMPRESSED格式。要使用这两种行格式，必须把innodb_file_format设置为Barracuda，innodb_file_per_table也必须启用。（Barracuda同样支持COMPACT和REDUNDANT行格式） 当一个表以ROW_FORMAT=DYNAMIC和ROW_FORMAT=COMPRESSED进行创建的时候，InnoDB就可以通过跨页存储很长的变长列值（VARCHAR, VARBINARY, BLOB, TEXT列类型），在聚簇索引记录中包含一个20-byte的指针指向溢出页。InnoDB也会将大于等于768bytes的字段编码成变长字段。比如，一个char(255)的列，在字符集大于3的时候可以超过768字节（utf8mb4编码）。 列值是否存储跨页依赖于页大小和行的大小。少于或等于40bytes的TEXT和BLOB列仅以行内方式存储。 DYNAMIC行格式会在行能存储在索引节点内的时候提高效率（COMPACT和REDUNDANT也这样），但是这种格式会将长列的大量数据存储在b-tree节点的问题。DYNAMIC来源于这么一个思路，如果一个很长数据的部分值存储在下一页，那还不如把所有的数据都存储在下一页去。以DYNAMIC格式存储，更短的行就会更多的留在b-tree节点内，减少了每个列需要的溢出页。 The COMPRESSED row format uses similar internal details for off-page storage as the DYNAMIC row format, with additional storage and performance considerations from the table and index data being compressed and using smaller page sizes. With the COMPRESSED row format, the option KEY_BLOCK_SIZE controls how much column data is stored in the clustered index, and how much is placed on overflow pages. For full details about the COMPRESSED row format, see Section 14.12, “InnoDB Table Compression”. ROW_FORMAT=DYNAMIC and ROW_FORMAT=COMPRESSED are variations of ROW_FORMAT=COMPACT and therefore handle CHAR storage in the same way as ROW_FORMAT=COMPACT. For more information, see Section 14.11.3, “Physical Row Structure of InnoDB Tables”. 14.14.4 COMPACT and REDUNDANT Row Formats14.15 InnoDB Disk I/O and File Space Management14.15.1 InnoDB Disk I/O14.15.2 File Space Management14.15.3 InnoDB Checkpoints14.15.4 Defragmenting a Table14.15.5 Reclaiming Disk Space with TRUNCATE TABLE14.16 InnoDB Fast Index Creation14.16.1 Overview of Fast Index Creation14.16.2 Examples of Fast Index Creation14.16.3 Implementation Details of Fast Index Creation14.16.4 Concurrency Considerations for Fast Index Creation14.16.5 How Crash Recovery Works with Fast Index Creation14.16.6 Limitations of Fast Index Creation14.17 InnoDB Startup Options and System Variables14.18 InnoDB INFORMATION_SCHEMA Tables14.18.1 InnoDB INFORMATION_SCHEMA Tables about Compression14.18.2 InnoDB INFORMATION_SCHEMA Transaction and Locking Information14.18.3 InnoDB INFORMATION_SCHEMA Buffer Pool Tables14.19 InnoDB Integration with MySQL Performance Schema14.19.1 Monitoring InnoDB Mutex Waits Using Performance Schema14.20 InnoDB Monitors14.20.1 InnoDB Monitor Types14.20.2 Enabling InnoDB Monitors14.20.3 InnoDB Standard Monitor and Lock Monitor Output14.20.4 InnoDB Tablespace Monitor Output14.20.5 InnoDB Table Monitor Output14.21 InnoDB Backup and Recovery14.21.1 The InnoDB Recovery Process14.22 InnoDB and MySQL Replication14.23 InnoDB Troubleshooting14.23.1 Troubleshooting InnoDB I/O Problems14.23.2 Forcing InnoDB Recovery14.23.3 Troubleshooting InnoDB Data Dictionary Operations14.23.4 InnoDB Error Handling","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://gowa2017.github.io/categories/MySQL/"}],"tags":[],"keywords":[{"name":"MySQL","slug":"MySQL","permalink":"https://gowa2017.github.io/categories/MySQL/"}]},{"title":"Calibre 制作含目录的电子书小说","slug":"Calibre-制作含目录的电子书小说","date":"2017-11-06T14:28:27.000Z","updated":"2018-09-27T11:55:19.000Z","comments":true,"path":"Kindle/Calibre-制作含目录的电子书小说.html","link":"","permalink":"https://gowa2017.github.io/Kindle/Calibre-制作含目录的电子书小说.html","excerpt":"还是mobi、azw3格式的小说在Kindle上看着舒服，但是总是发现没有目录的情况，所以搜索了一下网络，来制作一下对应的目录。","text":"还是mobi、azw3格式的小说在Kindle上看着舒服，但是总是发现没有目录的情况，所以搜索了一下网络，来制作一下对应的目录。 前提Calibre怎么安装，就不多说了。然后你还需要一个支持正则表达式的文本编辑器。Windows下推荐Emeditor，然后如果说Linux或者Unix下的话，直接用sed就好了。 处理先看一下转换书籍的内容目录项。对于目录的定义其是使用Xpath进行定义的。具体的意义我不是很明白，但是照着做就好了，抽空在学习一下。Xpath是针对html代码和文件的，所以我们要用html的方式来进行标签我们要处理的内容。比如我下载了一本小说的txt文件，ypjs.txt，修改一下扩展名为ypjs.html。里面分为两级架构，卷-章模式。我就用sed进行了批量的操作。sed -i bak 's/\\(^第[一二三四五六七八九十百零]*卷.*$\\)/# \\1/' ypjs.txtsed -i bak 's/\\(^第[一二三四五六七八九十百零]*章.*$\\)/## \\1/' ypjs.txtsed -i bak '/^ *$/d' ypjs 处理后的文本如下：Calibre设置如下：然后开转换吧 结果大功告成","categories":[{"name":"Kindle","slug":"Kindle","permalink":"https://gowa2017.github.io/categories/Kindle/"}],"tags":[{"name":"Kindle","slug":"Kindle","permalink":"https://gowa2017.github.io/tags/Kindle/"},{"name":"小说","slug":"小说","permalink":"https://gowa2017.github.io/tags/小说/"}],"keywords":[{"name":"Kindle","slug":"Kindle","permalink":"https://gowa2017.github.io/categories/Kindle/"}]},{"title":"SSH客户端文件配置","slug":"ssh-config-file-format","date":"2017-01-06T02:40:00.000Z","updated":"2018-03-12T02:48:21.000Z","comments":true,"path":"Linux/ssh-config-file-format.html","link":"","permalink":"https://gowa2017.github.io/Linux/ssh-config-file-format.html","excerpt":"在windows下，我们有xshell或者SecureCRT这样的利器供我们使用，但如果在macOS下的话用起来就恼火。但事实上我们可以通过配置ssh命令的行为来更加方便的管理设备。","text":"在windows下，我们有xshell或者SecureCRT这样的利器供我们使用，但如果在macOS下的话用起来就恼火。但事实上我们可以通过配置ssh命令的行为来更加方便的管理设备。官方文档链接 配置文件的读取ssh命令会按以下的顺序读取文件获得配置的参数。 命令行选项 ~/.ssh/config /etc/ssh/ssh_config 对于每个参数，第一个获得的值将被使用。 配置文件中用Host分开每个节，每个节的设备只会应用到匹配上Host指定模式的主机上。比如 ssh test 命令只会匹配配置文件中 Host test ... ... 指定的属性。由于只会使用第一个获取的值，所以要将某些特别的属性放在前面，共有的或默认的属性放在配置文件后面。 配置文件的格式空行及以#开头的的行识别为注释，否则的话每行就有keyword arguments这样的格式。在参数含有空格的时候，可以使用&quot;来包围参数。keywords不区分大小写，但arguments区分大小写。 常用选项 Host pattern 限制之后的直到下一个Host或Match之间的声明只应用于匹配pattern的主机。多个pattern用空白分割。*代表了所有主机默认选项。 HostName 真实主机名。IP和域名都可以接受。 IdentityFile 指定私钥文件位置，可指定多个，按序读取。 PasswordAuthentication 是否使用密码认证。 Port 连接端口，默认22 User 登录用户名。 更多选项 Match pattern 限制之后的直到下一个Host或Match之间的声明只应用于满足pattern。 AddKeysToAgent { no | yes | ask | confirm } AddressFamily { any | inet | inet6 } BatchMode { no | yes } 是否关闭 密码 询问。对某些脚本任务中不需要密码工作很有用。 BindAddress addr 使用本地机器上的addrIP进行连接 CanonicalDomains 当CanonicalizeHostname启用的时候，会在此选项指定的域名后缀列表查找目标主机。 CanonicalizeFallbackLocal 是否在规范化域名失败的时候返回一个错误。默认时yes，尝试使用系统解析器的查找规则来解析unqualified hostname。设置为no的话，当CanonicalizeHostname启用并且目标hostname没有在CanonicalDomains内查找到的时候，ssh立即返回失败。 CanonicalizeHostname { no | yes | always } 控制是否执行严格的域名标准化。默认是no，不进行任何域名重写，让系统解析器进行域名寻找。如果设置为yes，对没有使用ProxyCommand的连接，ssh命令将会对在命令行指定的域名按照CanonicalDomains给定的后缀和CanonicallizePermittedCNAMEs规则。如果设置为always，对使用代理的连接也使用域名规范化。这个选项启用后，会重新读取配置文件用新的target name来获取匹配Host或Match节中的选项。 CanonicalizeMaxDots 最多能指定的.数量。默认是1。 CanonicalizePermittedCNAMEs 控制在进行主机名规范化的时候是否跟随CNAMES。规则有source_domain_list:target_domain_list。 CertificateFile 指定证书文件位置，相应的私钥文件要单独提供。可指定多个，读取的时候按照顺序进行。 ChallengeResponseAuthentication { no | yes }* 挑战相应认证是否开启。 CheckHostIP { yes | no } 默认yes会检查主机IP是否存在于known_host文件内。用以检查一个主机的key是否因DNS欺骗而改变，同时会增加IP进入~/.ssh/known_hosts而不考虑StrictHostKeyChecking的设置。 Cipher 协议版本1中指定使用的算法。blowfish, 3des(默认), des（传统的ssh实现）支持。 Ciphers 协议版本2指定使用的算法。用逗号分割多种算法。如果指定的值前面有一个+号，那么就会在默认的值后面进行增加而不是替换默认值。支持的算法如下: 3des-cbcaes128-cbcaes192-cbcaes256-cbcaes128-ctraes192-ctraes256-ctraes128-gcm@openssh.comaes256-gcm@openssh.comarcfourarcfour128arcfour256blowfish-cbccast128-cbcchacha20-poly1305@openssh.com 默认的值是： chacha20-poly1305@openssh.com,aes128-ctr,aes192-ctr,aes256-ctr,aes128-gcm@openssh.com,aes256-gcm@openssh.com,aes128-cbc,aes192-cbc,aes256-cbc ClearAllForwardings { no | yes } 所有在配置文件、命令行指定的本地、远程、动态端口转发都被清理。 Compression { no | yes } 是否启用压缩 CompressionLevel 只是1(fast)到9(slow, best)，和gzip意义一样。默认等级是6。只对协议版本1有效。 ConnectionAttempts 重试次数。 ConnectTimeout 指定超时时间（秒），而不是使用tcp自己的超时机制。 ControlMaster 启用在一个连接上共享多个会话。 ControlPath ControlPersist DynamicForward 指定安全隧道端口，后续的远程机器会连接这个端口。参数必须是[bind_address:]port。默认情况下，端口与GatewayPorts设定的范围一致。支持socks4, socks5。常见用法对不同的主机使用不同的私钥Host blog Hostname blog.tuisiyuan.net IdentityFile ~/.ssh/id_rsa_blog User rootHost me Hostname 120.55.87.63 IdentityFile ~/.ssh/id_rsa_blog User root","categories":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/tags/Linux/"},{"name":"SSH","slug":"SSH","permalink":"https://gowa2017.github.io/tags/SSH/"}],"keywords":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}]},{"title":"FTP的主动模式(PORT)与被动模式(PASV)","slug":"FTP-PORT-PASV-MODE","date":"2017-01-04T14:47:43.000Z","updated":"2018-03-12T02:48:21.000Z","comments":true,"path":"Work/FTP-PORT-PASV-MODE.html","link":"","permalink":"https://gowa2017.github.io/Work/FTP-PORT-PASV-MODE.html","excerpt":"在服务器间进行数据传输的时候经常采用ftp协议，但是又要进行安全策略的控制，有的时候会出现连接失败的问题。所以研究一下这两者之间的不同。","text":"在服务器间进行数据传输的时候经常采用ftp协议，但是又要进行安全策略的控制，有的时候会出现连接失败的问题。所以研究一下这两者之间的不同。 控制连接与数据连接FTP的控制连接与数据连接是分开的。只有在需要数据连接的时候才会打开，用完则会进行关闭。PORT与PASV的区别就在于打开数据连接的流程和方式不同。 PASV模式大多数客户端(LINUX ftp命令)都用的这种模式。在需要打开数据连接的时候， 其基本流程是: 客户端请求一个数据传送 服务端将开放的数据端口发送给客户端 客户端连接此端口 传输数据PORT模式PORT模式是由客户端选择一端口进行开放，然后服务端通过20端口进行连接后传输数据。其流程为: 客户端发送PORT命令(包含数据端口) 服务端连接客户端的数据端口 传输数据访问策略的注意服务器间通过FTP进行数据传输的时候，作为服务端，21端口是必须进行允许要进行上传或者下载的IP进行连接。默认情况下，客户端都是采用的PASV模式进行传输，那么就是需要由服务端告知数据段口，客户端进行连接。在iptables的默认策略是ACCPET的情况下，这并没有什么问题，但是如果默认策略是REJECT就得小心了。而对于采用主动模式PORT的客户端，则就必须对进入的流量包进行一个允许了。","categories":[{"name":"Work","slug":"Work","permalink":"https://gowa2017.github.io/categories/Work/"}],"tags":[{"name":"FTP","slug":"FTP","permalink":"https://gowa2017.github.io/tags/FTP/"}],"keywords":[{"name":"Work","slug":"Work","permalink":"https://gowa2017.github.io/categories/Work/"}]},{"title":"Oracle中的union和join","slug":"Oracle中的union和join","date":"2017-01-03T14:39:53.000Z","updated":"2018-03-12T02:48:21.000Z","comments":true,"path":"Oracle/Oracle中的union和join.html","link":"","permalink":"https://gowa2017.github.io/Oracle/Oracle中的union和join.html","excerpt":"有时候，我们需要把很多表的查询结果给合并在一起显示或者导出，有时候呢我们又需要几张表联合一些条件进行查询，所以我们常会用到join和union语句。","text":"有时候，我们需要把很多表的查询结果给合并在一起显示或者导出，有时候呢我们又需要几张表联合一些条件进行查询，所以我们常会用到join和union语句。 UNION官方说明包含UNION [ALL], INTERSECT, MINUS三个操作符，具有相同的优先级（可以用(...)进行改变优先级），含有多个的时候，自左至右进行计算。在每个组成UNION查询的子查询中，其select list(选择列表)必须具有相同的数量和数据组类型。如果子查询选择的是字符数据，其返回值的数据类型由下决定： 所有的子查询选择的char值具有相同的length，返回值就是char(length)。如果查询的值类型分别是char(length1), char(length2)...，其返回值是varchar2(max(length1,length2,...)) 如果子查询选择的值都是varchar2，那么返回值就是varchar2。对于选择的是数值数据： 任何一个查询选择的值是binary_double，其返回值就是binary_double。 任何一个查询选择的值是binary_float，其返回值就是binary_float。 所有查询选择的值是number，其返回值才是number。 使用这几个集操作符的时候，Oracle不会进行隐含的数据类型组之间的转换。所以，如果查询包含number和char类型的话，Oracle返回一个错误。比如:select '3' from dual intersectselect 3f from dual; 会返回一个错误。但：select 3 from dual intersectselect 3f from dual; 则会被在类型组内隐含进行转换成：select to_binary_float(3) from dual intersectselect 3f from dual; 限制集操作符服从以下限制： 对列类型为BLOB, CLOB, BFILE, VARRAY或者嵌套表无效。 UNION, INTERSECT, MINUS对LONG列无效。 在集操作符前的选择列表包含表达式的话，那么必须得对列设置别名以便后面在order by clause内使用。 不能用for_update_clause共用 在这些操作符的子查询内不能使用order_by_clause You cannot use these operators in SELECT statements containing TABLE collection expressions.Example查询中to_char(null)用在当表中没有某列的时候来匹配数据类型。SELECT location_id, department_name \"Department\", TO_CHAR(NULL) \"Warehouse\" FROM departments UNION SELECT location_id, TO_CHAR(NULL) \"Department\", warehouse_name FROM warehouses; union操作符联合结果中不重复的结果，union all联合所有的结果。SELECT product_id FROM order_itemsUNIONSELECT product_id FROM inventories;SELECT location_id FROM locations UNION ALL SELECT location_id FROM departments; INTERSECT相交操作符联合子查询中都有的行。SELECT product_id FROM inventoriesINTERSECTSELECT product_id FROM order_items; MINUS相减操作符联合第一个查询的行并且没有在第二个查询中出现的行（同时会去重）。SELECT product_id FROM inventoriesMINUSSELECT product_id FROM order_items; JOIN官方说明JOIN用来从两或多个表、视图、物化视图中结合数据。在FROM后面的表都会进行一个JOIN操作，这样我们就可以用SELECT语句查询这个JOIN中的任意列。当然，如果这些表中有相同名的列，就要用tbl.col这样的形式来来完整引用列了。 Join Conditions大多数join查询有一个Join Condition，可能出现在FROM或WHERE语句中，其会比较从不同表中的两列。对Join Contidion为TRUE的行，就把两个表中那一行组合成一行。需要注意的是不能出现在select list中。对与join三个或以上的表，Oracle首先Join根据Join ConditionJoin前两个表，然后再把表这个结果和新表根据Join Conditon进行Join，直到把所有表都Join完。Oracle的Optimizer了决定Join的顺序。 Equijoins一个equijoin就是Join Condition包含一个等号，对指定的列具有相等的值的行进行Join。 Self Joins表本身进行Join。在FROM后出现两次，并且跟随别名。 Cartesian Products（笛卡尔乘积）如果一个Join查询不包含Join Conditon，那么Oracle返回的就是一个他们的Cartesian product。这个结果一般没有什么用，所以Join的时候最后都指定Join Conditon。 Inner Joins(simple join)只Join满足的行。 Outer JoinsOuter Join扩展了simple join的结果。一个outer join返回所有满足Join Conditon的行，同时从一个不满足条件的表返回一些或所有行。 LEFT [outer] JOIN想要Join表 A,B，同时返回A的所有行。在FROM后面使用left [outer] join语句，或者在WHERE语句中的Join Conditon对B的所有列使用outer join operator（+）。对A在B中没有匹配行，在B的列中就会返回NULL。举个例子有一个属地代码表md_area(areano, name)。有一个用户表users(mdn,areano,….)。我现在要统计users表中各属地的用户数，还要根据代码显示出属地名称，以便更加直观的进行统计。select area, areaname, ct from (select areano as area, count(*) as ct from users group by areano) t1 left join (select areano, name as areaname from md_area t2) on t2.areano = t1.area; Right [outer] Join接上例，其等于:select area, areaname, ct from (select areano, name as areaname from md_area t2) right join (select areano as area, count(*) as ct from users group by areano) t1 on t2.areano = t1.area; Antijoins (反连接）Semijoins （半连接）","categories":[{"name":"Oracle","slug":"Oracle","permalink":"https://gowa2017.github.io/categories/Oracle/"}],"tags":[{"name":"Oracle","slug":"Oracle","permalink":"https://gowa2017.github.io/tags/Oracle/"},{"name":"SQL","slug":"SQL","permalink":"https://gowa2017.github.io/tags/SQL/"},{"name":"数据库","slug":"数据库","permalink":"https://gowa2017.github.io/tags/数据库/"}],"keywords":[{"name":"Oracle","slug":"Oracle","permalink":"https://gowa2017.github.io/categories/Oracle/"}]},{"title":"贵州电信月末数据统计","slug":"贵州电信月末数据统计","date":"2017-01-03T09:37:41.000Z","updated":"2018-03-12T02:48:21.000Z","comments":true,"path":"Work/贵州电信月末数据统计.html","link":"","permalink":"https://gowa2017.github.io/Work/贵州电信月末数据统计.html","excerpt":"用来统计每个月月底的业务数据及数据库使用情况","text":"用来统计每个月月底的业务数据及数据库使用情况 注册用户发展情况201 固网 WLAN 302 CMDA 511用户数统计固网select servicetype,count(*) from v$b_broadband_user where status !=2 group by servicetype; C网select count(1) from V$C_IMSI; 净增用户数=开户数-销户数开户数C网select count(1) from V$C_IMSI where opendate &gt;= add_months(trunc(sysdate,'mm'), -1) and opendate &lt; trunc(sysdate,'mm'); 固网select servicetype,count(*) from v$b_broadband_user where opendate &gt;= add_months(trunc(sysdate,'mm'), -1) and opendate &lt; trunc(sysdate,'mm') group by servicetype; 销户数C网select count(distinct imsi) from C_IMSI_HIS a where a.otype=3 and a.itime &gt;= add_months(trunc(sysdate,'mm'), -1) and a.itime &lt; trunc(sysdate,'mm'); 固网select servicetype,count(*) from v$b_broadband_user where status=2 where opendate &gt;= add_months(trunc(sysdate,'mm'), -1) and opendate &lt; trunc(sysdate,'mm') group by servicetype; 活跃用户数select servicetype, sum(c) from ((select servicetype, count(*) as c from B_COMMON_BILL12_00 where timelen&gt;0 and accounttype=0 group by servicetype) union all(select servicetype, count(*) as c from B_COMMON_BILL12_01 where timelen&gt;0 and accounttype=0 group by servicetype) union all(select servicetype, count(*) as c from B_COMMON_BILL12_02 where timelen&gt;0 and accounttype=0 group by servicetype) union all(select servicetype, count(*) as c from B_COMMON_BILL12_03 where timelen&gt;0 and accounttype=0 group by servicetype) union all(select servicetype, count(*) as c from B_COMMON_BILL12_04 where timelen&gt;0 and accounttype=0 group by servicetype) union all(select servicetype, count(*) as c from B_COMMON_BILL12_05 where timelen&gt;0 and accounttype=0 group by servicetype)) group by servicetype order by servicetype; 清单统计报表固网select d1,servicetype,c from (select '25' as d1,servicetype,count(*) as c from b_broadband_det12_25 group by servicetype union allselect '26' as d1,servicetype,count(*) as c from b_broadband_det12_26 group by servicetype union allselect '27' as d1,servicetype,count(*) as c from b_broadband_det12_27 group by servicetype union allselect '25' as d1,servicetype,count(*) as c from b_dialup_det12 where stoptime &gt; to_date('2016-12-25 00:00:00','YYYY-MM-DD HH24:MI:SS') and stoptime &lt;= to_date('2016-12-26 00:00:00','YYYY-MM-DD HH24:MI:SS') group by servicetype union allselect '26' as d1,servicetype,count(*) as c from b_dialup_det12 where stoptime &gt; to_date('2016-12-26 00:00:00','YYYY-MM-DD HH24:MI:SS') and stoptime &lt;= to_date('2016-12-27 00:00:00','YYYY-MM-DD HH24:MI:SS') group by servicetype union allselect '27' as d1,servicetype,count(*) as c from b_dialup_det12 where stoptime &gt; to_date('2016-12-27 00:00:00','YYYY-MM-DD HH24:MI:SS') and stoptime &lt;= to_date('2016-12-28 00:00:00','YYYY-MM-DD HH24:MI:SS') group by servicetype) order by d1,servicetype C网select day,num from ( select '25' as day,count(*) as num from c_det12_25 union all select '26' as day,count(*) as num from c_det12_26 union all select '27' as day,count(*) as num from c_det12_27); 表空间及各表使用情况select x1 as 表空间名称, x4 as 表空间大小M, x5 as 空闲M, x6*100||'%' as 空闲百分比 from ( select a.a1 as x1,c.c2 as x2,c.c3 as x3,b.b2/1024/1024 as x4,(a.a2)/1024/1024 as x5,substr((a.a2)/b.b2,1,5) as x6 from (select tablespace_name a1, sum(nvl(bytes,0)) a2 from dba_free_space group by tablespace_name) a, (select tablespace_name b1,sum(bytes) b2 from dba_data_files group by tablespace_name) b, (select tablespace_name c1,contents c2,extent_management c3 from dba_tablespaces) c where a.a1=b.b1 and c.c1=b.b1 order by substr((b.b2-a.a2)/b.b2,1,5) desc);select SEGMENT_NAME as 表名,TABLESPACE_NAME as 表空间名,BYTES/1024/1024||'M' as 占用磁盘空间 from dba_segments where owner = USER and bytes&gt;3000000000 order by bytes desc; 关于日期select sysdate from dual; --output:17/1/3 15:03:35select trunc(sysdate,'YYYY') from dual; --output: 17/1/1 本年的一月一号select trunc(sysdate,'mm') from dual; --output: 17/1/1 本月的1号select trunc(sysdate,'dd') from dual; --output: 17/1/3 月份的天数select add_months(trunc(sysdate,'mm'),-3) from dual; --output: 16/10/1select add_months(trunc(sysdate,'mm'),-3)+25 from dual; --output: 16/10/26","categories":[{"name":"Work","slug":"Work","permalink":"https://gowa2017.github.io/categories/Work/"}],"tags":[{"name":"Work","slug":"Work","permalink":"https://gowa2017.github.io/tags/Work/"}],"keywords":[{"name":"Work","slug":"Work","permalink":"https://gowa2017.github.io/categories/Work/"}]},{"title":"贵州广电月末数据统计","slug":"贵州广电月末数据统计","date":"2017-01-03T09:37:41.000Z","updated":"2018-03-12T02:48:21.000Z","comments":true,"path":"Work/贵州广电月末数据统计.html","link":"","permalink":"https://gowa2017.github.io/Work/贵州广电月末数据统计.html","excerpt":"用来统计每个月月底的业务数据及数据库使用情况","text":"用来统计每个月月底的业务数据及数据库使用情况 注册用户发展情况301固网 302WLAN用户数统计select servicetype,count(*) from v$b_broadband_user where status !=2 group by servicetype order by servicetype; 净增用户数=开户数-销户数开户数select servicetype,count(*) from v$b_broadband_user where opendate &gt;= add_months(trunc(sysdate,'mm'), -1) and opendate &lt; trunc(sysdate,'mm') group by servicetype; 销户数select servicetype,count(*) from v$b_broadband_user where status=2 and closedate &gt;= add_months(trunc(sysdate,'mm'),-1) and closedate &lt; trunc(sysdate,'mm') group by servicetype; 活跃用户数select servicetype, sum(c) from ((select servicetype, count(*) as c from B_COMMON_BILL12_00 where timelen&gt;0 and accounttype=0 group by servicetype) union all(select servicetype, count(*) as c from B_COMMON_BILL12_01 where timelen&gt;0 and accounttype=0 group by servicetype) union all(select servicetype, count(*) as c from B_COMMON_BILL12_02 where timelen&gt;0 and accounttype=0 group by servicetype) union all(select servicetype, count(*) as c from B_COMMON_BILL12_03 where timelen&gt;0 and accounttype=0 group by servicetype) union all(select servicetype, count(*) as c from B_COMMON_BILL12_04 where timelen&gt;0 and accounttype=0 group by servicetype) union all(select servicetype, count(*) as c from B_COMMON_BILL12_05 where timelen&gt;0 and accounttype=0 group by servicetype)) group by servicetype order by servicetype; 清单统计报表select d1,servicetype,c from (select '25' as d1,servicetype,count(*) as c from b_broadband_det12_25 group by servicetype union allselect '26' as d1,servicetype,count(*) as c from b_broadband_det12_26 group by servicetype union allselect '27' as d1,servicetype,count(*) as c from b_broadband_det12_27 group by servicetype) order by servicetype,d1; 表空间及各表使用情况select x1 as 表空间名称, x4 as 表空间大小M, x5 as 空闲M, x6*100||'%' as 空闲百分比 from ( select a.a1 as x1,c.c2 as x2,c.c3 as x3,b.b2/1024/1024 as x4,(a.a2)/1024/1024 as x5,substr((a.a2)/b.b2,1,5) as x6 from (select tablespace_name a1, sum(nvl(bytes,0)) a2 from dba_free_space group by tablespace_name) a, (select tablespace_name b1,sum(bytes) b2 from dba_data_files group by tablespace_name) b, (select tablespace_name c1,contents c2,extent_management c3 from dba_tablespaces) c where a.a1=b.b1 and c.c1=b.b1 order by substr((b.b2-a.a2)/b.b2,1,5) desc);select SEGMENT_NAME as 表名,TABLESPACE_NAME as 表空间名,BYTES/1024/1024||'M' as 占用磁盘空间 from dba_segments where owner = USER and bytes&gt;3000000000 order by bytes desc; 关于日期select sysdate from dual; --output:17/1/3 15:03:35select trunc(sysdate,'YYYY') from dual; --output: 17/1/1 本年的一月一号select trunc(sysdate,'mm') from dual; --output: 17/1/1 本月的1号select trunc(sysdate,'dd') from dual; --output: 17/1/3 月份的天数select add_months(trunc(sysdate,'mm'),-3) from dual; --output: 16/10/1select add_months(trunc(sysdate,'mm'),-3)+25 from dual; --output: 16/10/26","categories":[{"name":"Work","slug":"Work","permalink":"https://gowa2017.github.io/categories/Work/"}],"tags":[{"name":"Work","slug":"Work","permalink":"https://gowa2017.github.io/tags/Work/"}],"keywords":[{"name":"Work","slug":"Work","permalink":"https://gowa2017.github.io/categories/Work/"}]},{"title":"AAA系统的接口资料","slug":"AAA系统的接口资料","date":"2016-12-23T02:06:19.000Z","updated":"2018-03-12T02:48:21.000Z","comments":true,"path":"Work/AAA系统的接口资料.html","link":"","permalink":"https://gowa2017.github.io/Work/AAA系统的接口资料.html","excerpt":"用来进行快速的接口操作。","text":"用来进行快速的接口操作。 Socket接口电信host:interface2path:/data/lcims/gzdx_lcbmi80/testcmd: LANG=zh_CN.gb18030;export LANGJAVA_HOME=\"/opt/java1.5\"$&#123;JAVA_HOME&#125;/bin/java -classpath .:../classes SocketClient 10.25.79.98 5902 ./20161223.txt 20161223.txt 为记录列表，每行一条操作记录，字段构造方式参考接口协议。 广电测试环境 主机: 10.4.1.21:8008 目录:/data/lcims/gzgd_lcbmi80 连接类型：短连接 ##des3#openUserNumexpirenum=65ec74e934aa87c1#yyyymmddexpiretime=37bf59c1ddbdeef7 修改为:10000 expirenum=29d21ca07eb0c66c20161211 expiretime=f282e0d777b3095c 常用报文开客户 1|||1|||P01=zgxtest0003|||P04=000|||M07=000205|||M32=boss lan开户 4|||1|||P01=zgxtest0003|||M02=492922|||M04=000205|||M05=3|||M06=10|||M10=8|||U12=1|||M15=0|||U38=0|||U23=bozs|||U24=5120|||U29=1024 lan销户，status=2 4|||3|||P01=zgxtest0001|||U23=boss lan复机 4|||4|||P01=zgxtest0001|||U23=boss lan修改 4|||5|||P01=zgxtest0001|||U11=34324324|||U23=web lan查询 4|||21|||P01=zgxtest0001|||U97=M04,U12,M10,U11,M15,U24,U29 lan欠费停机 4|||20|||P01=zgxtest0001|||U23=boss lan验证用户密码 4|||31|||P01=zgxtest0001|||M02=247104 认证失败查询 41|||21|||M01=zgxtest0001|||U08=20161205##20161205|||U97=M01,U08,U10** 认证成功查询 42|||21|||M01=zgxtest0001|||U08=20161205##20161205|||U97=M01,U03,U07,U08** 在线查询 91|||21|||M01=zgxtest0001|||U97=U06,U05,U14,U08 在线删除 91|||7|||M01=zgxtest0001|||M03=201|||U20=boss 用户删除 4|||7|||P01=zgxtest0001|||U23=test","categories":[{"name":"Work","slug":"Work","permalink":"https://gowa2017.github.io/categories/Work/"}],"tags":[{"name":"AAA","slug":"AAA","permalink":"https://gowa2017.github.io/tags/AAA/"}],"keywords":[{"name":"Work","slug":"Work","permalink":"https://gowa2017.github.io/categories/Work/"}]},{"title":"利用github API对markdown进行渲染","slug":"利用github-API对markdown进行渲染","date":"2016-12-22T01:15:18.000Z","updated":"2018-03-12T02:48:21.000Z","comments":true,"path":"杂项/利用github-API对markdown进行渲染.html","link":"","permalink":"https://gowa2017.github.io/杂项/利用github-API对markdown进行渲染.html","excerpt":"很喜欢github形式的markdown渲染，所以百度了一下，怎么样渲染成那样。结果还真有，github全占支持markdown，还提供了api接口。","text":"很喜欢github形式的markdown渲染，所以百度了一下，怎么样渲染成那样。结果还真有，github全占支持markdown，还提供了api接口。 环境OS: CentOS 5.10 x86_64个人比较喜欢nginx，所以就用了nginx + php来建立环境，不过在安装php-fpm的时候可能要花点力气，主要是因为用的是 CentOS 5.10的系统，源有点老。这里就不赘述安装过程了，主要说一下配置的时候所遇到的蛋疼的问题。 配置nginx配置路径:/etc/nginx/conf.d/default.conf server &#123; listen 80 default_server; #listen [::]:80 default_server; server_name _; root /usr/share/nginx/html; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; location / &#123; index index.html index.md README.md; &#125; location ~ \\.php$ &#123; root /usr/share/nginx/html; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; &#125; location ~ \\.md$ &#123; rewrite ^/([^?]*)(?:\\?(.*))? /md.php?f=$1&amp;$2 last; &#125; error_page 404 /404.html; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; &#125;&#125; php-fpm这里这个的配置就是要把user/group都改成nginx，用户跟组一致才行。 建立md.php文件&lt;?php// 参数检查代码省略，然而这是必须的，否则你的 VPS 将会有后顾之忧function curl_raw($url, $content) &#123; $curl = curl_init($url); curl_setopt($curl, CURLOPT_HEADER, false); curl_setopt($curl, CURLOPT_RETURNTRANSFER, true); curl_setopt($curl, CURLOPT_HTTPHEADER, array(\"Content-type: application/json\", \"User-Agent: \" . $_SERVER['HTTP_USER_AGENT'])); curl_setopt($curl, CURLOPT_POST, true); curl_setopt($curl, CURLOPT_POSTFIELDS, $content); curl_setopt($curl, CURLOPT_SSL_VERIFYPEER, false); $json_response = curl_exec($curl); $status = curl_getinfo($curl, CURLINFO_HTTP_CODE); curl_close($curl); return $json_response;&#125;$markdown_filename = $_GET['f'];$markdown_text = file_get_contents($markdown_filename);$render_url = 'https://api.github.com/markdown';$request_array['text'] = $markdown_text;$request_array['mode'] = 'markdown';$html_article_body = curl_raw($render_url, json_encode($request_array));echo '&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset=\"utf-8\"&gt;&lt;title&gt;' . $markdown_filename . '&lt;/title&gt;&lt;link rel=\"stylesheet\" href=\"/md_github.css\" type=\"text/css\" /&gt;&lt;/head&gt;';echo '&lt;article class=\"markdown-body\"&gt;';echo $html_article_body;echo '&lt;/article&gt;&lt;/body&gt;&lt;/html&gt;';?&gt; 最后是css点此下载","categories":[{"name":"杂项","slug":"杂项","permalink":"https://gowa2017.github.io/categories/杂项/"}],"tags":[{"name":"Github","slug":"Github","permalink":"https://gowa2017.github.io/tags/Github/"},{"name":"Markdown","slug":"Markdown","permalink":"https://gowa2017.github.io/tags/Markdown/"},{"name":"Nginx","slug":"Nginx","permalink":"https://gowa2017.github.io/tags/Nginx/"},{"name":"Php","slug":"Php","permalink":"https://gowa2017.github.io/tags/Php/"}],"keywords":[{"name":"杂项","slug":"杂项","permalink":"https://gowa2017.github.io/categories/杂项/"}]},{"title":"ntpd升级到最新4.2.8p9","slug":"ntpd升级到最新4-2-8p9","date":"2016-12-14T12:50:10.000Z","updated":"2018-03-12T02:48:21.000Z","comments":true,"path":"Linux/ntpd升级到最新4-2-8p9.html","link":"","permalink":"https://gowa2017.github.io/Linux/ntpd升级到最新4-2-8p9.html","excerpt":"时钟的同步对于很多对于要求实时性的应用来说是很重要的，特别是与应用与数据库的同步。所以一般都会以数据库所有服务器，其他所有客户端进行同步。但是其也是爆出一些安全漏洞的，所以进行更新是很必要的。","text":"时钟的同步对于很多对于要求实时性的应用来说是很重要的，特别是与应用与数据库的同步。所以一般都会以数据库所有服务器，其他所有客户端进行同步。但是其也是爆出一些安全漏洞的，所以进行更新是很必要的。 查看版本ntpd --version 启动路径cat /etc/init.d/ntpd | grep prog= prog=ntpd which ntpd /usr/sbin/ntpd 备份原来的配置cd /etc &amp;&amp; cp ntp.conf ntp.conf.bak 编译./configure --prefix=/usr --bindir=/usr/sbin \\ --sysconfdir=/etc --enable-clockctl \\ --docdir=/usr/share/doc/ntp-4.2.8p9 make make install &amp;&amp; install -v -o ntp -g ntp -d /var/lib/ntp ntpq -c version 查看新版本ntpd --version 重新启动cd /etc &amp;&amp; cp ntp.conf.bak ntp.conf service ntpd restart ntpq -p 如果输出正常就证明升级成功了","categories":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/tags/Linux/"},{"name":"ntpd","slug":"ntpd","permalink":"https://gowa2017.github.io/tags/ntpd/"}],"keywords":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}]},{"title":"DHCP Client的模拟客户端申请IP","slug":"DHCP-Client的模拟客户端申请IP","date":"2016-12-14T03:26:46.000Z","updated":"2018-03-12T02:48:21.000Z","comments":true,"path":"Work/DHCP-Client的模拟客户端申请IP.html","link":"","permalink":"https://gowa2017.github.io/Work/DHCP-Client的模拟客户端申请IP.html","excerpt":"Dhcp Client 用来模拟用户接入，发送各种报文到DHCP系统进行申请IP。现将其使用流程进行一下介绍。","text":"Dhcp Client 用来模拟用户接入，发送各种报文到DHCP系统进行申请IP。现将其使用流程进行一下介绍。 使用前的配置。 system.cfg 配置客户端、服务端信息。包括IP、端口、线程信息、日志记录级别等。 create.cfg 指定构造报文的内容、模拟终端数、Option属性等属性。 在create.cfg 里面配置 giaddr为192.168.0.1，然后在管理系统为这个设备、接口、这个来源地址分配一个地址段 192.168.0.0/24 option60配置为 &quot;2(option60_user=&quot;iptvtest9&quot;,option60_pwd=&quot;123456&quot;,option60_realm=&quot;iptv.ha&quot;,option60_enterprise_code=&quot;61&quot;)&quot; option82配置为 2(port_type=&quot;0&quot;,slot=&quot;1&quot;,subslot=&quot;1&quot;,port=&quot;2&quot;,vpi=&quot;100&quot;,vci=&quot;200&quot;,identifier=&quot;&quot;,rack=&quot;1&quot;,frame=&quot;1&quot;,slot=&quot;1&quot;,subslot=&quot;1&quot;,port=&quot;1&quot;,xpi=&quot;4000&quot;,xci=&quot;200&quot;)配置完毕即可进行执行测试并抓包。 几种Option的说明 Option60在IPoE认证流程中携带账号和密码及配置信息；MSE处理时，和MAC地址一起配合形成MAC@Option60格式Optioin60内容字段具体格式请参考《中国电信“我的e家”技术规范-e家终端（e8）》。 Option82在IPoE认证流程中，用于标识用户的线路信息，DHCPServer处理时，提取Option82信息形成相应的NAS-Port-ID属性；对于Option82的规范定义参照《中国电信宽带用户接入线路标识编码格式要求》以及《中国电信PON系统用户接入端口标识编码格式要求》定义，接入线路(端口)标识信息采用Sub-option1（即AgentCircuitIDSub-option）承载。DHCPServer处理Option82时，同样按照以上规范定义，从AgentCircuitIDSub-option中获取 业务规则的识别IPoE方式可以设置为[不]认证[不]计费6种方式，选择规则是根据接口或业务类型或属地来选择。可以根据报文中上来的vlan、域名、用户名前缀、侦听IP来识别属于是什么业务（ITV、IPTV、等等）。然后获得每种业务的认证、计费参数，进行认证或计费。 IPoE的认证流程（1）用户终端发起DHCP请求，Option60携带账号和密码信息；（2）中间途经的网络设备根据相关规范标记Option82信息；（3）BRAS/SR收到用户请求报文，标记相应的Option82信息(如果有需要)；同时直接转请求报文中继转发给相应的DHCPServer。（4）DHCPServer收到用户请求报文，提取请求报文中的相关信息，构造认证所需Username和Nas-Port-ID。现阶段建议Username由MAC地址和Option60信息形成，格式为：MAC@Option60；密码为任意字符串；并将Option82信息转换为NAS-Port-ID信息，送到AAA认证。建议DHCPSERVER与AAA之间的接口采用标准Radius接口。（5）AAA对Option60信息进行解析，获取账号和密码信息，对用户进行认证；认证通过后，则向DHCPServer发回认证通过信息，并携带用户一些相关属性。MAC地址只是作为内部用户标识，不作为认证校验信息。（6）DHCPServer根据用户不同的业务信息分配相应的地址；用户可以正常使用业务。 CMDSH 的使用 cd ~/tools/cmdsh ./cmdsh 127.0.0.1 3001 命令列表command key command description show config debug 显示debug配置信息show config log 显示log配置信息show config auth 显示auth配置信息show config ipa 显示ipa配置信息show config protocol 显示portocol处理配置信息show config parse 显示parse配置信息show config nak 显示nak配置信息show config sync 显示sync配置信息show config cmdCtl 显示cmdCtl配置信息show config stat 显示stat配置信息show config reply 显示reply配置信息show data interAddr 显示接口地址信息show data interInfo 显示接口信息show data deviceInfo 显示设备信息show data bannedDevice 显示黑名单设备信息show data ipaGroup 显示ipa组信息show data ipaSelect 显示ipa选择信息show data ipPool 显示地址池信息show data ipPoolSelect 显示地址池选择规则信息show data terminateAssemble 显示终端组装信息show data ipSegment 显示地址段信息show data ipoeInfo 显示ipoe信息show data ipoeIdentRule 显示ipoe识别规则show data serviceAcctInfo 显示业务计费信息show data serviceIdentRule 显示业务识别规则show data nakReplyRule 显示NAK包回复控制规则show data option125 显示option125信息show data option43 显示option43信息show data option54 显示option54信息show data option56 显示option56信息show run recvListSize 显示接收队列长度show run parseListSize 显示解析队列长度show run replyListSize 显示响应队列长度show run authListSize 显示认证队列长度show run ipaListSize 显示地址分配队列长度show run authToggle 显示认证开关show run IPAConnection 显示IPA连接状态show version 显示版本信息config debug flag 配置debug日志开关config log errPktFlag 配置错误包日志开关config log errPktTimeLevel 配置错误包日志文件时间间隔config log resultPktFlag 配置结果记录日志开关config log resultPktTimeLevel 配置结果日志文件时间间隔config auth serverIp 配置认证代理服务器地址config auth serverPort 配置认证代理服务器端口config auth timeOut 配置认证超时时间config auth listMaxSize 配置认证队列最大长度config auth timeoutdealmode 配置认证超时处理模式config auth timerPoolSize 配置定时器池最大容量config auth toggle 配置认证开关config auth monitorToggle 配置认证超时检测开关config auth monitorStart 配置认证超时检测开始条件config auth monitorStop 配置认证超时检测结束条件config auth crbQueueNum 配置CRB队列最大长度config ipa timeOut 配置地址分配超时时间config ipa threadNum 配置地址分配处理线程数config ipa listMaxSize 配置地址分配队列最大长度config ipa pingPreAlloc 配置地址分配预分配PING开关config ipa emergencyFlag 配置地址分配应急处理开关config protocol serverIp 配置dhcp本地服务地址config protocol serverPort 配置dhcp本地服务端口config protocol paresThreadNum 配置解析线程数config protocol socketRecvExtend 配置接收缓存扩大倍数config protocol socketSendExtend 配置发送缓存扩大倍数config protocol recvRate 配置接收速率config protocol recvListMaxSize 配置接收队列最大长度config protocol lineRecvRate 配置线路接收速率config protocol macRecvRate 配置MAC接收速率config parse serviceListenIp 配置业务侦听地址config parse informFlag 配置inform包控制开关config parse declineFlag 配置decline包控制开关config parse rebootFlag 配置reboot包控制开关config parse terminateIdentFlag 配置terminateIdent控制开关config parse extraParseFlag 配置extra解析控制开关config nak closeCode 配置不回复NAK的错误码config sync centerIp 配置分配中心地址config sync markIp 配置软件服务实例地址config sync markPort 配置软件服务实例端口config sync fileSaveInterval 配置数据储存文件保存时间间隔config sync putUActionLevel 配置用户行为日志入库级别config sync putUActionFilterCode 配置用户行为日志入库过滤错误号config cmdctl listenPort 配置CMD通信端口config reply option82Flag 配置回复option82控制开关config stat pktStatSoftware 配置系统处理包统计开关write 写数据文件reboot 重启系统help show all command list","categories":[{"name":"Work","slug":"Work","permalink":"https://gowa2017.github.io/categories/Work/"}],"tags":[{"name":"DHCP","slug":"DHCP","permalink":"https://gowa2017.github.io/tags/DHCP/"}],"keywords":[{"name":"Work","slug":"Work","permalink":"https://gowa2017.github.io/categories/Work/"}]},{"title":"tcpdump的使用-过滤表达式","slug":"tcpdump的使用-过滤表达式","date":"2016-12-08T08:13:42.000Z","updated":"2018-03-12T02:48:21.000Z","comments":true,"path":"Linux/tcpdump的使用-过滤表达式.html","link":"","permalink":"https://gowa2017.github.io/Linux/tcpdump的使用-过滤表达式.html","excerpt":"一直都有在用，但是远没有体会到强大，直到某一天，实在需要排除网络故障问题的时候，让我们一起来学习吧。","text":"一直都有在用，但是远没有体会到强大，直到某一天，实在需要排除网络故障问题的时候，让我们一起来学习吧。 基本命令格式OS： CentOS 5.10 X86_64 tcpdump version 3.9.4 libpcap version 0.9.4tcpdump [ -AdDeflLnNOpqRStuUvxX ] [ -c count ] [ -C file_size ] [ -F file ] [ -i interface ] [ -m module ] [ -M secret ] [ -r file ] [ -s snaplen ] [ -T type ] [ -w file ] [ -W filecount ] [ -E spi@ipaddr algo:secret,... ] [ -y datalinktype ] [ -Z user ] [ expression ] 选项说明 -A 以ASCII打印每个报文。放用来抓网页。 -c count 收到 count 个包后退出 -C file_size 在将包数据写入文件的时候，检查文件是否大于设置的file_size。如果大了就重新开一个文件。文件名用-w filename指定，并加上一个从1开始的数字。file_size的单位是（1,000,000 bytes, not 1,048,576 bytes） -d -dd -ddd 将捕捉条件以人易读的方式/C片段方式/10进制方式。一般不用 -D —list-interface 以 1.eth0 这样的方式打印网卡，供 -i 调用。可能在老版本的 libpcap 上（缺少pcap_findalldevs()函数）无法支持。 -e 打印出链路层的头部信息如mac地址。 -E 针对 Ipsec ESP包。 -f 用数字形式显示 ‘外部的’ 互联网地址, 而不是字符形式。 -F file 读取file内的表达式，命令行上的将失效。 -i interface 指定监听网卡 -l 以标准输出变成缓冲行。当在抓包的时候你也想进行查看数据时。tcpdump -l | tee data 或tcpdump -l &gt; data &amp; tail -f data会很有用 -L 打印数据链路类型，然后退出。 -m -M -n 并不将IP转换为主机名。用来避免DNS查询。 -nn 不要把协议、端口转换为明细。比如：不要把53端口转换为DNS。 -N 不显示完整的域名引用。应用此选项nic.ddn.mil将会只显示为nic -O 不运行代码优化器。 -q 快速输出输出更少的协议信息， -p 不使网卡进入混杂模式。 -R -r filename 从文件读取报文。（-w filename建立）。标准输入是-。 -S 打印绝对，而不是相对，TCP队列号。 -s -T -t 不打印时间戳。 -tt 打印未格式化的时间戳。 -ttt 打印上一行与这一行的时间变量值（ms）。 -tttt 打印默认时间格式，同时前面会加上日期。 -u 打印未解密的NFShandles -U packet-bufferd，每个包收到就存到-w filename指定的文件，而不是等输出缓冲区满。老版本libpcap缺少(pcap_dump_flush())函数的不支持。 -v -vv -vvv 打印的信息一个比一个多，详细。 -w filenmae 将报文存到 filename，可通过-r读入，标准输出是-*。 -W 与-C一起用，限制文件生成数量，文件号最大会从。会在序号前补0,以便更好的排序。如果数字序号已到最大，就从最开始的文件开始写入。 -x 16进制形式打印每个包内容（不包括链路层头部）。这是一个链路层的包，所以被填充的部分也会被打印（上层网络的数据包小于数据帧最小长度）。 -xx 包括链路层头部 -X 以16进制和ASCII格式打印包内容（不包括链路层头部）。 -XX 以16进制和ASCII格式打印包内容（包括链路层头部）。 -y 指定链路层类型 —version表达式用来过滤哪些报文需要被捕获，没有表达式则所有报文都会被捕获。表达式一般包括一个或多个条件，每个条件经常是一个限制符（qualifiers）和一个ID（NAME或NUMBER）构成。有三种限制符： type {host | net | port | portrange}，如果不指定，默认是host。例如：host foo、net 128.3、port 80、portrange 6000-6008。 dir { src | dest | src or dst | src and dst} 指定报文方向，如果不指定，默认是src or dst。例如：src foo、dst net 128.3、src or dst port ftp-data。 proto {ether | fddi | tr | wlan | ip | ip6 | arp | rarp | decnet | tcp | udp}，如果不指定，所有和type符合的协议会被捕获。例如ether src foo、arp net 128.3、tcp port 21、udp portrange 7000-7005。 fddi与ether是同义词，指的是在指定网卡上所使用的链路层协议。 除了上面三种限制符外，还有一些其他的限制符：gateway, broadcast, less, greater and arithmetic expressions。允许的格式： dst host host 如果IPv4/v6报文的目标是host则为真。host可以是IP或者主机名 src host host 如果IPv4/v6报文的源地址是host则为真。host可以是IP或者主机名 host host 如果目标地址或源地址是host则为真。 ether [ src | dst | host} ehost 以太网帧[源地址 | 目的地址 | 目的地址或源地址]是 ehost gateway host 如果报文的gateway是host。也就是说：ether帧的源地址或目的地址是host，但是IP报文的目的地址和源地址都不是host。 [ src | dst ] net {net mask netmask | net/len} 指定[源网络号 | 目的网络号 | 目的或源网络号]是 net","categories":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/tags/Linux/"},{"name":"tcpdump","slug":"tcpdump","permalink":"https://gowa2017.github.io/tags/tcpdump/"},{"name":"抓包","slug":"抓包","permalink":"https://gowa2017.github.io/tags/抓包/"}],"keywords":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}]},{"title":"Bash编程参考-参数与扩展","slug":"Bash编程参考-参数与扩展","date":"2016-12-07T07:41:07.000Z","updated":"2018-03-12T02:48:21.000Z","comments":true,"path":"Shell/Bash编程参考-参数与扩展.html","link":"","permalink":"https://gowa2017.github.io/Shell/Bash编程参考-参数与扩展.html","excerpt":"通过参考bash手册，详细的总结了其特殊参数，已经进行扩展的方式。","text":"通过参考bash手册，详细的总结了其特殊参数，已经进行扩展的方式。 引用引用的目的是去除某些字符或单词的特殊含义。可以用来禁止对特殊字符的特殊处理，使保留字不再是保留字，或者禁止参数扩展。其有三种方式进行引用。 \\ 转义字符，其后的字符具有字面意义。当其后跟随一个\\newline时，将会忽略这个换行，。 &#39; 单引号 所有单引号间的字符具有字面意义。&#39; some char&#39;间不能再出现&#39;，即使是被转义的。 &quot; 双引号 所有双引号间的字符具有字面意义，除了$$、‘、`、!(如果开启了历史扩展)。$$、‘`保留其特殊功能;反斜杠\\只有其后面是\\、$、&#39;、&quot;、newline才保留转义功能，不然表示的是它自己；如果\\后的字符并没有什么特殊意义，那么\\就会被保留；@、*具有特殊意义。shell 参数当你以 NAME=[VALUE] 形式的时候，你就定义了一个变量NAME，其值是VALUE（空字符串是允许的），你可以通过 unset命令取消这个变量。变量VALUE会进行大括号扩展、参数和变量扩展、命令替换、算数扩展、以及引用去除。位置参数(Positional Parameters)位置参数说的就是命令行的参数，如下命令行： ./test.sh one two three其具有位置参数$1, $2, $3 one, two, three** 。第N个参数可以表示为$N ，但是当参数大于等于10的时候，就必须用*${N} 来表示。位置参数不能进行赋值，只能通过set与shift（左移位置参数）来设置或删除。 特殊参数（如上例） $* 等价于 “$1 $2 $3” $@ 等价于 “$1” “$2” “$3” $* $@只有在用 “”包围起来引用的时候才有区别，否则看起来他们是一样的。 $# 参数个数 $? 退出状态 $- 验证shell是不是交互式的 Linux利用Cron定时任务编写脚本的注意 $$ 进程号。子shell() 中的时候，扩展为当前进程号而不是子shell进程号。 $! 最近在后台执行的命令退出状态。 $0 执行脚本名称 $_ 启动时，设置为启动shell的绝对路径，或者在执行环境或参数列表中所传递的待执行的shell脚本的绝对路径。随后，扩展为上一条命令的最后一个参数扩展后的值。还可设为每个已执行命令的绝对路径，这些路径是启动时指定的并且导入到命令的执行环境中。shell 扩展命令行被拆分成符号后要进行扩展，有七种方式： 大括号扩展 { } 波浪号扩展 ~引导 参数和变量扩展 $引导 命令替换 $( )或 算数扩展 $(( )) 单词拆分 文件名扩展扩展顺序为：大括号扩展、波浪号扩展、参数、变量和算术扩展、命令替换、单词拆分、文件名扩展。大括号扩展echo a&#123;a..z&#125;&#123;1..10&#125;becho a&#123;a,b,c,d&#125;b 波浪号（~） ~ $HOME的值 ~fred/foo 用户fred家目录下的foo目录 还有更多表示法，但是感觉不常用，所以没有进行说明。阅读的话参考手册 参数、变量扩展基本形式${ARG}。用以引导参数扩展、命令替换、算数扩展。以下的几种情况中，WORD要进行波浪号扩展、参数扩展、命令替换和算数扩展。也就说，WORD可以是：一个字符串、一个带波浪号的路径、一个变量、一串命令、一个算术表达式当不是进行字符扩展的时候，Bash测试ARG是否未设置或者为空;如果忽略了冒号，则只测试值是否设置。 ${ARG:-WORD} 如果就ARG没有设置或者为null，就扩展为WORD的值。 ${ARG:=WORD} 如果就ARG没有设置或者为null，扩展WORD值给ARG(ARG就会被设置)。位置参数和特殊参数不能这样操作。 ${ARG:?WORD} 如果就ARG没有设置或者为null，扩展WORD的值(如果没有设置WORD，给出意义差不多的信息)然后写到标准错误和shell，如果是在非交互模式下，退出shell。 ${ARG:+WORD} 如果就ARG没有设置或者为null，什么都不做。否则，就用WORD进行扩展。 ${ARG:OFFSET[:LENGTH]} 从ARG的OFFSET位置截取LENGTH个字符，LENGTH必须大于等于0。如果OFFSET小于0，那么就是从ARG值的结尾开始的偏移量(注意:和-号间要有一个空格)。如果ARG是@，那么就是从第OFFSET到第LENGTH个位置参数。如果ARG是以数组ARG[@]或ARG[*]，那么就是从第OFFSET位置开始的LENGTH个成员。除了位置参数的索引位置是从1开始外，字符串和数组都是从0开始的。 ${!PREFIX*} ${PREFIX@} ${!NAME[@]} $[!NAME[*]} ${&#35;ARG} 返回${ARG}的长度。如果ARG是@或*，那么返回位置参数的个数。如果是数组ARG[@]或ARG[*]，那么返回元素个数。 ${ARG&#35;WORD}${ARG&#35;&#35;WORD} 删除WORD模式从开始位置匹配的字符。WORD被扩展为一个模式，就跟文件名扩展一样。如果WORD模式与ARG扩展后的值开始部分匹配，那么#是最短匹配，##是最长匹配，然后删除匹配的字符。如果参数是#或*，扩展后得到的是位置参数列表。如果参数是带有下标#或*的数组，那么得到的是元素列表。 ${ARG%WORD} ${ARG%%WORD} 删除WORD模式从最后位置匹配的字符。WORD被扩展为一个模式，就跟文件名扩展一样。如果WORD模式与ARG扩展后的值结束部分匹配，那么%是最短匹配，%是最长匹配，然后删除匹配的字符。如果参数是#或*，扩展后得到的是位置参数列表。如果参数是带有下标#或*的数组，那么得到的是元素列表。 ${ARG/PATTERN/STRING} PATTERN产生一个类似文件名扩展的模式。将ARG的值扩展后最长匹配部分用STRING进行替换。如果PATTERN以/开始，那么所有匹配都会进行替换。如果PATTERN以#开始，那么从开始位置进行匹配。如果PATTERN以%开始，那么从结尾部分开始匹配。同样可以操作数组ary[*]或ary[@]。命令替换命令替换的形式类似 ( command ) `command` 其结果是命令的输出，并删除行尾换行符。命令替换形式$(cat filename)可以用效果等价但是速度更快的$(&lt; filename) 来替代。如果使用第二种格式，也就是使用了反引号。\\保留其本身含义，除非其后面的是$、`或\\。如果是$( command )中的所有字符组成命令，不会被特殊处理。 算术扩展算术替换类似 $(( expr )) 进程替换如果系统支持FIFO或以/dev/fd/N方式来命名打开的文件，就支持进程替换，基本格式是： &lt;(LIST) or &gt;(LIST) 注意：如果&gt;或&lt;与 (LIST)间有空格，则被认为是重定向。 这样进程 LIST运行时就会将其输入或输出与一个FIFO或文件/dev/fd/N相连接。例：ls -l &lt;(echo test)cat &lt;(echo test) 这样就了解echo test的输出与一个文件相关联，然后ll就去读取这个文件。执行一下看输出： lr-x——— 1 root root 64 12-09 09:52 /dev/fd/63 -&gt; pipe:[2215427]test 单词拆分shell会把扩展后的输入根据分割符IFS拆分一个个单词。用&quot;&quot;或&#39;&#39;明确指定的空白会进行保留。 文件名扩展单词拆分以后，shell会在每个单词内搜索字符*、?、[，除非打开了*-f选项。如果找到其中一个，就这个单词当作一个模式，并把与其匹配的文件名进行按字母排序来取代它。 * 匹配任何字符，包括空白。 ? 匹配单个字符。 […] 匹配方括号中的任一字符。还可以用[:type:]的POSIX形式来匹配。alnum 字母跟数字alpha 字母acsii 所有ASCII字符blank 所有空白字符cntrl 所有控制字符（ASCII中的20个字符）digit 数字graph 可显示字符（可打印，空格、退格无法显示）lower 小写字母print 可打印字符（非控制字符）punct 标点符号space 空格uperr 大写字母word 匹配单词里的字符（大小写字母、数字、下划线）xdigit 10进制字符（0-9 A-F）","categories":[{"name":"Shell","slug":"Shell","permalink":"https://gowa2017.github.io/categories/Shell/"}],"tags":[{"name":"编程","slug":"编程","permalink":"https://gowa2017.github.io/tags/编程/"},{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/tags/Linux/"},{"name":"Shell","slug":"Shell","permalink":"https://gowa2017.github.io/tags/Shell/"},{"name":"Bash","slug":"Bash","permalink":"https://gowa2017.github.io/tags/Bash/"}],"keywords":[{"name":"Shell","slug":"Shell","permalink":"https://gowa2017.github.io/categories/Shell/"}]},{"title":"AAA系统的报表生成脚本","slug":"AAA系统的报表生成脚本","date":"2016-12-07T03:29:32.000Z","updated":"2018-03-12T02:48:21.000Z","comments":true,"path":"Work/AAA系统的报表生成脚本.html","link":"","permalink":"https://gowa2017.github.io/Work/AAA系统的报表生成脚本.html","excerpt":"系统是利用定时任务部署脚本，调用sqlplus命令执行一系列的操作后生成报表的。分为日任务、周任务、月任务。","text":"系统是利用定时任务部署脚本，调用sqlplus命令执行一系列的操作后生成报表的。分为日任务、周任务、月任务。 定时任务的安排任务部署在lcimsdb2主机上，先看一下统计的任务列表 10 1 * * * sh /data1/lcims/tj/stat_sh/day_run.sh &gt;&gt; /data1/lcims/tj/log/stat.log.`date +\\%Y\\%m\\%d` 30 0 2 * * sh /data1/lcims/tj/stat_sh/month_run.sh &gt;&gt; /data1/lcims/tj/log/month.log.`date +\\%Y\\%m\\%d` 0 4 8 * * sh /data1/lcims/tj/stat_sh/month_downreason_run.sh &gt;&gt; /data1/lcims/tj/log/tmp.log.`date +\\%Y\\%m\\%d` 0 4 15 * * sh /data1/lcims/tj/stat_sh/month_downreason_run.sh &gt;&gt; /data1/lcims/tj/log/tmp.log.`date +\\%Y\\%m\\%d` 0 4 22 * * sh /data1/lcims/tj/stat_sh/month_downreason_run.sh &gt;&gt; /data1/lcims/tj/log/tmp.log.`date +\\%Y\\%m\\%d` 0 4 1 * * sh /data1/lcims/tj/stat_sh/month_downreason_run.sh &gt;&gt; /data1/lcims/tj/log/tmp.log.`date +\\%Y\\%m\\%d` 10 0 * * * sh /data1/lcims/tj/stat_sh/loginusernum.sh &gt;&gt; /data1/lcims/tj/log/loginusernum.log.`date +\\%Y\\%m\\%d` 20 0 1 * * sh /data1/lcims/tj/stat_sh/loginusernum_month.sh &gt;&gt; /data1/lcims/tj/log/loginusernum_month.log.`date +\\%Y\\%m\\%d` 0 6 * * * sh /data1/lcims/tj/stat_sh/tj_active_user.sh &gt;&gt; /data1/lcims/tj/log/tj_active_user.log 2&gt;&amp;1 day_run.sh 脚本工作流程：当前日期：20161207 获取昨天日期yesterday(20161206,yyyymmdd格式)。 客户统计 执行./customer_number.sh yesterday user pwd dblink 用户统计 执行./user_number.sh yesterday user pwd dblink 用户到达 执行./total_number.sh yesterday user pwd dblink 前天/昨天数据准备 执行./detail_tmp.sh yy mm dd user pwd dblink 按组别、属地统计周期内使用用户数、总次数、时长、费用、出入流量 执行./login user pwd dblink 分小时统计 执行./day_login.sh user pwd dblink 分段统计登录次数 执行./day_login_times.sh user pwd dblink 分段统计登录时长 执行./day_login_timelen.sh user pwd dblink 分小时统计在线数 执行./day_online.sh user pwd dblink 异常掉线统计 执行./downreason.sh user pwd dblink 周报表 执行./week_login.sh user pwd dblink WLAN统计 执行./day_run_wlan_tj_detail.sh user pwd dblink 其中数据比较大的就是 detail_tmp脚本，其工作流程是： TJ_DETAIL_TMP_B[efore] 表中删除 detdate小于yesterday - 2(20161206 - 2 = 20161204) 的记录（每次50000行） 将TJ_DETAIL_TMP_Y[esterday]表中数据插入到 TJ_DETAIL_TMP_B （当前存放的是5号的数据）。 truncate 表 TJ_DETAIL_TMP_Y。 将昨天（20161206）表 B_BROADBAND_DET12_`06`` 中的数据插入 TJ_DETAIL_TMP_Y 。 之后的几个统计脚本数据都基于表 TJ_DETAIL_TMP_B。","categories":[{"name":"Work","slug":"Work","permalink":"https://gowa2017.github.io/categories/Work/"}],"tags":[{"name":"Oracle","slug":"Oracle","permalink":"https://gowa2017.github.io/tags/Oracle/"},{"name":"Work","slug":"Work","permalink":"https://gowa2017.github.io/tags/Work/"}],"keywords":[{"name":"Work","slug":"Work","permalink":"https://gowa2017.github.io/categories/Work/"}]},{"title":"Bash编程参考-条件与循环","slug":"Bash编程参考-条件与循环","date":"2016-12-06T07:42:58.000Z","updated":"2018-03-20T15:56:33.000Z","comments":true,"path":"Shell/Bash编程参考-条件与循环.html","link":"","permalink":"https://gowa2017.github.io/Shell/Bash编程参考-条件与循环.html","excerpt":"一直以来都有在用sh进行自动化的任务部署，运维管理监控，但是一直没有系统的去看一下bash的参考手册。有的时候，写的脚本并不能达到的以为的结果，所以才萌生了从头到尾看一下参考手册并进行总结归纳的念头。条件与循环是每个编程语言、脚本语言，都不会缺少的语句，通过这些简单的语句，来实现复杂的逻辑，bash也不例外。","text":"一直以来都有在用sh进行自动化的任务部署，运维管理监控，但是一直没有系统的去看一下bash的参考手册。有的时候，写的脚本并不能达到的以为的结果，所以才萌生了从头到尾看一下参考手册并进行总结归纳的念头。条件与循环是每个编程语言、脚本语言，都不会缺少的语句，通过这些简单的语句，来实现复杂的逻辑，bash也不例外。 条件判断条件表达式（一元、二元）一般是通过[[、test、[命令使用的。一元表达式常用来测试文件状态，字符串操作符和数字比较操作符也是有的。对于符号链接，一般是其目标文件而不是链接本身。 逻辑判断 ! 非，取反的意思 ( expr ) 用来改变优先级。 expr1 -a expr2 与 expr1 -o expr2 或文件类型 -a file 文件是否存在？ -e file 文件是否存在(exist)，与-a等价）？ -b file 文件是否为块设备(block)？ -c file 文件是否为字符设备(char)？ -d file 文件是否目录(directory)？ -f file 文件是否常规文件(regular file)？ -h file 文件是否是符号链接？ -L file 文件是否是符号链接？ -p file 文件是否是管道(PIPO)？ -t fd 文件描述符fd是一个终端？ -S file 是套接字文件？ 文件状态 -r file 文件可读？ -w file 文件可写？ -x file 文件可执行？ -O file 当前用户的有效用户ID和文件的所有者ID是否一致？ -G file 当前用户的有效组ID和文件的组ID是否一致？ -N file 自上次访问后已被修改（文件访问时间小于修改时间）？ -s file 文件大小大于0？ -u file is setuid? -g file is setgid? -k file is sticky bit set? 字符 [-n] string string长度不为0？ -z string string长度为0？ string1 != string2 string1与string2不相等？ string1 &lt; string2 string1&lt;string2？（字典序） string1 &gt; string2 string1&gt;string2？（字典序） string1 == string2 string1 = string2 string1与string2相等？当与[[命令使用的时候，进行模式匹配。=应该与test命令一起用来兼容POSIX。[[ \"good\" == g* ]] &amp;&amp; echo true || echo false [ \"good\" == g* ] &amp;&amp; echo true || echo false 变量检查 -o arg shell选项arg enable？ -v arg 变量arg已设置（赋了一个值）？ -R arg 变量arg已设置（赋了一个值）且是一个name reference？ 算术比较 arg1 OP arg2 OP={-eq, -ne, -lt, -le, -gt, -ge}，分别代表{等于，不等于，小于，小于等于，大于，大于等于} 算术运算shell通过((命令，内建命令let、declare -i 进行求值。以0开始的值被当做八进制 解释，0x、0X开头的当做十六进制 解释。一般的值表示是[base#]n，base 从2到64间的一个，作为算数进制的基；如果省略了[base#] ，那么，就是10进制的。运算符的优先级、结合性、值和C语言一致。下面是一个由高至低的优先级排列，可以用( )来改变优先级。 运算符 说明 id++ id— 使用后自增/减 ++id —id 使用前自增/减 - + 正/负号 ! ~ 非 取反 ** 指数 * / % 乘 除 取余 + - 加 减 &lt;&lt; &gt;&gt; 按位左移/右移 &lt;= &gt;= &lt; &gt; 比较 == != 等于 不等于 &amp; 按位与 ^ 按位异或 &#124; 按位或 &amp;&amp; 逻辑与 &#124;&#124; 逻辑或 cond ? expr1 : expr2 条件运算 = *= /= %= += -= &lt;&lt;= &gt;&gt;= &amp;= ^= &#124;= 赋值 expr1, expr2 逗号运算 条件与循环语句循环语句bash的循环跟C语言类似，有until、while、for三种，其基本格式为：until condition; do cmd ...; donewhile condition; do cmd ...; donefor name [ [in [words ...] ] ; ] do cmd ...; donefor i; do echo $i; done #将会逐个输出位置参数 $1 $2 ...for (( expr1; expr2; expr3 )) ; do cmd ...; done 条件语句bash的条件语句有if、case、select、(( ))、[[ ]]。最简单的，当然是if。 ifif condition1; then cmd1 ...;[elif condition2; then cmd2 ...;][else cmd3 ...;]fi 对 condition 的不同形式请关注一下 Shell编程与C的一些不同 casecase word in [ [(] pattern [| pattern ...]) cmd ;; ] esac 通常用*来在最后表示默认动作。;;（只执行匹配后语句）可以用;&amp;（继续执行后面的语句）或;;&amp;（继续匹配后面的条件）结束[bash v4 才具有 ;&amp; ;;&amp;]。 selectselect你方便的生成菜单。select NAME [in WORDS ...]; do COMMANDS; doneselect sel in pwd date \"ifconfig -a\" \"ping www.baidu.com\"; do $sel; break; done (( … ))对算数表达式expr求值（bash特有，sh没有）。(( expr )) 与 let &quot;expr&quot;完全等价。 [[ … ]]对条件表达式求值（1 or 0）。 正则表达式任何出现在一个模式内的字符，除了下面提到的特殊字符，匹配其自身。NUL字符不应该出现在一个模式中。一个\\号会将下面的字符反引来匹配其自身。要匹配特殊模式字符，必须要进行引用。 * 匹配任何字符，包括 null 字符。 ? 匹配任意单个字符 [...] 匹配被包含字符中的一个。被连字符 - 连接起来的两个字符来就表示一个 RANGE EXPRESSION；这两个怎间的被排序，使用本地的排序和字符集进行匹配。如果在 [ 后的第一个字符是 ! 或 ^，表示不匹配其中字符。当连字符是第一个或最后一个字符的时候，其也会被匹配。] 在作为第一个字符的时候也会被匹配。比如，在默认的C语言环境中中，[a-dx-z] 等于 [abcdxyz]。很多语言以字典顺序排序字符，那么在这样的环境中 [a-dx-z] 并不等于 [abcdxyz]；有可能等于的是 [aBbCcDdxXyYz]。为了获得传统的范围解释，可以强制设置 LC_COLLATE, LC_ALL 环境变量为 C 来解决。在 [ 和 ] 中，字符类 可以用 [:CLASS:] 来指定，CLASS 是POSIX标准中指定的一种： alnum alpha ascii blank cntrl digit graphlower print punct space upper word xdigit word 类会匹配 字母，数字，以及 _。 如果 extglob shell 选项被 shopt 内建命令启用，几个扩展的模式匹配会被识别。在下面的描述中，一个 PATTERN-LIST 是一个表达式，或是多个以| 分隔的表达式。组合的模式，可能是被以下一个或多个子模式组成的： ?(PATTERN-LIST) 匹配0或1次给定模式*(PATTERN-LIST 匹配0或多次给定模式+(PATTERN-LIST) 匹配一次或多次给定模式@(PATTERN-LIST) 匹配一次给定模式!(PATTERN-LIST) 匹配给定模式之外的内容。 EREshell默认使用的是ERE，比如我的博客的文件名是用日期加上标题命名的，我想要匹配的话，就可以这样写： for f in `ls`; do if [[ $f =~ [0-9]&#123;4&#125;(-[0-9]&#123;2&#125;)&#123;2&#125;-* ]]; then echo $f fidone 另外，在[[ ]] 中，已经不用把表达式进行 “” 引用了","categories":[{"name":"Shell","slug":"Shell","permalink":"https://gowa2017.github.io/categories/Shell/"}],"tags":[{"name":"编程","slug":"编程","permalink":"https://gowa2017.github.io/tags/编程/"},{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/tags/Linux/"},{"name":"Shell","slug":"Shell","permalink":"https://gowa2017.github.io/tags/Shell/"},{"name":"Bash","slug":"Bash","permalink":"https://gowa2017.github.io/tags/Bash/"}],"keywords":[{"name":"Shell","slug":"Shell","permalink":"https://gowa2017.github.io/categories/Shell/"}]},{"title":"8086系CPU的内存寻址","slug":"8086系CPU的内存寻址","date":"2016-12-03T12:03:35.000Z","updated":"2018-03-12T02:48:21.000Z","comments":true,"path":"Device/8086系CPU的内存寻址.html","link":"","permalink":"https://gowa2017.github.io/Device/8086系CPU的内存寻址.html","excerpt":"大学时候，电子科学专业学过一门课程《微机技术原理与接口技术》，当时对里面的芯片介绍，汇编语言不甚明了，直至今日也不是很明白，恰好前几天看到Linux的内存分页机制的时候，回家把书捡起来看了一下，加深一下了解。","text":"大学时候，电子科学专业学过一门课程《微机技术原理与接口技术》，当时对里面的芯片介绍，汇编语言不甚明了，直至今日也不是很明白，恰好前几天看到Linux的内存分页机制的时候，回家把书捡起来看了一下，加深一下了解。 CPU的工作流程大体上来说，CPU是计算机中的大脑，负责从总线（BUS）读取数据，然后执行，最后得出结果通过总线输出。而其中各个流程的处理，分由不同的单元进行处理。 CPU的工作组成 总线接口部件BIU（Bus Interface Unit) 负责地址形成（把逻辑地址转换为物理地址）、取指令、指令队列、读/写操作数和总线控制。 其主要结构包含：16位的段寄存器（CS、DS、ES、SS）、指令指针寄存器（IP）、20位物理地址加法器、6字节指令队列、总线控制电路。 指令执行部件EU（Execution Unix) 负责将取指令队列中的指令进行译码后执行。 主要结构包含：16位的通用寄存器（AX、BX、CX、DX）、算数逻辑单元（ALU）、标志寄存器（flags，存放ALU的结果特征）、EU控制电路。 内存结构（Random Access Memory）我们常用的内存，不论是 静态存储器SRAM，还是 动态存储器DRAM，其结构都是一样的，由m个nbit的存储单元组成存储矩阵。比如，我们常用的内存最小单位是Byte，也就是8bit，一个单元。每次地址总线访问某个内存地址（物理地址）内的内容，都是一次性将这8bit数据读出来（其实是8个单元点路的电平情况，每个电路是0/1），那么就需要8条数据总线才能实现这个目的。而地址总线则限制了，CPU能进行物理寻址的范围是多大，8086是20位地址总线（其能寻址地址最大自然是2^20）、16位数据总线。如果我们的用8bit的存储单元来满足我们需要4GRAM的需求，那我们需要多少个存储单元组织在一起呢？4G=4\\*1024\\*1024\\*1024 bit=2^32 bit 所以需要2^29个存储单元。但很明显，20位地址总线并不能有效的利用这些内存，因为寻址范围不够。那么有没有什么手段或者技术能把它利用起来呢？很明显是有的，比如你在x86架构的CPU在LINUX上启用PAE的时候，就能寻址超过64GB的内存。不过这暂不在我们讨论的范围。 高速缓存存储器（Cache)CPU的时钟的周期是很短的，现在动不动就是GHz的频率。比如一个1GHz的CPU，其时钟周期（T状态），也就是1ns。CPU的工作过程就是执行指令的过程，每个指令周期（指令过程所需要的时钟周期数）是不同的，一般包含n（&gt;=1）个总线周期。每个总线周期即是BIU完成一次访问存储器或者I/O所需要的时间，包含n（&gt;=1）个T状态。而SRAM则快很多，当前已经有2ns的器件，但是其价格是非常昂贵的。其作用就是在CPU和RAM之间做一个缓存，每次CPU读取RAM数据的时候，就COPY一份到高速缓存（内存地址和内容）。下一次执行指令的时候就会看一下是不是地址在CACHE内有，有的话就直接读出而不访问RAM了。而DRAM的读取时间（从总线给出的有效地址，到数据读出）远达不到1ns（MOS一般在50ns-500ms），所以每个总线周期才会需要很多个T状态，这对CPU来说这一种很大的浪费。 寻址EU单元的内部寄存器都是16位，BIU的寄存器也是16位，其根本原因就是说，8086CPU的内部总线是16位的。其一次最多能传输2^16bit的数据，无论是地址，还是数据。因此其采用了段式内存管理。其最多能寻址的空间是2^16（64KB），所以每段就设置为这么大（这个是操作系统完成内存的分段？）。当程序载入的时候，就为其分配CS、DS、SS、ES，将每个段的段地址分别保存在CS、DS、SS、ES段寄存器内，这样加上一定的偏移量（Offset）就得到了逻辑地址：段选择符（Segment Selector)+偏移量（Offset）。然后BIU里面的物理地址加法器就会转将逻辑地址转换为物理地址：BaseAddr*16+Offset","categories":[{"name":"Device","slug":"Device","permalink":"https://gowa2017.github.io/categories/Device/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/tags/Linux/"},{"name":"CPU","slug":"CPU","permalink":"https://gowa2017.github.io/tags/CPU/"},{"name":"8086","slug":"8086","permalink":"https://gowa2017.github.io/tags/8086/"},{"name":"内存管理","slug":"内存管理","permalink":"https://gowa2017.github.io/tags/内存管理/"}],"keywords":[{"name":"Device","slug":"Device","permalink":"https://gowa2017.github.io/categories/Device/"}]},{"title":"Linux下的系统监控命令sar","slug":"Linux下的系统监控命令sar","date":"2016-12-01T09:06:28.000Z","updated":"2018-04-12T01:16:06.000Z","comments":true,"path":"Linux/Linux下的系统监控命令sar.html","link":"","permalink":"https://gowa2017.github.io/Linux/Linux下的系统监控命令sar.html","excerpt":"运维人员常用的命令如sar, vmstat, iostat等，各有千秋与侧中，不过sar是比较全的查看系统性能的命令了。对于CPU、磁盘、内存、IO的性能都能进行比较完整的监控并生成报表。对于自动化运维监控具有统一化的作用。","text":"运维人员常用的命令如sar, vmstat, iostat等，各有千秋与侧中，不过sar是比较全的查看系统性能的命令了。对于CPU、磁盘、内存、IO的性能都能进行比较完整的监控并生成报表。对于自动化运维监控具有统一化的作用。 简单介绍作者将代码开源在 sar官方地址。其实是一个系统状态工具集的集合。sar: 收集、报告或者保存系统活动信息。其基本命令形式如下：sar [options] [-A] [-o filename] [interval[count]] sar命令将操作系统中选定的累计活动计数器的内容写到标准输出。基于 count 和 interval 参数的值，记帐系统按指定次数(count)，以指定的时间间隔（interval，以秒为单位）写入信息。收集的数据也可以保存在由-o filename 标志指定的文件中。如果filename省略，那么就输出到每日的记录文件/var/log/sa/sadd。dd（01到31)代表某月的某一天。默认情况下数据是按天记录在里面的。可能你这个时候就会问了，那么，我平时都没有执行这个命令的时候，它的记录是怎么产生的呢，这就对了。其实sar不止它一个程序呢，还包括下面这些程序： sar 收集、报告或存储信息（CPU、内存、磁盘、中断、网卡、TTY、内核表等等） sadc 系统数据收集器，给sar做后台服务。 sa1 收记并存储二进制数据到每天的文件。这是设计来给cron执行一个sadc的前台程序。 sa2 生成总结报表。 sadf 以多种格式显示数据（CSV, XML, JSON, etc.），还可以用来生成SVG（Scalable Vector Graphics）图表，先理解一些概念虚拟内存(Virtual Memory)选项多的不说了，更多的介绍可以在你的系统上执行info sar命令查看。 -A 这选项等于 —bBdFHqrRSvwWy -I SUM -I XALL -m ALL -n ALL -r ALL -u ALL -P ALL -b 报告I/O和传输状态。 tps 每秒传输到物理设备的。一次传输就是一个I/O请求。多次逻辑的请求可以合并成一个物理I/O请求，每次传输的大小是不定的。 rtps 每秒向物理设备的读请求数。 wtps 每秒向物理设备的写请求数。 bread/s 每秒从设备读的block数。 bwrtn/s 每秒从设备写的block数。 -B 报告页状态，下面是会显示的值。 pgpgin/s 每秒从磁盘调入的内存页(KB)。 pgpgout/s 每秒从调出到磁盘的内存页(KB)。 fault/s 系统每秒产生的缺页(major+minor)。因为某些缺页不会产生I/O，所以这并不是一个对产生IO缺页的统计。 majflt/s 主要页错误。 -c 报告进程建立活动。 proc/s 每秒建立的进程数 -d 报告每个块设备的活动。在某些版本的内核下avgqu-sz, await, svctm, %util可能不可用，显示为0.00。 tps 每秒到设备的传输数。多个逻辑请求可以合并为一个物理I/O请求，每次请求的大小是不定的。 rd_sec/s 每秒读取的扇区（每扇区512b）数。 wr_sec/s 每秒写入的扇区数。 avgrq-sz 平均的请求扇区数。 avgqu-sz 平均的请求队列数。 await I/O请求的平均等待数(ms)。包括队列时间跟处理时间。 svctm 对I/O请求的平均处理时间。 %util 处理某个I/O请求花的CPU时间。这个值接进100%说明这设备已经饱和了。 -f filename 从-o filename创建的文件内获得记录。 -I {irq | ALL | SUM | XALL} 报告某一中断状态。irq是中断号。使用多个-I选项可以指定多个监控。SUM统计每秒中断数。ALL报告前16个中断。XALL报告所有中断。 -n { DEV | EDEV | NFS | NFSD | SOCK | ALL} 报告网络状态。指定DEV选项，以下值：IFACE 报告的网卡接口名。rxpck/s 每秒接收的报文数。txpck/s 每秒发送的报文数。rxbyt/s 每秒接收的比特数。txbyt/s 每秒发送的比特数。rxcmp/s 每秒接收的压缩比特数。（cslip等等）txcmp/s 每秒发送的压缩比特数。rxmcst/s 每秒接收的广播包数。指定EDEV选项，报告错误状态。IFACE 网卡名称。rxerr/s 每秒接收报文数。txerr/s 每秒发送报文数。coll/s 每秒传输过程中发生的碰撞数。rxdrop/s 因linux缓存空间不足，每秒丢弃的接收报文数。txdrop/s 因linux缓存空间不足，每秒丢弃的发送报文数。txcarr/s 每秒的传输错误数。（翻译不准确）rxfram/s 每秒接收报文帧错误数。rxfifo/s 接收报文每秒的FIFO溢出数。txfifo/s 发送报文每秒的FIFO溢出数。指定SOCK选项，报告sockets状态。totosck 使用的sockets总数tcpsck tcp使用的sockets数。udpsck udp使用的sockets数。rawsck raw使用的sockets数。ip-frag 当前IP分片数 -P { cpu | ALL } 报告CPU状态。ALL报告所有CPU状态。 -P 更友好的打印输出。与-d一起使用的时候，显示设备全明而不是类似 dev m-n这样，参看/etc/sysconfig/sysstat.ioconf文件。 -q 报告队列长度和负载。 run-qz 运行对列（等待允许的进程数）。 plist-sz 进程表中的进程和线程数。 ldavg-1 系统一分钟内负载。 ldavg-5 过去5分钟内负载。 ldavg-15 过去15分钟内负载。 -r 查看内存和交换分区使用情况 kbmemfree 空闲内存 kbmemused 已使用内存 %memused 已使用百分比 kbbuffers 内核用做缓冲区的大小。 kbcached 内核用来缓存数据的大小。 kbswpfree 空闲交换分区 kbswpused 交换分区使用 %swpused 交换分区使用率 kbswpcad 交换分区已缓存数据。 -R 报告内存状态。 frmpg/s 内核每秒释放的内核页数。一个负值说明内核正在占用内存。个页是4KB还是8KB取决于机器架构。 bufpg/s 内核每秒用来做缓冲的页数。 campg/s 内核每秒用来做缓存的页数。 -u CPU利用率。 %user 在用户级别（应用）执行使用的CPU。 %nice 在用户级别（应用）伴随nice优先级执行使用的CPU。 %system 在系统级别（内核）执行使用的CPU。 %iowait 在等待一个未完成I/O请求的CPU。 %steal 调度管理程序服务某一虚拟处理器的时候，其他处理器的等待时间 %idle 系统没有I/O请求的CPU百分比。 -v 报告i-node、文件、其他内核表情况。 dentunusd 目录缓存中没有使用的缓存项。 file-sz 未使用的文件handles inode-sz 未使用的i节点handles super-sz 内核分配的超级块handles %super-sz 已分配的超级块handles占linux最多能分配的百分比 dquot-sz 已分配的磁盘配额 rtsig-sz %rtsig-sz -w 报告系统切换活动。 cswch/s 每秒上下文切换总数 -W 交换分区情况。 pswpin/s 每秒进入swap的页 pswpout/s 每秒出去swap的页 -x { pid | SELF | ALL } 报告进程状态。此时-o、-f无限，最多报告256个。 minflt/s 此进程每秒产生的minor faults，这不需要从磁盘载入页到内存 majflt/s major faults，需要从磁盘载入页到内存。 %user 此程序在用户级别执行使用的CPU，不管有没有nice priorty %system 系统级别（内核）执行使用的CPU nswap/s 内核每秒交换出去的页数。 CPU 此进程在哪个CPU执行 -X { pid | SELF | ALL } 报告进程的子进程状态。此时-o、-f无限，最多报告256个。 cminflt/s 此进程子进程每秒产生的minor faults，这不需要从磁盘载入页到内存 cmajflt/s major faults，需要从磁盘载入页到内存。 %cuser 此程序在用户级别执行使用的CPU，不管有没有nice priorty %csystem 系统级别（内核）执行使用的CPU cnswap/s 内核每秒交换出去的页数。 -y 报告tty设备活动 rcvin/s 当前串行线每秒获得的中断数，串行线号由TTY列给出。 xmtin/s 当前串行线每秒非出的中断数，串行线号由TTY列给出。 framerr/s 当前串行线每秒发生的帧错误。 prtyerr/s 当前串行线每秒发生的奇偶(parity)错误。 brk/s 当前串行线每秒发生的break ovrun/s 每秒溢出 -e [hh:mm:ss] 报告的截止时间（24小时制），只配合-f、-o选项使用。 -s [hh:mm:ss] 报告的开始时间（24小时制），只配合-f、-o选项使用。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/tags/Linux/"},{"name":"监控","slug":"监控","permalink":"https://gowa2017.github.io/tags/监控/"},{"name":"sar","slug":"sar","permalink":"https://gowa2017.github.io/tags/sar/"}],"keywords":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}]},{"title":"Oracle的 exp/imp","slug":"Oracle的-exp-imp","date":"2016-11-30T08:23:24.000Z","updated":"2018-03-12T02:48:21.000Z","comments":true,"path":"Oracle/Oracle的-exp-imp.html","link":"","permalink":"https://gowa2017.github.io/Oracle/Oracle的-exp-imp.html","excerpt":"Oracle数据库的备份，可以通过物化视图，可以通过物理备份（需要关闭数据库），可以通过热备份（归档模式）等方式，但是如果数据量小的时候我可以通过导入/导出数据来进行备份，类似于mysqldump命令。","text":"Oracle数据库的备份，可以通过物化视图，可以通过物理备份（需要关闭数据库），可以通过热备份（归档模式）等方式，但是如果数据量小的时候我可以通过导入/导出数据来进行备份，类似于mysqldump命令。 前言exp/imp命令具有三种方式（级别）的导出，全库（FULL）、用户（OWNER）、表（TABLE） 完全（需要具有所有exp_full_database权限或者以特权用户sys/system） EXP SYSTEM/MANAGER BUFFER=34567 FILE=/backup/`date`.dmp DIRECT=y FULL=Y 用户（用户所有对象被导出） EXP SCOTT/TIGER BUFFER=34567 FILE=/backup/`date`-`id-un`.dmp DIRECT=y OWNER=SCOTT 表（用户的T1、T2表被导出） EXP SCOTT/TIGER BUFFER=34567 FILE=/backup/`date`-`id-un`.dmp DIRECT=y OWNER=SCOTT TABLES=(T1,T2) 上面的命令可以用 imp 进行替换。 direct=y：直接导出模式，数据直接从磁盘中读取到导出session的UGA中，跳过SQL命令处理层。避免了不必要的数据转换，然后将纪录返回给导出客户端，然后写到导出文件。跳过了SQL命令处理层表示DIRECT导出不支持QUERY选项。设置大的RECORDLENGTH值（最大64K）可以减少IO，加快速度。 exp命令格式EXP KEYWORD=value or KEYWORD=(value1,value2,...,valueN) 例子： EXP SCOTT/TIGER GRANTS=Y TABLES=(EMP,DEPT,MGR) or TABLES=(T1:P1,T1:P2) #if T1 is partitioned table 我们可以通过 exp help=y来看所有的选项 以下选项:USERID必须是第一个。 Keyword Description (Default) Keyword Description (Default) USERID username/password FULL export entire file (N) BUFFER size of data buffer OWNER list of owner usernames FILE output files (EXPDAT.DMP) TABLES list of table names COMPRESS import into one extent (Y) RECORDLENGTH length of IO record GRANTS export grants (Y) INCTYPE incremental export type INDEXES export indexes (Y) RECORD track incr. export (Y) DIRECT direct path (N) TRIGGERS export triggers (Y) LOG log file of screen output STATISTICS analyze objects (ESTIMATE) ROWS export data rows (Y) PARFILE parameter filename CONSISTENT cross-table consistency(N) CONSTRAINTS export constraints (Y) 更多选项： OBJECT_CONSISTENT transaction set to read only during object export (N)FEEDBACK display progress every x rows (0)FILESIZE maximum size of each dump fileFLASHBACK_SCN SCN used to set session snapshot back toFLASHBACK_TIME time used to get the SCN closest to the specified timeQUERY select clause used to export a subset of a tableRESUMABLE suspend when a space related error is encountered(N)RESUMABLE_NAME text string used to identify resumable statementRESUMABLE_TIMEOUT wait time for RESUMABLETTS_FULL_CHECK perform full or partial dependency check for TTSVOLSIZE number of bytes to write to each tape volumeTABLESPACES list of tablespaces to exportTRANSPORT_TABLESPACE export transportable tablespace metadata (N)TEMPLATE template name which invokes iAS mode export imp命令格式 IMP KEYWORD=value or KEYWORD=(value1,value2,...,valueN) 例子： IMP SCOTT/TIGER IGNORE=Y TABLES=(EMP,DEPT) FULL=N or TABLES=(T1:P1,T1:P2), #if T1 is partitioned table 以下选项:USERID必须是第一个。 Keyword Description (Default) Keyword Description (Default) USERID username/password FULL import entire file (N) BUFFER size of data buffer FROMUSER list of owner usernames FILE input files (EXPDAT.DMP) TOUSER list of usernames SHOW just list file contents (N) TABLES list of table names IGNORE ignore create errors (N) RECORDLENGTH length of IO record GRANTS import grants (Y) INCTYPE incremental import type INDEXES import indexes (Y) COMMIT commit array insert (N) ROWS import data rows (Y) PARFILE parameter filename LOG log file of screen output CONSTRAINTS import constraints (Y) 更多选项： DESTROY overwrite tablespace data file (N)INDEXFILE write table/index info to specified fileSKIP_UNUSABLE_INDEXES skip maintenance of unusable indexes (N)FEEDBACK display progress every x rows(0)TOID_NOVALIDATE skip validation of specified type idsFILESIZE maximum size of each dump fileSTATISTICS import precomputed statistics (always)RESUMABLE suspend when a space related error is encountered(N)RESUMABLE_NAME text string used to identify resumable statementRESUMABLE_TIMEOUT wait time for RESUMABLECOMPILE compile procedures, packages, and functions (Y)STREAMS_CONFIGURATION import streams general metadata (Y)STREAMS_INSTANTIATION import streams instantiation metadata (N)VOLSIZE number of bytes in file on each volume of a file on tape The following keywords only apply to transportable tablespaces TRANSPORT_TABLESPACE import transportable tablespace metadata (N)TABLESPACES tablespaces to be transported into databaseDATAFILES datafiles to be transported into databaseTTS_OWNERS users that own data in the transportable tablespace set","categories":[{"name":"Oracle","slug":"Oracle","permalink":"https://gowa2017.github.io/categories/Oracle/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://gowa2017.github.io/tags/数据库/"},{"name":"Oralce","slug":"Oralce","permalink":"https://gowa2017.github.io/tags/Oralce/"}],"keywords":[{"name":"Oracle","slug":"Oracle","permalink":"https://gowa2017.github.io/categories/Oracle/"}]},{"title":"Oracle的物化视图","slug":"Oracle的物化视图","date":"2016-11-30T03:51:07.000Z","updated":"2018-03-12T02:48:21.000Z","comments":true,"path":"Oracle/Oracle的物化视图.html","link":"","permalink":"https://gowa2017.github.io/Oracle/Oracle的物化视图.html","excerpt":"视图是对一系列包含一个或多个表或其他视图的数据的特定描述，一个视图像一个表一样响应一个查询。一个视图可以被视为一个虚拟表，或者一系列的查询，大多数能用表的地方，你也可以视图代替。视图并不需要存储数据，只需要存储其定义。同时我们不能定义触发器到视图，只能在基表（base table）上进行定义。","text":"视图是对一系列包含一个或多个表或其他视图的数据的特定描述，一个视图像一个表一样响应一个查询。一个视图可以被视为一个虚拟表，或者一系列的查询，大多数能用表的地方，你也可以视图代替。视图并不需要存储数据，只需要存储其定义。同时我们不能定义触发器到视图，只能在基表（base table）上进行定义。 一个例子staff视图从基表 employees而来，但是只包含了基表中的5列。 Materialized Views物化视图是一个可以用总结、结算、复制、分发数据的数据对象，用以存储一个查询的结果。这个查询在FROM语句后的可以是表、视图、或其他物化视图，我们把他们称做 主表(master tables，一个复制概念)或 detail tables（一个数据仓库概念）。为了一致，我们权且称之为 主表(master tables)，包含主表的数据库就叫 主库（master databases）。 为了向后兼容，建议使用snapshot，而不是 materialize view 出于复制的目的，物化视图允许你将远程数据库上的数据复制到本地。具有 高级复制(Advanced Replication) Materialized Views Log物化视图日志是一个用来关联物化视图与主表的表，用于物化视图的两种刷新方式： Fast(Incremental)与 Synchronous其与主表位于同一库的同一结构内，一个表只能用一个物化视图日志。 Refresh Materialized Views物化视图有三种更新方式： 快速（增量）、同步、完整刷新。 快速刷新：使用常规的物化视图日志，当DML语句更新主表的时候，物化视图日志会保存这些变化，并用来更新基于此表的物化视图。 同步刷新：使用一个特殊的物化视图日志staging log。DML对数据的改变会首先在staging log内进行描述，然后再用来更新主表及其物化视图。 完整刷新：用在没有物化视图日志的时候，比如你刚开始建立视图需要同步的时候。 快速刷新支持两种物化视图日志：timestamp-based和commit SCN-based。前一种方式在更新物化视图的时候需要更多的设置，后一种则不需要，因此会提高速度，默认情况下使用的是timestamp-based。已建立的视图无法用alter进行更改，只drop后重新建立。同步刷新只支持timestamp-based的staging log 用做复制备份的固化视图这里我们需要在LCIMS80BAK库内备份一些LCIMS80ZHU库内的一些表。 设置tnsnames.oraLCIMS80BAK = (DESCRIPTION = (ADDRESS_LIST = (ADDRESS = (PROTOCOL = TCP)(HOST = 10.168.24.61)(PORT = 1563)) ) (CONNECT_DATA = (SERVICE_NAME = LCIMS80) ) ) LCIMS80ZHU = (DESCRIPTION = (ADDRESS_LIST = (ADDRESS = (PROTOCOL = TCP)(HOST = 10.25.100.17)(PORT = 1521)) ) (CONNECT_DATA = (SERVICE_NAME = LCIMS80) ) 创建database linkcreate database link LCIMS80_GZ_dblinkconnect to absadmin identified by imsadmin32USING 'LCIMS80ZHU';commit; 创建物化视图CREATE MATERIALIZED VIEW m_customerON PREBUILT TABLE REFRESH FORCE WITH PRIMARY KEY AS SELECT * FROM m_customer@LCIMS80_GZ_DBLINK; 创建物化视图日志（LCIMS80ZHU）CREATE MATERIALIZED VIEW LOG ON m_customer WITH ROWID; 进行完整刷新sqlplus absadmin/imsadmin61@LCIMS80BAK &lt;&lt;! exec dbms_mview.refresh(&#39;M_CUSTOMER&#39;,&#39;C&#39;) quit ！ 定时任务进行增量刷新sqlplus absadmin/imsadmin61@LCIMS80BAK &lt;&lt;! exec dbms_mview.refresh(&#39;M_CUSTOMER$,&#39;F&#39;) quit ！ 补充使用查看物化视图及日志SELECT * FROM DBA_MVIEWS;SELECT * FROM DBA_MVIEW_LOGS;","categories":[{"name":"Oracle","slug":"Oracle","permalink":"https://gowa2017.github.io/categories/Oracle/"}],"tags":[{"name":"Oracle","slug":"Oracle","permalink":"https://gowa2017.github.io/tags/Oracle/"},{"name":"视图","slug":"视图","permalink":"https://gowa2017.github.io/tags/视图/"}],"keywords":[{"name":"Oracle","slug":"Oracle","permalink":"https://gowa2017.github.io/categories/Oracle/"}]},{"title":"Oracle数据库的当前Redo Log","slug":"Oracle数据库的当前Redo-Log","date":"2016-11-30T02:01:38.000Z","updated":"2018-03-12T02:48:21.000Z","comments":true,"path":"Oracle/Oracle数据库的当前Redo-Log.html","link":"","permalink":"https://gowa2017.github.io/Oracle/Oracle数据库的当前Redo-Log.html","excerpt":"Online Redo Log（常常简称为Redo Log，有别于 Archived Redo Log），是重建数据库（恢复、重新设置）最重要的文件，记录了所有数据库的改变。一般情况下一个数据库，只有一个Redo Thread，但在 RAC 环境下，每个实例具有自己的Redo Thread，用以避免对Redo Log的竞争，及潜在的性能瓶颈。","text":"Online Redo Log（常常简称为Redo Log，有别于 Archived Redo Log），是重建数据库（恢复、重新设置）最重要的文件，记录了所有数据库的改变。一般情况下一个数据库，只有一个Redo Thread，但在 RAC 环境下，每个实例具有自己的Redo Thread，用以避免对Redo Log的竞争，及潜在的性能瓶颈。 Redo Log ContentsRedo Log Files存储着一系列的redo records(redo entrys)。一个redo record由一组change vectors组成，每个change vector记录了数据库中一个block的所做的改变。举例来说，你在一个表emp中改变了一个salary的值，就会产生一个redo record包括描述了emp表的data segment block，undo segment block，和undo segment中事务表的变化。redo entry记录了你能用来重建数据库的数据，包括undo segments。因此，redo log同时也保护rollback data。 怎么写入Redo LogRedo Log包含两个或多个文件，用来保证始终有一个可写，其他的用来archived归档（在数据库是 ARCHIVELOG 模式）。LGWR循环写入Redo Log Files，当前使用的文件写满后，就会向下一个可用的文件进行写入，当最后一个写满了，就回到第一开始写。写满了的文件是否可重用，取决于数据库是否启用archiving。 archiving未启用（ NOARCHIVELOG模式），当其中记录的数据变化已经写入datafile。 archiving启用（ ARCHIVELOG 模式），需要其中记录的数据变化已写入datafile同时此文件已归档archived。 Active(Current)和InActive Redo Log FilesLGWR只会将redo logo buffer（SGA）中的redo records写到一个文件，LGWR当前正在写的文件就叫做 Current redo log file。实例需要用来进行恢复的就叫做 ACTIVE redo log file，不再需要的就叫做 INACTIVE redo log file。如果启动了archiving（ ARCHIVELOG模式），数据库只有重用或者写入一个 ACTIVE 文件直到 归档进程(ARCn)已经归档其中内容。如果没有启动archiving（ NOARCHIVELOG模式），当最后一个redo log file写满，就会使用第一个 ACTIVE的文件进行写入。 Log Switchs和Log Sequence Numberslog switch 是指数据库停止写入当前文件，而开始写另外一个。通常是当前文件已经完全写满的时候，当然我们可以手动进行切换。数据库会分配一个 log sequence number 在发生 log switch LGWR开始写入的时候。归档的时候会保留这个 log sequence number。每个 (online | archive) redo log 就是通过 log sequence number来识别唯一性。 Multiplexing Redo Log Files通过建立group，LGWR会将同样的数据写到组中的所有成员，这能有效的避免单点故障。组中的成员要具有相同的大小，放在不同的硬盘上最好，当然放在同一硬盘也是可以的，至少可以避免 I/O错误，文件错误 等等。当LGWR无法写入组中一个成员的时候，数据库会将此成员标注为INVALID，并且些一个错误信息到LGWR的trace file和数据库的alert log。大多数情况下，group应该是对称的，就是说具有相同的成员，但你也可以弄来不这样。不过，你必须拥有最少两个以上的group否则就是一个错误的配置。 创建组 ALTER DATABASE ADD LOGFILE [GROUP 10] (‘/oracle/dbs/log1c.rdo’, ‘/oracle/dbs/log2c.rdo’) SIZE 500K; group number是可选的，当你指定的时候，只能按递增的顺序。 添加成员有时候，组已经建立，只是有的成员可能挂掉了，那么你需要向当前组添加新的成员。 ALTER DATABASE ADD LOGFILE MEMBER ‘/oracle/dbs/log2b.rdo’ TO GROUP 2; 更多参考参阅Oracle Administartor’s Guide","categories":[{"name":"Oracle","slug":"Oracle","permalink":"https://gowa2017.github.io/categories/Oracle/"}],"tags":[{"name":"Oracle","slug":"Oracle","permalink":"https://gowa2017.github.io/tags/Oracle/"},{"name":"数据库","slug":"数据库","permalink":"https://gowa2017.github.io/tags/数据库/"}],"keywords":[{"name":"Oracle","slug":"Oracle","permalink":"https://gowa2017.github.io/categories/Oracle/"}]},{"title":"Oracle常用sql","slug":"Oracle常用sql","date":"2016-11-29T02:24:33.000Z","updated":"2018-03-12T02:48:21.000Z","comments":true,"path":"Oracle/Oracle常用sql.html","link":"","permalink":"https://gowa2017.github.io/Oracle/Oracle常用sql.html","excerpt":"主要是工作记录需要应用到的时候进行了一下记录，包括会话、session、锁等的查询。","text":"主要是工作记录需要应用到的时候进行了一下记录，包括会话、session、锁等的查询。 查询应用、连接数SELECT B.PROGRAM , COUNT(1) FROM V$PROCESS A, V$SESSION B WHERE A.ADDR = B.PADDR AND B.USERNAME IS NOT NULL GROUP BY B.PROGRAM; 历史最大会话数：SELECT SESSIONS_MAX,SESSIONS_WARNING,SESSIONS_CURRENT,SESSIONS_HIGHWATER FROM v$license; 查看session参数SELECT NAME, TYPE, VALUE FROM V$PARAMETER WHERE NAME LIKE &#39;session%&#39;; 查询被锁的表并释放sessionSELECT A.OWNER ,A.OBJECT_NAME ,B.XIDUSN ,B.XIDSLOT ,B.XIDSQN ,B.SESSION_ID ,B.ORACLE_USERNAME ,B.OS_USER_NAME ,B.PROCESS ,B.LOCKED_MODE ,C.MACHINE ,C.STATUS ,C.SERVER ,C.SID ,C.SERIAL# ,C.PROGRAM FROM ALL_OBJECTS A,V$LOCKED_OBJECT B,SYS.GV_$SESSION C WHERE A.OBJECT_ID = B.OBJECT_ID AND B.PROCESS = C.PROCESS ORDER BY 1,2; 查看系统IO较大的sessionSELECT se.sid ,se.serial# ,pr.spid ,se.username ,se.status ,se.terminal ,se.program ,se.module ,se.sql_address ,st.event ,st.p1text ,si.physical_reads ,si.block_changes FROM v$session se,v$session_wait st,v$sess_io si,v$process pr WHERE st.sid=se.sid AND st.sid=si.sid AND se.paddr=pr.ADDR AND se.sid&gt;6 AND st.wait_time=0 AND st.event NOT LIKE &#39;%SQL%&#39; ORDER BY physical_reads DESC; 查询消耗cpu较多的sessionselect a.sid ,spid ,status ,substr(a.program,1,40) prog ,a.terminal ,osuser ,value/60/100 value from v$session a,v$process b,v$sesstat c where c.statistic#=12 and c.sid=a.sid and a.paddr=b.addr order by value desc","categories":[{"name":"Oracle","slug":"Oracle","permalink":"https://gowa2017.github.io/categories/Oracle/"}],"tags":[{"name":"Oracle","slug":"Oracle","permalink":"https://gowa2017.github.io/tags/Oracle/"},{"name":"数据库","slug":"数据库","permalink":"https://gowa2017.github.io/tags/数据库/"}],"keywords":[{"name":"Oracle","slug":"Oracle","permalink":"https://gowa2017.github.io/categories/Oracle/"}]},{"title":"Linux利用Cron定时任务编写脚本的注意","slug":"Linux利用Cron定时任务编写脚本的注意","date":"2016-11-28T09:12:27.000Z","updated":"2018-03-12T02:48:21.000Z","comments":true,"path":"Linux/Linux利用Cron定时任务编写脚本的注意.html","link":"","permalink":"https://gowa2017.github.io/Linux/Linux利用Cron定时任务编写脚本的注意.html","excerpt":"设置了一个监控数据库的任务脚本，手动执行一切正常，但是，设置定时任务以后，总是不能获得正确的结果，而且没有设置一个输出日志，最后，经过了多次测试得出了结果。","text":"设置了一个监控数据库的任务脚本，手动执行一切正常，但是，设置定时任务以后，总是不能获得正确的结果，而且没有设置一个输出日志，最后，经过了多次测试得出了结果。 Interactive Shell从行为上讲，交互式即说的是启动一个shell，等待你的输入，然后给你反应这样。交互式shell(Interactive Shell)指的不带non-option参数启动，或以-i选项启动，所有的输出输入错误都会发送到Terminals。-s选项可以用来设置positional parameters($1 $2)。可以通过$-来判断当前是否是交互式shell。 case &quot;$-&quot; in *i*) echo This shell is interactive ;; *) echo This shell is not interactive ;; esac 可选的，启动脚本还会测试$PS1， if [ -z &quot;$PS1&quot; ]; then echo This shell is not interactive else echo This shell is interactive fi 而非交互式的就是，你启动shell执行一定的操作，但是并不与你进行交互。例如，当我们以sh cmdfile执行脚本的时候，是以non-interactive执行的。我们可以将上述两段代码放在一个脚本里面进行测试，看看输出是什么。 Login Shell我们把需要进行登录流程验证后启动的shell称做Login Shell，而不需要验证的就叫non-Login Shell，如sh启动shell执行的脚本，在X11桌面下启动的终端。当前shell是non-interactive时，-l和--login选项执行会启动一个login shell并执行启动文件。 配置文件的读取交互式login shell或非交互式shell--login当Bash以交互式login shell或非交互式shell以--login选项启动的时候，首先会执行/etc/profile的命令，然后执行~/.bash_profile、~/.bash_login、~/.profile，可以用--noprofile选项禁止此行为，三个文件中，找到一个执行即返回。当已登录shell退出时，执行~/.bash_logout文件。 strace bash -l test.sh 的输出可以说明，-l选项确实会执行此一流程。交互式non-login shellnon-login shell不用进行完整的登录流程认证，其首先执行~/.bashrc（可以用--norc禁止），--rcfile FILE选项强制shell读取FILE配置进行执行。常规地，~/.bash_profile会包含类似的行: if [ -f ~/.bashrc ]; then . ~/.bashrc; fi 以保证login shell与non login shell具有相同的环境变量。我们可以试试注释掉 ~/.bash_profile中的 上述代码，然后在~/.bashrc加入export TST=/www/tst，之后用 echo “echo $TST” &gt;&gt; tst.sh bash -i tst.sh看看发生了什么，去掉-i又发生了什么，我们用sh代替bash又发生了什么。非交互式shell执行以下命令的时候 if [ -n &quot;$BASH_ENV&quot; ]; then . &quot;$BASH_ENV&quot;; fi PATH变量不会被用来寻找$BASH_ENV文件。以sh启动shell当以sh启动bash的时候，只会读取/etc/profile、~/.profile两个文件，同样可以用--noprofile进行禁止，当交互式执行sh的时候，Bash寻找变量ENV（如果有定义），并执行其值。--rcfile将不会起作用。读取完这些文件后，bash进入POSIX模式。以sh启动非交互式shell的时候，不会读取其他启动文件。 变量是会继承的因为linux是以fork-and-exec进行执行shell所以会共享环境变量。 cron的环境变量启动任务的时候，有自己的环境变量，在/etc/crontab下，不会读取其他启动文件，所以获得不了正确的环境变量。所以获得不了正确的结果。同时是以non-interactive和non-login-shell执行的，所以不会执行~/.bashrc。 source命令事实上 source命令等于.，比如：source filename与 . filename是等价的。其作用是在当前的环境下读取并执行脚本后返回。如果filename不包含/，那么就用PATH变量中进行寻找命令，且不用具有x权限。在POSIX模式下，如果PATH中找不到，则会寻找当前目录。 文件内容的读取/etc/profile在用户登录系统的时候，会执行/etc/profile脚本，其作用是此会导出一系列变量： export PATH USER LOGNAME MAIL HOSTNAME HISTSIZE INPUTRC 并会执行/etc/profile.d/目录下的脚本文件:for i in /etc/profile.d/*.sh ; do if [ -r &quot;$i&quot; ]; then if [ &quot;$&#123;-#*i&#125;&quot; != &quot;$-&quot; ]; then . $i else . $i &gt;/dev/null 2&gt;&amp;1 fi fidone 包括的脚本为：/etc/profile.d/colorls.sh/etc/profile.d/cvs.sh/etc/profile.d/glib2.sh/etc/profile.d/krb5-devel.sh/etc/profile.d/krb5-workstation.sh/etc/profile.d/lang.sh/etc/profile.d/less.sh/etc/profile.d/vim.sh/etc/profile.d/which-2.sh","categories":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/tags/Linux/"},{"name":"Shell","slug":"Shell","permalink":"https://gowa2017.github.io/tags/Shell/"},{"name":"Cron","slug":"Cron","permalink":"https://gowa2017.github.io/tags/Cron/"}],"keywords":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}]},{"title":"How SED works","slug":"How-SED-works","date":"2016-11-24T07:18:22.000Z","updated":"2018-03-12T02:48:06.000Z","comments":true,"path":"SED-AWK/How-SED-works.html","link":"","permalink":"https://gowa2017.github.io/SED-AWK/How-SED-works.html","excerpt":"Linux下三大神器之一的sed，为你处理字符，批量替换，提供了超级效率的操作方法。sed是面向流(stream)，更确切的说是字符流，以行为单位进行操作。循环直至结束。","text":"Linux下三大神器之一的sed，为你处理字符，批量替换，提供了超级效率的操作方法。sed是面向流(stream)，更确切的说是字符流，以行为单位进行操作。循环直至结束。 工作机制sed 使用了两个数据缓存器 活动的 pattern space, 辅助的 hold space 。其刚开始命令的时候都是空的。sed 按以下循环进行工作: sed读取输入文件的一行，移除尾部的换行符，然后放入pattern_space。 执行命令。每个命令都可以指定执行的位置。 执行完毕后，如果没有打开-n选项就会将 pattern space 内容进行输出，并加上删除掉的换行符。 回到 [1.] 处理完一行，通常(某些情况我们可以使它保留)是将 pattern_space 清空，但并不清空 hold_space。对于每一个命令，我们都可以给它指定执行的范围（某一行，或，某一范围）。 理解 sed 每次只会读取输入的一行到缓冲区，对与理解 n 和N命令非常有用。 命令格式通常情况下我们是这样使用sed的： sed OPTIONS... [SCRIPT] [INPUTFILE...] OptionsOPTIONS可以说如下值[多个] --help 帮助--version 版本信息-n --quiet --silent 默认情况下，完成一行的处理后，sed默认打印pattern space的内容，此选项将关闭默认打印。-e SCRIPT --expression=SCRIPT 指定执行的命令，可以多次使用。当然，也可以用{}进行分组指定。-f SCRIPT-file --file=SCRIPT-file 在文件中指定执行命令。-i 直接修改输出到文件，而不是到标准输出-l N | --line-length=N 指定l命令换行的长度。长度为0表明从不换行，如果没有指定的话，值就是70。-b --binary 当操作系统区别文本文件和二进制文件的时候有用。--follow-symlinks 指定-i选项的时候，如果输入文件是一个符号链接则会跟随链接到文件。默认情况是不跟随。-E | -r | --regexp-extend 扩展正则表达式。-u | --unbufferd 尽量少的缓存输入和输入。(当用tail -f作为输入的时候，这个选项可以让你尽快的看到结果) 退出状态 0 success 1 Invalid command 2 One or more input file specified could not be opend 4 An I/O error。 范围的指定我们可以指定动作执行的范围（文件中的哪些行），及需要执行的命令（ pattern_space )上执行。number 一个确切的数字，指定某行$ 最后一行first~step first=起始 step=步长，想取奇数行就用 1~2,每五行就用 1~5。 GNU SED扩展/regexp/ 满足正则表达式的行。如果正则表达式内包含/，需要使用\\进行转义。\\%regexp% 为了避免上面那样的反引，你可以用任何一个符号来代替%。/regexp/I \\%regexp%I 以大小写不敏感的方式来匹配正则式。 GNU 扩展/regexp/M \\%regexp%M 多行模式匹配正则式。这个时候^表示其前有一个换行，$表示其后跟随一个换行。 GNU扩展ADDR1,+N ADDR1及其后的N行。 GNU 扩展ADDR1,~N 找到ADDR1后的，继续匹配直到是N的倍数的行。 注意与first~step区别,这条是匹配到了就不继续匹配了,而first-step是匹配到结束。 GNU 扩展! 跟随在一个地址范围后，其意义是就是不匹配地址范围表达式的才会被选择。 GNU扩展 常用的命令# 注释q [EXIT-CODE] 只接受一个地址范围参数，打印当前 pattern_ space 后退出，并返回退出码。 GNU扩展d 删除当前 pattern_ space，立即开始处理下一行，不会继续执行之后的命令。 seq 3 | sed 2d seq 3 | sed D 如果 pattern_ space 没有 换行符，等同于d命令。否则，将 pattern_ space 内容删除到第一个换行符为止，然后重新在 pattern_ space 上执行命令,并不会读入下一行到 pattern_ space。p 打印当前 pattern_ space 到标准输出，一般跟 -n选项配合使用 seq 3 | sed -n 2p P 打印 pattern_ space 到出现第一个换行符的位置n 如果自动打印没有被-n关闭，此命令会打印当前 pattern_ space， 然后把内容替换为下一行，如果没有输入了，就停止执行命令。这个命令对于跳过某些行非常有用，比如处理每 Nth行。 seq 6 | sed &#39;n;n;s/./x/&#39; N 给 pattern_ space 添加一个换行符 同时将下一行的输入读进来。如果没有输入，不执行命令即退出。{commands} 一连串命令集合，以’;’分割开的多条命令，在 pattern_ space 上执行。 GNU特性 seq 3 | sed -n &#39;2{s/2/X/ ; p} s 替换命令命令原型: s/REGEXP/REPLACEMENT/FLAGS /号同样可以用 其他符号代替，如:# % 等等避免/需要用转义工作流程是用REGEXP匹配 pattern_ space 如果成功，就用REPLACEMENT替换。REGEXP 可以用 ‘(‘ ‘)‘进行分组，在REPLACEMENT，可以用 \\1..9 进行引用，&amp;代表整个匹配的内容 在 GNU扩展 内 你还用一组’\\’跟’L’,’l’,’U’,’u’,’E’ 组成的序列。但这些并不常用。\\L 将REPLACEMENT变换为小写，直到 \\U or \\E出现。\\l 将REPLACEMENT中的下一个字符转变为小写.\\U 将REPLACEMENT变换为大写，直到 \\L or \\E出现。\\u 将REPLACEMENT中的下一个字符转变为大写.\\E 在REPLACEMENT中结束\\L,\\U的作用。 FLAGS：g 替换 pattern_ space 内所有匹配的位置。不加此标志，只替换第一次匹配的位置NUMBER 替换 pattern_ space 内第NUMBER匹配位置。（POSIX内并 没有定义 NUMBER 与g一起使用会是什么情况，GNU内，则表示从第NUMBER到最后一个匹配的位置)w FILENAME 如果s命令成功执行，将输出写到文件内。GNU扩展 支持使用/dev/stdout /dev/stderre 如果s命令匹配成功，在 pattern_ space 内的内容将会被当作命令执行，同时 pattern_ space被替换为命令的输出。 GNU 扩展p 打印出匹配后的 pattern_ space。同时指定ep 或pe 效果是不一样的。pe将会打印找到的命令，然后打印e输出，ep只是打印e的输出I,i 以大小写不敏感的方式来匹配正则式。GNU 扩展M,m 多行模式匹配正则式。这个时候^表示其前有一个换行，$表示其后跟随一个换行。GNU扩展 y 命令y/SOURCE_CHARS/DEST-CHARS/ 逐个替换为对应位置的字符比如 y/abc/ABC/ 凡 a被替换为A b替换为B 其他命令a\\TEXT (append)在当前循环输出后面加上TEXT。如果你用-n命令关闭了打印的话，则只打印TEXT。 seq 3 | sed &#39;2a\\hello&#39; i\\TEXT (insert)在当前输出前加上TEXT。 seq 3 | sed &#39;2i\\hello&#39; c\\TEXT 删除 pattern_ space 打印TEXT seq 3 | sed &#39;2c\\hello&#39; = 打印当前输入的是第几行，后面跟随一个换行符l N 清晰的模式打印 pattern_ space ，N是行宽，中文全变成\\232 \\245这样的的了。行尾加上$r FILENAME 读取文件到当前循环的输出流后。文件名不存在也没事，就当读了个空。 GNU扩展支持 /dev/stdin seq 3 | sed &#39;2r/etc/passwd&#39; w FILENAME 将 pattern_ space 写到文件。 GNU扩展支持/dev/stderr /dev/stdout 文件将被创建（当不存在）或被截短（当已存在），在没有读入行之前。所有w指令(包括s成功执行的w标志)不会关闭或者重新打开文件（提高效率） seq 3 | sed &#39;2woutfile&#39; h 用 pattern_ space 的内容替换 hold_ spaceH 在 hold_ space 后加一个换行符 同时把 pattern_ space 的内容copy 过来g 用 hold_ space 的内容替换 pattern_ space的内容G 在 pattern_ space 后加一个换行符 同时把 hold_ space 的内容copy 过来x 交换 pattern_ space 和 hold_ space的内容: LABEL 设置个标签b LABEL 无条件跳往 LABEL标签。下一循环开始的时候，将会忽略这个标签t LABEL s成功执行后跳转到LABEL标签 标签使用&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD标签主要使用 :, t, b三个命令实现的，分别是 设置标签，替换成功后跳转，无条件跳转三个意思。 ======= 7fa33ff02a6d163b73353e437388e527d9d7fefe使用标签可以让我们进入大师的行列。我们要明白的是，我们设置的标签，只是在当前的buffer内执行动作。比如，我们要给 123456789 加上千分号，变成 123,456,789这样： sed -e :a -e 's/\\(.*[0-9]\\)\\([0-9]\\&#123;3\\&#125;\\)/\\1,\\2/;ta' file 这先执行一个标签，然后匹配 pattern_space中的内容并进行替换，如果替换成功了，就跳转到标签，继续进行替换。有点类似 while循环的意思。 居中 我们可以以79个字符为宽度把文本居中： sed -e :a -e 's/^.\\&#123;1,77\\&#125;/ &amp; /'","categories":[{"name":"SED&AWK","slug":"SED-AWK","permalink":"https://gowa2017.github.io/categories/SED-AWK/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/tags/Linux/"},{"name":"SED","slug":"SED","permalink":"https://gowa2017.github.io/tags/SED/"}],"keywords":[{"name":"SED&AWK","slug":"SED-AWK","permalink":"https://gowa2017.github.io/categories/SED-AWK/"}]},{"title":"Basic RegEx与Extend RegEx","slug":"Basic-RegEx与Extend-RegEx","date":"2016-11-24T06:17:21.000Z","updated":"2018-03-12T02:48:21.000Z","comments":true,"path":"编程/Basic-RegEx与Extend-RegEx.html","link":"","permalink":"https://gowa2017.github.io/编程/Basic-RegEx与Extend-RegEx.html","excerpt":"当我们使用sed/awk/grep的时候，必然会用到的就是正则表达式，对与我们选取与操作字符串非常的有用。但却有两种比较常见的表达式，BRE(Basic RegEx)和ERE(Extent RegEx)，这其中确有些不同。","text":"当我们使用sed/awk/grep的时候，必然会用到的就是正则表达式，对与我们选取与操作字符串非常的有用。但却有两种比较常见的表达式，BRE(Basic RegEx)和ERE(Extent RegEx)，这其中确有些不同。 不同在GNU上来说，BRE与ERE的不同在于几个元字符的意义 不同 ：?, +, (), {}, |。BRE 要求在这几个字符加上 \\ 才能表示特殊意义，否则就匹配其自己，而在ERE中，匹配其自己需要用\\转义。 \\| 是一个GNU扩展，BRE并不提供这个功能。 Linux中，SED(通过-r/-E支持ERE)、VIM、GREP（通过-E选项支持ERE)使用的是BRE，GAWK使用的是ERE。 BRECHAR 匹配指定字符。. 匹配任意一个字符。^ 匹配行首非空字符。$ 匹配行尾非空字符。[LIST] [^LIST] 匹配/不匹配指定字符。(REGEXP1 | REGEXP2) 匹配REGEXP1或REGEXP2。 GNU扩展REGEXP1REGEXP2 匹配两个连续的RegEx。\\n 换行符\\CHAR 转义字符。$, *, ., \\, ^* 匹配任意次数。\\+ 匹配&gt;=1次。\\? 匹配0或1次。\\{I\\} 匹配I次。\\{I,J\\} 匹配I&lt;=N&lt;=J次。\\{I,\\} 匹配I &lt;= N次。\\(REGEXP\\) 分组，用[1-9]引用。\\DIGIT 匹配上面的分组 ERE. 匹配任意一个字符。CHAR 匹配指定字符。^ 匹配行首非空字符。$ 匹配行尾非空字符。[LIST] [^LIST] 匹配/不匹配指定字符。(REGEXP1 | REGEXP2) 匹配REGEXP1或REGEXP2。 GNU扩展REGEXP1REGEXP2 匹配两个连续的RegEx。\\n 换行符\\CHAR 转义字符。$, *, ., \\, ^* 匹配任意次数。+ 匹配&gt;=1次。? 匹配0或1次。{I} 匹配I次。{I,J} 匹配I&lt;=N&lt;=J次。{I,} 匹配I &lt;= N次。{,J} 匹配N &lt;= J次。 GNU特性\\(REGEXP\\) 分组，用[1-9]引用。\\DIGIT 匹配上面的分组","categories":[{"name":"编程","slug":"编程","permalink":"https://gowa2017.github.io/categories/编程/"}],"tags":[{"name":"RegEx","slug":"RegEx","permalink":"https://gowa2017.github.io/tags/RegEx/"},{"name":"正则表达式","slug":"正则表达式","permalink":"https://gowa2017.github.io/tags/正则表达式/"},{"name":"POSIX","slug":"POSIX","permalink":"https://gowa2017.github.io/tags/POSIX/"}],"keywords":[{"name":"编程","slug":"编程","permalink":"https://gowa2017.github.io/categories/编程/"}]},{"title":"OSPF协议及其配置实现","slug":"OSPF协议及其配置实现","date":"2016-11-23T01:17:29.000Z","updated":"2018-03-12T02:48:21.000Z","comments":true,"path":"Network/OSPF协议及其配置实现.html","link":"","permalink":"https://gowa2017.github.io/Network/OSPF协议及其配置实现.html","excerpt":"简介OSPF(Open Shortest Path First)是开放最短路径有限协议，V2针对IPV4网络，V3针对IPV6网络。是IETF组织开发的一个基于链路状态的内部网关协议。每台OSPF路由器根据自己周围的网络拓扑结构生成链路状态通告LSA(Link Stat Advertisement)，并通过更新报文将LSA发送到网络中的其他OSPF路由器。","text":"简介OSPF(Open Shortest Path First)是开放最短路径有限协议，V2针对IPV4网络，V3针对IPV6网络。是IETF组织开发的一个基于链路状态的内部网关协议。每台OSPF路由器根据自己周围的网络拓扑结构生成链路状态通告LSA(Link Stat Advertisement)，并通过更新报文将LSA发送到网络中的其他OSPF路由器。 过程每台OSPF路由器都会手机其他路由器发来的LSA，所有的LSA放在一起便组成了链路状态数据库LSDB(Link State Database)。LSA是对路由器周围网络拓扑结构的描述，LSDB则是对整个自治系统的网络拓扑结构描述。OPSF路由器将LSDB转换成一张带权的有向图，这张图便是对整个网络拓扑结构的真实反映。各个路由器得到的有向图是完全相同的。每台路由器根据有向图，使用SPF算法算出一棵以自己为根的最短路径树，这棵树给出了到自治系统中各节点的路由。随着网络扩大，LSDB也会越来越大，所以通过划分区域来解决LSDB过大的问题 区域根据区域特性不同，大体可分为以下几种区域:Backbone 区域——Backbone 区域，也被称为区域 0，其任务是汇总每个区域的网络拓扑到其他所有的区域。所有区域间通信必须通过骨干区域，非骨干区域之间不能直接交换数据包。因此，在规划 OSPF 网络时必须注意使所有非骨干区域与骨干区域物理或逻辑相 连。在实际应用中无法满足物理相连的条件时，可以通过配置虚连接实现逻辑相连。Stub 区域——Stub 区域也被称为末梢区域，是不允许 AS 外部 LSA 在其内部泛洪 的区域，只可以携带区域内部路由和区域间路由。Totally Stub 区域——Totally Stub 区域也被称为完全末梢区域，在 Stub 区域基础上 进一步减少了区域内 LSA 数量，不仅不允许携带 AS 外部路由，也不允许携带区域 间路由。NSSA 区域——NSSA(Not-So-Stubby-Area)区域也被称为非完全末梢区域，除通 过 ASBR 引入自治系统外部路由外，保留了其余 Stub 区域的特征。 路由器类型根据在AS中的不同位置，可分为以下几类:区域内路由器(Internal Routers) 该类路由器的所有接口都属于同一个 OSPF区域。区域边界路由器 ABR(Area Border Routers)该类路由器可以同时属于两个以上的区域，但其中一个必须是骨干区域。ABR 用 来连接骨干区域和非骨干区域，它与骨干区域之间既可以是物理连接，也可以是逻 辑上的连接。骨干路由器(Backbone Routers) 该类路由器至少有一个接口属于骨干区域。因此，所有的 ABR 和位于 Area0 的内部路由器都是骨干路由器。自治系统边界路由器 ASBR(AS Boundary Routers)与其他 AS 交换路由信息的路由器称为 ASBR。ASBR 并不一定位于 AS 的边界， 它可能是区域内路由器，也可能是 ABR。只要一台 OSPF 路由器引入了外部路由的 信息，它就成为 ASBR。 OSPF报文头部 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Version # | Type | Packet length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Router ID | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Area ID | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Checksum | AuType | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Authentication | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Authentication | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ 通过Type字段来定义五种报文: Hello 报文——Hello 报文用于发现和维护邻居和邻接关系，在广播型网络和 NBMA 网络也用来选举 DR 和 BDR。 DD 报文——DD(Database Description)报文通过携带 LSA 头部信息发送链路状态 数据库摘要。 LSR 报文——LSR(Link State Request)报文用于请求通过接受 DD 报文发现的本 路由器上没有的链路状态信息。 LSU 报文——LSU(Link State Update)报文通过发送详细的 LSA 来同步链路状态 数据库。 LSAck 报文——LSAck(Link State Ack)报文用于发送确认报文来确保路由信息的 交换过程是可靠的。 最终工作原理通过在路由器内启动OSPF进程，相互定义区域，那么只有相同区域内的报文会互相发送: 先配置router Id 进入ospf视图 配置area 配置网络 router id 1.1.1.1 ospfarea 0network 192.168.0.1 0.0.0.255 #反掩码quit 更多命令可以通过 dis ospf ? 进行查看","categories":[{"name":"Network","slug":"Network","permalink":"https://gowa2017.github.io/categories/Network/"}],"tags":[{"name":"网络","slug":"网络","permalink":"https://gowa2017.github.io/tags/网络/"},{"name":"OSPF","slug":"OSPF","permalink":"https://gowa2017.github.io/tags/OSPF/"}],"keywords":[{"name":"Network","slug":"Network","permalink":"https://gowa2017.github.io/categories/Network/"}]},{"title":"Gawk教程","slug":"Gawk教程","date":"2016-11-22T09:37:41.000Z","updated":"2018-03-12T02:48:21.000Z","comments":true,"path":"SED-AWK/Gawk教程.html","link":"","permalink":"https://gowa2017.github.io/SED-AWK/Gawk教程.html","excerpt":"awk与sed，两大神器，处理字符文本效率爆棚。一直有用，但是没有完整的记录，临时百度感觉不好，做一个完整系统的阅读，并进行info手册的翻译，方便时时回顾。","text":"awk与sed，两大神器，处理字符文本效率爆棚。一直有用，但是没有完整的记录，临时百度感觉不好，做一个完整系统的阅读，并进行info手册的翻译，方便时时回顾。 前言awk在很多系统上都有不同的实现，Gawk是awk在GNU/Linux的实现，其基本命令格式为： gawk [ POSIX or GNU style options ] -f program-file [ -- ] file ... gawk [ POSIX or GNU style options ] [ -- ] program-text file ... 更加直观一些的格式是: awk [ -F fs ] [ -v var=value ] [ &#39;prog&#39; | -f progfile] [ file ... ] 或者更简单一般的形式 awk [ -F fs ] &#39;pattern { action }&#39; 工作原理 awk以行为单为进行处理输入，然后用分隔符FS(field separator)把每行分隔成不同的域(field)。默认情况下使用空白符作为分隔符，但我们可以指定为任何我们想用的分隔符。 $0代表了整个行，$1, $2 ...代表了被分隔开的每个域。接下来就会根据匹配 pattern的进行 action 动作。 awk -F: &#39;{print $0,$1,$2,$3} 上面这个例子没有 pattern 代表着无条件执行 action 的意思。 然后观察一下输入是什么情况。 命令行选项 -F fs | —field-separator fs 指定域分隔符 -f source-file | —file source-file 指定程序文件 -v var=value | —assign var=value 在执行程序前设置变量。多个变量用awk -v foo=1 -v bar=2来指定 -b | character-as-bytes 将所有输入输出都认为是单字节的。 -d | —dump-variables[=file] 打印变量。不指定file的话，就会放在文件 awkvars 内。 -D[file] | —debug[=file] 内建命令","categories":[{"name":"SED&AWK","slug":"SED-AWK","permalink":"https://gowa2017.github.io/categories/SED-AWK/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/tags/Linux/"},{"name":"awk","slug":"awk","permalink":"https://gowa2017.github.io/tags/awk/"}],"keywords":[{"name":"SED&AWK","slug":"SED-AWK","permalink":"https://gowa2017.github.io/categories/SED-AWK/"}]},{"title":"mysql-dump 命令进行逻辑备份","slug":"mysql-dump-命令进行逻辑备份","date":"2016-11-21T09:38:02.000Z","updated":"2018-03-12T02:48:21.000Z","comments":true,"path":"MySQL/mysql-dump-命令进行逻辑备份.html","link":"","permalink":"https://gowa2017.github.io/MySQL/mysql-dump-命令进行逻辑备份.html","excerpt":"mysqldump经常用来备份数据库成为语句样式。但没有详细的一下具体的办法。其实很多东西都能在info里面找到非常详细的说明，只是，我们太忙了，只想要一个答案，而无心去看而已，所以呢，就把用得到的都看一下来记录吧。","text":"mysqldump经常用来备份数据库成为语句样式。但没有详细的一下具体的办法。其实很多东西都能在info里面找到非常详细的说明，只是，我们太忙了，只想要一个答案，而无心去看而已，所以呢，就把用得到的都看一下来记录吧。 命令模式mysqldump [options] [db_name [tbl_name ...]] 当不指定tbl_name 或者使用了 --databases | --all-databases， 整个库都会被备份。同时，mysqldump 不会备份 INFOMATION_SCHEMA 库，即使你显式的指定。 选项options选项组--opt 同等于 --add-drop-table --add-locks --create-options --disable-keys --extend-insert --lock-tables --quick --set-charset 这是一个默认的选项组。--compact 同等于 --skip-add-drop-table --skip-add-locks --skip-comments --skip-disable-keys --skip-set-charset 选项的反转我们可以用--skip-opt or --skip-compact 来进行反转以上选项。当我们想对—opt组中的某些选项进行取消的时候，我们可以用--skip来操作:比如，要取消extend inserts 跟 memory buffing: [--opt] --skip-extend-inserts --skip-quick。 （—opt可选是因为其是默认开启的）。 如果我们要取消--opt中的除禁止索引跟锁表外的选项，则可以用: --skip-opt --disable-keys --lock-tables。 如果是在组选项中要选择性的关闭或者开启一些功能，顺序很重要。 --disable-keys --lock-tables --skip-opt 将不会获得你想要的效果。 可能的缓存问题mysqldump 可以逐行的获取-备份表内容（至文件），同时可以在备份（至文件）前将整个内容缓存到内存中。数据过大的时候开启缓存会产生问题，想要逐行的进行备份，用--quick(或—opt，组选项中开启了—quick)，想要开启缓存那么用--skip-quick即可 更多的选项--help, -? 显示帮助信息--add-drop-database 在CREATE DATABASE..语句前加上DROP DATABASE ...。典型的使用是跟--all-databases 或--databases。--add-drop-table 在CREATE TABLE ...语句前加上DROP TABLE ...。--add-locks 在每个导出语句前后加上LOCK TABLES与UNLOCK TABLES，这样插入速度会更快。 更多见 7.3.2节 INSERT语句的速度--all-databases,-A 与--databases 所有库名...等价，备份所有库，表[infomationschema除外]--allow-keywords 允许建立field名为关键字的列，在每列加上表名作为前缀。--character-set-dir=path 字符集安装路径，更多见 9.5 字符节设置--comments,-i 默认开启，在备份文件写入版本、主机等信息。--skip-comments 关闭--compact 更紧凑的输出。将会开启--skip-add-drop-table --skip-add-locks --skip-comments --skip-disable-keys --skip-set-charset--compatible=name 为了与其他数据库系统兼容，name={ansi | mysql323 | mysql40 | postgresql | oracle | msssql | db2 | maxdb | no_key_options | no_table_options | no_field_options}多个选项的话用逗号分开。但这并不能保证就一定能与其他数据库兼容，只是保证输出尽量兼容。更多见 5.1.6 服务器SQL模式--complate-insert,-c 使用包含列的完整插入语句。--compress,-C 如果clien and server 支持压缩的话就压缩所有信息。--create-options 包含所有MySQL CREATE TABLE 语句支持的表选项--databases,-B 多个库--debug[=debug_options],-#[debug_options] 调试日志，debug_options典型格式d:t:o,file_name,默认值d:t:o,/tmp/mysqldump.trace--debug_info 在程序退出的时候打印 _内存和CPU的使用情况。 5.0.32增加--cdefault-character-set=charset-name 用charset-name 作为默认的字符集。如果没指定charset-name的话，默认使用utf8,早些版本用的是latin1。此选项对用--tab选项产生的文件没有影响。--delayed-insert 用INSERT DELAYED 代替 INSERT--delete-master-logs 在主从服务器上，在备份操作完成后会给服务器一个PURGE BINARY LOGS语句，删除二进制日志。此选项自动开启--master-data--disable-keys, -K 用/*!40000 ALTER TABLE tbl_name DISABLE KEYS */;和/*!40000 ALTER TABLE tbl_name ENABLE KEYS*/包围INSERT。这会让插入的时候更快，因为所有索引都在所有行插入完毕后建立。只有在非唯一索引的MyISAM表有效。--dump-date 在--comments 开启的情况下，默认在文件尾加上一条注释-- Dump complete on DATE。--skip-dump-date关闭，默认情况开启。--extend-insert, -e 使用多行的INSERT语句包含不止一条的值列表。会产生更小的dump file和更快的插入速度。--fields-terminated-by=...,--fields-enclosed-by=...,--fields-optionally-enclosed-by=...,--fields=escaped-by=... 与--tab选项同用，与LOAD DATA INFILE有相同意义。--first-slave 5.5已删除，使用--lock-all-tables替代。--flush-logs, -F 备份前刷新日志，需要RELOAD权限。当与--all-databases，每个库被备份时都会刷新。当使用--lock-all-tables or --master-data，日志只有在所有表在锁定的时候被刷新一次。想要备份跟日志一起刷新，就要配合--lock-all-tables or --master-data。--flush-privileges 备份库后发送FLUSH PRIVILEGES语句到服务器。当其他有库依赖于此库进行恢复的时候必须使用。--force, -f 出错依然继续。--host=host_name, -h host_name 指定主机，默认localhost--hex-blob 二进制列用16进制表示(abc-&gt;ox616263)，受影响的数据类型是BINARY,VARBINARY,BLOB--ignore-table=db_name.tbl_name 忽略表或视图，多张表就多次使用。--insert-ignore INSERT IGNORE ... 代替INSERT语句--lines-terminated-by=... 与—tab 选项联用--lock-all-tables, -x 所有库的表锁定。通过在备份期间产生一个read lock全局读锁，会自动关闭--single-transaction和--lock-tables。--lock-tables, -l 每个库备份前锁表。MyISAM表用READ LOCAL锁定来允许同步插入。事务性的表（InnoDb/BDB)，--single-transaction选项更好，因为不需要锁表。 因为--lock-tables为每个库单独锁表，并不能保证在备份在文件后的内容在库间逻辑上的一致。--log-error=file_name 默认情况下不作记录，此选项将警告或错误附加到file_name--single-transaction 备份前发送START TRANSACTION SQL语句给服务器，对事务性的表很有用。当BEGIN被执行的时候，其备份各库的一致状态，且不会阻塞任何应用。必须记住的是，只有事务表（innoDB/BDB）才会在一致状态下备份。假入是MyISAM，其状态依然会有可能改变。在备份期间，为了保证成功（备份文件正常、二进制文件坐标正确），其他连接不可使用任何一个： { ALTER TABLE | CREATE TABLE | DROP TABLE | RENAME TABLE | TRUNCATE TABLE}语句。因为一致性读与这些语句是不隔离的， 在要备份的表上执行这几个语句会使 mysqldump执行的 SELECT命令重新读取表内容而得到错误的内容或者失败。--single-transaction与--lock-tables是互斥的，因为--lock-tables会让所有未提交的事务悄悄的提交。对于较大的表，应该结合--quick使用。--master-data[=value] 产生的备份文件可以作用当前主从服务器的从属服务器。这将导致备份出来的文件含有一个CHANGE MASTER TO语句,指明二进制日志 （file name 和 position)与被备份服务器一致。 在导入从服务器后可以从主服务器日志处开始同步复制。 默认是value是1,如果值是2,只是写在信息式的写在注释内，并不生效。 此选项要求RELOAD权限和二进制日志必须开启。--master-data自动关闭--lock-tables。在--single-transaction没指定的情况下开启--lock-all-tables（这样情况下全局读锁只会在开始备份的产生很短的时间）。无论什么情况，备份的时刻日志就会产生动作。在已有的从服务器上备份出文件再做一个从服务器也是可以的。 停止从服务器进程，获取其状态： mysql &gt; STOP SLAVE SQL_THREAD;mysql &gt; SHOW SLAVE STATUS; 从上面得到主服务器二进制日制的坐标：Relay_Master_Log_File Exec_Master_Log_Pos字段，把他给记做file_name file_pos。 dump 从服务器。 shell &gt; mysqldump --master-data=2 --all-database &gt; dumpfile 重启从服务器线程 mysql &gt; START SLAVE; 新从服务器，导入dumpfile. shell &gt; mysql &lt; dumpfile 在新从服务器上，设置同步坐标。(file_name file_pos) mysql&gt; CHANGE MASTER TO MASTER_LOG_FILE=file_name MASTER_LOG_POS=file_pos; 自行添加CHAGE MASTER TO 需要的参数，比如主服务器地址等。--no-autocommit 以set autocommit=0 和COMMIT语句来包围INSERT语句。--no-create-db, -n 当--databases,-B | --all-databases指定的时候，禁用CREATE DATABASES语句--no-create-info, -t 不写出重新创建备份表的CREATE TABLE语句--no-data, -d 只要表结构。--no-set-names, -N 等价于--skip-set-charset--order-by-primary 当主键、或唯一索引存在的时候以此排序列行。当MyISAM表要转到InnoDB表的时候，但会花费更多时间。--password[=password],-p[password] 密码-pipe, -W--port=port_num, -P port_num--quick, -q 对于dump大表很实用。强制mysqldump一次获取一行而不是获得整个记录并且进行缓存。--quote-names, -Q--result-file=file_name, -r file_name 重定向至文件--routines, -R 包括函数跟结构。但没有时间戳，新导入的时间就是重新建立过程的时间戳。想要原来的时间戳，导出mysql.proc表后进行恢复。--set-charset 将SET NAMES default_character_set加到输出中。该选项默认启用。要想禁用SET NAMES语句，使用--skip-set-charset。--skip-comments 参见--comments选项的描述。--socket=path, -S path 当连接localhost(为默认主机)时使用的套接字文件。--tab=path, -T path 产生tab分割的数据文件。对于每个转储的表，mysqldump创建一个包含创建表的CREATE TABLE语句的tbl_name.sql文件，和一个包含其数据的tbl_name.txt文件。选项值为写入文件的目录。 默认情况，.txt数据文件的格式是在列值和每行后面的新行之间使用tab字符。可以使用--fields-xxx和--line--xxx选项明显指定格式。 注释：该选项只适用于mysqldump与mysqld服务器在同一台机器上运行时。你必须具有FILE权限，并且服务器必须有在你指定的目录中有写文件的许可。--tables 覆盖—-database或-B选项。选项后面的所有参量被看作表名。—tariggers —skip-triggers--user=user_name, -u user_name 用户名--verbose, -v 冗长模式。打印出程序操作的详细信息。--version, -V 显示版本信息并退出。--xml, -X 转存为xml文件","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://gowa2017.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://gowa2017.github.io/tags/MySQL/"},{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/tags/Linux/"},{"name":"数据库","slug":"数据库","permalink":"https://gowa2017.github.io/tags/数据库/"}],"keywords":[{"name":"MySQL","slug":"MySQL","permalink":"https://gowa2017.github.io/categories/MySQL/"}]},{"title":"Raid磁盘冗余阵列的理解","slug":"Raid磁盘冗余阵列的理解","date":"2016-11-21T09:26:24.000Z","updated":"2018-03-12T02:48:21.000Z","comments":true,"path":"Device/Raid磁盘冗余阵列的理解.html","link":"","permalink":"https://gowa2017.github.io/Device/Raid磁盘冗余阵列的理解.html","excerpt":"缘起公司部署业务的时候，6块盘需要做raid，以前还没有用过所以不知道，临时才去百度看了一下相关知识。最终在华为3108 2208扣卡上都做了raid10。","text":"缘起公司部署业务的时候，6块盘需要做raid，以前还没有用过所以不知道，临时才去百度看了一下相关知识。最终在华为3108 2208扣卡上都做了raid10。 部署当前可以用软raid与硬raid，软raid系统上建立，占用CPU与IO资源;硬RAID是用阵列卡来做，有自己的CPU、缓存及IO总线，所以效率很高，但是价格也是杠杠滴。 级别当前RAID有 0, 1, 2, 3, 4, 5, 6, 7, 10, 50, 60, 几个级别，2 3 4 已经不常用，5已经涵盖了它们的功能，只是在研究的时候才会用到。当前主要用的是 0, 1, 5, 10, 50, 60。刚好，我们用的华为3108扣卡磁盘阵列也支持这几个级别。 级别介绍RAID0它将两个以上的磁盘并联起来，成为一个大容量的磁盘。在存放数据时，分段后分散存储在这些磁盘中，因为读写时都可以并行处理，所以在所有的级别中，RAID 0的速度是最快的。但是RAID 0既没有冗余功能，也不具备容错能力，如果一个磁盘（物理）损坏，所有数据都会丢失。 RAID1两组以上的N个磁盘相互作镜像，在一些多线程操作系统中能有很好的读取速度，理论上读取速度等于硬盘数量的倍数，另外写入速度有微小的降低。只要一个磁盘正常即可维持运作，可靠性最高。其原理为在主硬盘上存放数据的同时也在镜像硬盘上写一样的数据。当主硬盘（物理）损坏时，镜像硬盘则代替主硬盘的工作。因为有镜像硬盘做数据备份，所以RAID 1的数据安全性在所有的RAID级别上来说是最好的。但无论用多少磁盘做RAID 1，仅算一个磁盘的容量，是所有RAID中磁盘利用率最低的一个级别。 RAID5 RAID Level 5是一种储存性能、数据安全和存储成本兼顾的存储解决方案。它使用的是Disk Striping（硬盘分区）技术。RAID 5至少需要三块硬盘，RAID 5不是对存储的数据进行备份，而是把数据和相对应的奇偶校验信息存储到组成RAID5的各个磁盘上，并且奇偶校验信息和相对应的数据分别存储于不同的磁盘上。当RAID5的一个磁盘数据发生损坏后，可以利用剩下的数据和相应的奇偶校验信息去恢复被损坏的数据。RAID 5可以理解为是RAID 0和RAID 1的折衷方案。RAID 5可以为系统提供数据安全保障，但保障程度要比镜像低而磁盘空间利用率要比镜像高。RAID 5具有和RAID 0相近似的数据读取速度，只是因为多了一个奇偶校验信息，写入数据的速度相对单独写入一块硬盘的速度略慢，若使用“回写缓存”可以让性能改善不少。同时由于多个数据对应一个奇偶校验信息，RAID 5的磁盘空间利用率要比RAID 1高，存储成本相对较便宜。 RAID6与RAID 5相比，RAID 6增加第二个独立的奇偶校验信息块。两个独立的奇偶系统使用不同的算法，数据的可靠性非常高，任意两块磁盘同时失效时不会影响数据完整性。RAID 6需要分配给奇偶校验信息更大的磁盘空间和额外的校验计算，相对于RAID 5有更大的IO操作量和计算量，其“写性能”强烈取决于具体的实现方案，因此RAID6通常不会通过软件方式来实现，而更可能通过硬件/固件方式实现。同一数组中最多容许两个磁盘损坏。更换新磁盘后，数据将会重新算出并写入新的磁盘中。依照设计理论，RAID 6必须具备四个以上的磁盘才能生效。 RAID10/RAID01 RAID 10是先镜射再分区数据，再将所有硬盘分为两组，视为是RAID 0的最低组合，然后将这两组各自视为RAID 1运作。RAID 01则是跟RAID 10的程序相反，是先分区再将数据镜射到两组硬盘。它将所有的硬盘分为两组，变成RAID 1的最低组合，而将两组硬盘各自视为RAID 0运作。当RAID 10有一个硬盘受损，其余硬盘会继续运作。RAID 01只要有一个硬盘受损，同组RAID 0的所有硬盘都会停止运作，只剩下其他组的硬盘运作，可靠性较低。如果以六个硬盘建RAID 01，镜射再用三个建RAID 0，那么坏一个硬盘便会有三个硬盘脱机。因此，RAID 10远较RAID 01常用，零售主板绝大部分支持RAID 0/1/5/10，但不支持RAID 01。 RAID50RAID 5与RAID 0的组合，先作RAID 5，再作RAID 0，也就是对多组RAID 5彼此构成Stripe访问。由于RAID 50是以RAID 5为基础，而RAID 5至少需要3颗硬盘，因此要以多组RAID 5构成RAID 50，至少需要6颗硬盘。以RAID 50最小的6颗硬盘配置为例，先把6颗硬盘分为2组，每组3颗构成RAID 5，如此就得到两组RAID 5，然后再把两组RAID 5构成RAID 0。RAID 50在底层的任一组或多组RAID 5中出现1颗硬盘损坏时，仍能维持运作，不过如果任一组RAID 5中出现2颗或2颗以上硬盘损毁，整组RAID 50就会失效。RAID 50由于在上层把多组RAID 5构成Stripe，性能比起单纯的RAID 5高，容量利用率比RAID5要低。比如同样使用9颗硬盘，由各3颗RAID 5再组成RAID 0的RAID 50，每组RAID 5浪费一颗硬盘，利用率为(1-3/9)，RAID 5则为(1-1/9)。 RAID60 RAID 6与RAID 0的组合：先作RAID 6，再作RAID 0。换句话说，就是对两组以上的RAID 6作Stripe访问。RAID 6至少需具备4颗硬盘，所以RAID 60的最小需求是8颗硬盘。由于底层是以RAID 6组成，所以RAID 60可以容许任一组RAID 6中损毁最多2颗硬盘，而系统仍能维持运作；不过只要底层任一组RAID 6中损毁3颗硬盘，整组RAID 60就会失效，当然这种情况的概率相当低。比起单纯的RAID 6，RAID 60的上层通过结合多组RAID 6构成Stripe访问，因此性能较高。不过使用门槛高，而且容量利用率低是较大的问题。","categories":[{"name":"Device","slug":"Device","permalink":"https://gowa2017.github.io/categories/Device/"}],"tags":[{"name":"Device","slug":"Device","permalink":"https://gowa2017.github.io/tags/Device/"},{"name":"Raid","slug":"Raid","permalink":"https://gowa2017.github.io/tags/Raid/"},{"name":"磁盘阵列","slug":"磁盘阵列","permalink":"https://gowa2017.github.io/tags/磁盘阵列/"}],"keywords":[{"name":"Device","slug":"Device","permalink":"https://gowa2017.github.io/categories/Device/"}]},{"title":"Go中的闭包","slug":"Lua与Go中的闭包","date":"2016-11-19T11:54:12.000Z","updated":"2018-03-12T02:48:21.000Z","comments":true,"path":"编程/Lua与Go中的闭包.html","link":"","permalink":"https://gowa2017.github.io/编程/Lua与Go中的闭包.html","excerpt":"不止一次见到过闭包这种词了，以前在游戏做脚本的时候用Lua，其中就有闭包这个特性，但是确实没有仔细的研究过，最近在学习Go语言也看到了这个特性，才从新来理解一下。","text":"不止一次见到过闭包这种词了，以前在游戏做脚本的时候用Lua，其中就有闭包这个特性，但是确实没有仔细的研究过，最近在学习Go语言也看到了这个特性，才从新来理解一下。 定义在Go语言中，是如下定义闭包的：Go 函数可以是一个闭包。闭包是一个函数值，它引用了其函数体之外的变量。该函数可以访问并赋予其引用的变量的值，换句话说，该函数被“绑定”在了这些变量上。例如，函数 adder 返回一个闭包。每个闭包都被绑定在其各自的 sum 变量上。package mainimport \"fmt\"func adder() func(int) int &#123; sum := 0 return func(x int) int &#123; sum += x return sum &#125;&#125;func main() &#123; pos := adder() for i := 0; i &lt; 5; i++ &#123; fmt.Println(pos(i)) &#125;&#125; 执行此函数，输出的结果是： 0 1 3 6 10 怎么理解闭包绑定例中pos被绑定在了sum上，怎么去理解它呢。看看维基百科的说明： 在计算机科学中，闭包（Closure）是词法闭包（LexicalClosure）的简称，是引用了自由变量的函数。这个被引用的自由变量将和这个函数一同存在，即使已经离开了创造它的环境也不例外。所以，有另一种说法认为闭包是由函数和与其相关的引用环境组合而成的实体。 也就是说，闭包两个定义前提是： 引用了自由变量 函数 adder()返回一个闭包pos, 它引用了变量sum，sum的生命周期由于返回函数的引用而变长。再来进行更细一步的探究：我们来打印pos的值和类型，因为它是一个闭包，看看会出现什么。我们来尝试打印sum的地址。 ... sum += x fmt.Println(&amp;sum) ... pos := adder() fmt.Printf(&quot;%v-%T&quot;, pos, pos) ... 然后看一下输出是什么： 0x401290-func(int) int0xc04203a1d0 0xc04203a1d0 0 0xc04203a1d0 1 0xc04203a1d0 3 0xc04203a1d0 6 0xc04203a1d0 10 pos的值是一个地址，其类型是一个函数，返回值地址是0xc04203a1d0，就是adder()返回的函数。sum变量一直存在，每次调用都会增加。 最后的理解闭包是一个函数，由一个变量指向其地址，其返回值是固定地址值。而每次闭包都引用都可以改变其引用变量的值。","categories":[{"name":"编程","slug":"编程","permalink":"https://gowa2017.github.io/categories/编程/"}],"tags":[{"name":"编程","slug":"编程","permalink":"https://gowa2017.github.io/tags/编程/"},{"name":"Go","slug":"Go","permalink":"https://gowa2017.github.io/tags/Go/"}],"keywords":[{"name":"编程","slug":"编程","permalink":"https://gowa2017.github.io/categories/编程/"}]},{"title":"Linux的用户权限与Saved set-user-id","slug":"Linux的用户权限与Saved-set-user-id","date":"2016-11-19T08:51:52.000Z","updated":"2018-03-12T02:48:21.000Z","comments":true,"path":"编程/Linux的用户权限与Saved-set-user-id.html","link":"","permalink":"https://gowa2017.github.io/编程/Linux的用户权限与Saved-set-user-id.html","excerpt":"Linux的程序、文件权限是一个很奇妙的设置，不进行一下深入的研究，总是会出现这样那样的疑问。特别是对s权限的疑问，估计很多人都想知道是为什么呢。","text":"Linux的程序、文件权限是一个很奇妙的设置，不进行一下深入的研究，总是会出现这样那样的疑问。特别是对s权限的疑问，估计很多人都想知道是为什么呢。 fork函数看到 AUPE 8.10节 fork函数 的时候，对于调用一次返回两次感觉好奇妙，而且之后父、子进程会共同执行更是感觉不可思议。执行fork后，父子进程继续执行fork命令后的指令，子进程是父进程的副本，有自己的 堆、栈和数据空间 但与父进程共享正文段。由于fork后经常跟随着的是exec，所以进行堆、栈、数据空间的复制是一个不必要的操作，所以很多实现采用了 写时复制(Copy-On-Write, COW技术) 。这些区域父子进程共享，并被内核设置为只读，只有当父、子进程试图进行修改的时候才会对那块区域做一个副本，通常是虚拟存储器的一”页”。子进程对父进程打开的文件描述符拥有副本。 在 3.14节，fcntl函数进行了定义：#include &lt;fcntl.h&gt;int fcntl(int fd, int cmd, .../* int arg */); 出错返回-1,具体返回值依赖于cmd参数。其中提到一个CMD，FD_GETFD FD_SETFD所返回的文件描述符标志FD_CLOEXEC(当前的文件描述符标志只有这一个)。在fork后我们经常会执行exec，若设置了FD_CLOEXEC标志，子进程对父进程的文件描述符副本，被关闭。否则，将不关闭。默认情况下，子进程调用exec并不关闭这些文件描述符副本，除非显式地用fcntl(fd,FD_SETFL,1)进行设置。对于目录流，POSIX.1明确要求将此标志设置为1,通常，由opendir函数调用fcntl实现。 与进程关联的ID与一个进程关联的ID有6个。real uid/real gid login时从登录文件取出，显然，你用什么用户登录系统，实际用户就是谁。effective uid/effective gid/supplementary group IDssaved set-user-ID/saved set-group-ID 被exec函数保存的saved set-user-ID/saved set-group-ID。 当一个程序被加载到内存执行的时候，通常用的是exec函数中的一个。一般情况下，real uid与effective uid是相同的，你以什么身份执行一个程序，这个进程就属于谁。但是：当set-user-ID位被设置，也就是文件权限位第三位是s的时候，exec将会：把进程的effective user id 设置为文件所有者ID。这个时候，如果不属于当前用户的文件被执行，其effective user id = 文件所有者ID。同时，exec还会将此文件所有者ID进行保存，所以，才叫saved set-user-id那么，当执行一个具有set-user-id位的程序的时候，进程的real user id 与 effective user id 是不一定相同的。 我们可以用一个小程序来验证是否属实。这个程序打印 程序运行时候的 real user ID与effective user ID。#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;intmain(int argc, char *argv[])&#123;puts(&quot;I am child process&quot;);printf(&quot;userId=%d,euserId=%d\\n&quot;,getuid(),geteuid());return 0;&#125; 同时将其权限设置为 -rwsr-xr-x 中的’s’就是saved-user-Id，当执行此程序时将以超级用户权限执行。要想验证很简单。编译后执行他。获得输出： I am child processuserId=500,euserId=0 同时，我们可以在程序中调用int setuid (uid_t newuid)函数来更改进程的real user id, effective user id但是我们必须明白： user id 更改规则1、只有root进程可以更改 real user id , saved set-user-id。2、当root进程调用setuid函数时 real user id , effective user id , saved-user-id都被设置为newuid;3、如果一个不具有root权限的进程试图调用此函数，会出现什么呢？ 如果 newuid == real user id or newuid == saved set-user-id那么进程的 uid = newuid。不然，出错。同时，任何时候，进程都可以用setuid函数将，进程UID设置为：real user id 或者 saved set-user-id; 我们可以用 getuid() geteuid() 函数获取 real user id 和 effective user id,但我们无法用函数获得 saved set-user-id;","categories":[{"name":"编程","slug":"编程","permalink":"https://gowa2017.github.io/categories/编程/"}],"tags":[{"name":"编程","slug":"编程","permalink":"https://gowa2017.github.io/tags/编程/"},{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/tags/Linux/"},{"name":"Unix","slug":"Unix","permalink":"https://gowa2017.github.io/tags/Unix/"}],"keywords":[{"name":"编程","slug":"编程","permalink":"https://gowa2017.github.io/categories/编程/"}]},{"title":"Unix编程中exec函数族的一点疑问","slug":"Unix编程中exec函数族的一点疑问","date":"2016-11-19T08:31:28.000Z","updated":"2019-03-09T07:28:34.370Z","comments":true,"path":"编程/Unix编程中exec函数族的一点疑问.html","link":"","permalink":"https://gowa2017.github.io/编程/Unix编程中exec函数族的一点疑问.html","excerpt":"在观看 AUPE8.12节 解释器文件 的时候，很迷惑不不解。问题不出在这几个函数，而在于看后面章节文解释器的时候发现一个很奇妙的问题。","text":"在观看 AUPE8.12节 解释器文件 的时候，很迷惑不不解。问题不出在这几个函数，而在于看后面章节文解释器的时候发现一个很奇妙的问题。 exec函数族的定义#include &lt;unistd.h&gt; int execl(const char *pathname, const char *arg0, ... /* (char *)0 */ );int execv(const char *pathname, char *const argv []);int execle(const char *pathname, const char *arg0, ... /* (char *)0, char *const envp[] */ );int execve(const char *pathname, char *const argv[], char *const envp []);int execlp(const char *filename, const char *arg0, ... /* (char *)0 */ );int execvp(const char *filename, char *const argv []); 第一个参数是路径名或者文件名， 后续的是一连串字符串参数或者指针数组。来研究一下文中的小程序。 举例#include \"apue.h\"#include &lt;sys/wait.h&gt;char *env_init[] = &#123; \"USER=unknown\", \"PATH=/tmp\", NULL &#125;;intmain(void)&#123; pid_t pid; if ((pid = fork()) &lt; 0) &#123; err_sys(\"fork error\"); &#125; else if (pid == 0) &#123; /* specify pathname, specify environment */ if (execle(\"/home/sar/bin/echoall\", \"echoall\", \"myarg1\", \"MY ARG2\", (char *)0, env_init) &lt; 0) err_sys(\"execle error\"); &#125; if (waitpid(pid, NULL, 0) &lt; 0) err_sys(\"wait error\"); if ((pid = fork()) &lt; 0) &#123; err_sys(\"fork error\"); &#125; else if (pid == 0) &#123; /* specify filename, inherit environment */ if (execlp(\"echoall\", \"echoall\", \"only 1 arg\", (char *)0) &lt; 0) err_sys(\"execlp error\"); &#125; exit(0);&#125; #include \"apue.h\"intmain(int argc, char *argv[])&#123; int i; char **ptr; extern char **environ; for (i = 0; i &lt; argc; i++) /* echo all command-line args */ printf(\"argv[%d]: %s\\n\", i, argv[i]); for (ptr = environ; *ptr != 0; ptr++) /* and all env strings */ printf(\"%s\\n\", *ptr); exit(0);&#125; 对于： execle(\"/home/sar/bin/echoall\", \"echoall\", \"myarg1\", \"MY ARG2\", (char *)0, env_init) 的调用，感性的判断认为，应该是将echoall myarg1 &quot;MY ARG2&quot;三个参数传给echoall那么，加上程序本身，应该是有四个参数，然而结果却不是如此。输出的结果是： argv[0]: echoallargv[1]: myarg1argv[2]: MY ARG2 为何argv[0]会变成了传入的第二个参数呢。翻看英文版看到仔细的阅读了一下。 Note also that we set the first argument, argv[0] in the new program, to be the filename component of the pathname.Some shells set this argument to be the complete pathname. This is a convention only.We can set argv[0] to any string we like. 这是把 传入exec执行程序的第一个参数 新程序的argv[0] 设置为路径名的文件名部分。某些shell会把这个参数设置为完整路径名，只是为了方便。我们可以把argv[0]设置为任何值(pathname为完整的情况下)","categories":[{"name":"编程","slug":"编程","permalink":"https://gowa2017.github.io/categories/编程/"}],"tags":[{"name":"编程","slug":"编程","permalink":"https://gowa2017.github.io/tags/编程/"},{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/tags/Linux/"},{"name":"Unix","slug":"Unix","permalink":"https://gowa2017.github.io/tags/Unix/"}],"keywords":[{"name":"编程","slug":"编程","permalink":"https://gowa2017.github.io/categories/编程/"}]},{"title":"Linux下的文件与目录的权限","slug":"Linux下的文件与目录的权限","date":"2016-11-19T08:27:53.000Z","updated":"2018-03-12T02:48:21.000Z","comments":true,"path":"Linux/Linux下的文件与目录的权限.html","link":"","permalink":"https://gowa2017.github.io/Linux/Linux下的文件与目录的权限.html","excerpt":"前些天遇到有朋友在群内讨论权限的问题，不是很清楚，为了几个比较细的问题，我一时也记得不太清楚。只记得需要对目录写入文件的话需要w权限，后面看了才确认还需要执行权限。","text":"前些天遇到有朋友在群内讨论权限的问题，不是很清楚，为了几个比较细的问题，我一时也记得不太清楚。只记得需要对目录写入文件的话需要w权限，后面看了才确认还需要执行权限。 从APUE看起记得我在看APUE的时候有看到过关于目录项与文件像的说明，所以重新回去看了一下。请看 APUE 4.14节 文件系统 i-node(i 节点)我们可以把一个硬盘分为几个分区，每个分区都可以包含一个文件系统，那么这个文件系统的结构组成可能是以下这样的，i-node是一些固定长度的单元：更加细致的看一下cylinder group1中的i-nodes与data blocks。i-node包含的信息很多，包括文件类型、文件权限位、文件大小、指向data blocks的指针等。data blocks包含常规的数据块data blocks与存放目录项的 directory blocks。内核通过i-node信息来确定数据存放的位置，通过i-node中的type字段来确定存放的是一般数据还是目录。 例子听起来有不知所云，多看两次可能也觉得迷糊，我们通过一个例子来说明一下。我们可以通过 ls -il 命令来查看文件的i节点号。通过 -ldi来显示目录的i节点[www@iZ23fz9kp5sZ data]$ ll -di / /etc /etc/passwd 2 drwxr-xr-x 23 root root 4096 11-15 12:24 /2064385 drwxr-xr-x 96 root root 12288 11-18 12:24 /etc2066133 -rw-r--r-- 1 root root 1914 11-18 11:45 /etc/passwd 通过挂载点信息找到 / 的i-node号为2。读取i-node 2指向的 directory blocks，此blocks中会存放类似 2064385 etc/ 的目录项读取 2064385 i-node的信息，根据type field字段知道这指向一个 directoryblocks。读取2064385指向的 directory blocks，找到类似 2066133 passwd 的目录项读取 2066133 i-node的信息，前往对应blocks读取数据。 总结参考APUE 4.5节对于权限位 rwx大家都知道是 读写执行，但对于目录来说，可能不太清楚，咱们举例说明。对一个目录例如 /etc/ 如果我们想在其目录下创建文件，其实是对 etc/ 存放目录项的增加，所以，我们需要 w写权限i-node中的r权限信息决定了我们是否能够对此node指向的directory blocks进行读操作。x权限决定了我们是否能够通过这个目录。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/tags/Linux/"}],"keywords":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}]},{"title":"Iptables在大流量的情况下启动导致服务拒绝","slug":"Iptables在大流量的情况下启动导致服务拒绝","date":"2016-11-14T09:46:15.000Z","updated":"2018-03-12T02:48:21.000Z","comments":true,"path":"Linux/Iptables在大流量的情况下启动导致服务拒绝.html","link":"","permalink":"https://gowa2017.github.io/Linux/Iptables在大流量的情况下启动导致服务拒绝.html","excerpt":"大多数情况下我都喜欢也习惯于iptables来进行端口限制，转发，甚至过滤等操作，作为安全加固，在流量小的情况下是可靠的，但，但面对巨大的流量的时候，就会出现意料之外的情况了。这不，我最近就遇到了。","text":"大多数情况下我都喜欢也习惯于iptables来进行端口限制，转发，甚至过滤等操作，作为安全加固，在流量小的情况下是可靠的，但，但面对巨大的流量的时候，就会出现意料之外的情况了。这不，我最近就遇到了。 起因DNS服务器平时对外提供服务，QPS大概是3万-5万，安全厂商进行扫描的时候出现安全漏洞，需要用将端口进行限制。于是我就用了一条语句增加了规则，这机器之前并未启动iptables。 iptables -A INPUT -s 192.168.1.0/24 -p tcp -m tcp --dprot 22 -j ACCEPT iptables -A INPUT -p tcp -m tcp --dport 22 -j REJECT 乍一看，是正常的，确实工作得也还不错。可过了一会机器就不能登录了。连忙前往机房，查看了一下日志 nf_conntrack: table full, dropping packet。在这种情况下，启动iptables是不科学的，即使设置net.netfilter.nf_conntrack_max/net.netfilter.nf_conntrack_tcp_timeout_established流量大了也会出现问题。 为什么会出现这样情况启动iptables的时候，就会加载nf_conntrack模块，运行于内核，用来跟踪链接状态，iptables的nat和state模块就会用到其跟踪的状态。查看一下iptables的默认规则就会发现其中一条规则： iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT 这一条一般都在第一个，是为了将相关联的，通信中的状态直接放行，而不用匹配到最终规则后才用默认动作ACCEPT进行处理。但这完全没有任何意义，对于DNS服务器来说，其并不需要进行后续连接状态的跟踪，响应报文就OK了，而iptable在启动后，每个报文都会匹配一下规则，并且被nf_conntrack跟踪状态，但无法跟踪，则会丢包，拒绝服务。 解决办法我们应该将DNS服务53端口出去或进来的包都禁用跟踪，这需要在raw/PREROUTING进行处理。 iptables -t raw -A PREROUTING -p udp -m udp --dport 53 -j NOTRACK iptables -t raw -A OUTPUT -p udp -m udp --sport 53 -j NOTRACK 同样再本地环回接口来的包我们也不应该进行跟踪处理： iptables -t raw -A PREROUTING -i lo -j NOTRACK iptables -t raw -A OUTPUT -o lo -j NOTRACK 但是但我们进行这样的规则实质后，后续的任何依赖链接状态的规则都将不能正常工作，因为无法匹配其状态。 或者我们可以将流量的过滤放在上层的防火墙设备进行，这样就最好了。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/tags/Linux/"},{"name":"加固","slug":"加固","permalink":"https://gowa2017.github.io/tags/加固/"},{"name":"iptables","slug":"iptables","permalink":"https://gowa2017.github.io/tags/iptables/"}],"keywords":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}]},{"title":"Shell编程与C的一些不同","slug":"Shell编程与C的一些不同","date":"2016-11-13T01:37:17.000Z","updated":"2018-03-12T02:48:21.000Z","comments":true,"path":"Shell/Shell编程与C的一些不同.html","link":"","permalink":"https://gowa2017.github.io/Shell/Shell编程与C的一些不同.html","excerpt":"事情是这样的，前几天整理一下业务脚本的时候，发现有几处写的地方让我莫名其妙，后面经过仔细的了解才明白，确实有点反常。","text":"事情是这样的，前几天整理一下业务脚本的时候，发现有几处写的地方让我莫名其妙，后面经过仔细的了解才明白，确实有点反常。 开始不明白的例子观察以下代码，按照逻辑，if condition; then ... 才会执行，同学们来看看这会出现什么。CheckDb()&#123;ret=`sqlplus -s absadmin/imsadmin32@LCIMS80 &lt;&lt; !set pagesize 0set feedback offselect 'ok' from dual;!` ret=`echo $ret` if [ \"$&#123;ret&#125;\" != \"ok\" ] then echo \"`date +'[%Y-%m-%d %H:%M:%S]'` $&#123;ret&#125;\" echo 1 return 1 fi echo 0 return 0&#125;for times in 1 2 3do if CheckDb then auth0=`ps -ef | grep 'AB_AUTH 0' | grep -v monitor | grep -v grep | wc -l` if [ $&#123;auth0&#125; -gt 0 ] then echo \"`date +'[%Y-%m-%d %H:%M:%S]'` resume from no DB !\" SendMsg \"resume+from+no+DB\" sh $&#123;AAA_HOME&#125;/bin/restartall fi break fi if [ $times -eq 3 ] then AuthNoDB break fi SendMsg \"login+DATABASE+fail+$times+times\" sleep 3donei 事实上，shell的if中的condition有三种模式。if command; then ...; fi 这种情况下command(可以是函数)执行成功，返回0,那么执行then后面的语句，而不是进行T|F判断;if [ condition ]; then ...; fi 这种情况下condition为真才会执行then。 if [ 1 -gt 2 ]; then echo true; else echo false; fi if test condition; then ...; fi 这种情况下condition为真才会执行then。 if test 1 -gt 2 ; then echo true; else echo false; fi 因为在shell中 test 与 [] 是完全一样的。","categories":[{"name":"Shell","slug":"Shell","permalink":"https://gowa2017.github.io/categories/Shell/"}],"tags":[{"name":"编程","slug":"编程","permalink":"https://gowa2017.github.io/tags/编程/"},{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/tags/Linux/"},{"name":"Shell","slug":"Shell","permalink":"https://gowa2017.github.io/tags/Shell/"}],"keywords":[{"name":"Shell","slug":"Shell","permalink":"https://gowa2017.github.io/categories/Shell/"}]},{"title":"Kindle越狱操作","slug":"Kindle越狱操作","date":"2016-11-12T00:29:55.000Z","updated":"2018-09-27T11:55:19.000Z","comments":true,"path":"Kindle/Kindle越狱操作.html","link":"","permalink":"https://gowa2017.github.io/Kindle/Kindle越狱操作.html","excerpt":"前不久女朋友送了个Kindle Voyage，不过用来看pdf文档实在是不好看，寻思良久，网络上果然有狱越之法，遂记录之，以备固件升级重装之用。","text":"前不久女朋友送了个Kindle Voyage，不过用来看pdf文档实在是不好看，寻思良久，网络上果然有狱越之法，遂记录之，以备固件升级重装之用。 可升级固件当前固件版本已经升级到了5.8.5.0.2，这是不能升级的，需要手刷到低版本的固件，待越狱成功后，再手刷高版本的固件，这样越狱不会消失。可升级固件下载地址下载解压得到.bin文件放到kindle根目录下，断开USB连接，菜单-&gt;设置-&gt;菜单-&gt;更新你的Kindle更新重启即可。接下来你可以选择自动推送升级，或者自己手刷升级。所有固件下载地址 安装KUAL插件程序及插件包安装了这个插件你就可以干很多活儿了参考原文地址文中有两个附件，都下载完毕。 将KUAL-v2.7.zip解包，将其中的KUAL-KDK-2.0.azw2放到 kindle的documents目录下。 将kual-helper-0.5.N.zip解包，将extensions\\放到根目录下，这样越狱就算完成了。你就可以在你的书籍界面看到一个kindle launcher了 下载mrinstaller，直接解压到根目录即可包含extensions和mrpackages 下载kpvbooklet，然后将update_kpvbooklet_x.x.x_install.bin放到mrpackages目录。打开kindle launcher -&gt; helper -&gt; Install MR Packages，重启。 下载Koreader。解压，koreader文件夹放到根目录,extensions目录也复制到根目录 这样，你就可以打开epub 可以进行pdf重排了 展示 KV 5.9.4 越狱恢复下载两个文件：KUAL-v2.7.2-gea85a19-20171125.tar.xz kual-mrinstaller-1.6.N.zip 解压kual-mrinstaller-1.6.N.zip，直接解压把得到的两个文件夹复制到kindle根目录 打开KUAL-v2.7.2-gea85a19-20171125.tar.xz，找到Update_KUALBooklet_v2.7.2_install.bin文件，放到kindle的mrpackages文件夹内 弹出kindle 在kindle搜索 ;log mrpi 自动安装kual，自动重启","categories":[{"name":"Kindle","slug":"Kindle","permalink":"https://gowa2017.github.io/categories/Kindle/"}],"tags":[{"name":"Kindle","slug":"Kindle","permalink":"https://gowa2017.github.io/tags/Kindle/"},{"name":"越狱","slug":"越狱","permalink":"https://gowa2017.github.io/tags/越狱/"},{"name":"阅读","slug":"阅读","permalink":"https://gowa2017.github.io/tags/阅读/"}],"keywords":[{"name":"Kindle","slug":"Kindle","permalink":"https://gowa2017.github.io/categories/Kindle/"}]},{"title":"查看服务器信息.md","slug":"查看服务器硬件信息","date":"2016-11-02T02:29:50.000Z","updated":"2018-03-12T02:48:21.000Z","comments":true,"path":"Work/查看服务器硬件信息.html","link":"","permalink":"https://gowa2017.github.io/Work/查看服务器硬件信息.html","excerpt":"记录设备资产的时候会用到。","text":"记录设备资产的时候会用到。 Linux查看序列号：dmidecode -t 1 AIX 查看序列号：prtconf Sun查看序列号：prtdiag -v","categories":[{"name":"Work","slug":"Work","permalink":"https://gowa2017.github.io/categories/Work/"}],"tags":[{"name":"Work","slug":"Work","permalink":"https://gowa2017.github.io/tags/Work/"},{"name":"序列号","slug":"序列号","permalink":"https://gowa2017.github.io/tags/序列号/"},{"name":"硬件信息","slug":"硬件信息","permalink":"https://gowa2017.github.io/tags/硬件信息/"}],"keywords":[{"name":"Work","slug":"Work","permalink":"https://gowa2017.github.io/categories/Work/"}]},{"title":"信息系统日常操作.md","slug":"信息推送系统日常操作","date":"2016-11-01T05:40:50.000Z","updated":"2018-03-12T02:48:21.000Z","comments":true,"path":"Work/信息推送系统日常操作.html","link":"","permalink":"https://gowa2017.github.io/Work/信息推送系统日常操作.html","excerpt":"工作中需要用此系统来进行指定用户的信息推送。推送方案在前台上传设置。推送结束后统计覆盖率及成功率。","text":"工作中需要用此系统来进行指定用户的信息推送。推送方案在前台上传设置。推送结束后统计覆盖率及成功率。 一、登录infopush-radius1机器，进行入库操作1)先进入数据库清理上期清单：sqlplus infopush/asiainfo123@gzpushselect count(1) from push_user where policyid=100;delete from push_user where policyid=100;commit; 2)修改清单文件权限并查看记录数cd /home/ftp/push_userchown lcims.lcims KDTS_20161010.senawk ‘END &#123;print NR&#125;’ KDTS_20161010.sen 以lcims用户执行:/home/lcims/pushsys/interface/gzinterface/shell/getPushUser.sh 3)进库检查是否与文件一致sqlplus -s &quot;infopush/asiainfo123@gzpush&quot; &lt;&lt; !select count(*) from push_user where policyid=100;! 二、重启清洗模块cd /home/lcims/pushsys/FilterServer/sh./restart.sh 然后检查进程是否存在。策略模块此机不用重启。 三、重启infopush-radius2机器上的策略模块、清洗模块cd /home/lcims/pushsys/FilterServer/sh./restart.shcd /home/lcims/pushsys/lcbpis/sh./restart.sh 然后检查进程是否已启动。 四、批量加入黑名单操作切换oracle用户 su - oracle 编辑清单文件（一行一个） vi /tmp/whitelist/white_user.sen 执行入库脚本 /tmp/whitelist/whiter_user.sh policyID 执行步骤 三","categories":[{"name":"Work","slug":"Work","permalink":"https://gowa2017.github.io/categories/Work/"}],"tags":[{"name":"Work","slug":"Work","permalink":"https://gowa2017.github.io/tags/Work/"}],"keywords":[{"name":"Work","slug":"Work","permalink":"https://gowa2017.github.io/categories/Work/"}]},{"title":"F5的负载均衡","slug":"F5的负载均衡","date":"2016-10-31T08:39:08.000Z","updated":"2018-03-12T02:48:21.000Z","comments":true,"path":"Device/F5的负载均衡.html","link":"","permalink":"https://gowa2017.github.io/Device/F5的负载均衡.html","excerpt":"电信业务，如3A等都部署了负载均衡设备。F5、Array都有接触，但实在没空去研究细节，只能把其工作机理讲一下。进入F5去看的时候发现其BIG-IP系统本身即是一个Linux的发行版进行定制的，一应Linux utility 一应俱全。","text":"电信业务，如3A等都部署了负载均衡设备。F5、Array都有接触，但实在没空去研究细节，只能把其工作机理讲一下。进入F5去看的时候发现其BIG-IP系统本身即是一个Linux的发行版进行定制的，一应Linux utility 一应俱全。 从配置文件看起配置文件在 /config下，有 bigip_base.conf bigip_sys.conf bigip.conf bigip_local.conf等 基本概念POOL MEMBER IP:PORTNODE IPPOOL many POLL MEMBERSVIRTUAL SERVER F5对外提供的一个IP与端口，与POOL关联HEALTH MONITOR Node:icmp Pool member:tcp connection Content check:http GET / 工作流程bigip.conf文件包含了绝大部分的配置，包括Pool设置，Monitor设置，路由指定。以下配置，将发往 v-cw-1812服务(172.16.10.100:radius)的报文负载均衡到 cdma-1812-pool去&lt;!-- 对外提供服务并关联cdma-1812-pool--&gt;virtual v_cw-1812 &#123; pool cdma-1812-pool destination 172.16.10.100:radius ip protocol udp profiles fastL4 &#123;&#125; vlans &#123; vlan01-inside vlan3-cn2 &#125; enable&#125;&lt;!-- 定义了一个POOL 使用 cdma-1812-monitor来进行健康检测--&gt;pool cdma-1812-pool &#123; monitor all cdma-1812-monitor members &#123; 10.10.1.1:radius &#123;&#125; 10.10.1.2:radius &#123;&#125; 10.10.1.3:radius &#123;&#125; 10.10.1.4:radius &#123;&#125; 10.10.1.5:radius &#123;&#125; 10.10.1.6:radius &#123;&#125; 10.10.1.7:radius &#123;&#125; 10.10.1.8:radius &#123;&#125; 10.10.1.9:radius &#123;&#125; 10.10.1.10:radius &#123;&#125; 10.10.1.11:radius &#123;&#125; 10.10.1.12:radius &#123;&#125; &#125;&#125;&lt;!-- 检测服务是否可用 模拟发包--&gt;monitor cdma-1812-monitor &#123; defaults from radius dest \\*:radius password &quot;3413420131219&quot; secret &quot;jy343fd2504&quot; username &quot;cdmaevdoht&quot;&#125;&lt;!-- 将所有 origins的IP源地址修改为172.16.10.100 --&gt;snat out-to-cn2 &#123; translation 172.16.10.100 origins &#123; 10.10.1.1 10.10.1.2 10.10.1.3 10.10.1.4 10.10.1.5 10.10.1.6 10.10.1.7 10.10.1.8 10.10.1.9 10.10.1.10 10.10.1.11 10.10.1.12 &#125;&#125;&lt;!-- node 使用 icmp检测--&gt;node 10.10.1.1 &#123; monitor icmp screen pc_cdma01&#125;","categories":[{"name":"Device","slug":"Device","permalink":"https://gowa2017.github.io/categories/Device/"}],"tags":[{"name":"F5","slug":"F5","permalink":"https://gowa2017.github.io/tags/F5/"},{"name":"负载均衡","slug":"负载均衡","permalink":"https://gowa2017.github.io/tags/负载均衡/"}],"keywords":[{"name":"Device","slug":"Device","permalink":"https://gowa2017.github.io/categories/Device/"}]},{"title":"Oracle数据库基本架构","slug":"Oracle数据库基本架构","date":"2016-10-31T07:05:45.000Z","updated":"2018-03-12T02:48:21.000Z","comments":true,"path":"Oracle/Oracle数据库基本架构.html","link":"","permalink":"https://gowa2017.github.io/Oracle/Oracle数据库基本架构.html","excerpt":"ORACLE数据库服务器由物理存储的数据库及一个数据库实例组成(包括分配的内存区域、运行的进程等)。多数时候我们管理数据库并不再在意它的物理架构，而只在意它的逻辑架构。但是，对物理架构的了解会让你更容易进行管理好数据库。","text":"ORACLE数据库服务器由物理存储的数据库及一个数据库实例组成(包括分配的内存区域、运行的进程等)。多数时候我们管理数据库并不再在意它的物理架构，而只在意它的逻辑架构。但是，对物理架构的了解会让你更容易进行管理好数据库。 1、数据库的物理存储数据文件(data file)每个库有一个或多个数据文件(data file)，包括了数据库中的所有数据。可以通过 v$datafile dba_data_files 进行查看 控制文件(control file)每一个 Oracle 数据库都有控制文件（control file）。 控制文件包含元数据指定的数据库的物理结构，包括有数据库名称、数据库文件的名称和存储位置。可以通过v$controlfile进行查看。 在线重做日志文件(online redo log file)每一个 Oracle 数据库都有在线重做日志（online redo log），包含两个或多个在线重做日志文件（online redo log files）的集合。在线重做日志（redo log）由重做条目（或者称作重做记录（redo records）） 构 成 ， 其 中记录了所有数据的改变。 在数据恢复操作中，在线重做日志是最重要的。相关视图：v$log v$logfile 存档重做日志文件(archived Redo Log)对比Online，这是将一个或多个充满了的Online Log进行离线存储，数据库运行在ARCHIVELOG mode下由archiving进程处理 2、数据库的逻辑存储结构数据库的逻辑存储结构从大到小依次可为：表空间-&gt;段-&gt;区-&gt;数据块。每个数据库都会分配一个表空间。表空间至少包含一个数据文件(data file)。表空间是段逻辑上的容器。段则是区的集合，用来分配给用户的对象、撤销数据(undo data)、临时数据。数据库在表空间中使用数据段(data segment)来保存表中数据。一个段包含由数据块(data blocks)组成的扩展区(extents)。可以通过如下表或视图来查看信息。v$tablespacev$datafilev$tmpfiledba_tablespaces, user_tablespacesdba_free_space, user_free_spacedba_segments, user_segments","categories":[{"name":"Oracle","slug":"Oracle","permalink":"https://gowa2017.github.io/categories/Oracle/"}],"tags":[{"name":"Oracle","slug":"Oracle","permalink":"https://gowa2017.github.io/tags/Oracle/"}],"keywords":[{"name":"Oracle","slug":"Oracle","permalink":"https://gowa2017.github.io/categories/Oracle/"}]},{"title":"Oracle数据字典检查","slug":"Oracle数据字典检查","date":"2016-10-31T07:00:27.000Z","updated":"2018-03-12T02:48:21.000Z","comments":true,"path":"Oracle/Oracle数据字典检查.html","link":"","permalink":"https://gowa2017.github.io/Oracle/Oracle数据字典检查.html","excerpt":"作为一个Oracle菜鸟想要管理数据库，怎么能不看一下官方的文档呢，日常所用的检查也能了解得差不多了。表空间、数据文件、控制文件段等等都可以得到很好的解答。","text":"作为一个Oracle菜鸟想要管理数据库，怎么能不看一下官方的文档呢，日常所用的检查也能了解得差不多了。表空间、数据文件、控制文件段等等都可以得到很好的解答。那么下面，我们开始了。 查看数据库及链接库SELECT * from v$database; SELECT * from dba_db_links; 查看控制文件SELECT * FROM V$CONTROLFILE; 查看数据在线重做日志文件SELECT * FROM V$LOG; SELECT * FROM V$LOGFILE; 查看回滚表空间SELECT OWNER,SUM(BYTES)/1024/1024 AS &quot;I_SIZE/MB&quot; FROM DBA_UNDO_EXTENTS GROUP BY OWNER; 查看数据文件与表空间关联SELECT * FROM DBA_DATA_FILES; 查询某一表空间的数据文件SELECT file_name,bytes/1024/1024 as &quot;size&quot;,online_status FROM dba_data_files WHERE tablespace_name=&#39;OTHER_DATA&#39;; 查看表空间大小SELECT TABLESPACE_NAME,SUM(BYTES)/1024/1024 AS &quot;TOTAL/MB&quot; FROM DBA_DATA_FILES GROUP BY TABLESPACE_NAME ORDER BY TABLESPACE_NAME; 查看空闲表空间SELECT TABLESPACE_NAME,SUM(BYTES)/1024/1024 AS &quot;FREE / MB&quot; FROM DBA_FREE_SPACE GROUP BY TABLESPACE_NAME; 查看某一表空间内使用最多的表SELECT SEGMENT_NAME,SUM(BYTES)/1024/1024 AS USED FROM DBA_SEGMENTS T WHERE TABLESPACE_NAME=&#39;OTHER_INDEX&#39; GROUP BY SEGMENT_NAME ORDER BY USED DESC; 查看所有表与表空间关联SELECT * FROM USER_TABLES; 查看表空间使用情况SELECT tbs tablespace_name, sum(totalM), sum(usedM), sum(remainedM), round(sum(usedM)/sum(totalM)*100,2) as &quot;use%&quot;, round(sum(remainedM)/sum(totalM)*100,2) as &quot;free%&quot; FROM(SELECT b.file_id ID, b.tablespace_name tbs, b.file_name name, b.bytes/1024/1024 totalM, (b.bytes-sum(nvl(a.bytes,0)))/1024/1024 usedM, sum(nvl(a.bytes,0)/1024/1024) remainedM, sum(nvl(a.bytes,0)/(b.bytes)*100), (100 - (sum(nvl(a.bytes,0))/(b.bytes)*100)) FROM dba_free_space a,dba_data_files b WHERE a.file_id = b.file_id GROUP BY b.tablespace_name,b.file_name,b.file_id,b.bytes ORDER BY b.tablespace_name) GROUP BY tbs; 为表空间增加一个数据文件ALTER tablespace_name ADD DATAFILE &#39;data2.ora&#39;; 表空间数据文件设置为自增ALTER DATABASE DATAFILE &#39;data3.ora&#39; AUTOEXTEND ON NEXT 50M MAXSIZE 1000M; 新建一个表空间CREATE tablespace_name DATAFILE &#39;data4.ora&#39; SIZE 2G;","categories":[{"name":"Oracle","slug":"Oracle","permalink":"https://gowa2017.github.io/categories/Oracle/"}],"tags":[{"name":"Oracle","slug":"Oracle","permalink":"https://gowa2017.github.io/tags/Oracle/"},{"name":"数据库","slug":"数据库","permalink":"https://gowa2017.github.io/tags/数据库/"}],"keywords":[{"name":"Oracle","slug":"Oracle","permalink":"https://gowa2017.github.io/categories/Oracle/"}]},{"title":"PPPoe-以太网上的点对点传输协议","slug":"PPPoe-以太网上的点对点传输协议","date":"2016-10-31T06:24:42.000Z","updated":"2018-03-12T02:48:21.000Z","comments":true,"path":"Network/PPPoe-以太网上的点对点传输协议.html","link":"","permalink":"https://gowa2017.github.io/Network/PPPoe-以太网上的点对点传输协议.html","excerpt":"PPPoE（英语：Point-to-Point Protocol Over Ethernet），以太网上的点对点协议，是将点对点协议（PPP）封装在以太网（Ethernet）框架中的一种网络隧道协议。由于协议中集成PPP协议，所以实现出传统以太网不能提供的身份验证、加密以及压缩等功能，也可用于缆线调制解调器（cable modem）和数字用户线路（DSL）等以以太网协议向用户提供接入服务的协议体系。本质上，它是一个允许在以太网 广播域中的两个以太网接口间创建点对点隧道的协议。","text":"PPPoE（英语：Point-to-Point Protocol Over Ethernet），以太网上的点对点协议，是将点对点协议（PPP）封装在以太网（Ethernet）框架中的一种网络隧道协议。由于协议中集成PPP协议，所以实现出传统以太网不能提供的身份验证、加密以及压缩等功能，也可用于缆线调制解调器（cable modem）和数字用户线路（DSL）等以以太网协议向用户提供接入服务的协议体系。本质上，它是一个允许在以太网 广播域中的两个以太网接口间创建点对点隧道的协议。 协议概述PPPoE分为两个阶段，即Discovery（地址发现）阶段和PPP会话阶段。当某个主机希望发起一个PPPoE会话时，它必须首先执行Discovery来确定对方的以太网MAC地址并建立起一个PPPoE会话标识符SESSION_ID(Access Concentrator生成)。虽然PPP定义的是端到端的对等关系，Discovery却是天生的一种客户端-服务器关系。在Discovery的过程中,主机(作为客户端)发现某个访问集中器（Access Concentrator，作为服务器），根据网络的拓扑结构，可能主机能够跟不止一个的访问集中器通信 。Discovery阶段允许主机发现所有的访问集中器并从中选择一个。当Discovery阶段成功完成之后，主机和访问集中器两者都具备了用于在以太网上建立点到点连接所需的所有信息。Discovery阶段保持无状态（stateless）直到建立起一个PPP会话。一旦PPP会话建立，主机和访问集中器两者都必须为一个PPP虚拟接口分配资源。 报文格式以太网帧格式(更多介绍请查看RFC894/tcp/ip协议详解:卷1 第2章)ETHER_TYPE设置为0x8863(Discovery阶段)或者0x8864(PPP会话阶段) payloadheader payload内容包含0个或多个tag，每个tag是一个tlv(type-length-value)三元组 发现阶段(discovery stage)发现阶段分为四步:PADI、PADO、PADR、PADS。当HOST收到PADS后，那么HOST与AC(access concentrator)间的点对点关系就已建立，进入了会话阶段(session stage)。 PPPoE Active Discovery Initiation数据包(PADI)主机发送DESTINATION_ADDR 为广播地址的PADI数据包，CODE域设置为0x09,SESSION_ID域必须设置为0x0000。PADI数据包必须包含且仅包含一个TAG_TYPE为Service-Name的TAG，以表明主机请求的服务，以及任意数目的其它类型的TAG。整个PADI数据包（包括PPPoE头部）不允许超过1484个字节，以留足空间让中继代理（向数据包中）增加类型为Relay-Session-Id的TAG。 The PPPoE Active Discovery Offer 数据包(PADO) 如果访问集中器能够为收到的PADI请求提供服务，它将通过发送一个PADO数据包来做出应答。DESTINATION_ADDR为发送PADI的主机的单播地址，CODE域为0x07,SESSION_ID域必须设置为0x0000。 PADO数据包必须包含一个类型为AC-Name的TAG（包含了访问集中器的名字），与PADI中相同的Service-Name，以及任意数目的类型为Service-Name的TAG表明访问集中器提供的其它服务。如果访问集中器不能为PADI提供服务，则不允许用PADO作响应。 The PPPoE Active Discovery Request 数据包(PADR) 由于PADI是广播的,主机可能收到不止一个PADO,它将审查接收到的所有PADO并从中选择一个。可以根据其中的AC-Name或PADO所提供的服务来作出选择。然后主机向选中的访问集中器发送一个PADR数据包。其中，DESTINATION_ADDR域设置为发送PADO的访问集中器的单播地址，CODE域设置为0x19，SESSION_ID必须设置为0x0000。 PADR必须包含且仅包含一个TAG_TYPE为Service-Name的TAG，表明主机请求的服务，以及任意数目其他类型的TAG。 The PPPoE Active Discovery Session-confirmation 数据包(PADS) 当访问集中器收到一个PADR数据包，它就准备开始一个PPP会话。它为PPPoE会话创建一个唯一的SESSION_ID并用一个PADS数据包来给主机作出响应。DESTINATION_ADDR域为发送PADR数据包的主机的单播以太网地址，CODE域设置为0x65,SESSION_ID必须设置为所创建好的PPPoE会话标识符。 PADS数据包包含且仅包含一个TAG_TYPE为Service-Name的TAG，表明访问集中器已经接受的该PPPoE会话的服务类型，以及任意数目的其他类型的TAG。 如果访问集中器不喜欢PADR中的Service-Name,那么它必须用一个带有类型为Service-Name-Error的TAG(以及任意数目的其它TAG类型)的PADS来作出应答。这种情况下，SESSION_ID必须设置为0x0000。 The PPPoE Active Discovery Terminate数据包(PADT) 这种数据包可以在会话建立以后的任意时刻发送，表明PPPoE会话已经终止。它可以由主机或访问集中器发送，DESTINATION_ADDR域为单播以太网地址，CODE域设置为0xa7,SESSION_ID必须表明终止的会话，这种数据包不需要任何TAG。 当收到PADT以后，就不允许再使用该会话发送PPP流量了。在发送或接收到PADT后，即使是常规的PPP结束数据包也不允许发送。PPP通信双方应该使用PPP协议自身来结束PPPoE会话，但在无法使用PPP时可以使用PADT。 会话阶段(session stage)一旦PPPoE会话开始，PPP数据就像其它PPP封装一样发送。所有的以太网数据包都是单播的。ETHER_TYPE域设置为0x8864。PPPoE的CODE必须设置为0x00。PPPoE会话的SESSION_ID不允许发生改变，必须是Discovery阶段所指定的值。PPPoE的payload包含一个PPP帧，帧始于PPP Protocol-ID。 TAG_TYPE和TAG_VALUE0x0000 End-Of-List 该TAG表明表中没有其它TAG了。该TAG的TAG_LENGTH必须总是0。不要求使用该标签，存在是为了向后兼容。 0x0101 Service-Name 该TAG表明后面紧跟的是服务的名称。TAG_VALUE是不以NULL结束的UTF-8字符串。当TAG_LENGTH为0时，该TAG用于表明接受任何服务。使用Service-Name标签的例子是表明ISP(Internet服务提供商)或者一类服务或者服务的质量。 0x0102 AC-Name 该TAG表明后面紧跟的字符串唯一地表示了某个特定的访问集中器。它可以是商标、型号以及序列号等信息的集合，或者该访问集中器MAC地址的一个简单的UTF-8表示。它不以NULL来结束。 0x0103 Host-Uniq 该TAG由主机用于把访问集中器的响应（PADO或者PADS）与主机的某个唯一特定的请求联系起来。TAG_VALUE是主机选择的长度和值为任意的二进制数据。它不能由访问集中器解释。主机可以在PADI或者PADR中包含一个Host-Uniq标签。如果访问集中器收到了该标签，它必须在对应的PADO或者PADS中不加改变的包含该标签。 0x0104 AC-Cookie 该TAG由访问集中器用于防止拒绝服务攻击（见“安全方面的考虑”）。访问集中器可以在PADO数据包中包含该TAG。如果主机收到了该标签，它必须在接下来的PADR中不加改变的包含该标签。TAG_VALUE I是长度和值任意的二进制数据，不能由主机解释。 0x0105 Vendor-Specific 该TAG用来传送厂商自定义的信息。TAG_VALUE的头4个字节包含了厂商的识别码 ，其余字节尚未定义。厂商识别码的高字节为0，低3个字节为网络字节序的厂商的SMI网络管理专用企业码，如“定义值RFC”（参考文献[4]）中定义的那样。 不推荐使用该TAG。为了确保互操作性，实现可以悄悄的忽略Vendor-Specific TAG。 0x0110 Relay-Session-Id 该TAG可由中继流量的中间代理加入到Discovery数据包中。TAG_VALUE对主机和访问集中器都是晦涩难懂的（paque）。如果主机或访问集中器收到该TAG，则它们必须在所有的Discovery数据包中包含该TAG以作为响应。所有的PADI数据包必须保证足够空间来加入TAG_VALUE长度为12字节的Relay-Session-Id标签。 如果Discovery数据包中已经包含一个Relay-Session-Id标签，则不允许再加入该标签。这种情况下，中间代理应该使用该现有的Relay-Session-Id标签。如果它不能使用现有的标签，或者没有足够空间来增加一个Relay- Session-Id标签,那么它应该向发送者返回一个Generic-Error标签。 0x0201 Service-Name-Error 该TAG(典型的有一个长度为零的数据部分)表明了由于某种原因，没有理睬所请求的Service-Name。如果有数据部分,并且数据部分的头一个字节非0，那么它必须是一个 可打印的UTF-8字符串，解释请求被拒绝的原因。该字符串可以不以NULL结束。 0x0202 AC-System-Error 该TAG表明了访问集中器在处理主机请求时出现了某个错误。(例如没有足够资源来创建一个虚拟电路。PADS数据包中可以包含该标签。 如果有数据，并且数据的第一个字节不为0，那么（数据）必须是一个可打印的UTF-8 字符串，该字符串解释了错误的性质。该字符串可以不以NULL结束。 0x0203 Generic-Error 该TAG表明发生了一个错误。当发生一个不可恢复的错误并且没有其它合适的TAG时，它可被加到PADO, PADR或PADS数据包中。如果出现数据部分，那么数据必须是一个UTF-8字符串，解释错误的性质。该字符串不允许以NULL结束。 数据包例子","categories":[{"name":"Network","slug":"Network","permalink":"https://gowa2017.github.io/categories/Network/"}],"tags":[{"name":"PPPoE","slug":"PPPoE","permalink":"https://gowa2017.github.io/tags/PPPoE/"}],"keywords":[{"name":"Network","slug":"Network","permalink":"https://gowa2017.github.io/categories/Network/"}]},{"title":"OpenSSH升级","slug":"OpenSSH升级","date":"2016-10-31T06:06:47.000Z","updated":"2018-03-12T02:48:21.000Z","comments":true,"path":"Linux/OpenSSH升级.html","link":"","permalink":"https://gowa2017.github.io/Linux/OpenSSH升级.html","excerpt":"SSH，运维人员都不会陌生，可以说天天都与之打交道。但是时不时爆出的漏洞也让人感到很无语，对于大批量的服务器的要让我做安全加固的时候，内心其实是崩溃的。如果不是非常必要的话，还是用iptables/ipsec等方式来进行包过滤吧，这升级，实在是太折腾人了，本文并不保证在你的机器上能没有毛病的升级。","text":"SSH，运维人员都不会陌生，可以说天天都与之打交道。但是时不时爆出的漏洞也让人感到很无语，对于大批量的服务器的要让我做安全加固的时候，内心其实是崩溃的。如果不是非常必要的话，还是用iptables/ipsec等方式来进行包过滤吧，这升级，实在是太折腾人了，本文并不保证在你的机器上能没有毛病的升级。OpenSSH官方安装文档 环境 OS: CentOS 6.8 x64 zlib: 1.1.4 or 1.2.1.2 版本上 libcrypto: OpenSSL &gt;=0.9.8f &lt; 1.1.0 LibreSSL/OpenSSL should be compiled as a position-independent library(i.e. with -fPIC) otherwise OpenSSH will not be able to link with it.If you must use a non-position-independent libcrypto, then you may needto configure OpenSSH —without-pie. Note that because of API changes,OpenSSL 1.1.x is not currently supported. 1、开启 telnet 服务Linuxyum install -y telnet-server telnet /etc/xinet.d/telnet 中的yes 修改为no service xinetd restart AIXlssrc -s inetd startsrc -t telnet stopsrc -t telnet 2、下载相关文件wget http://ftp.openbsd.org/pub/OpenBSD/OpenSSH/portable/openssh-7.4p1.tar.gz wget https://www.openssl.org/source/openssl-1.0.1u.tar.gz wget https://sourceforge.net/projects/libpng/files/zlib/1.2.8/zlib-1.2.8.tar.gz --no-check-certificate 3、编译安装安装zlibtar zxvf zlib-1.2.8.tar.gz cd zlib-1.2.8 ./configure make &amp;&amp; make install 安装openssl解压 tar zxvf openssl-1.0.1u.tar.gz cd openssl-1.0.1u 快速开始 ./config -fPIC shared zlib make make install 这将会把OpenSSL安装在默认位置（因为历史原因）/usr/local/ssl。我们可以验证一下: ls -1 /usr/local/ssl bincertsincludelibmanmiscopenssl.cnfprivate 安装在自定义位置如果想安装在一个自己想要的地方，可以像下面一样指定： ./config -fPIC shared zlib --prefix=/usr/local --openssldir=/usr/local/openssl make make depend # if prompted then you must do so make test make install 安装前后的不同正常情况下（Linux）系统本身的openssl位于/usr/{bin,lib[64],include/openssl}，为了我们使用到的是新安装的，我们还需要做一下动作 mv /usr/bin/openssl /usr/bin/openssl.bak mv /usr/include/openssl /usr/include/openssl.bak ln -s /usr/local/ssl/bin/openssl /usr/bin/openssl ln -s /usr/local/ssl/include/openssl /usr/include/openssl echo &quot;/usr/local/ssl/lib&quot; &gt;&gt; /etc/ld.so.conf ldconfig -v 关于安装后的目录 bin openssl二进制文件和一些其他程序 include/openssl 在协同libcrypto或libssl编译程序的时候需要的头文件 lib OpenSSL库文件关于编译的选项 —prefix=DIR 安装在DIR/{bin,lib,include/openssl}，配置文件会在DIR/ssl或者 --openssldir指定的目录。 —openssldir=DIR OpenSSL文件的目录。如果没有指定—prefix，那么二进制文件也会安装在这个地方。 —prefix —openssldir 1.0.2及以下版本，可以不用指定，默认是/usr/local/ssl。1.1.0以上则必须指定。请避免使用—prefix=/usr no-threads 编译的时候不使用多进程。 threads 编译的时候使用多进程 no-zlib 编译的时候不进行zlib压缩、解压缩支持 zlib 编译支持zlib压缩、解压缩 zlib-dynamic 类似zlib，只在需要的时候载入zlib库，只在允许共享库的操作系统。默认选择 no-shared 不创建共享库文件 shared 对静态库的补充，还会创建共享库文件。安装过程中遇到的问题编译的时候出现 Bad Value类似的错误，需要 make clean一下。然后重新./config shared zlib，再进行编译就OK。 安装OpenSSH 解压 tar zxvf openssh-7.4p1.tar.gz cd openssh-7.4p1 安装 ./configure --sysconfdir=/etc/ssh --with-pam make make install sed -i &#39;s/^GSSAPI/#&amp;/&#39; /etc/ssh/sshd_config 这样会将OpenSSH二进制文件安装到/usr/local/bin，配置文件在/usr/local/etc，服务在/usr/local/sbin。安装在不同位置如果想安装在不同的位置，可以指定--prefix。 ./configure --prefix=/usr/opt \\ # Will install OpenSSH in /usr/opt/{bin,etc,lib,sbin} --sysconfdir=/etc/ssh \\ # will place the configuration files in /etc/ssh. make make install 4、修改启动文件并重启vi /etc/init.d/sshd ，修改SSHD=/usr/sbin/sshd 为 SSHD=/usr/local/sbin/sshd sed -i &#39;s#sbin/sshd#local/&amp;#&#39; /etc/init.d/sshd /etc/init.d/sshd restart 5、 验证安装telnet 127.0.0.1 22 验证 根据回显看是否成功 6、替换客户端mv /usr/bin/ssh /usr/bin/ssh_bak ln -s /usr/local/bin/ssh /usr/bin/ssh","categories":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/tags/Linux/"},{"name":"SSH","slug":"SSH","permalink":"https://gowa2017.github.io/tags/SSH/"},{"name":"OpenSSH","slug":"OpenSSH","permalink":"https://gowa2017.github.io/tags/OpenSSH/"},{"name":"OpenSSL","slug":"OpenSSL","permalink":"https://gowa2017.github.io/tags/OpenSSL/"}],"keywords":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}]},{"title":"AIX用IPSec进行包过滤","slug":"AIX用IPSec进行包过滤","date":"2016-10-31T05:56:55.000Z","updated":"2018-03-12T02:48:21.000Z","comments":true,"path":"AIX/AIX用IPSec进行包过滤.html","link":"","permalink":"https://gowa2017.github.io/AIX/AIX用IPSec进行包过滤.html","excerpt":"Linux上有iptables这样好用的包过滤工具，AIX肯定也有，只是以前没有接触过而已，最近要公司要给一批AIX服务器进行安全加固，所以就用到了相关的知识。IPSEC是一个协议，HU－UX，SunOS，AIX都有类似的机制。此文讲述了IPSEC的开启及规则的建立。","text":"Linux上有iptables这样好用的包过滤工具，AIX肯定也有，只是以前没有接触过而已，最近要公司要给一批AIX服务器进行安全加固，所以就用到了相关的知识。IPSEC是一个协议，HU－UX，SunOS，AIX都有类似的机制。此文讲述了IPSEC的开启及规则的建立。 AIX上的IPSEC在AIX可以通过以下步骤打开IP Security smitty ipsec4 —&gt; Start/Stop IP Security —&gt; Start IP Security [Now and After Reboot] 注意，此时请将 Deny All Non_Secure IP Packets [no]敲Enter Command: OK stdout: yes stderr: no Before command completion, additional instructions may appear below. ipsec_v4 Available Default rule for IPv4 in ODM has been changed. Successfully set default action to PERMIT 此时启动，默认IPv4规则已经设置，同时默认动作是 PERMIT。这时我们可以用命令查看一下设备状态 lsdev -C -c ipsec ipsec_v4 Available IP Version 4 Security Extension ipsec_v6 Available IP Version 6 Security Extension 相关管理命令为： lsfilt mkfilt mvfilt chfilt ckfilt genfilt rmfilt 查看规则lsfilt -v4 -O 1|permit|0.0.0.0|0.0.0.0|0.0.0.0|0.0.0.0|no|udp|eq|4001|eq|4001|both|both|no|all packets|0|all|0|||Default Rule 2|*** Dynamic filter placement rule for IKE tunnels ***|no 0|permit|0.0.0.0|0.0.0.0|0.0.0.0|0.0.0.0|yes|all|any|0|any|0|both|both|no|all packets|0|all|0|||Default Rule 我们可以通过smitty来进行增加规则。 smitty ipsec4 --&gt; Advanced IP Security Configuration -&gt; Configure IP Security Filter Rules -&gt; Add an IP Security Filter Rules. * Rule Action [permit] * IP Source Address [] * IP Source Mask [] IP Destination Address [] IP Destination Mask [] * Apply to Source Routing? (PERMIT/inbound only) [yes] * Protocol [all] * Source Port / ICMP Type Operation [any] * Source Port Number / ICMP Type [0] * Destination Port / ICMP Code Operation [any] * Destination Port Number / ICMP Type [0] * Routing [both] * Direction [both] * Log Control [no] * Fragmentation Control [0] * Interface [] Expiration Time (sec) [] Pattern Type [none] Pattern [] Description [] genfilt命令增加规则genfilt与以上操作有异曲同工之效，基本命令模式 genfilt -v 4|6 [ -n fid] [ -a D|P|I|L|E|H|S ] -s s_addr -m s_mask [-d d_addr] [ -M d_mask] [ -g Y|N ] [ -c protocol] [ -o s_opr] [ -p s_port] [ -O d_opr] [ -P d_port] [ -r R|L|B ] [ -w I|O|B ] [ -l Y|N ] [ -f Y|N|O|H ] [ -t tid] [ -i interface] [-D description] [-e expiration_time] [-x quoted_pattern] [-X pattern_filename ] [-C antivirus_filename] -C antivirus_filename 指定抗病毒名。-C 标志意味着ClamAV病毒库的一些版本。-D description 描述介绍。-v 4|6 指定IP版本-n fid 所添加ID将会被添加至第 fid 条规则之前-a Action D(eny) | P(ermit) | I(f) | (e)L(se) | E(ndif)。所有IF规则必须关联ENDIF规则结束。-s s_addr 源地址-m s_mask 源地址掩码-d d_addr 目标地址-M d_mask 目标地址掩码-g Y|N 用于Permit规则，默认为Y，表示过滤规则可以使用源路由的IP包。-c protocol 协议，默认all。有效值udp/icmp/icmpv6/tcp/tcp.ack/ospf/ipip/esp/ah/all-o s_opr | ICMP Code Opertion 源端口或者ICMP类型 操作。有效值:lt/le/gt/ge/eq/neq/any。默认any，当-c ospf时，必须为any。-p s_port 源端口或ICMP类型。-O d_opr | ICMP Code Opertion 目标端口或者ICMP类型 操作。有效值:lt/le/gt/ge/eq/neq/any。默认any，当-c ospf时，必须为any。-P d_port 目标端口或ICMP类型-r R|L|B 路由，默认B。指定规则是用于R(转发包)、L（发往或来自本机的包）、B（两者都使用）-w I|O|B 默认B。指定规则应用于I（输入包）、O（输出包）、B（两者都使用）。使用代-x -X或-C 模式是使用O选项无效，使用B有效，但只检查输入包。-l Y|N 是否记录（匹配规则的包）日志，默认N。-f Y|N|O|H 分段控制、默认为Y（所有包）。N（未分段包）、O（只用于分段和分段头）、H（只应用于分段头和未分段）。-t tid 指定于该规则相关的通道标识，所有匹配包都要经过此通道。不指定此项，规则只作用于非流量通道。-i interface 指定接口卡，默认为all。-e expiration_time 过期时间（秒）。-x pattern 匹配模式-X patternfile 匹配模式文件。每行一个模式常用举例： genfilt -v 4 -a P -s 192.168.0.1 -m 255.255.255.0 -d 192.168.0.88 -M 255.255.255.255 [-o any] [-p 0] -O eq -P 22 [-r B] [-w B] -l Y [-f Y] [-i all] -D &quot;permit lan host visit port 22&quot; [-e 0] 默认情况下我们加限制22端口的话，对所有的包都会进行规则匹配。可以利用默认的设置而进行简略 genfilt -v 4 -a P -s 192.168.0.1 -m 255.255.255.0 -d 192.168.0.88 -M 255.255.255.255 -O eq -P 22 genfilt -v 4 -a D -O eq -P 22 使命令生效mkfilt -v 4|6 [-d] [-u] [-z P|D] [-g start|stop] -i -u 激活rule table中的所有状态的规则。与-d 互斥-d 停止表中规则。与-u 互斥-z 使默认规则（最后一条）执行P或者D动作。-g 日志启动与停止-i 与-u一起使用，激活所有”active”状态规则。","categories":[{"name":"AIX","slug":"AIX","permalink":"https://gowa2017.github.io/categories/AIX/"}],"tags":[{"name":"AIX","slug":"AIX","permalink":"https://gowa2017.github.io/tags/AIX/"},{"name":"IPSec","slug":"IPSec","permalink":"https://gowa2017.github.io/tags/IPSec/"},{"name":"加固","slug":"加固","permalink":"https://gowa2017.github.io/tags/加固/"}],"keywords":[{"name":"AIX","slug":"AIX","permalink":"https://gowa2017.github.io/categories/AIX/"}]},{"title":"SYSLOG审计日志配置","slug":"SYSLOG审计日志配置","date":"2016-10-31T05:42:08.000Z","updated":"2018-03-12T02:48:21.000Z","comments":true,"path":"AIX/SYSLOG审计日志配置.html","link":"","permalink":"https://gowa2017.github.io/AIX/SYSLOG审计日志配置.html","excerpt":"前言syslog是UNIX系统中提供的一种日志记录方法(RFC3164)，syslog本身是一个服务器，程序中凡是使用syslog记录的信息都会发送到该服务器，服务器根据配置决定此信息是否记录，是记录到磁盘文件还是其他地方，这样使系统内所有应用程序都能以统一的方式记录日志，为系统日志的统一审计提供了方便。AIX上同样提供这套服务。","text":"前言syslog是UNIX系统中提供的一种日志记录方法(RFC3164)，syslog本身是一个服务器，程序中凡是使用syslog记录的信息都会发送到该服务器，服务器根据配置决定此信息是否记录，是记录到磁盘文件还是其他地方，这样使系统内所有应用程序都能以统一的方式记录日志，为系统日志的统一审计提供了方便。AIX上同样提供这套服务。 服务与配置默认情况下，配置文件位于/etc/syslog.conf。但我们可以用-f选项来指定程序启动时读取的配置文件。AIX使用 startsrc -s syslogd stopsrc -s syslogd 来启动或者停止相应服务。 配置文件配置文件用来告诉syslogd服务将哪些程序产生的，什么等级的信息，写入到什么地方。每行配置文件类似以下格式： selection action rotation &lt;msg_src_list&gt; &lt;destination&gt; [rotate [size &lt;size&gt; k|m] [files &lt;files&gt;] [time &lt;time&gt; h|d|w|m|y] [compress] [archive &lt;archive&gt;]] 程序选择：kern 内核 user 用户等级 mail 邮件子系统 daemon 守护程序 auth 安全或授权 syslog syslogd守护程序 lpr 行式打印机 news 新闻子系统 uucp uucp子系统 local0-7 本地使用 * 所有程序 优先级emerg 指定紧急消息（LOG_EMERG）。这些消息并非分发给所有用户。可以将 LOG_EMERG 优先级消息记录到单独文件备查。alert 指定重要的消息（LOG_ALERT），如严重的硬件错误。这些消息分发给所有用户。crit 指定不列为错误的关键消息（LOG_CRIT），如不适当的登录尝试。LOG_CRIT 和较高优先级消息会发送到系统控制台。err 指定表示错误情况的消息（LOG_ERR），例如失败的磁盘写入。warning 指定反常但可恢复的情况的消息（LOG_WARNING）。notice 指定重要的参考消息（LOG_NOTICE）。没有指定优先级的消息会映射为此优先级的消息。info 指定参考消息（LOG_INFO）。这些消息可以废弃，但它们在分析系统是很有用。debug 指定调试消息（LOG_DEBUG）。这些消息可以废弃。none 排除选定的程序。只有在同一 selector 字段里跟在带有 *（星号）的条目后时，该优先级级别才有用。 例子 1. 要在调试级别或更高级别将所有的邮件工具消息记录到文件 /tmp/mailsyslog，请输入以下命令： mail.debug /tmp/mailsyslog 2. 要将除来自邮件工具之外的所有系统消息发送到主机 rigil，请输入以下命令： *.debug;mail.none @rigil 3. 要将所有工具中优先级为 emerg 的消息和邮件工具与守护程序工具中优先级为 crit 及更高级别的消息发送到用户 nick 和 jam，请输入以下命令： *.emerg;mail,daemon.crit nick, jam 4. 要将所有邮件工具消息发送到所有用户的终端屏幕，请输入以下命令： mail.debug * 5. 要将调试级别或更高级别的工具消息记录到 /tmp/syslog.out，并且在下列情况下旋转文件：文件超过 500 KB，一周之后将旋转文件数限制为 10，使用压缩并使用 /syslogfiles 作为归档目录，请输入以下命令： *.debug /tmp/syslog.out rotate size 500k time 1w files 10 compress archive /syslogfiles &lt;S-Del&gt;","categories":[{"name":"AIX","slug":"AIX","permalink":"https://gowa2017.github.io/categories/AIX/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/tags/Linux/"},{"name":"unix","slug":"unix","permalink":"https://gowa2017.github.io/tags/unix/"}],"keywords":[{"name":"AIX","slug":"AIX","permalink":"https://gowa2017.github.io/categories/AIX/"}]},{"title":"AIX-chsec命令修改配置文件","slug":"AIX-chsec命令修改配置文件","date":"2016-10-31T05:40:50.000Z","updated":"2018-03-12T02:48:21.000Z","comments":true,"path":"AIX/AIX-chsec命令修改配置文件.html","link":"","permalink":"https://gowa2017.github.io/AIX/AIX-chsec命令修改配置文件.html","excerpt":"AIX的所有配置设置通过一个命令来进行更改配置文件中的键－值对，以达到修改配置的目的。如：group/user/limits/passwd等等。每次都用编辑器去改实在是太LOW了。","text":"AIX的所有配置设置通过一个命令来进行更改配置文件中的键－值对，以达到修改配置的目的。如：group/user/limits/passwd等等。每次都用编辑器去改实在是太LOW了。 前言AIX的所有配置设置通过一个命令来进行更改配置文件中的键－值对，以达到修改配置的目的。如：group/user/limits/passwd等等 命令格式chsec [-f file] [-s Stanza] [-a attribute = value ...] 可以进行修改的配置文件/etc/security/environ/etc/security/group/etc/security/audit/hosts/etc/security/lastlog/etc/security/limits/etc/security/login.cfg/usr/lib/security/mkuser.default/etc/nscontrol.conf/etc/security/passwd/etc/security/portlog/etc/security/pwdalg.cfg/etc/security/roles/etc/security/rtc/rtcd_policy.conf/etc/security/smitacl.user/etc/security/smitacl.group/etc/security/user/etc/security/user.roles/etc/secvars.cfg 补充说明Stanza参数限制 修改/etc/security下的environ、last、limists、passwd、user，必须是有效的用户名或default。 修改groups时必须是有效的组名或者default。 修改portlog时必须是有效的端口名。 修改login.cfg时必须是有效的端口名、方法名或usw属性。 修改portlog、login.cfg中不存在的节属性时，自动创建该节。 passwd文件中的passwd节不能用chsec修改，只能用passwd命令修改 修改/usr/lib/security/mkuser.default时必须是admin或user。 例子1.修改默认密码策略 chsec -f /etc/security/user -s default -a minlen=8 -a histexpire=12 -a umask=077 -a loginretries=6 -a histsize=5 2.禁止root直接登录 chsec -f /etc/security/user -s root -a rlogin=false 3.允许所有用户登录时间 chsec -f /etc/security/user -s defalut -a logintimes=:0800-1700","categories":[{"name":"AIX","slug":"AIX","permalink":"https://gowa2017.github.io/categories/AIX/"}],"tags":[{"name":"AIX","slug":"AIX","permalink":"https://gowa2017.github.io/tags/AIX/"}],"keywords":[{"name":"AIX","slug":"AIX","permalink":"https://gowa2017.github.io/categories/AIX/"}]},{"title":"CentOS system install and setup","slug":"CentOS-system-install-and-setup","date":"2016-10-31T04:05:57.000Z","updated":"2018-03-12T02:48:21.000Z","comments":true,"path":"Linux/CentOS-system-install-and-setup.html","link":"","permalink":"https://gowa2017.github.io/Linux/CentOS-system-install-and-setup.html","excerpt":"大多数时候我们需要安装系统并进行一下配置，乃至加固等，这就记录一下，下次就不弄到处去找来给人了。包括LVM建立、服务启动设置、SSH设置、网卡配置、源配置","text":"大多数时候我们需要安装系统并进行一下配置，乃至加固等，这就记录一下，下次就不弄到处去找来给人了。包括LVM建立、服务启动设置、SSH设置、网卡配置、源配置 1安装时分区建立 建立/boot分区 500M /swap 10000M 剩余空间建立PV PV加入VG 建立LV 全部挂在到/ 2安装模式选择基本安装 开发工具全部装，SERVER 全部不选，中文语言支持装上，记得gcc一定要安装 3设置DVD源 mkdir /media/dvd mount /dev/cdrom /media/dvd cd /etc/yum.repos.d mv CentOS-Base.repo CentOS-Base.repo.bak 修改 baseurl 增加 file:///media/dvd设置enable=1 yum clear all 4服务开启 chkconfig —level 35 ntpd on chkconfig —level 35 sshd on chkconfig —level 35 network on chkconfig —level 35 iptables off chkconfig —level 35 networkmanager off service networkmanager stop 5禁止root登录 sed -i ‘s/PermitRootLogin yes/PermitRootLogin no/‘ /etc/ssh/sshd_config 6增加用户并修改密码 groupadd lcims useradd -d /lcims -s /bin/bash -g lcims lcims chown lcims.lcims /data passwd lcims 7修改显示模式 echo “export PS1=’[\\u@\\h $PWD]# ‘“ &gt;&gt; /etc/profile source /etc/profile 8主机名 vim /etc/sysconfig/network 9双网卡配置 检查是否支持（默认情况下是支持的) cat /boot/config-2.6.32-431.el6.x86_64 | grep -i CONFIG_BONDINGconfig-XX是内核版本号 出现 CONFIG_BONDING=m说明支持，继续下一步，否则要进行编译内核支持。 备份网卡设置 cd /etc/sysconfig/network-scripts cp ifcfg-eth0 ifcfg-eth0.bak cp ifcfg-eth1 ifcfg-eth1.bak 建立bond0网卡 touch ifcfg-bond0 网卡配置 DEVICE=”bond0”BOOTPROTO=staticNM_CONTROLLED=noONBOOT=yesTYPE=EthernetIPADDR=10.11.189.66NETMASK=255.255.224.0GATEWAY=10.11.189.94IPV6INIT=noUSERCTL=noBONDING_OPTS=”mode=1 miimon=50” 修改eth0/eth1网卡配置 DEVICE=”eth0”BOOTPROTO=noneONBOOT=yesTYPE=EthernetUSERCTL=noMASTER=bond0SLAVE=yes 模块加载配置 echo “alias bond0 bonding” &gt;&gt; /etc/modprobe/dist.conf 网卡顺序设置 echo “ifenslave bond0 eth0 eth1” &gt;&gt; /etc/rc.d/rc.localecho “touch /var/lock/subsys/local” &gt;&gt; /etc/rc.d/rc.local 重启网络服务 service network restart 验证MAC地址是否一致 ifconfig -a | grep HW 运行状态检查 cat /proc/net/bonding/bond0","categories":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/tags/Linux/"}],"keywords":[{"name":"Linux","slug":"Linux","permalink":"https://gowa2017.github.io/categories/Linux/"}]}]}