<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>TensorFlow中的LSTM了解 | 退思园</title><link rel="stylesheet" type="text/css" href="//fonts.loli.net/css?family=Source+Code+Pro"><link rel="stylesheet" type="text/css" href="/css/style.css?v=2.0.3"><link rel="stylesheet" type="text/css" href="/css/highlight.css?v=2.0.3"><link rel="Shortcut Icon" href="/favicon.ico"><link rel="bookmark" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css?v=2.0.3"><script src="https://unpkg.com/gitalk/dist/gitalk.min.js?v=2.0.3"></script><script src="//cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.js?v=2.0.3"></script></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">TensorFlow中的LSTM了解</h1><a id="logo" href="/.">退思园</a><p class="description">烦恼一般都是想太多了。</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div><div id="search-form"><div id="result-mask" class="hide"></div><label><input id="search-key" type="text" autocomplete="off" placeholder="搜索"></label><div id="result-wrap" class="hide"><div id="search-result"></div></div><div class="hide"><template id="search-tpl"><div class="item"><a href="/{path}" title="{title}"><div class="title">{title}</div><div class="time">{date}</div><div class="tags">{tags}</div></a></div></template></div></div></div><div id="layout" class="layout-g"><div class="layout-l"><div class="content_container"><div class="post"><h1 class="post-title">TensorFlow中的LSTM了解</h1><div class="post-meta"><a href="/TensorFlow/TensorFlow中的LSTM了解.html#comments" class="comment-count"><i data-disqus-identifier="TensorFlow/TensorFlow中的LSTM了解.html" class="disqus-comment-count"></i>留言</a><p><span class="date">Nov 26, 2018</span><span><a href="/categories/TensorFlow/" class="category">TensorFlow</a></span><span><i id="busuanzi_container_page_pv"><i id="busuanzi_value_page_pv"></i><i>点击</i></i></span></p></div><div class="post-content"><p>LSTM（长短期记忆）是最常用的 RNN （递归神经网络了）。经常用于序列数据。关于它的详细介绍可以看这个 <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="noopener">权威博客</a>。本文章原文位于：<a href="https://jasdeep06.github.io/posts/Understanding-LSTM-in-Tensorflow-MNIST/" target="_blank" rel="noopener">这里</a></p>
<a id="more"></a>
<h1 id="MNIST-数据集"><a href="#MNIST-数据集" class="headerlink" title="MNIST 数据集"></a>MNIST 数据集</h1><p>MNIST 是一个手写数字识别的数据集。可以用代码来下载使用：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">"/tmp/data/"</span>, one_hot=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure>
<p>数据分割为三个部分：</p>
<ol>
<li><em>mnist.train</em>  55000 个图片数据</li>
<li><em>mnist.test</em> 10000 的测试图片数据。</li>
<li><em>mnist.validation</em>  5000 个有效的图片数据。</li>
</ol>
<h2 id="数据形状"><a href="#数据形状" class="headerlink" title="数据形状"></a>数据形状</h2><p>让我们讨论关于MNIST数据集的训练数据的形状。所有三个部分数据的形状是相同的。</p>
<p>训练数据，55000 张图片，每张图片 28 X 28 pixels。这 784 个像素点放在一个维度是 784 的向量中。所以呢，训练数据的形状就是 <em>(55000,784)</em>，可通过 <em>mnist.train.images</em> 进行引用。</p>
<p> 55000 个训练图片中，每个都有一个对应的标签，表示了图片所数的类（是哪个数字）。这里有 10 个（ 0,1,2….）。类标签以一种热编码形式表示。</p>
<p> 标签在 numpy 数组中的形式为 <em>(55000,10)</em>，通过 <em>mnist.train.lables</em>。</p>
<h1 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h1><p>写代码前先画出一个概要，这有助于我们的代码更直观。</p>
<h2 id="vanilla-RNN"><a href="#vanilla-RNN" class="headerlink" title="vanilla RNN"></a>vanilla RNN</h2><p>把一个 RNN 进行展开的话，就是如下这样：</p>
<p><img src="../res/Unrolled_RNN.png" alt></p>
<p>在这里：</p>
<ol>
<li><script type="math/tex">X_t</script> 引用在 t 时刻的输入。</li>
<li><script type="math/tex">S_t</script> 引用在 t 时刻的隐藏状态。可以把它想象成我们网络的 <strong>记忆</strong>。</li>
<li><script type="math/tex">O_t</script> 引用 t 时刻的输出。</li>
<li><em>U, V, W</em> 表示在所有的时刻中共享的参数。使用同样参数的意义在于，我们的模型在每个时刻做的任务是一样的，只是输入不同。</li>
</ol>
<p>通过把 RNN 展开，我们达到了一个目的：在任何时刻，我们都会考虑前一时刻的输入，所以可以想象它是一个 <strong>前馈网络</strong>（由时刻之间的联系表示）</p>
<h2 id="两个要点"><a href="#两个要点" class="headerlink" title="两个要点"></a>两个要点</h2><p>我们的实施将取决于两个主要概念，这些概念将使我们对实施感到满意：</p>
<ol>
<li>TensorFlow 中对于 LSTM 神经元的解释。</li>
<li>传递数据给 TensorFlow RNN 前把数据格式化。</li>
</ol>
<h2 id="TensorFlow-中的-LSTM-神经元"><a href="#TensorFlow-中的-LSTM-神经元" class="headerlink" title="TensorFlow 中的 LSTM 神经元"></a>TensorFlow 中的 LSTM 神经元</h2><p>我们可以很简单的在 TensorFlow 中声明一个 LSTM 神经元：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">tf.contrib.rnn.BasicLSTMCell(num_units)</span><br></pre></td></tr></table></figure>
<p><em>num_units</em> 代表了 LSTM 神经元中的单元数。<br><em>num_units</em> 可以类比于前馈神经网络的隐藏层。在一个前馈神经网络中隐藏层的节点数<strong>等于</strong>这个网络中每个时刻 LSTM 神经元内 LSTM 中的单元数。下面的图片可能会减少我们的疑惑。</p>
<p><img src="../res/num_units.png" alt></p>
<p>num_units 的任何一个 LSTM 单元可以被看作是一个标准的 LSTM 单元：</p>
<p><img src="../res/lstm_unit.png" alt></p>
<h2 id="格式化输入"><a href="#格式化输入" class="headerlink" title="格式化输入"></a>格式化输入</h2><p>TensorFlow 中最简单的 RNN 就是 <em>static_rnn</em> 了。</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">tf.static_rnn(cell,inputs)</span><br></pre></td></tr></table></figure>
<p>其拥有很多参数，但现在我们只关注这两个。</p>
<p><em>inputs</em> 参数接受一个<strong>张量列表</strong>，形状为 <em>(batch_size, input_size)</em> 。列表的长度，就是这个网络展开的时刻数。就是说，在我们的网络中，一个输入就对应了一个时刻。</p>
<p>就我们的 MNIST 图片数据而言，我们的图片大小是 28 X 28。可以把图片看成是 28 行，每行有 28 pixels。我们会把我们的网络展开成 28 个时刻，这样，每个时刻我们就可以输入一行数据了（28 pixels, input_size，输入张量的维度），一个图片就会走完 28 个时刻。 如果我们提供了 <em>batch_size</em> 个图片数据，每个时刻都会提供 <em>batch_size</em> 条数据。下面的图片看得更清楚：</p>
<p><img src="../res/inputs.png" alt></p>
<p><em>static_rnn</em> 的输入是一个张量列表，形状 <em>(batch_size, num_units)</em>。列表的长度，就是网络展开的长度。在此实现中，我们将仅关注最终时间步的输出，因为当将图像的所有行提供给RNN时将生成预测结果，也就是最后一个时刻。</p>
<p>现在我们已经完成了所有繁重的工作，我们已经准备好编写代码。一旦上述概念清楚，编码部分就非常直接了。</p>
<h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><p>开始，让我们导入必要的依赖项，数据集并声明一些常量。我们将使用batch_size = 128 和 num_units = 128。</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.contrib <span class="keyword">import</span> rnn</span><br><span class="line"></span><br><span class="line"><span class="comment">#import mnist dataset</span></span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line">mnist=input_data.read_data_sets(<span class="string">"/tmp/data/"</span>,one_hot=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#define constants</span></span><br><span class="line"><span class="comment">#unrolled through 28 time steps</span></span><br><span class="line">time_steps=<span class="number">28</span></span><br><span class="line"><span class="comment">#hidden LSTM units</span></span><br><span class="line">num_units=<span class="number">128</span></span><br><span class="line"><span class="comment">#rows of 28 pixels</span></span><br><span class="line">n_input=<span class="number">28</span></span><br><span class="line"><span class="comment">#learning rate for adam</span></span><br><span class="line">learning_rate=<span class="number">0.001</span></span><br><span class="line"><span class="comment">#mnist is meant to be classified in 10 classes(0-9).</span></span><br><span class="line">n_classes=<span class="number">10</span></span><br><span class="line"><span class="comment">#size of batch</span></span><br><span class="line">batch_size=<span class="number">128</span></span><br></pre></td></tr></table></figure>
<p>现在让我们声明占位符和权重以及偏差变量，这些变量将用于将shape [batch_size，num_units]的输出转换为[batch_size，n_classes]，以便可以预测正确的类。</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">#weights and biases of appropriate shape to accomplish above task</span></span><br><span class="line">out_weights=tf.Variable(tf.random_normal([num_units,n_classes]))</span><br><span class="line">out_bias=tf.Variable(tf.random_normal([n_classes]))</span><br><span class="line"></span><br><span class="line"><span class="comment">#defining placeholders</span></span><br><span class="line"><span class="comment">#input image placeholder</span></span><br><span class="line"><span class="comment"># [None, time_steps, n_input] 代表了 批量数，网络展开时刻数，每个时刻输入数据的大小</span></span><br><span class="line">x=tf.placeholder(<span class="string">"float"</span>,[<span class="keyword">None</span>,time_steps,n_input])</span><br><span class="line"><span class="comment">#input label placeholder</span></span><br><span class="line">y=tf.placeholder(<span class="string">"float"</span>,[<span class="keyword">None</span>,n_classes])</span><br></pre></td></tr></table></figure>
<p>现在我们正在接收 shape [batch_size，time_steps，n_input] 的输入，我们需要将其转换为长度为 time_steps 的shape [batch_size，n_inputs]的张量列表，以便可以将其输入static_rnn。</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">#processing the input tensor from [batch_size,n_steps,n_input] to "time_steps" number of [batch_size,n_input] tensors</span></span><br><span class="line"><span class="comment"># 将 [batch_size,n_steps,n_input] 沿 time_steps 展开后，结果就是 [batch_size,n_input] 列表，大小是 time_steps。列表中每个元素都会被每个时刻当做输入。</span></span><br><span class="line">input=tf.unstack(x ,time_steps,<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>现在我们已经准备好定义我们的网络。我们将使用一层BasicLSTMCell并使用我们的static_rnn网络。</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">#defining the network</span></span><br><span class="line">lstm_layer=rnn.BasicLSTMCell(num_units,forget_bias=<span class="number">1</span>)</span><br><span class="line">outputs,_=rnn.static_rnn(lstm_layer,input,dtype=<span class="string">"float32"</span>)</span><br></pre></td></tr></table></figure>
<p>由于我们只考虑上一次时间步的输入，我们将从中生成我们的预测:</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">#converting last output of dimension [batch_size,num_units] to [batch_size,n_classes] by out_weight multiplication</span></span><br><span class="line">prediction=tf.matmul(outputs[<span class="number">-1</span>],out_weights)+out_bias</span><br></pre></td></tr></table></figure>
<p>定义损失，优化器和准确性。</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">#loss_function</span></span><br><span class="line">loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction,labels=y))</span><br><span class="line"><span class="comment">#optimization</span></span><br><span class="line">opt=tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)</span><br><span class="line"></span><br><span class="line"><span class="comment">#model evaluation</span></span><br><span class="line">correct_prediction=tf.equal(tf.argmax(prediction,<span class="number">1</span>),tf.argmax(y,<span class="number">1</span>))</span><br><span class="line">accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))</span><br></pre></td></tr></table></figure>
<p>现在我们已经定义了图表，我们可以运行它。</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">#initialize variables</span></span><br><span class="line">init=tf.global_variables_initializer()</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    iter=<span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> iter&lt;<span class="number">800</span>:</span><br><span class="line">        batch_x,batch_y=mnist.train.next_batch(batch_size=batch_size)</span><br><span class="line"></span><br><span class="line">        batch_x=batch_x.reshape((batch_size,time_steps,n_input))</span><br><span class="line"></span><br><span class="line">        sess.run(opt, feed_dict=&#123;x: batch_x, y: batch_y&#125;)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> iter %<span class="number">10</span>==<span class="number">0</span>:</span><br><span class="line">            acc=sess.run(accuracy,feed_dict=&#123;x:batch_x,y:batch_y&#125;)</span><br><span class="line">            los=sess.run(loss,feed_dict=&#123;x:batch_x,y:batch_y&#125;)</span><br><span class="line">            print(<span class="string">"For iter "</span>,iter)</span><br><span class="line">            print(<span class="string">"Accuracy "</span>,acc)</span><br><span class="line">            print(<span class="string">"Loss "</span>,los)</span><br><span class="line">            print(<span class="string">"__________________"</span>)</span><br><span class="line"></span><br><span class="line">        iter=iter+<span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>这里需要注意的一件重要事情是，我们的图像基本上被展平为一个维度784的矢量。函数next_batch（batch_size）必然返回这些784维向量的batch_size批量。因此，它们被重新整形为[batch_size，time_steps，n_input]，以便我们的占位符可以接受它们。</p>
<p>我们还可以计算出我们模型的测试精度 - </p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">#calculating test accuracy</span></span><br><span class="line">test_data = mnist.test.images[:<span class="number">128</span>].reshape((<span class="number">-1</span>, time_steps, n_input))</span><br><span class="line">test_label = mnist.test.labels[:<span class="number">128</span>]</span><br><span class="line">print(<span class="string">"Testing Accuracy:"</span>, sess.run(accuracy, feed_dict=&#123;x: test_data, y: test_label&#125;))</span><br></pre></td></tr></table></figure>
<p>在运行时，模型运行的测试精度为99.21％。</p>
</div><div class="post-copyright"><blockquote><p>原文作者: Gowa2017 Zhang</p><p>原文链接: <a href="https://gowa2017.github.io/TensorFlow/TensorFlow中的LSTM了解.html">https://gowa2017.github.io/TensorFlow/TensorFlow中的LSTM了解.html</a></p><p>版权声明: 转载请注明出处(必须保留作者署名及链接)</p></blockquote></div><div class="tags"><a href="/tags/TensorFlow/">TensorFlow</a></div><div class="post-share"><div class="social-share"><span>分享到:</span></div></div><div class="post-nav"><a href="/Java/Poi中添加Anchor图片到Docx文档.html" class="pre">Poi中添加Anchor图片到Docx文档</a><a href="/Java/Dagger与安卓.html" class="next">Dagger与安卓</a></div><div id="comments"><div id="disqus_thread"></div></div></div></div></div><div class="layout-r"><div id="sidebar"><div class="search-pla"></div><div id="toc" class="widget"><div class="widget-title"><i class="fa fa-fei">文章目录</i></div><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#MNIST-数据集"><span class="toc-text">MNIST 数据集</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#数据形状"><span class="toc-text">数据形状</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#实现"><span class="toc-text">实现</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#vanilla-RNN"><span class="toc-text">vanilla RNN</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#两个要点"><span class="toc-text">两个要点</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#TensorFlow-中的-LSTM-神经元"><span class="toc-text">TensorFlow 中的 LSTM 神经元</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#格式化输入"><span class="toc-text">格式化输入</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#代码"><span class="toc-text">代码</span></a></li></ol></div><div class="widget"><div class="widget-title"><i class="fa fa-xie"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/Python/关于Python做数据库同步的一些库及使用.html">关于Python做数据库同步的一些库及使用</a></li><li class="post-list-item"><a class="post-list-link" href="/Java/IdeaVim的的一些使用.html">IdeaVim的的一些使用</a></li><li class="post-list-item"><a class="post-list-link" href="/Android/Gson常规使用-fromJson().html">Gson常规使用-fromJson()</a></li><li class="post-list-item"><a class="post-list-link" href="/Android/RecyclerView的converView与viewHolder.html">RecyclerView的converView与viewHolder</a></li><li class="post-list-item"><a class="post-list-link" href="/Android/Android-View的绘制过程.html">Android-View的绘制过程</a></li><li class="post-list-item"><a class="post-list-link" href="/Linux/了解locale环境变量.html">了解locale环境变量</a></li><li class="post-list-item"><a class="post-list-link" href="/Android/Retrofit对象的建立及与RxJava的使用.html">Retrofit对象的建立及与RxJava的使用</a></li><li class="post-list-item"><a class="post-list-link" href="/Java/RxJava的一些基本概念及文档.html">RxJava的一些基本概念及文档</a></li><li class="post-list-item"><a class="post-list-link" href="/Android/View的绘制过程.html">View的绘制过程</a></li><li class="post-list-item"><a class="post-list-link" href="/Java/Tomcat服务器架构.html">Tomcat服务器架构</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-gui"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/AIX/">AIX</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Android/">Android</a><span class="category-list-count">34</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Cocos-Creator/">Cocos Creator</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Cocos2d-X/">Cocos2d-X</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Device/">Device</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/GTD/">GTD</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Git/">Git</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Golang/">Golang</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Java/">Java</a><span class="category-list-count">38</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/JavaScript/">JavaScript</a><span class="category-list-count">10</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Kindle/">Kindle</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a><span class="category-list-count">25</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Lua/">Lua</a><span class="category-list-count">15</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/MySQL/">MySQL</a><span class="category-list-count">15</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Network/">Network</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Novel/">Novel</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Office/">Office</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Oracle/">Oracle</a><span class="category-list-count">9</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/SED-AWK/">SED&AWK</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Shell/">Shell</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/TensorFlow/">TensorFlow</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Vim/">Vim</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Work/">Work</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/macOS/">macOS</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/杂项/">杂项</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/编程/">编程</a><span class="category-list-count">4</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-biao"> 标签</i></div><div class="tagcloud"><a href="/tags/内存管理/" style="font-size: 15px;">内存管理</a> <a href="/tags/curl/" style="font-size: 15px;">curl</a> <a href="/tags/装修/" style="font-size: 15px;">装修</a> <a href="/tags/brew/" style="font-size: 15px;">brew</a> <a href="/tags/Java/" style="font-size: 15px;">Java</a> <a href="/tags/Word/" style="font-size: 15px;">Word</a> <a href="/tags/Office/" style="font-size: 15px;">Office</a> <a href="/tags/弯头/" style="font-size: 15px;">弯头</a> <a href="/tags/管件/" style="font-size: 15px;">管件</a> <a href="/tags/水管/" style="font-size: 15px;">水管</a> <a href="/tags/sed/" style="font-size: 15px;">sed</a> <a href="/tags/Golang/" style="font-size: 15px;">Golang</a> <a href="/tags/编程/" style="font-size: 15px;">编程</a> <a href="/tags/Lua/" style="font-size: 15px;">Lua</a> <a href="/tags/Cocos2d-X/" style="font-size: 15px;">Cocos2d-X</a> <a href="/tags/MySQL/" style="font-size: 15px;">MySQL</a> <a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/LVM/" style="font-size: 15px;">LVM</a> <a href="/tags/Android/" style="font-size: 15px;">Android</a> <a href="/tags/java/" style="font-size: 15px;">java</a> <a href="/tags/android-studio/" style="font-size: 15px;">android studio</a> <a href="/tags/svn/" style="font-size: 15px;">svn</a> <a href="/tags/android/" style="font-size: 15px;">android</a> <a href="/tags/word/" style="font-size: 15px;">word</a> <a href="/tags/REST/" style="font-size: 15px;">REST</a> <a href="/tags/Maven/" style="font-size: 15px;">Maven</a> <a href="/tags/VNC/" style="font-size: 15px;">VNC</a> <a href="/tags/Docx/" style="font-size: 15px;">Docx</a> <a href="/tags/SSH/" style="font-size: 15px;">SSH</a> <a href="/tags/X5/" style="font-size: 15px;">X5</a> <a href="/tags/Tbs/" style="font-size: 15px;">Tbs</a> <a href="/tags/Cocos-Creator/" style="font-size: 15px;">Cocos Creator</a> <a href="/tags/Cocos-Js/" style="font-size: 15px;">Cocos-Js</a> <a href="/tags/Cocos-Creator/" style="font-size: 15px;">Cocos-Creator</a> <a href="/tags/TensorFlow/" style="font-size: 15px;">TensorFlow</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/机器学习/" style="font-size: 15px;">机器学习</a> <a href="/tags/ML/" style="font-size: 15px;">ML</a> <a href="/tags/Git/" style="font-size: 15px;">Git</a> <a href="/tags/杂项/" style="font-size: 15px;">杂项</a> <a href="/tags/Oracle/" style="font-size: 15px;">Oracle</a> <a href="/tags/macOS/" style="font-size: 15px;">macOS</a> <a href="/tags/Sqlplus/" style="font-size: 15px;">Sqlplus</a> <a href="/tags/Application/" style="font-size: 15px;">Application</a> <a href="/tags/php/" style="font-size: 15px;">php</a> <a href="/tags/apache/" style="font-size: 15px;">apache</a> <a href="/tags/Dagger/" style="font-size: 15px;">Dagger</a> <a href="/tags/Network/" style="font-size: 15px;">Network</a> <a href="/tags/PAC/" style="font-size: 15px;">PAC</a> <a href="/tags/SQL/" style="font-size: 15px;">SQL</a> <a href="/tags/NFS/" style="font-size: 15px;">NFS</a> <a href="/tags/SVN/" style="font-size: 15px;">SVN</a> <a href="/tags/JavaScript/" style="font-size: 15px;">JavaScript</a> <a href="/tags/Promise/" style="font-size: 15px;">Promise</a> <a href="/tags/Pomelo/" style="font-size: 15px;">Pomelo</a> <a href="/tags/Retrofit/" style="font-size: 15px;">Retrofit</a> <a href="/tags/The-Java-Tutorial/" style="font-size: 15px;">The Java Tutorial</a> <a href="/tags/Closure/" style="font-size: 15px;">Closure</a> <a href="/tags/skynet/" style="font-size: 15px;">skynet</a> <a href="/tags/epoll/" style="font-size: 15px;">epoll</a> <a href="/tags/select/" style="font-size: 15px;">select</a> <a href="/tags/poll/" style="font-size: 15px;">poll</a> <a href="/tags/rsync/" style="font-size: 15px;">rsync</a> <a href="/tags/Gradle/" style="font-size: 15px;">Gradle</a> <a href="/tags/Vue/" style="font-size: 15px;">Vue</a> <a href="/tags/GTD/" style="font-size: 15px;">GTD</a> <a href="/tags/Shell/" style="font-size: 15px;">Shell</a> <a href="/tags/Bash/" style="font-size: 15px;">Bash</a> <a href="/tags/Selector/" style="font-size: 15px;">Selector</a> <a href="/tags/CPU/" style="font-size: 15px;">CPU</a> <a href="/tags/8086/" style="font-size: 15px;">8086</a> <a href="/tags/Vim/" style="font-size: 15px;">Vim</a> <a href="/tags/Work/" style="font-size: 15px;">Work</a> <a href="/tags/AAA/" style="font-size: 15px;">AAA</a> <a href="/tags/AIX/" style="font-size: 15px;">AIX</a> <a href="/tags/IPSec/" style="font-size: 15px;">IPSec</a> <a href="/tags/加固/" style="font-size: 15px;">加固</a> <a href="/tags/RegEx/" style="font-size: 15px;">RegEx</a> <a href="/tags/正则表达式/" style="font-size: 15px;">正则表达式</a> <a href="/tags/POSIX/" style="font-size: 15px;">POSIX</a> <a href="/tags/Kindle/" style="font-size: 15px;">Kindle</a> <a href="/tags/小说/" style="font-size: 15px;">小说</a> <a href="/tags/F5/" style="font-size: 15px;">F5</a> <a href="/tags/负载均衡/" style="font-size: 15px;">负载均衡</a> <a href="/tags/FTP/" style="font-size: 15px;">FTP</a> <a href="/tags/awk/" style="font-size: 15px;">awk</a> <a href="/tags/iptables/" style="font-size: 15px;">iptables</a> <a href="/tags/越狱/" style="font-size: 15px;">越狱</a> <a href="/tags/阅读/" style="font-size: 15px;">阅读</a> <a href="/tags/Cron/" style="font-size: 15px;">Cron</a> <a href="/tags/Unix/" style="font-size: 15px;">Unix</a> <a href="/tags/Go/" style="font-size: 15px;">Go</a> <a href="/tags/网络/" style="font-size: 15px;">网络</a> <a href="/tags/OSPF/" style="font-size: 15px;">OSPF</a> <a href="/tags/OpenSSH/" style="font-size: 15px;">OpenSSH</a> <a href="/tags/OpenSSL/" style="font-size: 15px;">OpenSSL</a> <a href="/tags/数据库/" style="font-size: 15px;">数据库</a> <a href="/tags/Oralce/" style="font-size: 15px;">Oralce</a> <a href="/tags/视图/" style="font-size: 15px;">视图</a> <a href="/tags/Device/" style="font-size: 15px;">Device</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-archive"> 归档</i></div><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/04/">四月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">三月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/02/">二月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">一月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">十二月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">十一月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/10/">十月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">九月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">八月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">七月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/06/">六月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">五月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">四月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">三月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/02/">二月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">一月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">十二月 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">十一月 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/01/">一月 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/12/">十二月 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/11/">十一月 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/10/">十月 2016</a></li></ul></div></div></div></div><a id="totop" href="#top"></a><div id="footer"><div class="footer-info"><p><a href="/baidusitemap.xml">网站地图</a> |  <a href="/atom.xml">订阅本站</a> |  <a href="/about/">联系博主</a></p><p>本站总访问量：<i id="busuanzi_container_site_pv"><i id="busuanzi_value_site_pv"></i></i>次，本站总访客数:<i id="busuanzi_container_site_uv"><i id="busuanzi_value_site_uv"></i></i>人</p><p><span> Copyright &copy;<a href="/." rel="nofollow">Gowa2017 Zhang.</a></span><span> Theme by<a rel="nofollow" target="_blank" href="https://github.com/chaooo/hexo-theme-BlueLake"> BlueLake.</a></span><span> Count by<a href="http://busuanzi.ibruce.info/"> busuanzi.</a></span><span> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a></span></p></div></div></div><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','UA-137245514-1','auto');ga('send','pageview');
</script><script type="text/javascript" src="/js/search.json.js?v=2.0.3"></script><<<<<<< Updated upstream<script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  }
});</script><script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML" async></script><script type="text/javascript" src="/js/toctotop.js?v=2.0.3" async></script><link rel="stylesheet" type="text/css" href="/share/css/share.css"><script type="text/javascript" src="/share/js/social-share.js" charset="utf-8"></script><script type="text/javascript" src="/share/js/qrcode.js" charset="utf-8"></script><script>var disqus_shortname = 'gowa-1';
var disqus_identifier = 'TensorFlow/TensorFlow中的LSTM了解.html';
var disqus_title = 'TensorFlow中的LSTM了解';
var disqus_url = 'https://gowa2017.github.io/TensorFlow/TensorFlow中的LSTM了解.html';
(function() {
  var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();</script><script id="dsq-count-scr" src="//gowa-1.disqus.com/count.js" async></script><script type="text/javascript" src="//gowa-1.disqus.com/recent_comments_widget.js?num_items=5&amp;hide_avatars=1&amp;avatar_size=32&amp;excerpt_length=20&amp;hide_mods=1"></script></body></html>